 
 
 

Oscar Nierstrasz and Dennis Tsichritzis, 
Software Composition

, Prentice Hall, 1995. 

Object-Oriented 

Reproduced with the permission of the Publisher, Prentice Hall (a 
Pearson Education company).  This work is protected by 
copyright and may not be reproduced other than when 
downloaded and viewed on a single Central Processor Unit 
(CPU) for private use only.  It is not otherwise to be reproduced or 
transmitted or made available on a network without prior written 
permission of Prentice Hall.  All other rights reserved.

 

 

 

 

 

 
 

 

 
 

 

 

 

 
 

 

Object-
Oriented
Software

Composition

E

DITED BY

Oscar Nierstrasz
U

NIVERSITY OF 

B

ERNE

AND

Dennis Tsichritzis

U

NIVERSITY OF 

G

ENEVA

 

 

 

First published 1995 by 

Prentice Hall International (UK) Ltd

Campus 400, Maylands Avenue

Hemel Hempstead

Hertfordshire, HP2 7EZ

A division of

Simon & Schuster International Group 

© Prentice Hall 1995 

All rights reserved. No part of this publication may be reproduced, 
stored in a retrieval system, or transmitted, in any form, or by any 

means, electronic, mechanical, photocopying, recording or otherwise,

without prior permission, in writing, from the publisher. 

For permission within the United States of America 
contact Prentice Hall Inc., Englewood Cliffs, NJ 07632

Printed and bound in Great Britain by

T.J. Press (Padstow) Ltd, Padstow, Cornwall. 

Library of Congress Cataloging-in-Publication Data 

Object-oriented software composition / edited by Oscar Nierstrasz and

Dennis Tsichritzis. 

p. cm.—(The Object-oriented series)

Includes bibliographical references and index. 
ISBN 0-13-220674-9 
1. Object-oriented programming (Computer science) I. Nierstrasz Oscar Marius, 1957-      .

II. Tsichritzis, Dionysios C. III. Series: Prentice-Hall object-oriented series.
QA76.64.0277 1995 
005.1'1—dc20
CIP

95-7616 

British Library Cataloguing in Publication Data

A catalogue record for this book is available from

the British Library

ISBN: 0-13-220674-9

 

 

 

 

 

 

 

 

 

 

 

Contents

Contributors 

Foreword 
Akinori Yonezawa

Preface 
Oscar Nierstrasz and Dennis Tsichritzis

PART I  Introduction 

1 Component-Oriented Software Technology

Oscar Nierstrasz and Laurent Dami
1.1
1.2
1.3
1.4
1.5

Introduction 
Objects vs. Components 
Technical Support for Components 
Component Engineering 
Conclusions 

PART II  Concurrency and Distribution 

2 Concurrency in Object-Oriented Programming Languages

Michael Papathomas
Introduction 
2.1
Design Space 
2.2
2.3
Criteria for Evaluating Language Design Choices 
Exploring the Language Design Space 
2.4
2.5
Conclusion 

 ix

 xi

 xiii

 1

 3

 3
 7
 9
 20
 24

  29

 31

 31
 33
 43
 49
 63

 
 

 

 

 

 

 

 

 

 

vi

3

Interoperation of Object-Oriented Applications
Dimitri Konstantas
3.1
3.2
3.3
3.4
3.5
3.6
3.7
3.8

Reusing Objects from Different Environments 
Procedure-Oriented Interoperability 
Object-Oriented Interoperability 
Comparison of Interoperability Support Approaches 
Interface Bridging — Object-Oriented Interoperability 
Interface Adaption 
Object Mapping 
Conclusions and Research Directions 

PART III  Specification and Composition 

4 Regular Types for Active Objects

Oscar Nierstrasz
4.1
4.2
4.3
4.4
4.5
4.6
4.7
4.8
4.9

Introduction 
Types, Substitutability and Active Objects 
Intersecting Service Types 
Request Substitutability 
Viewing Objects as Regular Processes 
Subtyping Regular Types 
Request Satisfiability 
Open Problems 
Concluding Remarks 

5 A Temporal Perspective of Composite Objects

Constantin Arapis
5.1
5.2
5.3
5.4
5.5

Introduction 
Propositional Temporal Logic 
The Specification of Temporal Properties 
Verification 
Concluding Remarks 

Contents

 69

 69
 71
 73
 75
 76
 81
 87
 90

 97

 99

 99
 101
 103
 105
 108
 110
 113
 117
 119

 123

 123
 126
 132
 144
 150

 
 

 

 

 

 

 

 

 

 

 

 

 

 

λ
6 Functions, Records and Compatibility in the 
N Calculus

Laurent Dami
6.1
6.2
6.3
6.4
6.5

Introduction 
A Lambda Calculus with Named Parameters 
The Calculus at Work 
Compatibility Relationship 
Conclusion 

PART IV  Software Information Management 

7 Component Classification in the Software Information Base

Panos Constantopoulos and Martin Dörr
7.1
7.2
7.3
7.4
7.5
7.6
7.7

Introduction 
The Software Information Base 
Information Retrieval and User Interface 
The Classification Scheme 
Streamlining the Classification Process 
Experiences 
Conclusion 

8 Managing Class Evolution in Object-Oriented Systems

Eduardo Casais
8.1
8.2
8.3
8.4
8.5
8.6
8.7
8.8
8.9

Object Design and Redesign 
Class Tailoring 
Class Surgery 
Class Versioning 
Class Reorganization 
Change Avoidance 
Conversion 
Filtering 
Conclusion 

9 The Affinity Browser

Xavier Pintado
9.1
9.2
9.3
9.4
9.5

Introduction 
Browsing Requirements 
The Affinity Browser 
The Affinity Browser by Example 
Conclusion 

vii

 153

 153
 156
 162
 167
 172

 175

 177

 177
 179
 183
 186
 191
 192
 197

 201

 201
 203
 206
 212
 218
 230
 233
 236
 240

 245

 245
 251
 252
 259
 270

 
 

 

 

 

 

 

 

 

 

 

viii

Contents

PART V  Frameworks and Applications 

10 Visual Composition of Software Applications

Introduction 

Vicki de Mey
10.1
10.2 Related Work 
10.3 A Framework for Visual Composition 
10.4 Vista — A Prototype Visual Composition Tool 
10.5
10.6 Discussion 
10.7 Conclusion 

Sample Applications 

11 Multimedia Component Frameworks

Simon Gibbs
11.1 Digital Media and Multimedia 
11.2 Multimedia Systems and Multimedia Programming 
11.3 Multimedia Frameworks 
11.4 A Multimedia Framework Example — Components 
11.5 Video Widgets — A Programming Example 
11.6

Summary 

12 Gluons and the Cooperation between Software Components

Introduction 

Xavier Pintado
12.1
12.2 An Overview of Cooperation Patterns 
12.3 Requirements for a Financial Framework 
12.4 Gluons 
12.5 Gluons and the Financial Framework 
12.6 Conclusion 

Index 

 273

 275

 275
 276
 278
 287
 290
 297
 300

 305

 305
 306
 308
 309
 313
 317

 321

 321
 324
 333
 338
 341
 347

 351

 

 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

Contributors

*

Dr. Costas Arapis
GERMANY. 

E-mail: 

arapis@viswiz.gmd.de

, GMD, Abtl. VMSD, Schloß Birlinghoven, D-53757 Sankt Augustin, 

Dr. Eduardo Casais
D-76131 Karlsruhe, GERMANY. 

E-mail:

 casais@fzi.de

, Forschungszentrum Informatik (FZI), Haid-und-Neu-Straße 10-14,

Prof. Panos Constantopoulos
, Institute of Computer Science, Foundation for Research 
and Technology — Hellas, Science and Technology Park of Crete, Vassilika Vouton, P.O. 
Box 1385, GR-71110 Heraklion, Crete, GREECE. 

 panos@ ics.forth.gr

E-mail:

Dr. Laurent Dami
24, rue Général-Dufour, CH-1211 Genève 4, SWITZERLAND.
E-mail:

 dami@cui.unige.ch

, Centre Universitaire d’Informatique, Université de Genève, 

Dr. Vicki de Mey
CA 95014, UNITED STATES. 

E-mail

: vicki@apple.com

, Apple Computer, Inc., One Inﬁnite Loop, MS 301-4I, Cupertino,

, Institute of Computer Science, Foundation for Research and Technology 

Dr. Martin Dörr
— Hellas, Science and Technology Park of Crete, Vassilika Vouton, P.O. Box 1385,
GR-71110 Heraklion, Crete, GREECE. 

 doerr@ ics.forth.gr

E-mail:

Dr. Simon Gibbs
E-mail

: Simon.Gibbs@gmd.de

, GMD, Schloß Birlinghoven, D-53757 Sankt Augustin, GERMANY.

Dr. Dimitri Konstantas
24, rue Général-Dufour, CH-1211 Genève 4, SWITZERLAND. 
E-mail

: dimitri@cui.unige.ch

, Centre Universitaire d’Informatique, Université de Genève,

Prof. Oscar Nierstrasz
3012 Bern, SWITZERLAND. 

E-mail

: oscar@iam.unibe.ch

, Institut für Informatik (IAM), Universität Bern, Neubrückstrasse 10, CH-

Dr. Michael Papathomas
Lancaster LA1 4YR, UNITED KINGDOM.
E-mail

: michael@computing.lancaster.ac.uk

, Lancaster University, Computing Department,

Dr. Xavier Pintado
24, rue Général-Dufour, CH-1211 Genève 4, SWITZERLAND.
E-mail: 

pintado@cui.unige.ch

, Centre Universitaire d’Informatique, Université de Genève,

Prof. Dennis Tsichritzis
E-mail

: dt@castle.gmd.de

, GMD, Schloß Birlinghoven, D-53757 Sankt Augustin, GERMANY.

Up-to-date information concerning the authors is also available on the World Wide Web 
at: http://www.iam.unibe.ch/~oscar/OOSC/

*. Many of these coordinates have long become obsolete. Please contact oscar.nierstrasz@acm.org if you 
require help in contacting any of the authors.

 

x

Contributors

 

 

 

 

 

Foreword

Perhaps, “Going Beyond Objects” should be the subtitle of this volume, as a large portion
of the contents departs from the early and popularly perceived image of “Objects.”

The object-oriented programming paradigm has now been ﬁrmly accepted in the soft-
ware community as offering the most powerful and promising technology for software de-
velopment currently available, and its expressiveness and modelling power have been
much appreciated. But, one of the greatest promises it made in its early stage was a dra-
matic improvement in the ease of software composition and reuse, which is yet to be
achieved. (People are sometimes entangled with webs of class hierarchies.) And the re-
search continues.

About ten years ago, Dennis and Oscar, moving from Toronto, founded the Object Sys-
tems Group at the University of Geneva, and started a number of research projects to ex-
tend the object-oriented paradigm in various ways. It did not take more than a couple of
years for the group to become the most active and visible research centre of object-orient-
ed technology in Europe. In the mean time, part of the group became involved in a large
ESPRIT project called ITHACA which aimed at producing an application development
environment based object-oriented technology. This volume presents, in a written form,
the fruits of the group’s ten-year research and development, as directed by Dennis’ clear
philosophy on research and innovation. The group attacked real problems and problems
ﬁrmly based on reality. Dennis’ early career as a recursive function theorist, taught by
Alonzo Church in Princeton, also encouraged foundational work in the group, and some
chapters in this volume represent it.

“Beyond Objects” was the title of the panel discussion at the European Conference on
Object-Oriented Programming (ECOOP’91), which was organized by Oscar Nierstrasz
and Dennis Tsichritzis in Geneva in July, 1991. They already had clear visions of where
we/they should go from the “Objects” that only partially fulﬁl the early promise. One of
their visions was the “Component-Based” approach for software construction. Future
software construction for ﬂexible open application should be performed by composition
and  conﬁguration  of  plug-compatible  software  components  that  generalize  objects,
agents and functions. Oscar and Laurent explain this approach in the ﬁrst chapter of this
volume.

Now in the mid 90’s, advanced researchers are struggling to go beyond “Objects” in
search for better software development approaches. Intelligent Agents, Coordination Lan-
guages, Integration of Constraints and Objects, Component-Based Development ... The
contributions in this volume offer valuable clues and suggestions to those who wish go be-
yond “Objects.”

University of Tokyo, January 1995

Akinori Yonezawa

Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

 

xii

Foreword

 

 

 

 

 

 

 

 
 

Preface

Object-oriented technology has been with us since the mid 1960s, but has begun to have a
signiﬁcant  industrial  impact  only  since  the  mid  1980s. There  are  both  good  and  bad
reasons for adopting the technology, and even the success stories suggest that it is not so
easy to introduce object-oriented techniques where they were not practised before. Some
of the questionable reasons for “going OO” are:

• “Object-oriented programming is a better kind of structured programming” — per-
haps, but structured programming methods won’t help you very much in developing
object-oriented  applications.  Object-oriented  programming  is  not  just  structured
programming wearing a new hat.

• “We’ll be able to build applications more quickly because objects are reusable” —
there can be a huge gap between software written in an object-oriented language and
a truly reusable framework of object classes. Frameworks are hard to develop, and
not always easy to use.

• “It will be easier to sell our products if we can tell our customers that they are object-
oriented” — the cost and risk of adopting object-oriented technology can be very
high, and should not be taken lightly.

Still, there are good reasons for adopting object-oriented technology: so far it appears
to offer the best means to cope with complexity and variation in large systems. When fam-
ilies of similar systems must be built, or single systems must undergo frequent changes in
requirements, object-oriented languages, tools and methods offer the means to view such
systems as ﬂexible compositions of software components. It may still require a great deal
of skill to build ﬂexible systems that can meet many different needs, but at least object-ori-
ented technology simpliﬁes the task.

Object-Oriented Software Composition

composing

 ﬂexible software applications from software 

 adopts the viewpoint that object-oriented tech-
nology is essentially about 
com-
. Although object-oriented languages, tools and methods have come a long way
ponents
since the birth of object-oriented programming, the technology is not yet mature. This
book presents the results of a series of research projects related to object-oriented software
composition that were carried out within the Object Systems Group at the University of
Geneva, or by partners in collaborative research projects, during a period of about ten
years. As such, this book is an attempt to synthesize and juxtapose ideas that were devel-
oped by a group of people working closely together over several years.

Although many different topics are treated, by presenting them together, we intend to
show how certain ideas and principles are closely related to software composition, wheth-
er one considers programming language design, formal speciﬁcation, tools and environ-

Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

 
 

 

 

 

 

 

 

 

 

 

 
 

 
 

 

 

 

 

 

 

 

xiv

Preface

plug compatibility

ments,  or  application  development.  Common  threads  running  throughout  the  book
 as a way of formalizing valid ways of composing components,
include 
 as a
active objects
necessary aspect of plug-compatibility for active objects, 
higher-order functional compo-
 of objects and object frame-
sition
works as an essential aspect to capture in the software lifecycle.

 as being fundamental to the development of open systems, 

 as complementary to object composition, and 

protocols

evolution

This book should appeal to researchers and practitioners familiar with object-oriented
technology, who are interested in research trends related to software composition. Al-
though this book was not designed as a textbook, it would be suitable for an advanced sem-
inar on object-oriented research. Individual chapters can be read independently. The order
of presentation has been selected mainly to illustrate a progression of ideas from program-
ming language design issues to environments and applications. Not only is the “Geneva
view” of object-oriented development presented, but considerable effort has gone into
placing the work in context, and several of the chapters contain extensive surveys of relat-
ed work.

The Object Systems Group was founded by Dennis Tsichritzis in 1985, after he had
spent several years directing research in the area of Ofﬁce Information Systems. At the
time, it became clear that (1) object-oriented modelling was essential to modelling ofﬁce
systems, but these models were not yet well developed, and (2) prototypes of advanced of-
ﬁce tools would be easier to develop using object-oriented tools and techniques, but the
technology was not available. These two observations led us to conclude that, since object-
orientation was a critical factor for the construction of advanced and complex applica-
tions, we should concentrate on developing this technology rather than carrying on re-
search in ofﬁce systems with inadequate tools and methodological support.

The ﬁrst chapter of this book summarizes the relationship between object-oriented
approaches  and  component-oriented  development,  and  surveys  the  principal  research
problems in the design of programming languages, tools, environments and methods to
support compositional development.The distinction between objects and components is
discussed in detail, and the impact of compositional development on software lifecycles is
introduced. An important theme that runs through this book is the notion that the role of a
as a person who is responsible for deﬁning component frame-
component engineer — 
works — must be explicitly represented in the software lifecycle. Although this book
focuses on technological issues, there is a progression of concerns from programming lan-
guages and systems towards tools, frameworks and methods.

The ﬁrst two research projects of the group focused on programming language issues.
 was an early attempt to integrate classes and inheritance with other, “orthogonal”
Hybrid
features such as strong-typing, concurrency and persistence. 
 were active objects that
could migrate from computer to computer within a local area network, and dynamically
change their behaviour according to rules triggered by internal conditions or the state of a
communications blackboard. 
 bear close comparison to what are now known as “in-
telligent agents.” The work on 
 ultimately led to more detailed investigations by
Michael Papathomas into the relationship between concurrency and reuse (chapter 2), and
by Dimitri Konstantas into distribution support for ﬂexible open systems (chapter 3). The

Hybrid

Knos

Knos

 
 

 

 

xv

Knos

 led to fundamental work by Eduardo Casais into more disciplined forms of
work on 
evolution of object-oriented libraries and to new techniques to reorganize class hierarchies
(chapter 8).

This initial phase of experimentation allowed us to gain essential insight into both the
theoretical and practical issues of object systems. As a ﬁrst consequence, the group’s in-
terest in the formal aspects of programming language semantics and the speciﬁcation of
object  systems  became  deeper,  and  led  to  work  by  Michael  Papathomas  and  Oscar
Nierstrasz on notions of “plug compatibility” for active objects (chapter 4), by Costas Ar-
apis on modelling and reasoning about temporal aspects of collaborating object systems
(chapter 5), and by Laurent Dami on new models of compositionality, extensibility and
subtyping for objects (chapter 6).

In parallel with these theoretical investigations, the group developed new interests in
the area of software tools and development environments. Eugene Fiume, who was visit-
ing from the University of Toronto, and Laurent Dami in 1988 developed a prototype of a
“temporal scripting language” for animated objects. This was the group’s ﬁrst foray into
applying  object-oriented  technology  to  the  domain  of  multimedia  applications.  The
notion of a “script” as a high-level speciﬁcation of coordination amongst a set of pre-
packaged objects became a key theme in the group at the time, though it was not clear how
the idea could be carried over from the domain of animation to software objects in general.
At about this time we became involved in ITHACA, a large Technology Integration
Project of the European Community’s ESPRIT programme. The lead partner was Nixdorf
Informationssysteme (later Siemens-Nixdorf) in Berlin, and other partners included Bull
(Paris), Datamont (Milan), TAO — Tècnics en Automatitzaciò d’Oﬁcines (Barcelona)
and FORTH—the Foundation of Research and Technology, Hellas (Heraklion). The goal
of the project was to produce a complete, application development environment based on
object-oriented technology, including a state-of-the-art fourth-generation persistent ob-
ject-oriented programming language and its associated tools, and a set of application
“workbenches” to support development in a selected set of domains. A key component of
ITHACA was the “software information base” (SIB) that was to serve as a repository for
all reusable software artefacts (see chapter 7, by Panos Constantopoulos and Martin Dörr).
The SIB was intended to drive application development from requirements collection and
speciﬁcation (according to stored domain knowledge and requirements models), through
design (according to reusable generic designs), all the way to implementation (according
to reusable software components and frameworks). The key insight of this approach is that
the potential for reuse offered by object-oriented technology lies not only in libraries of
object classes, but runs through the entire software development process. To exploit this
potential, however, one needs more than object-oriented languages and tools: the software
lifecycle must reﬂect the role of reuse; the analysis and design methods must reﬂect the
new lifecycle; the project management strategy must support the lifecycle and the meth-
ods; and some form of software information system is needed to store and manage the re-
usable artefacts.

Our contribution to ITHACA was more speciﬁcally to develop a “visual scripting tool”
for dynamically conﬁguring applications from visually presented software components.

 
 

 

 

 

 

 

 
 

 

 
 

 

 
 

 

xvi

Preface

We developed a ﬁrst prototype, called VST, in which the notions of ports and “plug-
compatibility,” and the idea that a script could be packaged up as a component, emerged
naturally. Eventually we came to realize the term “script” carried too much semantic
baggage from other domains in which timing was a concern (such as animation). More to-
the-point was the view of an application as a 
 of software components, and so
we began to speak of 
 rather than “scripting.” A framework for visual
composition was elaborated and realized by Vicki de Mey as part of the ITHACA project
(chapter 10).

visual composition

composition

An important aspect of a software information system is a convenient interface for nav-
igation. Whereas traditional browsers based on class hierarchies display software artefacts
 dynamically adapts its presenta-
only according to ﬁxed relationships, an 
tion according to changing notions of afﬁnity between entities. New techniques were de-
veloped by Xavier Pintado and incorporated into a prototype (chapter 9).

afﬁnity browser

Within ITHACA, object technology was applied to the areas of ofﬁce systems and
public  administration.  In  Geneva,  we  also  explored  its  application  to  the  domains  of
multimedia systems and ﬁnancial applications. A multimedia laboratory was built up over
several years, and was used as an experimental platform for a multimedia framework. The
framework, designed by Simon Gibbs, allowed heterogeneous hardware and software
multimedia components to be encapsulated as objects that could be connected according
to a standard set of paradigms (chapter 11). One of the uses of the visual composition tool
developed  within  ITHACA  was  its  application  to  the  multimedia  framework,  thus
allowing one to compose multimedia objects interactively instead of having to code C++
programs to glue them together explicitly.

gluons

A second framework for the visualization of real-time ﬁnancial data was designed and
realized by Xavier Pintado. In this framework, a complementary approach was taken to
visual composition. Instead of requiring that components provide standard plug-compat-
 (chapter 12).
ible interfaces, the bindings between components are encapsulated as 
Various themes run through this book. The dominant theme is that ﬂexible, open appli-
cations should be seen not only as object-oriented constructions, but as 
compositions of
. The distinction between objects and components,
plug-compatible software components
and the notion of plug-compatibility must be speciﬁed with care. A second theme is that
, but that integration of concurrency and
concurrency and distribution are fundamental
other dynamic aspects into the object model of a programming language poses various
technical difﬁculties. New computational models are needed that take behavioural aspects
of objects to be fundamental rather than orthogonal. A third theme is that development of
open systems should be 
, and that this in turn requires new lifecycles,
methods and tools. In particular, the development of component frameworks by compo-
nent engineers is an evolutionary process, which must be supported by software informa-
tion  management  tools. Application  developers  similarly  need  appropriate  tools  that
facilitate instantiation of applications from frameworks and component libraries.

framework-driven

Our research on object systems resulted in a number of Ph.D. theses (by Casais, Arapis,
Papathomas, Konstantas, de Mey, Dami and Pintado), produced between 1991 and 1994,
which form the basis for seven chapters of this book. Since most of the authors have now

 
 

 

 

Acknowledgements

xvii

left the group, the book also represents the end of a cycle (and the beginnings of new ones).
Work on high-level coordination languages, on distributed object systems, and on ﬁnan-
cial frameworks is continuing in Geneva, whereas some of the other research directions
are being pursued at new locations.

It is a hopeless task to try to indicate such a moving target as current activities in a me-
dium as archival as a book. Up-to-date information on the activities of the Object Systems
Group can be found on the World Wide Web at:

http://cuiwww.unige.ch/OSG/

More information concerning the editors and authors of this book can be found at:

http://iamwww.unibe.ch/~oscar/OOSC/

Acknowledgements

Many  more  people  participated  in  the  projects  reported  here  than  could  possibly
contribute  as  authors.  Marc  Stadelmann  and  Jan  Vitek  implemented  the  ﬁrst  VST
prototype. Betty Junod and Serge Renfer contributed to ITHACA and to other projects.
Gérald Burnand, Philippe Cornu, Jean-Henry Morin, Frédéric Pot, Vassilis Prevelakis and
Didier Vallet have contributed much to the group. The group also beneﬁted greatly from
the participation of several visitors, who stayed anywhere from several months to a couple
of years. Jean Bell, Christian Breiteneder, Eugene Fiume, Rosario Girardi, John Hogg,
Nigel Horspool, Gerti Kappel, Barbara Pernici, Claudio Trotta, Peter Wegner and Claudia
Werner helped a great deal in the elaboration of our ideas.

A number of people were also invaluable in the preparation of this book. We especially
thank Jiri Dvorak, Karl Guggisberg, Thilo Kielmann, Markus Lumpe, Theo Dirk Meijler,
Jean-Guy Schneider, Patrick Varone and Jan Vitek for their careful reviews of several of
the chapters of this book. We also thank the authors, and especially Eduardo Casais, Lau-
rent Dami, Simon Gibbs, Dimitri Konstantas and Vicki de Mey for their contributions to
chapters they did not co-author. Finally, we thank Isabelle Huber and Angela Margiotta for
their help in preparing the ﬁnal manuscript.

We gratefully acknowledge the ﬁnancial support of the Swiss National Foundation for
Scientiﬁc Research (FNRS) which sponsored a series of projects over the years. We thank
the Commission for the Encouragement of Scientiﬁc Research (CERS) for their contribu-
tion to our participation in the ITHACA project. We thank the University of Geneva for
providing the infrastructure and support needed to carry out the research we describe. We
also thank the Union Bank of Switzerland’s Ubilab research facility for its generous ﬁnan-
cial support. Finally we would like to thank our various industrial and academic partners
for their stimulating support over the years.

Geneva
May, 1995

Oscar Nierstrasz
Dennis Tsichritzis

xviii

PART I

Introduction

2

Chapter 1
Component-Oriented 
Software Technology

Oscar Nierstrasz and Laurent Dami

Abstract    Modern software systems are increasingly required to be open and
distributed. Such systems are open not only in terms of network connections
and  interoperability  support  for  heterogeneous  hardware  and  software
platforms,  but,  above  all,  in  terms  of  evolving  and  changing  requirements.
Although object-oriented technology offers some relief, to a large extent the
languages,  methods  and  tools  fail  to  address  the  needs  of  open  systems
because they do not escape from traditional models of software development
that assume system requirements to be closed and stable. We argue that open
systems  requirements  can  only  be  adequately  addressed  by  adopting  a
component-oriented  as  opposed  to  a  purely  object-oriented  software
development approach, by shifting emphasis away from programming and
towards generalized software composition.

1.1

Introduction

There has been a continuing trend in the development of software applications away from
closed, proprietary systems towards so-called open systems. This trend can be largely at-
tributed to the rapid advances in computer hardware technology that have vastly increased
the computational power available to end-user applications. With new possibilities come
new needs: in order to survive, competitive businesses must be able to effectively exploit
new technology as it becomes available, so existing applications must be able to work with
new,  independently  developed  systems. We  can  see,  then,  that  open  systems  must  be
“open” in at least three important ways [49]:

1. Topology: open applications run on conﬁgurable networks.

2. Platform: the hardware and software platforms are heterogeneous.

3. Evolution: requirements are unstable and constantly change.

Oscar Nierstrasz and Laurent Dami, “Component-Oriented Software Technology,” Object-Oriented Software Composition, O. 
Nierstrasz and D. Tsichritzis (Eds.), pp. 3-28, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

4

Component-Oriented Software Technology

Object-oriented software development partially addresses these needs by hiding data
representation and implementation details behind object-oriented interfaces, thus permit-
ting multiple implementations of objects to coexist while protecting clients from changes
in implementation or representation. Evolution is only partially addressed, however, since
changes in requirements may entail changes in the way that the objects are structured and
conﬁgured. In fact, to address evolution, it is necessary to view each application as only
one instance of a generic class of applications, each built up of reconﬁgurable software
components. The notion of component is more general than that of an object, and in
particular may be of either much ﬁner or coarser granularity. An object encapsulates data
and its associated behaviour, whereas a component may encapsulate any useful software
abstraction. Since not all useful abstractions are necessarily objects, we may miss oppor-
tunities for ﬂexible software reuse by focusing too much on objects. By viewing open ap-
plications as compositions of reusable and conﬁgurable components, we expect to be able
to cope with evolving requirements by unplugging and reconﬁguring only the affected
parts.

1.1.1 What Are Components?

If we accept that open systems must be built in a component-oriented fashion, we must
still answer the following questions: What exactly are components, and how do they differ
from objects? What mechanisms must programming languages and environments provide
to support component-oriented development? Where do components come from in the
software development lifecycle, and how should the software process and methods ac-
commodate them?

In attempting to answer these questions, we must distinguish between methodological
and technical aspects. At a methodological level, a component, we will argue, is a compo-
nent because it has been designed to be used in a compositional way together with other
components. This means that a component is not normally designed in isolation, but as
part of a framework of collaborating components. A framework may be realized as an ab-
stract class hierarchy in an object-oriented language [23], but more generally, components
need not be classes, and frameworks need not be abstract class hierarchies. Mixins, func-
tions, macros, procedures, templates and modules may all be valid examples of compo-
nents [3], and component frameworks may standardize interfaces and generic code for
various kinds of software abstractions. Furthermore, components in a framework may
also be other entities than just software, namely speciﬁcations, documentation, test data,
example applications, and so on. Such components, however, will not be discussed in de-
tail in this paper: we will mainly concentrate on some technical aspects related to software
components.

At a software technology level, the vision of component-oriented development is a very
old idea, which was already present in the ﬁrst developments of structured programming
and modularity [32]. Though it obtained a new impulse through the compositional mech-
anisms provided by object-oriented programming languages, component-oriented soft-

Introduction

5

Static assembly of 
components

Dynamic assembly of 
cooperating and 
communicating “entities” 
(objects, agents, ...)

Figure 1.1   Static and dynamic views of an application.

ware  development  is  not  easy  to  realize  for  both  technological  and  methodological
reasons. For a programming language to support component-oriented development, it
must cleanly integrate both the computational and the compositional aspects of software
development. An application can be viewed simultaneously as a computational entity that
delivers results, and as a construction of software components that ﬁt together to achieve
those results (ﬁgure 1.1). A component per se does not perform any computation, but may
be combined with others so that their composition does perform useful computations,
much in the way that the parts of a machine do not necessarily perform any function indi-
vidually, but their composition does. The integration of these two aspects is not straight-
forward, however, since their goals may conﬂict. To take a concrete example, concurrency
mechanisms, which are computational, may conﬂict with inheritance, which is a a com-
positional feature, in that implementation details must often be exposed to correctly im-
plement inheriting subclasses [26] [31] (see chapter 2 for a detailed discussion of the
issues). To complicate things even further, the distinction between “composition time”
and “run time” is not always as clear as in the picture above: with techniques such as dy-
namic loading, dynamic message lookup or reﬂection, applications can also be partially
composed or recomposed at run-time.

In order to achieve a clean integration of computational and compositional features, a
common semantic foundation is therefore needed in which one may reason about both
kinds of features and their interplay. As we shall see, the notions of objects, functions and
agents appear to be the key concepts required for such a foundation. In consequence, we
will adopt a deﬁnition of software component which is sufﬁciently abstract to range over
these various paradigms.

In short, we say that a component is a “static abstraction with plugs”. By “static”, we
mean that a software component is a long-lived entity that can be stored in a software base,
independently of the applications in which it has been used. By “abstraction”, we mean
that a component puts a more or less opaque boundary around the software it encapsulates.

6

Component-Oriented Software Technology

Figure 1.2   A software component and its plugs.

“With plugs” means that there are well-deﬁned ways to interact and communicate with the
component (parameters, ports, messages, etc.). So, seen from the outside, a component
may appear as in ﬁgure 1.2: a single entity, which may be moved around and copied, and
in particular may be instantiated in a particular context, where the plugs (the small black
rectangles) will be bound to values or to other components. In fact, such visual represen-
tations of components can be very convenient for supporting interactive composition of
applications from component frameworks (see chapter 10). Software composition, then, is
the process of constructing applications by interconnecting software components through
their plugs. The nature of the plugs, the binding mechanisms and the compatibility rules
for connecting components can vary quite a bit, as we shall see, but the essential concepts
of components, plugs, plug-compatibility and composition remain the same.

1.1.2 Where Do Components Come From?

Once the programming language and associated tools support the development of com-
ponents, we are still left with the question, “Where do the components come from?”
Although we argue that a component-oriented approach is necessary to deal with evolving
requirements, it turns out that components themselves only emerge through an iterative
and evolutionary software lifecycle. This is reasonable, if we consider that components
are only useful as components if they can be easily used in many contexts. Before a “re-
useful” component can be designed [23], one must ﬁrst collect, understand and analyze
knowledge about these different contexts to determine how their different needs can be
addressed by some common frameworks. When component frameworks are put to use,
they must be evaluated with respect to how easily they can be applied to new problems,
and improvements must then be introduced on the basis of new experience. Component-
oriented  development  is  therefore  a  capital-intensive  activity  that  treats  component
frameworks as capital goods (or “reusable assets”), and requires investment in component
development to achieve economic beneﬁts in the long-term [53]. This means that not only
must  the  programming  language  technology  and  support  environment  address  the
technical  requirements  of  component-oriented  development,  but  the  entire  software
process,  including  the  analysis  and  design  methods,  must  incorporate  the  activity  of
“component engineering” into the software lifecycle.

Udell, who has provocatively proclaimed the “failure of object-oriented systems to
deliver on the promise of software reuse,” [50] supports this view by arguing that sets of

Objects vs. Components

7

components,  such  as  those  delivered  with  VisualBasic  are  a  much  more  successful
example of software reuse than object-oriented programming. An animated discussion
followed on the Internet* which ﬁnally came to the obvious agreement that successful
software reuse is a matter of methodology and design, more than technology; so object-
oriented systems cannot be taken as responsible for lack of reusability: they are more
likely to help in producing reusable software, provided that the right design decisions are
taken in the ﬁrst place. Additional arguments on the same line can be found in [22], where
various authors discuss software reuse not only in terms of technology, but above all in
terms of economical, human and organizational factors.

Our position is that both software methods and development technology need to under-
go some signiﬁcant changes in order to take advantage of component-oriented develop-
ment. We will ﬁrst focus on some of the foundational issues concerning the difference
between objects and components, and their integration in programming languages and
environments;  then  we  will  brieﬂy  survey  related  technological  and  methodological
problems to be resolved; ﬁnally, we will conclude with some prospects for the future of
component-oriented development.

1.2 Objects vs. Components

Object-oriented programming languages and tools constitute an emerging software tech-
nology that addresses the development of open systems in two important ways:

1. as an organizing principle;
2. as a paradigm for reuse.
In the ﬁrst case, one may view an object-oriented application as a collection of collab-
orating objects. The fact that each object properly encapsulates both the data and the cor-
responding behaviour of some application entity, and that one may only interact with this
entity through a well-deﬁned interface means that reliability in the face of software mod-
iﬁcations is improved, as long as client–server interfaces are respected. In the second case,
one may view applications as compositions of both predeﬁned and specialized software
components. Application classes inherit interfaces and some core behaviour and represen-
tation from predeﬁned abstract classes. Interactions within an application obey the proto-
cols deﬁned in the generic design. Inheritance is the principle mechanism for sharing and
reusing generic designs within object-oriented applications.

Despite these two signiﬁcant advantages of object-oriented development, it is still true
that present-day object-oriented languages emphasize programming over composition,
that is, they emphasize the ﬁrst view of applications to the detriment of the second. In
general, it is not possible to reuse classes without programming new ones — one cannot
simply compose object classes to obtain new classes in the way that one can compose

* The discussion took place during September 1994 in the newsgroup comp.object, under the subject head-
ing “Objects vs Components.”

8

Component-Oriented Software Technology

functions to obtain new functions. Furthermore, one is either forced to deﬁne a given com-
ponent as a class, whether or not the object paradigm is an appropriate one, or, if other
kinds of components are supported, the list is typically ad hoc (for example, mixins, mac-
ros, modules, templates).

If we consider the various dimensions of programming languages supporting some no-
tion of objects, we discover a mix of features concerned with computational and compo-
sitional issues. Wegner [54] has proposed a classiﬁcation scheme with the following seven
“dimensions”: objects, classes, inheritance, data abstraction, strong typing, concurrency
and persistence. According to the criterion that sets of features are orthogonal if they occur
independently in separate programming languages, it turns out that objects, abstraction,
types, concurrency and persistence are orthogonal. But this does not tell us how easy or
difﬁcult it is to cleanly integrate combinations of features within a single language.

In fact, if we consider just objects, classes and inheritance, it turns out that it is not at all
straightforward to ensure both object encapsulation and class encapsulation in the pres-
ence of inheritance [47]. One way of explaining this is that classes are overloaded to serve
both as templates for instantiating objects and as software components that can be extend-
ed by inheritance to form new classes. Typically, these two roles are not cleanly separated
by the introduction of separate interfaces. Instead, various ad hoc rules must be introduced
into each object-oriented programming language to determine what features of a class
may be visible to subclasses. Since these rules cannot possibly take into account the needs
of all possible component libraries, the net effect is that encapsulation must often be vio-
lated* in order to achieve the desired degree of software reusability.

A reasonably complete programming language for open systems development should
not only support objects and inheritance, but also strong typing and concurrency. Types
are needed to formalize and maintain object and component interfaces, and concurrency
features are needed to deal with interaction between concurrent or distributed subsystems.
(Fine-grain parallelism is also of interest, but is not an overriding concern.) Though types
and concurrency are supposedly orthogonal to objects and inheritance, their integration is
not a simple matter. 

One source of difﬁculty for types is that objects are not simply values taken in isolation,
like integers, strings, higher-order functions, or even more complex constructs such as ab-
stract datatypes. Objects typically belong to a global context, and may contain references
to other objects in that context. Furthermore, since they are dynamic entities, they may
change behaviour or state, and hence the meaning of references changes over time. Hence,
extracting static type information from such dynamic systems is considerably more difﬁ-
cult. Modelling inheritance is also problematic, due to the two different roles played by
classes. Many difﬁculties in early attempts arose from efforts to identify inheritance and
subtyping. It turns out, on the contrary, that subtyping and inheritance are best considered

* We say that encapsulation is violated if clients of a software component must be aware of implementa-
tion details not specified in the interface in order to make correct use of the component. In particular, if 
changes in the implementation that respect the original interface may affect clients adversely, then encap-
sulation is violated. If the inheritance interface cannot be separately specified, then encapsulation can be 
violated when implementation changes cause subclasses to behave incorrectly.

Technical Support for Components

9

as independent concepts [1] [7]. It may even be convenient to have a separate notion of
type for the inheritance interface [28].

When concurrency is also brought into the picture, the same conﬂicts are seen to an ex-

aggerated degree:

1. Concurrency features may conﬂict with object encapsulation if clients need to be

aware of an object’s use of these features [45] (see chapter 2).

2. Class encapsulation may be violated if subclasses need to be aware of implementa-

tion details [26] [31].

3. Type systems generally fail to express any aspect of the concurrent behaviour of ob-
jects that could be of interest to clients (such as the requirement to obey a certain
protocol in issuing requests — see chapter 4).

The source of these technical difﬁculties, we claim, is the lack of a sufﬁciently compo-
nent-oriented view of objects. Components need to be recognized as entities in their own
right, independently of objects. A class as a template for instantiating objects is one kind
of component with a particular type of interface. An object is another kind of component
with an interface for client requests. A class as a generator for subclasses is yet another
kind of component with a different kind of interface. Each of these components has its
own interface for very different purposes. It is possible to provide syntactic sugar to avoid
a proliferation of names for all of these different roles, but the roles must be distinguished
when the semantics of composition is considered.

The other lesson to learn is that each of these dimensions cannot simply be considered
as an “add-on” to the others. An appropriate semantic foundation is needed in which to
study the integration issues. If state change and concurrency are modelling requirements,
then a purely functional semantics is not appropriate. As a minimum, it would seem that a
computational model for modelling both objects and components would need to integrate
both agents and functions, since objects, as computational entities, can be viewed as par-
ticular kinds of communicating agents, whereas components, as compositional entities,
can be seen as abstractions, or functions over the object space. Moreover, since compo-
nents may be ﬁrst-class values, especially in persistent programming environments where
new components may be dynamically created, it is essential that the agent and function
views be consistently integrated. From the point of view of the type system, both objects
and components are typed entities, although they may have different kinds of types.

1.3

Technical Support for Components

Component-oriented software development not only requires a change of mind-set and
methodology: it also requires new technological support. In this section, we will review
some of the issues that arise:

• What are the paradigms and mechanisms for binding components together?
• What is the structure of a software component?

10

Component-Oriented Software Technology

• At which stage do composition decisions occur, i.e. how can we characterize the

composition process?

• How do we formally model components and composition, and how can we verify that

fragments are correctly composed?

• To which extend does a concurrent computational model affect software composi-

tion?

These questions obviously are interrelated; moreover, they depend heavily on the compo-
sition paradigm being used. We have argued that, ideally, a complete environment for soft-
ware  composition  should  somehow  provide  a  combination  of  objects,  functions  and
agents. So far, these paradigms have evolved quite independently. In order to combine
them into a common environment, considerable care must be taken to integrate them
cleanly. In the following, we examine the speciﬁc contributions of each paradigm to soft-
ware composition, we discuss how they may be integrated, and we summarize the princi-
ple open research problems.

1.3.1 Paradigms for Assembling Components

Probably the most fundamental composition mechanism to mention is functional compo-
sition. In this paradigm one entity is ﬁrst encapsulated and parameterized as a functional
abstraction, and is then “activated” (instantiated) by receiving arguments that are bound to
its  parameters.  Obviously  this  compositional  mechanism  occurs  in  nearly  every
programming environment, and is by no means restricted to functional programming
languages. Many languages, however, do not allow arbitrary software entities to be treated
as values, and therefore do not support functional composition in its most general form.
Parameterized modules, containing variables that can be bound later to other modules, for
example, are still absent from many programming languages. At the other end of the spec-
trum,  functional  languages  use  functional  composition  at  every  level  and  therefore
provide homogeneity: any aspect of a software fragment can be parameterized and then
bound  to  another  component,  thereby  providing  much  ﬂexibility  for  delimiting  the
boundaries of components. Furthermore, functional programming supports higher-order
composition, i.e. components themselves are data. In consequence, composition tasks
themselves can be encapsulated as components, and therefore some parts of the composi-
tion process can be automated. Finally, functional composition has the nice property of
being easily veriﬁable, since functions can be seen externally as black boxes: under some
assumptions about the parameters of a function, it is possible to deduce some properties
of the result, from which one can know if that result can safely be passed to another func-
tion. Current functional programming languages have developed sophisticated type sys-
tems to check correctness of composed software [37][21].

Functional composition is a local composition mechanism, in the sense that it only in-
volves one abstraction and the values passed as parameters. By contrast, agent environ-
ments  typically  use  a  global  composition  mechanism,  often  called  a  blackboard.  A
blackboard is a shared space, known by every component, in which information can be put

Technical Support for Components

11

and retrieved at particular locations. For systems of agents communicating through chan-
nels, the blackboard is the global space of channel names. Even without agents, global
memory in traditional imperative programming also constitutes a kind of blackboard.
Blackboard composition supports n-ary assemblies of components (whereas local com-
position mechanisms are mostly binary); furthermore, free access to the shared space im-
poses less constraints on the interface of components. The other side of the coin, however,
is that blackboard composition systems are much more difﬁcult to check for correctness
because interaction between components is not precisely localized. As a partial remedy to
the  problem,  blackboard  composition  systems  often  incorporate  encapsulation
mechanisms for setting up boundaries inside the global space within which interference is
restricted to a well-known subset of components. By this means, at least some local prop-
erties of a blackboard system can be statically veriﬁed. The π-calculus [35], for example,
has an operator to restrict the visibility of names; in the world of objects, islands [19] have
been proposed as a means to protect local names and avoid certain traditional problems
with aliasing. 

Finally, object-oriented systems have introduced a new paradigm for software compo-
sition with the notion of extensibility — the possibility of adding functionality to a com-
ponent  while  remaining  “compatible”  with  its  previous  uses.  Extensibility,  typically
obtained in object-oriented languages through inheritance or delegation, is an important
factor for smooth evolution of software conﬁgurations. The delicate question, however, is
to  understand  what  compatibility  means  exactly.  For  example,  compatibility  between
classes is usually decided on the basis of the sets of methods they provide, possibly with
their signatures; in the context of active objects, this view does not take into account which
sequences of methods invocations are accepted by an object. Chapter 4 studies how to
capture  this  aspect  through  so-called  regular  types.  Moreover,  compatibility  can  be
meaningful not only for classes, but for more generalized software entities; in particular,
object-oriented systems based on prototypes and delegation need to understand com-
patibility directly at the level of objects. Chapter 6 investigates a functional calculus in
which compatibility is deﬁned at a fundamental level, directly on functions.

Figure 1.3 is an attempt to represent visually the different paradigms. Functional com-
position is pictured through the usual image of functions as boxes, with parameters repre-
sented as input ports and results of computation as output ports. Connections between
components  are  established  directly  and  represent  bindings  of  values  to  formal  para-
meters. The blackboard paradigm has an addressing scheme that structures the global
space; it sometimes also uses direct connections, but in addition, components are put at
speciﬁc locations, and they may establish connections with other components through
their locations. Here locations are pictured as coordinates in a two-dimensional space for
the purpose of the visual illustration. In practice, the common space will most often be
structured by names or by linear memory addresses. Finally, extensibility is pictured by
additional ports and connections added to an existing component, without affecting the
features that were already present. Seen at this informal level, it is quite clear that some co-
habitation of the paradigms should be possible, but it is also clear that many details need

12

Component-Oriented Software Technology

Functional Composition

Blackboard

(x1, y1)

(x2, y2)

(x3, y3)

(x4, y4)

Extensibility

Figure 1.3   Composition paradigms.

careful study. The next subsections discuss the notions of components (the boxes), mech-
anisms (the arrows), and software conﬁgurations (the assemblies).

1.3.2 Components as Static Abstractions

In the introduction, we described components in terms of their usage: a software fragment
is a component if it is designed for reuse and is part of a framework. This does not tell
much about the structural aspects of a component. Some global invariants seem to be valid
within any composition paradigm: components typically are static entities; moreover,
they always consist of some kind of abstraction. Both notions, however, deserve more
careful examination.

There are many different kinds of static software entities: procedures, functions, mod-
ules, classes and so on. In each case, they have a persistent existence independent of their
surrounding context, allowing them to be manipulated and stored individually. Once as-
sembled into a program, these static entities control the creation and evolution of dynamic
entities, which in current languages are usually not components (procedure activations,
objects, dynamic data structures). Several examples can be found, however, of dynamic
entities that could be interesting as reusable software fragments, but cannot directly par-
ticipate in a composition because of limitations of the software environment. For example,
in most object-oriented languages the classes are static, but the objects (instances) are not.

Technical Support for Components

13

In such languages various strategies are typically used by programmers to have objects as
composable entities, such as deﬁning a class that encapsulates a single object (instance).
Another strategy, heavily used in the NeXTStep environment [39], is to deﬁne complex ar-
chiving procedures so that groups of objects can be stored into ﬁles (so-called “nib” ﬁles);
the corresponding ﬁles can then be composed and the resulting conﬁguration used to rec-
reate at run-time the collection of objects deﬁned in the individual groups. In cases like
this, where the structure of the objects composing a user interface is known statically and
does not evolve at run-time, the ability to directly store objects would be much more con-
venient than writing programs or description ﬁles that will dynamically recreate a conﬁg-
uration of objects.

Another limitation to composition occurs in exactly the reverse situation: saying that
components are static entities does not mean that they should be always assembled stati-
cally. Open systems have an increasing need to dynamically manipulate and exchange
components, and dynamically link them with a running application. Recent languages for
distributed agents such as Telescript [56] or Obliq [5] are good examples of this new
direction. Dynamic assembly means that software can be conﬁgured at the latest stage,
according to user’s needs, or that several running applications can dynamically collab-
orate to exchange information. 

The notion of a component is also closely related to that of an abstraction, a self-
contained entity, with some kind of boundary around it, which can later be composed with
other entities. A procedure is an abstraction for a sequence of instructions; a class is an ab-
straction for a collection of objects; a module is a set of named abstractions. The fact that
abstractions  have  boundaries  is  crucial  for  software  composition,  since  it  provides  a
means for structuring software, controlling interaction between components, and verify-
ing proper assembly. Unfortunately, most software environments impose some restric-
tions on the use of abstractions: boundaries cannot be drawn arbitrarily, according to
user’s  needs,  but  must  follow  speciﬁc  patterns.  For  example,  in  most  object-oriented
systems, boundaries cannot cross inheritance paths, i.e. a class cannot be deﬁned without
explicitly referencing its superclass. Only CLOS [27] supports a notion of inheritance
through mixins in which the superclass need not be known and can be bound later. Full
ﬂexibility  for  drawing  abstraction  boundaries  requires  all  software  components  to  be
treated as ﬁrst-class values that can be passed as parameters to other components. As
discussed above, the languages that are most advanced in that direction are functional
languages, where “everything is a function,” and functions are data. Since functional
abstraction  is  the  only  abstraction  mechanism,  programmers  have  great  ﬂexibility  in
choosing which aspects to ﬁx in a function deﬁnition and which aspects to leave open in
parameters.

Besides treating components as values, another property of abstractions that has a great
impact on compositionality is scalability, namely the possibility to use the same abstrac-
tion and composition mechanisms at every level of a conﬁguration. Again this is obviously
the case with functions, where an assembly of functions is a function again. The advantage
is the economy of concepts, and the fact that there is no limit on the granularity of compo-
nents. Through their inheritance interface, classes can be seen as scalable, since the incre-

14

Component-Oriented Software Technology

mental modiﬁcations of a subclass, together with the parent class, form a class again. By
contrast, modules are usually not scalable: an assembly of modules is not a module itself.
An environment without scalability imposes a ﬁxed granularity of composition (modules
can only be assembled into programs), and therefore restrict reusability of components.
Furthermore, the absence of scalability often creates problems for formal studies of pro-
gramming and composition environments, because formal theories are most successful
when they can rely on a small set of universal operators. A striking example can be ob-
served in the area of concurrency, where theoreticians typically use process calculi with
scalability (a pool of agents or processes is itself a process), while most practical imple-
mentations involving concurrency clearly distinguish between a process and a system of
processes.

1.3.3 The Composition Process

In traditional environments for software development the various phases for building an
application are well-deﬁned and distinct: ﬁrst one has to write a collection of modules,
possibly with some interdependencies, and with some dependencies to predeﬁned mod-
ules stored in libraries; then one has to compile the modules, in order to generate machine
code and, in strongly typed systems, to check type correctness of the modules; ﬁnally, one
has to link the various pieces of machine code together, using a global name space to
resolve all cross-references. This, of course, is the schema for compiled languages, but it
accounts for the great majority of development environments in current use. Therefore, in
such systems, the granularity of components seen by programmers is basically the same
as the granularity of units manipulated by the development environment.

In order to get more ﬂexible composition environments, this well-established scheme
of program development has to be reviewed. There are several reasons why a component-
oriented lifecycle is needed, and there are several tendencies in modern languages that
demonstrate the possibility of improving the traditional three-phase assembly of software.
We discussed above the necessity for open systems to be able to dynamically link new
agents into a running system. This implies that the information that is normally discarded
at link-time, namely the association between global names and memory addresses, needs
to be kept both in the running system and in the agent that will be added to it. In other
words, even a complete system can no longer considered to be totally closed: names may
be locally resolved, but they still need to be considered as potential free variables that can
be linked later to a dynamic entity. 

In some object-oriented systems, this is true to a further degree: not only the linkage in-
formation, but also a major part of compile-time information is required at run-time —
this is necessary to implement features such as delegation or even reﬂection. Early advo-
cates of object-oriented programming were often arguing in favour of the high level of
ﬂexibility offered by fully dynamic object-oriented systems, even if they admitted that
such choices have a cost in terms of resources: dynamicity typically consumes more mem-
ory and more computing power than statically optimized code. Later, some thought they

Technical Support for Components

15

had found the adequate compromise with C++: use objects and classes, but compile away
a maximum of information, only keeping what is strictly necessary (namely tables for
dynamic binding of virtual functions); this is one of the main reasons why the C++ com-
munity grew so rapidly. Indeed, C++ has been and is very successful for a large number of
applications, but one could say that the original target of proponents of object-oriented
programming has shifted: C++ is being used as a replacement for C, for applications in
which interaction with operating system, efﬁcient use of resources, tractability for large-
scale  projects  are  essential.  We  are  slowly  rediscovering,  however,  that  if  ﬂexibility,
openness, fast prototyping are really important issues, then the choice of C++ is no longer
justiﬁed. In the recent years, demand for qualiﬁed Smalltalk programmers has been stead-
ily  increasing,  and  large-scale  high-level  platforms  for  application  development  like
OpenStep [40] are being based on Objective-C instead of C++; both languages differ from
C++ in that they maintain full information about objects, classes and methods in the run-
time environment. So the market is progressively acknowledging that efﬁciency is not
necessarily the most important feature in any case, and that it also has its cost in terms of
lack of openness and ﬂexibility.

We are not saying that the future of software components is necessarily in fully inter-
preted languages, but that ﬂexible open systems need to deal with components in many
possible forms, ranging from source code to machine code through several intermediate
representations, partially compiled and optimized. Some modern languages in various
areas already demonstrate this tendency, and show that much progress has been done for
such implementation strategies. For example, both the scripting language Perl [52] and
the functional language CAML-Light [30] are compiled into an intermediate form that is
then interpreted; actually, interpreted Perl programs are sometimes faster than equivalent
compiled programs written in C, and the implementation of the CAML-Light interpreter
is faster than compiled versions of the original CAML language! Another example is the
Self language [51], which provides a very high level of run-time ﬂexibility, and yet has ef-
ﬁcient implementations based on the principle of compile-by-need: the run-time system
includes a Self compiler, and methods are compiled whenever needed. Static compilation
of a method in an object-oriented system is sometimes complicated, because one has to
make assumptions about the context in which it will be called (taking inheritance into
account); if, instead, the method is compiled at run-time, then more information is known
about the context (i.e. which actual object the method belongs to), which allows for a more
efﬁcient compilation of the method. In other words, the time lost to compile the method at
run-time may be quickly recovered through subsequent calls to the same method.

Ideally, the responsibility of switching between high-level, human-readable represen-
tations of components and low-level, optimized internal representations should be left to
the composition environment. In practice, however, programmers still often need to guide
these choices. This means that the granularity of components manipulated by the system
is visible to programmers. In itself, this is not necessarily a disadvantage, but the problem
is that this granularity is often identiﬁed with the granularity of logical components of a
software system. In other words, programmers are forced to think in terms of “compila-

16

Component-Oriented Software Technology

tion units,” instead of thinking in terms of “modules.” Leroy [29] explained very clearly
the distinction:

Modularization is the process of decomposing a program in[to] small units (mod-
ules) that can be understood in isolation by the programmers, and making the rela-
tions between those units explicit to the programmers. Separate compilation is the 
process of decomposing a program in[to] small units (compilation units) that can be 
type-checked and compiled separately by the compiler, and making the relations be-
tween these units explicit to the compiler and linker.

Identifying the two concepts is very common, and yet is limiting, as Leroy points out in
the context of the SML language [37]. Modules — i.e. logical units of a program — may
be structurally much more complex than compilation units, especially if, as discussed
above, one wants to be able to treat them as ﬁrst-class values and to perform higher-order
module combinations, either statically or even dynamically. In this respect, SML has
probably the most sophisticated module system for an existing programming language,
yet it does not support separate compilation. Several researchers are currently working on
removing this limitation [29][16].

1.3.4 Veriﬁcation of Composition

Whenever components are assembled to perform a common task, there is always an im-
plicit contract between them about the terms of the collaboration. In order to be able to ver-
ify the correctness of a conﬁguration, the contracts need to be made explicit and to be
compared for eventual discrepancies. This issue can be addressed by a type system. How-
ever, conventional type systems cannot capture in general all the aspects of a contract, be-
cause of their limited expressiveness. Two approaches can be taken for dealing with this
problem. One approach, taken by Meyer in the Eiffel language [33], is to enrich the inter-
faces of components with additional constraints expressing the expectations and promises
of each partner in the contract. Part of the constraints are checked by the type system, and
part of them are veriﬁed at run-time, each time that an actual collaboration (control pass-
ing) between two components takes place. The other approach is to improve the expres-
siveness of type systems. Much research has been done in this direction, especially in the
area of functional programming languages. Polymorphic type inference in languages such
as ML or Haskell [21] actually provides a level of security that is much higher than in a tra-
ditional language like Pascal, without putting any additional burden on the programmer.
However, as soon as one leaves the functional model, such results are no longer applica-
ble: in systems with blackboard composition (imperative programming languages, con-
current systems) one cannot infer much type information. As far as object systems are
concerned, this is still an open question, examined in detail in a survey by Fisher and
Mitchell [11]. The addition of subtyping makes both type inference and type checking
considerably harder, so despite important progress made over the recent years, no object-
oriented language with an ML-like type system has yet been developed.

Technical Support for Components

17

To capture the recursive semantics of objects at a type level, most researchers use ex-
plicitly typed systems with either recursive types or existential quantiﬁcation; such solu-
tions have improved the state of the art for object typing, but are not likely to be applied
soon in real languages, since the complexity of the resulting type expressions would prob-
ably appal most programmers not familiar with type theory. Therefore we believe that
practicability of object typing will be achieved through type inference rather than through
explicit typing; preliminary results in that direction are discussed in [18]. The difﬁcult
point, however, is to be able to infer types that are both “minimal” in the sense of sub-
typing, and “principal” in the sense of Curry type schemes (a type scheme is principal for
a term if and only if it can generate all other types of that term by substitution of type
variables). To our knowledge, this is still an open problem; but some recent results on prin-
cipal types for objects are collected in [15].

Coming back to the problem of explicit contracts between components, we should
mention another family of solutions that puts the contract, not inside components, but out-
side. For interlanguage composition, this is even the only possibility, since it would be
quite difﬁcult to compare contracts speciﬁed in different languages and models. An exam-
ple of a contract being outside of the components is a database schema that speciﬁes the
conditions under which a common database may be accessed, and which must be respect-
ed by every program doing transactions on the database.While providing a glue between
heterogeneous components, this kind of solution has the disadvantage of being quite rigid:
the terms of the contract are speciﬁed from the beginning and can hardly be changed later;
moreover, this approach cannot support scalability, since components are clearly distinct
from conﬁgurations of multiple components. Contracts outside of components are also
found in module interconnection languages, whose job is precisely to perform composi-
tion of software components. The amount of information handled in such languages varies
from one system to the other; Goguen, for example, advocates an algebraic approach to
capture semantic information about the components [13]. It should be noted, however,
that module interconnection languages seem to have lost part of their importance in the
literature in favour of more homogeneous approaches in which the distinction between
components and component assemblies is less strict. Object-oriented approaches fall into
that category, as do functional approaches to an even greater degree.

Type systems and algebraic speciﬁcations aim at verifying correctness in a machine-
checkable way by statically looking at a software conﬁguration. They belong, therefore,
to the world of static semantics. By contrast, a number of techniques have been developed
for studying the dynamic behaviour of programs, like denotational, algebraic, operational
or axiomatic semantics. Since such techniques deal with dynamic information, and are
therefore not decidable in general, they are commonly used for studying programming
languages and environments rather than particular software conﬁgurations. It is therefore
not our purpose here to discuss them in detail. It should be noted, however, that several of
the points discussed above for the evolution of component-oriented software development
will have some impact on these analysis techniques. For example, most of these semantics
are compositional, but they are not modular (for denotational semantics, this is acknowl-
edged by Mosses [38]). In the scenario of iterative compositional development, it should

18

Component-Oriented Software Technology

be possible to progressively reﬁne the semantics of a component according to the availa-
ble knowledge about its context: we know more about a component inserted into a given
conﬁguration than about this component seen in isolation. Instead of the usual distinction
between static semantics, dynamic semantics, and what Jones [25] calls “binding time
analysis,” we should again have a whole range of intermediate steps, corresponding to the
various intermediate stages of assembly.

Finally, it should be noted that traditional semantic techniques induce an equivalence
relationship over software components — they have been designed to be able to state
whether two components are equal or not. In the context of object-oriented programming,
this is no longer sufﬁcient, since the idea is to extend components — to produce new com-
ponents that are not just “equal” to previous ones (plug-compatible), but in some sense are
“better” (extended). To deal with this aspect, theoreticians of object-oriented languages
have developed the notion of partial equivalence relationships (PERs) [4], which equates
components not universally, but relative to a given type: for example the records {x=1,
y=3}, {x=1, y=4, z=10} are equivalent as type {x:Int}, but not as type {x:Int, y:Int}. An
alternative approach is proposed in this book in chapter 6, in which components are this
time universally related, but by a compatibility partial order instead of an equivalence re-
lationship.

1.3.5 Objects as Processes

Earlier in this chapter we argued that components and concurrency are both fundamental
concepts, and cannot be considered as “add-ons” to programming languages. Further-
more, the semantic issues are sufﬁciently subtle and complex that it is essential to have a
formal object model and a semantic foundation  for reasoning about all language features.
What, then, should the object model look like, and what would be an appropriate semantic
foundation?

Let us consider the features we would need to model in a language that supports com-

ponent-oriented development:

1. Active Objects: objects can be viewed as autonomous agents or processes.

2. Components: components are abstractions, possibly higher-order, over the compu-

tational space of active objects.

3. Composition: generalized composition is supported, not just inheritance.

4. Types: both objects and components have typed interfaces, but, since objects are dy-
namic entities and components are static, the type system must distinguish between
them.

5. Subtypes: subtyping should be based on a notion of “plug compatibility” that per-
mits both objects and components to be substituted if their clients are satisﬁed [55].

Technical Support for Components

19

An object model must therefore cope with both objects and components. Objects en-
capsulate services, and possess identity, state and behaviour*. The services are obtained
through the behaviour according to some client/server protocol. Components, on the other
hand, are abstractions used to build object systems, i.e., they are functions over the object/
process space. Although functions are fundamental, we cannot model objects as function-
al entities because they are long-lived and concurrent. Since input and output are on-go-
ing,  and  the  same  input  may  produce  different  results  at  different  times,  objects  are
essentially non-functional. Ideally, an object calculus [41] would merge the operational
features of a process calculus with the compositional features of the λ calculus.

Interestingly, recent progress in the study of process calculi addresses many aspects of
the semantics of concurrent object-oriented systems. The original work by Milner on a
Calculus of Communicating Systems (CCS) [34] resulted in a highly expressive process
calculus that nevertheless could not be used to model “mobile processes” that can ex-
change the names of their communication ports in messages. This, of course, is essential
to model objects. Work by Engberg and Nielsen [10] borrowed and adapted concepts from
the λ-calculus to deal with this, and Milner [36] reﬁned and simpliﬁed their results to pro-
duce the π-calculus, a true “calculus for mobile processes.” In the meantime, Thomsen
[48] developed the ﬁrst “Calculus for Higher-Order Communicating Systems” (CHOCS)
which essentially added term-passing to CCS. From an object systems point of view, this
should allow one to model objects and components as values at run-time. Milner extended
the π-calculus to a polyadic form [35], which allows one to express communication of
complex messages, and he introduced a simple type system for the calculus. Following on
work by Milner, Sangiorgi [46] developed a higher-order process calculus (HOπ), whose
semantics can be faithfully preserved by a mapping to the unadorned π-calculus, and Hen-
nessy [17] has developed a denotational model of higher-order process calculi. Honda
[20] has also developed the ν-calculus, a process calculus based on asynchronous com-
munication, whose semantics is obtained by a reduction of the features of the π-calculus.
Going in the opposite direction, Dezani et al. [9] have investigated synchronous parallel-
ism and asynchronous non-determinism in the classical λ-calculus. In the object-oriented
community, there have been several other attempts to develop object calculi that take their
initial inspiration from either process calculi or the λ-calculus, or both [8] [20] [41].

We propose that a formal model of objects and components based on recent develop-
ments in process calculi and λ-calculi should form a good basis not only for understanding
and explaining abstraction and composition in a component-oriented software develop-
ment method, but can actually serve as an abstract machine for developing a new genera-
tion of component-oriented languages [43] [44], much in the same way that the λ-calculus
has served as a semantic foundation for modern functional programming languages.

* The distinction between “state” and “behaviour” is admittedly artificial, but is useful for conceptual rea-
sons, since state is thought of as hidden and behaviour as visible. In fact, the notions are dual, and one can 
consider the “state” of an object to be its “current behaviour.”

20

Component-Oriented Software Technology

1.3.6 Summary of Research Topics

In this section we have listed some very ambitious wishes for the future of component-
oriented development environments, but we have also shown that several directions al-
ready present in modern programming languages can give us some conﬁdence about ful-
ﬁlment  of  that  program. To  summarize,  here  are  the  points  that  we  consider  as  most
important research issues:

• Merge current notions of abstraction in process calculi, functional languages and
object-oriented  languages  into  a  single  notion  of component,  which  should  be  a
ﬁrstclass,  storable  entity  equipped  with  the  notions  of  parameterization  (leaving
some  aspects  of  the  component  “open”)  and  instantiation  (ability  to  generate  a
“copy”  of  the  component  in  a  given  run-time  context),  and  furthermore  should
support scalability (possibility to encapsulate a partial conﬁguration of components
as a new component).

• Develop software manipulation tools that are able to deal with partial conﬁgurations
and support an iterative assembly process, by using various levels of intermediate
representations  of  components.  Current  tasks  of  type  checking,  compilation  to
machine code and linkage will be replaced by incremental change of intermediate
representation.

• Find expressive, yet decidable type inference/partial evaluation systems, that will be
able to statically decide about the correctness of a partial conﬁguration, in a way that
is transparent to (or requires minimal typing information from) programmers.

It can be seen that these research directions require a tight integration between current
research being done both at a theoretical level (semantics and types of programming
languages) and at a practical level (implementations, compiler/interpreter design).

1.4 Component Engineering

Once we have a language and environment that permits us to develop software component
frameworks,  there  remains  the  question  how  these  components  should  be  developed,
maintained and applied. With traditional software development, applications are in prin-
ciple designed to meet very speciﬁc requirements. Component frameworks, on the other
hand, must be designed to meet many different sets of requirements, and should even be
built to anticipate unknown requirements. 

Consider the following scenario* [42] for application development: an application de-
veloper has access to a software information system (SIS) that contains not only descrip-
tions of available component frameworks, but domain knowledge concerning various
application domains, descriptions of requirements models, generic designs, and guide-
lines for mapping requirements speciﬁcations in the problem space to designs and imple-

* This scenario was elaborated as part of the ITHACA project (described briefly in the preface).

Component Engineering

21

mentations in the solution space (see chapter 7 for a description of a such a system). A
software information system is closer in spirit to an expert system than to a repository; in
fact, the principle of a SIS is that it should encode and present the knowledge acquired by
a domain expert.

To use the SIS, the application developer ﬁrst enters into a dialogue to identify the rele-
vant application domain. The information pertaining to this domain can be referred to as a
Generic  Application  Frame  (GAF).  The  GAF  determines  the  context  for  application
development. The next step in the dialogue is to specify the requirements. Since the GAF
includes domain knowledge and requirements models, the requirements speciﬁcation is
largely performed according to existing patterns. The speciﬁc requirements will then lead
the SIS to suggest, according to stored guidelines, generic designs and component frame-
works that can be used to build the application. The guidelines may also suggest how com-
ponents should be instantiated or specialized to meet speciﬁc requirements. (Chapter 10
contains a brief description of RECAST, an interactive tool for requirements collection
and speciﬁcation, based on this scenario.)

The process of completing requirements speciﬁcations, making design decisions and
reﬁning and composing components results in a new information structure that we will
call a Speciﬁc Application Frame (SAF). The SAF consists not only of the completed
application, but all the information that was generated along the way. When application
requirements evolve, the SIS is again used, but in this case the dialogue results in pre-vious
decisions being reconsidered and a new SAF being built from the old.

This scenario is very appealing, but suggests more questions than it answers. How is do-
main knowledge to be captured and represented in the SIS? How are generic designs and
component frameworks developed and described? How are guidelines determined and en-
coded? Who is responsible for maintaining the SIS and its contents, and how are the con-
tents evaluated and maintained? Is the scenario even realistic? How much will the SIS
need to be supported by human experts? We believe it is, because successful generic ap-
plications and component frameworks do exist, but nobody knows how far this scenario
can be pushed to work well in practice. Will it only work for very restricted and well-
understood  application  domains,  or  is  it  also  valid  for  more  complex  and  evolving
domains?

This suggests that the role of component engineering is fundamentally different from
the more traditional role of application development. Although the same person may in
some cases play both roles, it is important to separate them in order to keep the different
sets of requirements distinct. In particular, the clients for each are very different. The cli-
ents of an application are (ultimately) the end-users, whereas the clients of a component
framework are the application developers.

Why  is  it  necessary  to  elevate  component  engineering  to  a  distinguished  activity?
Should it not be possible to ﬁnd reusable components by scavenging existing object-
oriented applications? A plausible scenario might have application developers use tradi-
tional methods to arrive at an object-oriented design, and then search for reusable objects
that would at least partially meet the speciﬁcations. The “found” objects would then be
tailored to ﬁt the task at hand.

22

Component-Oriented Software Technology

The problem with this scenario is that you do not get something for nothing. Software
components are only reusable if they have been designed for reuse. A repository of soft-
ware objects from previous applications is like a “software junkyard” that, more likely
than not, will not contain just what you are looking for. The cost of searching for and
ﬁnding  something  that  approximately  meets  one’s  needs,  and  the  additional  cost  of
adapting it to ﬁt may exceed the cost of developing it from scratch. Worse, the tailored
components are not maintainable, since such an approach will encourage a proliferation
of hacked-up, incompatible versions of somewhat similar components, none of which is
ultimately  reusable.  Systematic  rather  than  accidental  software  reuse  requires  an
investment  in  component  framework  development  and  in  software  information
management [53].

1.4.1 Beneﬁts and Risks

A component that has been designed for reuse always forms part of a framework of com-
ponents that are intended to be used together, much in the way that modular furniture is
made of components that can be combined in many ways to suit different needs. Clearly
the development of a component framework represents an investment that must be evalu-
ated against the expected return. The beneﬁts can be measured in two ways: a component
framework should make it easier (i) to ﬁll (at least partially) the needs of many different
applications, and (ii) to adapt a given application to changing needs. (These are also the
main  selling  points  of  modular  furniture.)  If  either  or  both  of  these  requirements  are
present to a sufﬁcient degree, it may be worthwhile developing a component framework,
or investing in the use and possible adaptation of an existing framework.

In fact, one can easily argue that component frameworks should always be used: long-
lived applications necessarily undergo changes in requirements with time that can be more
easily met with the use of a framework, and short-lived applications must typically be de-
veloped under tight time constraints, which can also be facilitated by the use of an existing
framework. The risks, however, must also be considered:

1. A steep learning curve can be associated with the use of a framework. Developers
must be willing to invest time and effort into learning a framework before the bene-
ﬁts can be realized. The not invented here syndrome can be difﬁcult to overcome.

2. Development of new frameworks is a costly and long-term activity. The long-term
beneﬁts must be justiﬁed in terms of the opportunities for recovering the invest-
ment.

3.

Individual projects have short-term goals and deadlines that conﬂict with the long-
term goals of component-engineering. Management must commit to developing a
service-oriented infrastructure to support the provision of frameworks to projects
[14]. If the use of frameworks introduces too much overhead, projects will not adopt
them.

Component Engineering

23

4. New frameworks evolve rapidly in the beginning, and may undergo several com-
plete redesigns before they stabilize. The costs of re-engineering client applications
of a redesigned framework may be quite high, though the long-term beneﬁts of re-
engineering can be signiﬁcant. In principle one should not use unstable frameworks
for a large base of client applications, but on the other hand, a framework will not
evolve to the point that it stabilizes unless it is applied to many different kinds of ap-
plications.

The reason that each of these points can be considered a risk is that present software
engineering practice actually discourages component-oriented development by focusing
on the individual application rather than viewing it as part of a much broader software
process. To address these points we need to rethink the way software is developed and
introduce new activities into the software lifecycle. 

If we reject the “software junkyard” model of software reuse, we can still consider it as
a starting point for component engineering. A component engineer processes and digests
the  results  of  previous  development  efforts  to  synthesize  (i)  domain  knowledge  and
requirements models [2], (ii) design patterns [12] and generic architectures, (iii) frame-
works [24] and component libraries, (iv) guidelines to map from problem to solution do-
mains (i.e. from requirements to designs and implementations). The result of component
engineering, therefore, resembles a well-designed cookbook — it is not just a collection
of prepackaged recipes, but it contains a lot of background information, generic recipes,
suggestions on how to combine and tailor recipes, and advice on how to meet speciﬁc
needs. The “cookbook” is intended to compensate for the fact that not everyone can afford
the time and expense required to become an expert, and so the acquired expertise is re-
duced to a standard set of guidelines and rules. Naturally one cannot hope to answer all
possible needs with such an approach, but a large class of relatively mundane problems
can be addressed.

Note that component engineering is not concerned only with developing software com-
ponents, but touches all aspects of software development from requirements collection
and speciﬁcation, through to design and implementation. The point is that the most bene-
ﬁcial artefacts to reuse are often not software components themselves but domain knowl-
edge and generic designs. Software reuse is most successful if one plans for it in advance.
By waiting until after requirements are speciﬁed and the systems are designed, many op-
portunities for reuse may have been wasted, and one may not even be able to ﬁnd suitable
components to reuse.

Component engineering can only be considered successful if the results are used to
build more ﬂexible applications. Ideally, these results actually drive the application devel-
opment process: an application developer should be quickly positioned in the software
information  space  to  some  GAF,  and  the  activities  of  requirements  collection  and
speciﬁcation, application design, component selection and reﬁnement should follow from
a ﬂexible dialog between the developer and a software information system on the basis of
the contents of the GAF.

24

Component-Oriented Software Technology

1.4.2 How to Get There from Here

However attractive such a software information system might be, little is known about
how one should build one that would be successful in practice. (See chapter 7 for a discus-
sion of some of the issues.) Good results have been achieved by introducing a so-called
“Expert Services Team” of individuals who are responsible for introducing reusable as-
sets into projects [14]. In this way, some of the domain expertise is formalized in terms of
reusable assets, but the knowledge of how to apply them to particular situations remains a
responsibility of this team. The hard parts remain: (i) how to identify the reusable assets
applicable to a given situation (identifying the GAF), (ii) mapping the results of analysis
to available architectures and designs, (iii) elaborating missing subsystems and compo-
nents, (iv) adapting frameworks to unforeseen requirements.

More generally, there are various aspects of component-oriented development that can
only be considered open research problems. Some of the more signiﬁcant problems are:
1. Domain knowledge engineering: how should domain knowledge be captured and

formalized to support component-oriented development?

2. Synergy between analysis and design: traditional software engineering wisdom
would keep design issues separate from analysis, but opportunities for reuse can be
missed unless one plans for it. How can analysis beneﬁt from the knowledge that
frameworks will be used in system design?

3. Framework design: what methods apply to framework design? Object-oriented
analysis  and  design  methods  do  not  address  the  development  of  frameworks.
Guidelines exist, but no methods [23].

4. Framework evolution: frameworks evolve as they stabilize. What principles should
be applied to their evolution? How do we resolve the technical difﬁculties of main-
taining applications based on evolving frameworks? [6]

5. Reuse metrics: traditional software metrics are of limited use in the development of
object-oriented software. Less is known about measuring the cost of developing
component-oriented software. How does one measure potential for reuse? The size
and cost of framework-based applications? The cost of developing and maintaining
reusable assets? [14]

6. Tools and environments: what software tools would facilitate component-oriented
development? How can the software information space be managed in such a way
as to provide the best possible support both for application developers and compo-
nent engineers?

1.5 Conclusions

Component-oriented  software  development  builds  upon  object-oriented  programming
techniques and methods by exploiting and generalizing object-oriented encapsulation and

References

25

extensibility, and by shifting emphasis from programming towards composition. Present
object-oriented technology is limited in its support for component-oriented development
in several ways. First and foremost, the notion of a software component is not explicitly
and generally supported by object-oriented languages. A component, as opposed to an
object, is a static software abstraction that can be composed with other components to
make an application. Various kinds of components can be deﬁned with object-oriented
languages, but their granularity is typically too closely linked with that of objects — in
addition to classes, both more ﬁnely and coarsely grained abstractions are useful as com-
ponents.

Supporting both components, as software abstractions, and objects, as run-time enti-
ties,  within  a  common  framework  requires  some  care  in  integrating  corresponding
language features within a common framework. In particular, it is not so easy to devise a
satisfactory type system that captures “plug compatibility” in all its useful forms and
guises. Concurrency and evolving object behaviour pose particular difﬁculties, as is seen
in chapters 2, 4 and 5. For these reasons, we argue, it is necessary to establish a suitable
semantic foundation of objects, functions and agents that can be used to reason about
software composition at all levels.

Foundational issues, though important, address only a small part of the difﬁculties in
making component-oriented development practical. Even if we manage to produce com-
puter languages that are better suited to expressing frameworks of plug-compatible soft-
ware components, there is a vast range of technological and methodological issues to be
resolved before we can expect that component-oriented development will become wide-
spread. The most fundamental question — where do the components come from? — is the
hardest to answer. In a traditional software lifecycle, application “components” are tailor-
made to speciﬁc requirements. In a component-oriented approach, the activity of compo-
nent engineering must be explicitly incorporated into the lifecycle, and supported by the
software process, the methods and the tools. “Software reuse” is not something that can be
achieved cheaply by arbitrarily introducing libraries or “repositories” into an existing
method. In fact, rather than focusing on software reuse, we must concentrate on reuse of
design, of architecture and of expertise. Component engineering is the activity of distilling
and packaging domain expertise in such a way as to make component-oriented application
development possible.

References

[1]

Pierre America, “A Parallel Object-Oriented Language with Inheritance and Subtyping,” Proceedings
OOPSLA/ECOOP ’90, ACM SIGPLAN Notices, vol. 25, no. 10, Oct. 1990, pp. 161–168.

[2] Roberto Bellinzona, Mariagrazia Fugini, Vicki de Mey, “Reuse of Speciﬁcations and Designs in a De-
velopment Information System,” Proceedings IFIP WG 8.1 Working Conference on Information Sys-
tem Development Process, ed. N. Prakash, C. Rolland, B. Pernici, Como, Italy, Sept. 1–3 1993, pp.
79–96.

[3] Gilad Bracha, ‘‘The Programming Language Jigsaw: Mixins, Modularity and Multiple Inheritance,’’

Ph.D. thesis, Dept. of Computer Science, University of Utah, March 1992. 

26

Component-Oriented Software Technology

[4] Kim B. Bruce and Giuseppe Longo, “A Modest Model of Records, Inheritance, and Bounded Quan-

tiﬁcation,” in Information and Computation, vol. 87, 196–240, 1990.
Luca Cardelli, “Obliq: A Language with Distributed Scope,” preliminary draft, March 1994.
Eduardo Casais, ‘‘An Incremental Class Reorganization Approach,’’ Proceedings ECOOP ’92, ed. O.
Lehrmann Madsen, Lecture Notes in Computer Science, vol. 615, Springer-Verlag, Utrecht, June/July
1992, pp. 114–132. 

[5]
[6]

[8]

[7] William Cook, Walter Hill and Peter Canning, ‘‘Inheritance is not Subtyping,’’ Proceedings POPL

’90, San Francisco, Jan. 17–19, 1990, pp. 125–135. 
Laurent Dami, ‘‘Software Composition: Towards an Integration of Functional and Object-Oriented
Approaches,’’ Ph.D. thesis no. 396, University of Geneva, 1994. 

[9] Mariangiola Dezani-Ciancaglini, Ugo de’Liguoro, Adolfo Piperno, “Fully Abstract Semantics for
Concurrent Lambda-calculus,” in Proceedings TACS ’94, Lecture Notes in Computer Science, vol.
789, Springer-Verlag, 1994, pp. 16–35.

[10] Uffe Engberg and M. Nielsen, ‘‘A Calculus of Communicating Systems with Label Passing,’’ DAIMI

PB-208, University of Aarhus, 1986. 

[11] Kathleen Fisher and John C. Mitchell, “Notes on Typed Object-Oriented Programming,” in Proceed-
ings TACS 94, Lecture Notes in Computer Science, vol. 789, Springer-Verlag, Utrecht, 1994, pp. 844–
885.

[12] Erich Gamma, Richard Helm, Ralph E. Johnson and John Vlissides, “Design Patterns: Abstraction
and  Reuse  of  Object-Oriented  Design,”  Proceedings  ECOOP  ’93,  Lecture  Notes  in  Computer
Science, Springer-Verlag, vol. 707, 1993, pp. 406–431.

[13] Joseph A. Goguen, “Reusing and Interconnecting Software Components,” in IEEE Computer, Feb.

1986, pp. 16–27.

[14] Adele Goldberg and Kenneth S. Rubin, Succeeding with Objects: Decision Frameworks for Project

Management, Addison-Wesley, 1995, forthcoming. 

[15] Carl A. Gunter and John C. Mitchell, Theoretical Aspects of Object-Oriented Programming, MIT

Press, Cambridge, Mass. , 1994. 

[16] Robert Harper and Mark Lillibridge, “A Type-Theoretic Approach to Higher-Order Modules with

Sharing,” in Proceedings POPL ’95, ACM Press, 1995, pp. 123–137.

[17] Matthew Hennessy, “A Fully Abstract Denotational Model for Higher-Order Processes,” in Informa-

tion and Computation, vol. 112(1), pp. 55–95, 1994.

[18] Andreas  Hense,  “Polymorphic  Type  Inference  for  Object-Oriented  Programming  Languages,”

Dissertation, Saarbrücken, Pirrot, 1994.

[19] John Hogg, “Islands: Aliasing Protection in Object-Oriented Languages,” in Proceedings OOPSLA

91, ACM SIGPLAN Notices, vol. 26, no. 11, pp. 271–285, Nov. 1991.

[20] Kohei Honda and Mario Tokoro, ‘‘An Object Calculus for Asynchronous Communication,’’ Proceed-
ings ECOOP ’91, ed. P. America, Lecture Notes in Computer Science, vol. 512, Springer-Verlag, Ge-
neva, July 15–19, 1991, pp. 133–147.

[21] Paul Hudak, Simon Peyton Jones and Philip Wadler (eds), ‘‘Report on the Programming Language
Haskell — A Non-Strict, Purely Functional Language (Version 1.2),’’ ACM SIGPLAN Notices, vol.
27, no. 5, May 1992. 
IEEE Software, Software Reuse, vol. 11, no. 5, Sept. 1994.

[22]
[23] Ralph  E.  Johnson  and  Brian  Foote,  ‘‘Designing  Reusable  Classes,’’  Journal  of  Object-Oriented

Programming, vol. 1, no. 2, 1988, pp. 22–35.

[24] Ralph E. Johnson, “Documenting Frameworks using Patterns,” Proceedings OOPSLA ’92, ACM SIG-

PLAN Notices, vol. 27, no. 10, Oct. 1992, pp. 63–76.

[25] Neil D. Jones, “Static Semantics, Types, and Binding Time Analysis,” Theoretical Computer Science,

vol. 90, 1991, pp. 95–118.

References

27

[26] Dennis G. Kafura and Keung Hae Lee, ‘‘Inheritance in Actor Based Concurrent Object-Oriented
Languages,’’ Proceedings ECOOP ’89, ed. S. Cook, Cambridge University Press, Nottingham, July
10–14, 1989, pp. 131–145.

[27] Gregor Kiczales, Jim des Rivières and Daniel G. Bobrow, The Art of the Metaobject Protocol, MIT

Press, Cambridge, Mass., 1991.

[28] John Lamping, ‘‘Typing the Specialization Interface,’’ Proceedings OOPSLA 93, ACM SIGPLAN No-

tices, vol. 28, no. 10, Oct. 1993, pp. 201–214.

[29] Xavier  Leroy,  “Manifest Types,  Modules,  and  Separate  Compilation,”  in Proceedings  POPL’94,

ACM Press, 1994, pp. 109–122.

[30] Xavier Leroy and Pierre Weiss, Manuel de Référence du Langage CAML, InterEditions, 1994. Also

available by WWW at http://pauillac.inria.fr/doc-caml-light/refman.html.

[31] Satoshi Matsuoka and Akinori Yonezawa, ‘‘Analysis of Inheritance Anomaly in Object-Oriented Con-
current Programming Languages,’’ Research Directions in Concurrent Object-Oriented Program-
ming, ed. G. Agha, P. Wegner and A. Yonezawa, MIT Press, Cambridge, Mass., 1993, pp. 107–150.

[32] M.D. McIlroy, ‘‘Mass Produced Software Components,’’ Software Engineering, ed. P. Naur and B.

Randell, NATO Science Committee, Jan. 1969, pp. 138–150.

[33] Bertrand Meyer, Object-Oriented Software Construction, Prentice Hall, Englewood Cliffs, NJ, 1988.
[34] Robin Milner, Communication and Concurrency, Prentice Hall, Englewood Cliffs, NJ, 1989. 
[35] Robin Milner, ‘‘The Polyadic pi Calculus: a tutorial,’’ ECS-LFCS-91-180, Computer Science Dept.,

University of Edinburgh, Oct. 1991. 

[36] Robin Milner, Joachim Parrow and David Walker, ‘‘A Calculus of Mobile Processes, Part I/II,’’ Infor-

mation and Computation, vol. 100, 1992, pp. 1–77. 

[37] Robin Milner, Mads Tofte and Robert Harper, The Deﬁnition of Standard ML, MIT Press, Cambridge,

Mass., 1990.

[38] Peter D. Mosses, “Denotational Semantics,” in ed. J. van Leuwen, Handbook of Theoretical Computer

Science, vol. B, Elsevier, Amsterdam, 1990, pp. 575–631.
[39] NeXTstep Reference Manual, NeXT Computer, Inc., 1990.
[40] Next Computer, Inc. and SunSoft, Inc., OpenStep Speciﬁcation, 1994. Available at ftp address ftp://

ftp.next.com/pub/OpenStepSpec/.

[41] Oscar  Nierstrasz,  ‘‘Towards  an  Object  Calculus,’’  Proceedings  of  the  ECOOP  ’91 Workshop  on
Object-Based Concurrent Computing, ed. M. Tokoro, O. Nierstrasz, P. Wegner, Lecture Notes in Com-
puter Science, vol. 612, Springer-Verlag, pp. 1–20, 1992.

[42] Oscar Nierstrasz, Simon Gibbs and Dennis Tsichritzis, ‘‘Component-Oriented Software Develop-

ment,’’ Communications of the ACM, vol. 35, no. 9, Sept. 1992, pp. 160–165.

[43] Oscar Nierstrasz, ‘‘Composing Active Objects,’’ Research Directions in Concurrent Object-Oriented
Programming, ed. G. Agha, P. Wegner and A. Yonezawa, MIT Press, Cambridge, Mass., 1993, pp.
151–171.

[44] Oscar Nierstrasz and Theo Dirk Meijler, ‘‘Requirements for a Composition Language,’’ Proceedings
of  the  ECOOP  ’94  Workshop  on  Coordination  Languages,  ed.  P.  Ciancarini,  O.  Nierstrasz,  A.
Yonezawa, Lecture Notes in Computer Science, Springer-Verlag, 1995, to appear. 

[45] Michael  Papathomas  and  Oscar  Nierstrasz,  ‘‘Supporting  Software  Reuse  in  Concurrent  Object-
Oriented Languages: Exploring the Language Design Space,’’ Object Composition, ed. D. Tsichritzis,
Centre Universitaire d’Informatique, University of Geneva, June 1991, pp. 189–204. 

[46] Davide Sangiorgi, ‘‘Expressing Mobility in Process Algebras: First-Order and Higher-Order Para-
digms,’’ Ph.D. thesis, CST-99-93 (also: ECS-LFCS-93-266), Computer Science Dept., University of
Edinburgh, May 1993. 

[47] Alan Snyder, ‘‘Encapsulation and Inheritance in Object-Oriented Programming Languages,’’ Pro-

ceedings OOPSLA ’86, ACM SIGPLAN Notices, vol. 21, no. 11, Nov. 1986, pp. 38–45. 

28

Component-Oriented Software Technology

[48] Bent Thomsen, ‘‘Calculi for Higher Order Communicating Systems,’’ Ph.D. thesis, Imperial College,

London, 1990. 

[49] Dennis Tsichritzis, ‘‘Object-Oriented Development for Open Systems,’’ Information Processing 89

(Proceedings IFIP ’89), North-Holland, San Francisco, Aug. 28–Sept. 1, 1989, pp. 1033–1040. 

[50] Jon Udell, “Componentware,” in Byte, vol. 19, no. 5, May 1994, pp. 46–56.
[51] David Ungar and Randall B. Smith, ‘‘Self: The Power of Simplicity,’’ Proceedings OOPSLA ’87,

ACM SIGPLAN Notices, vol. 22, no. 12, Dec. 1987, pp. 227–242. 

[52] Larry Wall and Randal L. Schwartz, Programming Perl, O’Reilly & Associates, Inc., 1990. 
[53] Peter Wegner, ‘‘Capital-Intensive Software Technology,’’ IEEE Software, vol. 1, no. 3, July 1984. 
[54] Peter Wegner, ‘‘Dimensions of Object-Based Language Design,’’ Proceedings OOPSLA ’87, ACM

SIGPLAN Notices, vol. 22, no. 12, Dec. 1987, pp. 168-182. 

[55] Peter Wegner and Stanley B. Zdonik, ‘‘Inheritance as an Incremental Modiﬁcation Mechanism or
What Like Is and Isn’t Like,’’ Proceedings ECOOP ’88, ed. S. Gjessing and K. Nygaard, Lecture
Notes in Computer Science, vol. 322, Springer-Verlag, Oslo, Aug. 15–17, 1988, pp. 55–77.

[56] J.E. White, Telescript Technology: The Foundation for the Electronic Marketplace, White Paper, Gen-

eral Magic, Inc.

PART II

Concurrency and 
Distribution

30

Chapter 2
Concurrency in
Object-Oriented 
Programming Languages

Michael Papathomas

Abstract        An  essential  motivation  behind  concurrent  object-oriented
programming  is  to  exploit  the  software  reuse  potential  of  object-oriented
features in the development of concurrent systems. Early attempts to introduce
concurrency to object-oriented languages uncovered interferences between
object-oriented and concurrency features that limited the extent to which the
beneﬁts  of  object-oriented  programming  could  be  realized  for  developing
concurrent  systems. This  has  fostered  considerable  research  into  languages
and  approaches  aiming  at  a  graceful  integration  of  object-oriented  and
concurrent  programming. We  will  examine  the  issues  underlying  concurrent
object-oriented  programming,  examine  and  compare  how  different
approaches for language design address these issues. Although it is not our
intention  to  make  an  exhaustive  survey  of  concurrent  object-oriented
languages, we provide a broad coverage of the research in the area.

2.1

Introduction

Considerable research activity in the past few years has concentrated on the design of con-
current object-oriented programming languages (COOPLs). This research activity aimed
at providing an integration of object-oriented and concurrent programming. The follow-
ing points discuss some motivation for concurrent object-based programming: 

• To augment the modelling power of the object-oriented programming paradigm. One
goal of object-oriented programming can be seen as to model the real world directly
and naturally [89]. Concurrency then adds to the modelling power by making it easier
to model the inherently concurrent aspects of the real world.

Michael Papathomas, “Concurrency in Object-Oriented Programming Languages,” Object-Oriented Software Composition, O. 
Nierstrasz and D. Tsichritzis (Eds.), pp. 31-68, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

32

Concurrency in Object-Oriented Programming Languages

• To take advantage of the software design beneﬁts of object-oriented programming
and the potential for software reuse in the development of concurrent and distributed
systems. Concurrent and distributed systems are becoming more widespread and the
need to develop concurrent programs is becoming more common. This is witnessed
by the support provided for concurrent programming at the application level provid-
ed by modern operating systems.

• To  support  sharing  of  distributed  persistent  data.  The  object-oriented  paradigm
lends itself well for providing location transparency by encapsulating within objects
access to distributed persistent data. However, as information has to be shared, ac-
cess to the objects has to be scheduled in a way that avoids interference and provides
support for recovering from failures in the distributed environment. Although this
could be left to the language implementation, as is the case in database management
systems, taking advantage of the semantics of object types to ensure atomicity has
substantial  beneﬁts  with  respect  to  performance  and  availability.  This,  however,
requires the use of concurrency control mechanisms for the implementation of object
types[90].

• To  take  advantage  of  parallelism  in  the  implementation  of  object  classes  for
increased  execution  speeds.  Data  abstraction  can  be  used  to  conceal  parallel
implementations of objects from programs that use them so as to increase their per-
formance when run on parallel machines. Parallelizing compilers could be used to
generate parallel implementations of object classes, thus avoiding the need for con-
currency constructs. However, better results are generally achieved by the use of ex-
plicit parallel algorithms as implicit approaches for parallel execution uncover and
exploit only a number of restricted classes of parallelism [46]. Moreover, as data ab-
straction hides the details of the implementation of classes, users of these classes
need not be aware of their concurrent implementation.

In all of the above cases it is necessary to combine the concurrent and object-oriented
programming paradigms, provide linguistic support for concurrent object-oriented pro-
gramming and, ideally, exploit the reuse potential of object-oriented programming for
concurrent software. 

However, combining object-oriented and concurrency features has proven to be more
difﬁcult than might seem at ﬁrst sight. Clearly, devising a language that has both concur-
rent programming and object-oriented constructs poses no problem. There has been a
large number of proposals for combining object-oriented and concurrency features. How-
ever, they are not equally successful in drawing the beneﬁts of object-oriented program-
ming for concurrent software development. The problem is that these features are not
orthogonal, and consequently they cannot be combined in an arbitrary way. Most of the re-
search in the area is devoted to devising graceful combinations that limit the interference
of features. 

In this chapter we present a design space for the approaches for combining object-
oriented and concurrency features and a set of criteria for evaluating the various choices.
We  use  the  criteria  to  evaluate  some  proposals  and  identify  approaches  that  do  not

Design Space

33

adequately support object-oriented programming as well as approaches that do achieve a
graceful combination of the features. 

 In section 2.2 we present a design space for combining object-oriented and concurren-
cy features with respect to several aspects of language design. In section 2.3, we discuss
the issues that have to be addressed to provide the beneﬁts of object-oriented program-
ming. Section 2.4 examines the impact of some proposals on the integration of the pro-
gramming paradigms and their potential for reuse. Finally, in section 2.5 we present our
conclusions, discuss open problems and directions for further work in the area.

2.2

Design Space

We start by presenting three aspects of COOPLs that we consider for constructing the de-
sign space, and then we discuss the design choices with respect to each of these aspects.
Later, in section 2.4, we will examine more closely some existing languages showing how
the design of their features situate them in the design space.

2.2.1 A Design Space for Concurrent Object-Oriented Languages

We seek to evaluate language design choices with respect to the integration of their con-
currency and object-oriented features and the degree to which software reuse is supported.
In particular, we wish to understand how choices of concurrency constructs interact with
object-oriented techniques and affect the reusability of objects. As such, our classiﬁcation
scheme concentrates on the relationship between objects and concurrency. We shall con-
sider the following aspects:

• Object models: how is object consistency maintained in the presence of concurren-
cy? The way objects are considered with respect to concurrent execution may or may
not provide them with a default protection with respect to concurrent invocations.
Furthermore, different languages may favour or enforce a particular way of structur-
ing programs to protect objects.

• Internal concurrency: can objects manage multiple internal threads? This issue con-
cerns the expressive power that is provided to objects for handling requests. Note that
the execution of internal threads is also related to the protection of the internal state
objects, which is determined by the choice of object model.

• Constructs for object interaction: how much freedom and control do objects have in
the way that requests and replies are sent and received? The choice of concurrency
constructs for sending and receiving messages determines the expressive power that
is provided for implementing concurrent objects. Moreover, the design of constructs
for conditional acceptance of messages interacts with the use of class inheritance.

34

Concurrency in Object-Oriented Programming Languages

In the presentation of the design space, it will become apparent that these aspects are not
entirely independent: certain combinations of choices are contradictory and others are re-
dundant or lack expressive power.

2.2.2 Concurrent Object Models

There are different ways one can structure a concurrent object-based system in order to
protect objects from concurrency. A language may support constructs that favour or even
enforce one particular way, or may leave it entirely to the programmer to adopt a particular
model. There are three main approaches:

• The  orthogonal  approach:  Concurrent  execution  is  independent  of  objects.
Synchronization constructs such as semaphores in Smalltalk-80 [40], “lock blocks”
as in Trellis/Owl [68] or monitors as in Emerald [19] must be judiciously used for
synchronizing concurrent invocations of object methods. In the absence of explicit
synchronization, objects are subject to the activation of concurrent requests and their
internal consistency may be violated.

• The homogeneous approach: All objects are considered to be “active” entities that
have control over concurrent invocations. The receipt of request messages is delayed
until the object is ready to service the request. There is a variety of constructs that can
be used by an object to indicate which message it is willing to accept next. In POOL-
T [6] this is speciﬁed by executing an explicit accept statement. In Rosette [83] an en-
abled set is used for specifying which set of messages the object is willing to accept
next.

• The heterogeneous approach: Both active and passive objects are provided. Passive
objects do not synchronize concurrent requests. Examples of such languages are Eif-
fel // [26] [27] and ACT++ [45]. Both languages ensure that passive objects cannot
be invoked concurrently by requiring that they be used only locally within single-
threaded active objects. Argus [55] provides both guardians (active objects) and
CLU clusters (passive objects) [52]. 

2.2.3 Internal Concurrency

Wegner [87] classiﬁes concurrent object-based languages according to whether objects
are internally sequential, quasi-concurrent or concurrent:

• Sequential objects possess a single active thread of control. Objects in ABCL/1 [94]

and POOL-T and Ada tasks [9] are examples of sequential objects.

• Quasi-concurrent objects have multiple threads but only one thread may be active at
a time. Control must be explicitly released to allow interleaving of threads. Hybrid
domains [47][70][71][72] and monitors [42] are examples of such objects.

Design Space

35

Internal concurrency

Sequential

Quasi-noncurrent

Concurrent

Single thread of control 

ABCL/1, POOL-T

There are several logical threads 
but only one at a time. Thread 
interleaving occurs at programmer 
defined places

Hybrid, monitors

There may be several 
threads of control active 
within an object.

Figure 2.1   Approaches to internal concurrency.

 

• Concurrent objects do not restrict the number of internal threads. New threads are
created freely when accepting requests. Ada packages and POOL-T units resemble
concurrent objects (though they are not ﬁrst-class objects). Languages like Small-
talk-80 that adopt the orthogonal object model also support concurrent objects. From
the point of view of the called objects, a new local thread is effectively created when-
ever a method is activated in response to a message.

According to the above classiﬁcation, the threads of concurrent objects are created free-
ly when an object receives a message. However, there are languages where objects may
have internally concurrent threads that are not freely created by message reception. In or-
der to include these languages in the classiﬁcation and to capture more information about
the way that threads are created, we generalize the concurrent object category to include
any language in which objects have concurrent threads, irrespective of the way they are
created, and consider separately the issue of thread creation. 

We identify three, non-exclusive ways for the creation of threads within objects as fol-

lows:

• By message reception: Thread creation is triggered by reception of a message. An ob-
ject cannot create a thread on its own unless it can arrange for a message to be sent to
it without blocking the currently executing thread. Depending on whether objects
may control the creation of threads, we have the following subcategories:
— Controlled  by  the  object: The  object  may  delay  the  creation  of  threads.  For
example, in the language Sina [84] a new concurrent thread may be created for
the execution of a method belonging to a select subset of the object’s methods
only if the currently active thread executes the detach primitive.

— Unconstrained creation: Threads are created automatically at message recep-

tion. This is the default for languages with an orthogonal object model.

• Explicit creation: Thread creation is not triggered by message reception but the ob-
ject itself initiates the creation of the new thread. For instance, in SR [12] there is a
construct similar to a “cobegin” [11] to initiate the execution of concurrent threads.

36

Concurrency in Object-Oriented Programming Languages

Thread creation 

 By message reception

Explicit creation

SR co, Smalltalk-80 fork

Uncontraintsed
creation of threads⇒
Orthogonal object model

Smalltalk-80, Ada packages

Creation of threads is
controlled by the object

Sina, Act++

Figure 2.2   Approaches to thread creation.

Another way to create a new thread, in the absence of a special construct, is to call
asynchronously an operation of the object. This requires, however, that such calls are
not blocked at the object’s interface. This approach is used in a recent version of Sina.
Such calls bypass the normal method synchronization constraints as well as the re-
quest queue at the object’s interface. Finally, it would also be possible to create new
independent objects to call the object methods in parallel. However, this is cumber-
some and it also requires some means of bypassing the message queue at the object’s
interface.

 The next and become primitives in Rosette and ACT++ can be viewed as a controlled
creation of threads, with the additional restriction that concurrent threads may not share
the object’s state since they execute on different “versions” of the object.

 In Guide [48], an object may be associated with a set of activation conditions that
specify which methods may be executed in parallel by internally concurrent threads. In the
default case, as with any language following an orthogonal approach for concurrency, ob-
jects may be viewed as concurrent with unconstrained creation of threads triggered by ex-
ternal messages. 

The creation of threads by reception of external messages or by execution of a special
construct are neither mutually exclusive design choices — as illustrated by SR, which
supports both — nor redundant, as we will see in section 2.3.

2.2.4 Constructs for Object Interaction

We classify these constructs with respect to the degree of control that can be exercised by
objects in the client and server roles. We speciﬁcally consider reply scheduling, which
concerns the degree of ﬂexibility the client has in accepting a reply, and request schedul-
ing, which concerns the control the server can exercise in accepting a request.

Design Space

37

Issuing Requests

2.2.4.1
The following important issues can be identiﬁed with respect to the constructs supported
for issuing requests:

• Addressing: How are the recipients of a request speciﬁed and determined? How and
where is the reply to be sent? Flexible control over the reply destination can reduce
the amount of message passing required.

• Synchronization for requests and replies: Can the current thread continue after issu-
ing the request? What mechanisms are supported for matching replies to requests?
How does the client synchronize itself with the computation and delivery of the re-
ply?

• First-class representation of requests and replies: Do requests and replies have a
ﬁrst-class representation that permits them to be forged or changed dynamically?
What aspects (e.g. destination, method name) can be changed dynamically?

We further discuss these issues below and present how they are addressed by different

proposals. 

Addressing

In most languages the recipient of a request is speciﬁed directly by using its object identi-
ﬁer. However, there are some proposals allowing for more ﬂexible ways of addressing
where the system determines the recipient of the request. We review some of these propos-
al below.
Types as Recipients in PROCOL

In PROCOL [49] [85] an object type may be used to specify the recipient of a request. In
this case the potential recipients are any instance of the type that is in a state such that it
may accept the request. The system determines one recipient among the set of potential re-
cipients and delivers the request. It is important to note that this feature does not support
any form of multicast; exactly one message is exchanged with the chosen recipient in a
point to point fashion. 
ActorSpace

ActorSpace [2] is a general model providing a ﬂexible and open-ended approach to object
communication that has been developed in the context of the actor model. 

In this mode, destination patterns may by used to designate the recipients of a request.
Patterns are matched against attributes of actors in an speciﬁed actorspace — a passive
container of actors — to determine a set of potential recipients. A message may be sent by
either one of two primitives: send or broadcast.The former delivers exactly one message
to a recipient chosen non-deterministic by the system. The latter provides a form of multi-
cast by delivering the request to all potential recipients.

38

Concurrency in Object-Oriented Programming Languages

Client–server interaction

One -way message passing

Request/reply

Higher-level protocols must 
be explicitly programmed

PROCOL, CSP

Balanced requests and 
replies are supported

RPC

Proxies

Sending a request 
blocks the current 
thread until a reply is 
received

Sending requests and receiving 
replies may be delegated, as with 
CBoxes and futures

ABCL/1, ConcurrentSmalltalk, Eiffel //

Figure 2.3   Client–server interaction mechanisms.

Extra  ﬂexibility  is  provided  in  this  model  by  allowing  the  dynamic  inclusion  and
removal of actors from ActorSpaces as well as by allowing the dynamic modiﬁcation of
actor attributes. Moreover, ActorSpaces may be nested.

Synchronization for Requests and Replies 

We initially distinguish between one-way message passing communication primitives
and constructs supporting a request/reply protocol. The latter provide support for object
interactions where requests will be eventually matched by replies. These mechanisms
vary in ﬂexibility when sending requests and receiving replies. Strict RPC approaches en-
force that requests will be matched by a reply and delay the calling thread until the reply
is available. Further ﬂexibility is provided by “proxy” objects which disassociate the
sending or receiving of messages from the current thread of control. Examples of built-in
proxy objects are future variables [94] and CBoxes [92].

One-Way Message Passing

Whether communication is synchronous with one-way message passing, as in CSP [43]
or PROCOL [85], or asynchronous, as in actor languages, clients are free to interleave
activities while there are pending requests. Similarly, replies can be directed to arbitrary
addresses since the delivery of replies must be explicitly programmed.

Design Space

39

 The main difﬁculty with one-way message passing is getting the replies. The client and
the server must cooperate to match replies to requests. As we shall see in section 2.3, the
additional ﬂexibility and control provided by one-way message passing over request/re-
ply based approaches can only be properly exploited if objects (i.e. servers) are imple-
mented in such a way that the reply destination can always be explicitly speciﬁed in a
request.
Remote Procedure Call

With RPC the calling thread of the client is blocked until the server accepts the request,
performs the requested service and returns a reply. Most object-oriented languages sup-
port this form of interaction, though “message passing” is generally compiled into proce-
dure calls.

Supporting RPC as the only means for object interaction may be a disadvantage when
objects are sequential as we will see in the next section. Although it is trivial to obtain a
reply, it is not possible to interleave activities or to specify reply addresses.
Proxies

An alternative approach that provides the client with more ﬂexibility in sending and re-
ceiving replies is to introduce proxies. The main idea is to delegate the responsibility of de-
livering the request and obtaining the reply to a proxy. (The proxy need not be a ﬁrst-class
object, as is the case with future variables [94].) The actual client is therefore free to
switch its attention to another activity while the proxy waits for the reply. The proxy itself
may also perform additional computation or even call multiple servers.

If necessary, the reply is obtained by the original client by an ordinary (blocking) re-
quest. This approach, variants of which are supported by several languages [27][94][92],
maintains the beneﬁts of an RPC interface and the ﬂexibility of one-way message passing.
In contrast to one-way message passing, however, there is no difﬁculty in matching replies
to requests.

A  closely  related  approach  is  to  combine  RPC  with  one-way  message  passing.  In
ABCL/1, for example, an object that externally has an RPC interface may internally use
lower-level message-passing primitives to reply by sending an asynchronous message to
the client or to its proxy. The use of such facilities is further discussed in section 2.4.2.

First-Class Representation of Requests and Replies

The ability to have a ﬁrst-class representation of requests and replies may enhance sub-
stantially the expressive power of a language. There is a range of aspects of requests and
replies that may have a ﬁrst-class representation in a language. This varies from (almost)
no ﬁrst-class representation at all to a full ﬁrst-class representation of all aspects of re-
quests and replies. Below we discuss how this issue is addressed in some languages that
are characteristic of the various possibilities.

40

Concurrency in Object-Oriented Programming Languages

Minimal First-Class Representation

Apart from the method’s arguments and the target, all other aspects, such as the method
name and the return address, cannot be speciﬁed dynamically. This the case for languages
such as POOL-T, Hybrid and Trellis/Owl. One could argue that since the target and the ar-
guments can be speciﬁed at run-time, there is a ﬁrst-class representation of some aspects
and that the categorization is not accurate. In fact, in older language proposals such as CSP
[43] the targets of messages were determined statically. This, however, is uncommon in
more recent languages since it makes it hard to develop software libraries: a server that
must be statically bound to its potential callers has a low reuse potential. A ﬁrst-class rep-
resentation of the target and arguments can be considered as a minimum that one should
expect to ﬁnd in every language.
First-Class Representation of Method Names and Reply Addresses

PROCOL supports the ﬁrst-class representation of method names. The name of the meth-
od to call may be supplied as a string. This allows the method names for a request to be
passed in messages or computed at run-time. 

With ABCL/1 it is possible to specify dynamically and explicitly the object that is to re-
ceive the reply of a request. The beneﬁts of the use of this feature are discussed in section
2.4.2.
Full First-Class Representation

As one would expect, full ﬁrst-class representation of requests is provided in reﬂective
languages such as ABCL/R. However, it is also provided in languages such as Smalltalk
and Sina which are not fully reﬂective. In fact, the latter two illustrate the usefulness and
the possibility of having such features in any concurrent language which is not fully
reﬂective. Briot [23] has used the features of Smalltalk to build a several object-oriented
programming models using the relative primitive concurrency features provided in the
Smalltalk system. Aksit et al. [4] show how these features may be used to abstract and
reuse several object coordination paradigms.

2.2.4.2 Accepting Requests
A main concern from the point of view of an object acting as a server is whether requests
can be conditionally accepted.* When a request arrives, the server may be busy servicing
a previous request, waiting itself for a reply to request it has issued, or idle, but in a state
that requires certain requests to be delayed. We distinguish initially between conditional
and unconditional acceptance of requests. Conditional acceptance can be further discrim-
inated according to whether requests are scheduled by explicit acceptance, by activation
conditions or by means of reﬂective computation (see ﬁgure 2.4).

* A secondary issue is whether further activity related to a request may continue after the reply has been 
sent as in the Send/Receive/Reply model [39], but this can also be seen as concern of internal concurrency 
where follow-up activity is viewed as belonging to a new thread.

Design Space

41

Request scheduling

Conditional
acceptance

Unconditional 
acceptance

No synchronization with the 
state of the target

Ada packets, Smalltalk-80, 
Emerald, Trellis/Owl

Explicit acceptance

Activation conditions

 Reﬂective computation

The execution of the 
operation is synchronized 
with an “accept” statement 
explicitly executed by the 
target

ADA tasks, ABCL/1, SR
POOL-T, Eiffel //

Explicit or implicit conditions on 
the target’s state determine 
when the execution of an 
operation may take place

The arrival of a message at the 
target triggers a reflective 
computation in the associated 
meta-object. This determines 
whether the requested operation 
should be executed

ABCL/R, ACTALK

Representation speciﬁc

Conditions are expressed 
directly on the hidden object 
state

Guide, Hybrid, Sina

Abstract – representation 
independent

Conditions are expressed in terms of 
abstract properties of the object and do 
not refer to the particular implementation

ACT++, ROSETTE, PROCOL,
path expressions

Figure 2.4   Approaches to scheduling requests.

Unconditional Acceptance

Unconditional acceptance of requests is illustrated by monitors [42] and by Smalltalk-80
[40] objects. The mutual exclusion that is provided by monitors could be considered as an
implicit condition for the acceptance of requests. However, the mutual exclusion property
is captured by viewing monitors as quasi-concurrent objects so we consider request ac-
ceptance to be unconditional. Note that message acceptance for languages with an orthog-
onal object model is by default unconditional. 

42

Concurrency in Object-Oriented Programming Languages

Explicit Acceptance

With explicit acceptance, requests are scheduled by means of an explicit “accept” state-
ment executed in the body of the server. Accept statements vary in their power to specify
which  messages  to  accept  next. Acceptance  may  be  based  on  message  contents  (i.e.
operation name and arguments) as well as the object’s state. Languages that use this
approach are Ada, ABCL/1, Concurrent C, Eiffel//, POOL-T and SR. With this approach
objects are typically single-threaded, though SR is an exception to this rule.

 Activation Conditions

With activation conditions, requests are accepted on the basis of a predicate over the ob-
ject’s state and, possibly, the message contents. The activation condition may be partly im-
plicit, such as the precondition that there be no other threads currently active within the
object. An important issue is whether the conditions are expressed directly over a particu-
lar representation of the object’s state or if they are expressed in more abstract terms. In
Guide, for example, each method is associated with a condition that directly references the
object’s instance variables, whereas in ACT++ the condition for accepting a message is
that the object be in an appropriate abstract state which abstracts from the state of a par-
ticular implementation. Another approach is to specify the legal sequences of message ac-
ceptance by means of a regular expression, as in path expressions [24] and PROCOL [85].
 There are also some proposals such as synchronizers [38], separate method arguments
[66] and state predicates [74], for activation conditions that depend on the state or the
computation history of other objects. 

A synchronizer [38] is a special object associated with a group of objects. When a meth-
od of any of these objects is called a condition in the synchronizer is evaluated. Depending
on the outcome, the execution of the method may proceed, or be delayed until the con-
dition becomes true. Synchronizers may have their own variables that are used to store
information about the computation history of a group of objects.

Separate method arguments [66] can be used to constraint the execution of a method by
preconditions on the argument declared as “separate.” The execution of the method is de-
layed until the preconditions are true and the separate objects are “reserved” for the dura-
tion of the call. That is, they can only be used in the body of a method.

With state predicate notiﬁers [74], the execution of a method can be constrained by the
notiﬁcation that another object has reached a state that satisﬁes a state predicate.This fea-
ture has synchronous and asynchronous forms. In the synchronous variant, the notifying
object waits until the method is executed and the method gains exclusive access to the
object. In the asynchronous variant the notifying object proceeds independently.

Reﬂective Computation

With reﬂective computation the arrival of a request triggers a method of the server’s meta-
object. The meta-object directly then manipulates object-level messages and mailboxes as

Criteria for Evaluating Language Design Choices

43

objects. This approach is followed by the language ABCL/R [86] and it is also illustrated
in Actalk [23] where some reﬂective facilities of the Smalltalk-80 system are used to in-
tercept messages sent to an object and synchronize their execution in a way that simulates
message execution in actor-based languages. 

2.3 Criteria for Evaluating Language Design Choices

So far we have presented a design space covering the most signiﬁcant choices in the design
of concurrency features for OOPLs, but we have said little about how the various ap-
proaches compare. Since our goal is to arrive at COOPLs that provide the advantages of
object-oriented programming for the development of concurrent systems, we must ﬁrst
formulate our requirements as precisely as possible, before beginning to compare the
approaches. We ﬁrst discuss the issue of developing object classes that have high reuse
potential. Then, we turn our attention to the support for reuse at a ﬁner granularity than
objects and examine the issues related to the use of inheritance and the reuse of synchro-
nization constraints. 

2.3.1 Object-Based Features — Support for Active Objects

The main issue for reuse at the object level is that concurrency in an object-oriented lan-
guage should not diminish the beneﬁts of object-based features with respect to reuse. For
instance, encapsulation should still protect the internal state of objects from surrounding
objects and it should still be possible to insulate objects’ clients from implementation
choices. This should make it possible to change the implementations without affecting the
clients provided that the interfaces are maintained and that changes are, in some sense, be-
haviourally compatible.

Object-oriented and concurrent programming have different aims that incur different
software structuring paradigms. Object-oriented programming aims at the decomposition
of software into self-contained objects to achieve higher software quality and to promote
reusability. Concurrent programming aims at expressing and controlling the execution,
synchronization and communication of conceptually parallel activities. Its primary goal is
to provide notations that are suitable for devising solutions to problems that involve the
coordination of concurrent activities [11].

In order to compare language designs it is necessary to adopt a programming model for
concurrent object-based programming and evaluate how well the various languages sup-
port this model. Our view regarding the way the two programming paradigms should be
combined is by structuring programs as cooperating objects that exchange messages. This
is similar to the way sequential object-oriented programs are structured, however, in con-
current programs objects may encapsulate one or more concurrent threads that implement
their behaviour. Moreover, the operations of an object may be invoked by concurrently ex-
ecuting objects. 

44

Concurrency in Object-Oriented Programming Languages

We use the term active objects for this programming model to emphasize that objects
themselves rather than the threads that invoke their operations have the responsibility to
schedule concurrent requests. Requests should be scheduled in a way consistent with the
object’s internal state and the possibly spontaneous execution of internal threads. The ob-
jects developed following this model are independent self-contained entities. They can be
reused across applications and they may be reﬁned to support different scheduling poli-
cies for invoked operations. The programs that use the objects should not be affected by
such changes.

Although any language combining concurrent and object-oriented features could be
used to develop software following this model, as will be illustrated in section 2.4, not all
combinations of concurrent and object-oriented features are equally successful in sup-
porting this programming model. Below we develop a number of requirements on the lan-
guage features to adequately support programming following an active object model. In
section 2.4 we will use these requirements to evaluate language design choices and iden-
tify the shortcomings of some approaches.

Requirements

2.3.1.1
According to the active object model discussed above, we would like languages to support
the development of self-contained objects with high reuse potential. A general principle
for achieving this is that reusable object classes should make minimal assumptions about
the behaviour of applications that will use them. Furthermore, the choice of constructs
should not constrain the possible implementations of a class. We can formulate our re-
quirements as follows:

1. Mutual  exclusion  —  protecting  the  objects’  state:  The  internal  state  of  objects
should be automatically protected from concurrent invocations so that it will be
possible to reuse existing objects in concurrent applications without modiﬁcation.
2. Request scheduling transparency: An object should be able to delay the servicing
of requests based on its current state and on the nature of the request. This should be
accomplished in a way that is transparent to the client. Solutions that require the co-
operation of the client are not acceptable from the point of view of reusability since
the client then cannot be written in a generic fashion.
Internal concurrency: The concurrency constructs should allow for the implemen-
tation  of  objects  that  service  several  requests  in  parallel  or  that  make  use  of
parallelism in their implementation for increased execution speed in the processing
of a single request. This could be done either by supporting concurrent threads
within  an  object  or  by  implementing  an  object  as  a  collection  of  concurrently
executing  objects.  Whatever  approach  is  chosen,  it  is  important  that  internal
concurrency be transparent to the object’s clients so that sequential implementa-
tions of objects may be replaced by parallel ones.

3.

4. Reply scheduling transparency: A client should not be forced to wait until the serv-
ing object replies. In the meantime it may itself accept further requests or call other
objects in parallel. It may even want replies to be directly sent to a proxy. Request

Criteria for Evaluating Language Design Choices

45

Clients 

Workload manager

Workers

Administrator

Figure 2.5   The administrator example.

scheduling by the client should not require the cooperation of the server since this
would limit the ability to combine independently developed clients and servers.

2.3.1.2 An Example 
In order to compare the design choices and their combinations with respect to the reuse re-
quirements, we shall refer to an instance of a “generic” concurrent program structure: the
administrator inspired by [39]. The administrator is an object that uses a collection of
“worker” objects to service requests. An administrator application consists of four main
kinds of components. The clients issue requests to the administrator and get back results.
The administrator accepts requests from multiple concurrent clients and decomposes
them into a number of subrequests. The workload manager maintains the status of work-
ers and pending requests. Workers handle the subrequests and reply to the administrator.
The administrator collects the intermediate replies and computes the ﬁnal results to be re-
turned to clients (see ﬁgure 2.5).

The administrator is a very general framework for structuring concurrent applications.
For example, workers may be very specialized resources or they may be general-purpose
compute servers. The workload manager may seek to maximize parallelism by load bal-
ancing or it may allocate jobs to workers based on their individual capabilities.

The components described above identify functionally distinct parts of the application
that could have been developed independently and reused as indicated above to construct
a new application.These components do not have to be implemented as single objects, and
indeed, as we see later, depending on the constructs provided by certain languages, several
objects will be necessary for realizing the desired functionality. However, it should be pos-
sible to modify the implementation of the above components without affecting the rest as
if they were single objects.

The following points relate the language design requirements listed above to the reuse

issues in the case of the example application:

46

Concurrency in Object-Oriented Programming Languages

• Mutual exclusion: (i) Workload manager reuse – the workload manager must be pro-
tected from concurrent requests by the administrator. There may be cases where the
administrator does not invoke the workload manager concurrently. Although in such
cases no protection is needed, workload managers that are not protected could not be
reused in different concurrent implementations of the administrator. In such a con-
current implementation the administrator may use a collection of proxies that may
invoke  the  workload  manager  concurrently.  (ii)  Worker  reuse  –  workers  should
similarly be protected so that arbitrary objects may be used as workers with various
implementations of the administrator, including concurrent ones.

• Request scheduling transparency: (iii) Genericity of clients, reusing the administra-
tor with different clients — the administrator must be able to interleave (or delay)
multiple client requests, but the client should not be required to take special action.
In fact it should be possible to implement any object as an administrator and it should
not matter to the object’s clients if the serving object happens to be implemented as
an administrator.

• Internal concurrency: (iv) Client/worker reuse — the administrator should be open
to concurrent implementation (possibly using proxies) without constraining the in-
terface of either clients or workers;

• Reply scheduling transparency: (v) Worker reuse — it must be possible for the ad-
ministrator to issue requests to workers concurrently and to receive their replies
when it chooses without special action by workers;

2.3.2 Inheritance and Synchronization

There are two main issues concerning reuse at a ﬁner granularity than objects. 
• The ﬁrst is to maintain in concurrent languages the reuse potential offered by inher-
itance in sequential languages. Several early papers have reported difﬁculties in us-
ing class inheritance in COOPLs as well as in the design of languages that integrate
class inheritance and concurrency constructs [19] [6] [22]. In some cases inheritance
was left out as it was deemed difﬁcult to integrate and of limited use. The need to syn-
chronize the execution of inherited, overridden and newly deﬁned methods, without
breaking the encapsulation between classes, makes it more difﬁcult to take advan-
tage of class inheritance than in sequential languages. For instance, if mutexes are
used for synchronizing method execution, a method deﬁned in a subclass would have
to access a mutex deﬁned in a superclass in order to be synchronized with superclass
methods. This would break encapsulation between classes. The design of concurren-
cy constructs should be made in way to avoid such problems. 

• The second is to make it possible to reuse algorithms, often called synchronization
constraints, for scheduling the execution of methods of a class. For instance, a class
may implement a synchronization algorithm that schedules its methods according to
the readers and writers synchronization scheme. It would be desirable to be able to

Criteria for Evaluating Language Design Choices

47

reuse this algorithm in other classes taking into account the reader/writer property of
its methods. 

In most languages the reuse of synchronization constraints is achieved through class
inheritance and the term inheritance of synchronization constraints is often used for this
issue. We have chosen the term reuse of synchronization constraints since class inherit-
ance is only one possible means to achieve reuse. Furthermore, it is questionable whether
class inheritance should be used for this purpose. We will further elaborate on this point
below. Then, we will discuss separately the requirements for supporting class inheritance
and for reusing synchronization constraints.

Inheritance is often considered as the most prominent feature of object-oriented pro-
gramming. The most widespread object-oriented languages such as C++, Smalltalk and
Eiffel provide an inheritance mechanism that may be used for different purposes. These
include: the reuse of the implementation of a class in the implementation of a new class;
the speciﬁcation of a type compatibility relation between a class and its parent classes,
considering for type-checking purposes that instances of the class are of the same type as
instances of its superclasses; ﬁnally, it may be used to express that the concept or entity
modelled by the subclass is, in some sense, a reﬁnement of the concepts or entities repre-
sented by its parent classes. 

The use of a single mechanism for all these purposes can, on one hand, be a source of
confusion and on the other, limit the effectiveness of the mechanism for each of these dif-
ferent purposes. For instance, subtypes have to be related to a class inheritance relation-
ship even if they do not share any part of their implementation. In order to use part of the
implementation of a class in a new class, all the methods have to be inherited to comply
with the subtype relation that is also expressed by the inheritance link.Wegner and Zdonik
[88] provide a general and in-depth discussion of inheritance as an incremental modiﬁca-
tion mechanism and illustrate its use for different purposes. Guide [48] and POOL-I [8]
are concrete examples of languages with mechanisms that distinguish between the differ-
ent uses of inheritance. Both languages distinguish between class inheritance as a code re-
use mechanism and typing. POOL-I goes even further by also allowing the speciﬁcation
of behaviourally compatible classes. 

In section 2.4.3 we will examine more closely the approaches for the reuse of synchro-
nization constraints followed by different languages. This will illustrate the interactions
that class inheritance may have with the reuse of synchronization constraints in these dif-
ferent approaches.

2.3.2.1 Class Inheritance
The issues listed below have to be addressed in order to take advantage effectively of the
reuse potential of inheritance. The ﬁrst two are concerned with the reuse of superclass
methods. The third one concerns the use of inheritance for providing generic algorithms
through the deﬁnition and reﬁnement of abstract classes [36] [44]. 

• Separate speciﬁcation of the synchronization constraints: If the code that imple-
ments the synchronization decisions related to the execution of methods is included

48

Concurrency in Object-Oriented Programming Languages

directly in methods, inherited methods typically will have to be modiﬁed to account
for the synchronization constraints of the subclass [45].

• Interface between methods and the synchronization constraints: The separate speci-
ﬁcation of synchronization control actions and method code does not necessarily
mean that the execution of methods once started should be carried out without any
further interaction with the synchronization constraints. Such an approach limits the
expressive power of a language. Instead, there should be a well-deﬁned interface be-
tween methods and the synchronization constraints that allows several actions in the
execution of the method to interact with the synchronization constraints associated
with the various classes where it is reused.

• Consistency with other uses of inheritance for software composition: Apart from re-
using individual methods, inheritance serves to facilitate sharing of algorithms and
designs [36]. For this purpose, inheritance is paired with other features such as invo-
cation of methods through pseudo-variables such as self or super in Smalltalk. 

Reuse of Synchronization Constraints

2.3.2.2
The issues discussed below are important for evaluating and comparing the proposals for
the speciﬁcation and reuse of synchronization constraints:

• Flexibility of the binding mechanism: The mechanism that is used to apply con-
straints to a particular class determines the ﬂexibility with which constraints may be
reused. Depending on the mechanism, constraints are bound to exactly one class (the
class where they were introduced), or to any class that inherits from the class that
introduced the constraints. Additionally, method names appearing in a constraint
speciﬁcation may be considered as variables to be substituted at binding time with
method names deﬁned in a particular class.

• Compositionality and extensibility: This concerns the support provided for reusing
previously deﬁned constraints in the deﬁnition of new ones. A related issue is extend-
ing the application of constraints to methods that are introduced at a later stage.

• Polymorphism: The potential applicability of constraints to different classes. This is
related to the binding mechanism and modularity; constraints could be speciﬁed in a
way that would allow them to be applied to different classes. However, this may be
impossible or inconvenient because of the absence of an appropriate binding mech-
anism.

• Modiﬁability and locality of change: There are circumstances where it may be desir-
able or necessary to change the implementation of a class or of just the synchroni-
zation constraint. Depending on the approach, this may be achieved easily through
some local modiﬁcation or it may require a cascade of changes in synchronization
constraints. In some cases it may even be needed to modify the inheritance hierarchy.
Most of the other aspects discussed above come into play when considering this
issue.

Exploring the Language Design Space

49

2.4

Exploring the Language Design Space

We now propose to compare the various approaches to the design of COOPLs by system-
atically exploring the language design space and evaluating design choices against the re-
quirements speciﬁed in the previous section. Since the various aspects of the design space
are sometimes intertwined, we will ﬁnd ourselves returning to common issues on occa-
sion.  Basically  we  will  take  the  following  course:  ﬁrst  we  brieﬂy  consider  the  three
categories of object models; then we consider object interaction mechanisms in combina-
tion with internal concurrency; ﬁnally we explore inheritance and synchronization con-
straints as a topic worthy of separate study. We summarize our conclusions in section
2.4.4.

2.4.1 Object Models

By the requirement of mutual exclusion, we can immediately discount the orthogonal
object model as it provides no default protection for objects in the presence of concurrent
requests. The reusability of workers and workload managers is clearly enhanced if they
will function correctly independently of assumptions of sequential access.

The heterogeneous model is similarly defective since one must explicitly distinguish
between active and passive objects. A generic administrator would be less reusable if it
would have to distinguish between active and passive workers. Similarly worker reusabil-
ity is weakened if we can have different kinds of workers.

The homogeneous object model is the most reasonable choice with respect to reusabil-

ity. No distinction is made between active and passive objects.

Note that it is not clear whether the performance gains one might expect of a hetero-
geneous model are realizable since they depend on the programmer’s (static) assignment
of objects to active or passive classes. With a homogeneous approach, the compiler could
conceivably make such decisions based on local consideration — whether a component is
shared by other concurrently executing objects is application speciﬁc and should be inde-
pendent of the object type.

2.4.2 Object Interaction Mechanisms

Request-reply mechanisms such as an RPC-like interface provide more support for object
reuse. Using our administrator example, we can see that one-way message passing has
several disadvantages over RPC for reusing objects. 

A concurrent client may issue several requests to the administrator before it gets a reply.
In this case it is important for the client to know which reply corresponds to which request.
Are replies returned in the same order as requests? In the case of synchronous message
passing an additional difﬁculty is that the administrator may get blocked when it sends the
reply until the client is willing to accept it. Requiring the client to accept the reply imposes

50

Concurrency in Object-Oriented Programming Languages

additional requirements on the client and makes reuse more difﬁcult. Either a different
mechanism has to be supported for sending replies or proxies have to be created. 

One-way message passing is also inconvenient for coping with the interaction between
the administrator and worker objects. A difﬁculty with using one-way messages is getting
the replies from workers: as there will be several workers that are invoked in parallel, as
well as potentially concurrent invocations of single worker, it can be difﬁcult for the ad-
ministrator to tell which reply is associated with which request.

A solution to this problem is to create a proxy for each request. The proxy would carry
out the request and then send a message to the administrator containing the worker’s reply
plus some extra information used for identifying the request. As with sequential RPC the
administrator will also have to manage local queues for partially completed requests.

Sequential Objects

2.4.2.1
We argued that an RPC interface for objects provides better support for object reuse than
one-way message passing. However, we quickly discover that if objects have a single
thread of control and RPC is the only communication mechanism, the request and reply
scheduling requirements of the administrator are not satisﬁed. We further discuss the lim-
itation of this design choice combination below. Then we show additional mechanisms
that may be used to overcome these limitations without giving up the RPC-interface or
completely discarding sequential object design choice. The limitation of the combination
of sequential objects (“modules” in their case) and RPC is discussed at length in [54].
However, they reach the conclusion that either the sequential object or the RPC choice
should be discarded. 

Limitations of the Sequential Object–RPC Combination

In particular, a sequential RPC administrator will not be able to interleave multiple clients’
requests as it will be forced to reply to a client before it can accept another request. The
only “solution” under this assumption requires the cooperation of the client, for example:
the administrator returns the name of a “request handler” proxy to the client, which the cli-
ent must call to obtain the result. In this way the administrator is immediately free to ac-
cept new requests after returning the name of the request handler. Such an approach is,
however, incompatible with the requirement on request scheduling transparency since
scheduling of requests by the administrator is not transparent to its clients. 

Consider for instance that we would like to replace the sequential implementation of an
existing object class by a parallel implementation where instances of the class act as ad-
ministrators for a collection of appropriate worker objects. In accord with our require-
ments we would like to take advantage of encapsulation and data abstraction to replace the
old implementation without having to modify the programs that used it. This, however, is
not possible since, as discussed above, in order to be able to process client requests con-
currently, an object, implemented as an administrator, has to have a different interface than
an object having a sequential implementation.

Exploring the Language Design Space

51

The sequential RPC combination also provides limited support for reply scheduling by
the  administrator.  If  the  administrator  invokes  workers  directly  using  RPC,  its  single
thread will get blocked until the invoked worker computes the result and returns the reply.
The sequential RPC combination prevents the administrator from invoking several work-
ers in parallel, or accepting further client requests while a worker computes the result and
receiving the workers’ replies at a later time.

It is also possible to have the workers cooperate with the administrator so that it does not
block when delegating work to them, but such solutions require workers to be coded in a
special way to implement the cooperation. This is incompatible with our requirement of
request scheduling transparency, which would allow any object to be potentially used as a
worker.

Using Proxies for Reply Scheduling

The limitation of the sequential RPC combination for reply scheduling can be overcome
by the use of “courier” proxies used by the administrator to invoke workers. Each time the
administrator needs to invoke a worker it creates an appropriate courier proxy that will in-
voke the worker instead. To get a worker’s reply, the administrator could invoke a method
of the corresponding courier or alternatively the courier could call an administrator’s
method when the reply becomes available.

 The former alternative has the disadvantage that the administrator may get blocked if it
invokes the courier too early. This may never occur with the latter approach. However, the
administrator has to manage local queues for replies that are sent to it and that it cannot use
immediately. Furthermore, each time a reply is returned, it should check whether all the
replies needed so far for handling a client’s request are available so that it may proceed
with the client’s request.

The use of proxy objects for carrying out requests and for storing replies is also needed

in the case of one-way message passing for allowing requests to be paired with replies. 

Although proxies are a general programming approach, it is cumbersome to program
and use them explicitly. In fact unless the language supports classes with type parameters
and a ﬂexible manipulation of method names, a new proxy class would have to be deﬁned
for each different worker class in an administrator application. 

Future variables in ABCL/1 [94], the process type in PAL [18] and CBox objects in
ConcurrentSmalltalk [92] provide functionality which is somewhat similar to the courier
proxies that were used by the administrator to call workers. These mechanisms could be
used by the administrator to call workers without getting blocked and for collecting work-
er replies at a later time.

 The advantage of these mechanisms over program-deﬁned proxies is that they can be
used for calling workers of any class. Future variables, however, are not ﬁrst-class objects
and so are not as ﬂexible. For instance, a future variable cannot be sent in a message allow-
ing a different object than the one that made the request to receive the reply.

52

Concurrency in Object-Oriented Programming Languages

A difﬁculty with built-in proxies is that the administrator may at some point in time
have to get blocked and wait for a further client request or the reply to a previous worker
request. Unless there exists a synchronization mechanism that allows the administrator to
wait on either of these events, the administrator may get blocked to obtain a reply or re-
quest that is not available and will thus be unable to accept other requests or replies. This
problem could be circumvented either by polling if a non-blocking request acceptance
mechanism is supported or by additional, explicitly programmed proxies that would re-
turn the replies by invoking some administrator’s operation especially provided for that
purpose. This way a synchronization mechanism for selectively accepting requests would
allow the administrator to be woken up either for receiving the results of a previous re-
quests or for accepting new requests.

Still, the administrator’s code may get quite involved. If there is no way to prevent being
woken up by messages containing client requests or worker replies that cannot be used
right away, local message queues will have to be managed by the administrator. So, it ap-
pears that built-in proxies combined with single-thread objects provide limited support for
reply scheduling by the administrator since one should again rely on the use of explicitly
programmed proxies.

Combining Request/Reply and One-Way Message Passing

It is also possible to relax the RPC style of communication without going all the way to
supporting one-way message passing as the main communication primitive. This has the
advantage that it is possible to present an RPC interface to clients and, at the same time,
obtain more ﬂexibility for processing requests by the administrator. This possibility is il-
lustrated by ABCL/1 [94] which permits the pairing of an RPC interface at the client side
with one-way asynchronous message passing at the administrator’s side. Moreover, the
reply message does not have to be sent by the administrator object. This provides even
more ﬂexibility in the way that the administrator may handle requests since the replies
may be directly returned to the client by proxies. The following segment of code shows
how this is accomplished.
 The RPC call at the client side looks like:

result := [ administrator <== :someRequest arg1 ... argn] ...

A message is sent to the administrator to execute the request someRequest with arguments
arg1,...,argn. The client is blocked until the reply to the request is returned and the result is
stored in the client’s local variable result.

At the administrator’s side the client’s request is accepted by matching the message pat-

tern:

(=> :someRequest arg1 ... argn @ whereToReply 

.... actions executed in response to this request ... )

When the administrator accepts this request, the arguments are made available in the
local variables arg1,...,argn and the reply destination of the request in the local variable

Exploring the Language Design Space

53

whereToReply. The reply destination may be used as the target of a “past type,” i.e. asyn-
chronous, message for returning the reply to the client. As a reply destination may also be
passed around in messages, it is possible for another object to send the reply message to
the client. This action would look like:

[ whereToReply <== result ]

where whereToReply is a local variable containing the reply destination obtained by the
message acceptance statement shown above, and result is the result of the client’s request.
Another interesting way of using the possibility to combine one-way message passing
with RPC is for ﬂexible reply scheduling by the administrator. In the previous section, on
built-in proxies, we mentioned that a difﬁculty was that the administrator should be able
to wait to accept both returned replies and further requests. A way to circumvent this prob-
lem was to use explicitly programmed proxies that would return results by invoking some
operation provided by the administrator. In this way, replies were returned by requests so
that a request acceptance mechanism was sufﬁcient for allowing the administrator to wait
for  both  requests  and  replies.  A  different  approach  is  possible  by  pairing  one-way
messages  to  the  RPC  interface  supported  by  workers.  With  this  approach,  the
administrator may use a past type message, with itself as reply destination, for calling the
workers  which  present  an  RPC  interface.  The  replies  from  the  workers  can  then  be
received  by  the  administrator  as  any  past-type  message  request.  This  allows  the
administrator to use the message acceptance mechanism for receiving both requests and
replies.

This approach has, however, some of the drawbacks of one-way message passing: some
extra work is needed in order to ﬁnd out which reply message is related to what request and
also that the administrator has to manage queues for replies that may not be used immedi-
ately. 

2.4.2.2 Multi-Threaded Objects
Another way for allowing the administrator to service several concurrent requests is by
supporting multiple concurrent or quasi-concurrent threads. A separate concurrent thread
may now be used for handling each client request. However, depending on the mecha-
nisms provided for thread creation and scheduling, it may still be necessary to resort to the
solutions discussed previously in order to achieve a satisfactory level of concurrency in
the processing of client requests. 

We consider in turn quasi-concurrent and concurrent approaches and examine the sup-
port provided by the thread creation and scheduling mechanisms for programming admin-
istrators.

Quasi-Concurrent Approaches

A traditional example of “objects” with quasi-concurrent thread structure is provided by
monitors  [42]  [21].  However,  monitors  present  some  well-known  difﬁculties  such  as
“nested monitor calls,” and they unduly constrain parallelism [56] [77] [20] when used as

54

Concurrency in Object-Oriented Programming Languages

the main modular units of concurrent programs. These limitations are due to some extent
to the quasi-concurrent structure of threads. However, an approach based on monitors
would also constrain concurrency among different objects because of its limited support
for reply scheduling. Assuming that the administrator is a monitor, then when calling a
worker the monitor would remain blocked until the invoked operation would return. This
situation, called remote delay [53], makes it impossible for the administrator to accept
further client requests or to call a second worker.

 Consequently, certain object-oriented languages have adopted more ﬂexible varia-
tions. For example, Emerald [19] uses monitors as deﬁned by Hoare [42]. However, not all
operations of an object have to be declared as monitor procedures and also several inde-
pendent monitors may be used in the implementation of an object. Lock blocks and wait
queues in Trellis/Owl [68] also allow for more ﬂexible implementation schemes than if
objects were identiﬁed to monitors. With this approach, however, objects in these lan-
guages are not quasi-concurrent any more.

The restricted support for concurrency among objects by monitors is not due to the
quasi-concurrent  structure  of  objects,  but  rather  to  the  limited  ﬂexibility  for  reply
scheduling.  This  is  illustrated  by  the  second  quasi-concurrent  approach  we  examine
which by providing a more ﬂexible reply scheduling scheme does not restrict concurrency
among objects.

 Hybrid [71] is another language which adopts a quasi-concurrent thread structure for
objects. However, in contrast to monitors, the delegated call mechanism provides a more
ﬂexible reply scheduling approach that does not restrain concurrency among objects. The
administrator may use the delegated call mechanism to invoke workers. In such a case a
new thread may be activated in the administrator for processing another client request in
the meantime.

The delegated call mechanism is satisfactory for allowing the administrator to accept
further client requests while a worker is executing a previous request, thus providing sup-
port for concurrency among several client requests. However, it is of no help for allowing
several workers to execute in parallel for a single client request.

This may only be done by using proxies for invoking the workers or by a construct for
specifying the creation of a new quasi-concurrent thread. Such a construct was proposed
in  the  original  design  of  Hybrid.  The  newly  created  quasi-concurrent  threads  would
resume each other by using delegated calls. This construct was not included in the proto-
type because it substantially increased the complexity of the rules for message accept-
ance.

Concurrent Objects

With concurrent threads it is straightforward to process several client requests concurrent-
ly by creating a new thread for processing each client request. Provided that satisfactory
mechanisms  are  supported  for  constraining  the  creation  and  activation  of  concurrent
threads, this does not result in the mutual exclusion problems of languages with an orthog-

Exploring the Language Design Space

55

onal object model. The concurrent execution that may take place is explicitly speciﬁed by
the programmer and the scope of the potential interference of the concurrent threads is re-
stricted to the state of a single object. 

Provided that there is some way to suspend the execution of a concurrent thread or avoid
its creation, languages that support concurrent threads provide adequate support for re-
quest scheduling and for internal concurrency to the extent that several client requests may
be processed concurrently.

A different issue that is not necessarily addressed by the support for concurrent threads
is the possibility to use concurrency for processing a single request. Unless the creation of
multiple threads can be initiated by the object, the support for reply scheduling of concur-
rent threads is not sufﬁcient for processing a request in parallel.

For example, the language Sina [84] makes it possible to use several concurrent threads
within an object for processing requests; there is no direct means, however, for one of
these threads to create more threads for calling the worker objects in parallel. This is done
indirectly by creating a courier proxy, as described previously. It is therefore not necessar-
ily redundant to support both multiple threads and non-blocking communication primi-
tives.

A satisfactory way for calling workers in parallel without using proxies or asynchro-
nous message passing is to support a construct by which more threads may be created in
the object. In this case a worker can be called by each of these threads in an RPC fashion.
With quasi-concurrent threads, a call to a worker should trigger the execution of another
thread. In SR the code segment of the administrator that is used for issuing requests to
workers in parallel would look like this:

result1 := w1.doWork(...) -> loadManager.terminated(w1)
result2 := w2.doWork(...) -> loadManager.terminated(w2)

co
//
oc
globalResult := computResult(result1,result2);
...

2.4.3 Inheritance and Reuse of Synchronization Constraints

A large body of research has concentrated on the issues of making effective use of inher-
itance  in  COOPLs  as  well  as  on  the  related  issue  of  reusing  synchronization  con-
straints.We will provide a brief overview of this work. Then we will turn our attention to
the issues discussed in section 2.3.2 and illustrate the issues and how they are addressed
by various language designs putting particular emphasis on some points that have not
received the attention they deserved in related work. More extensive presentations and
systematic  comparisons  of  the  proposals  for  supporting  inheritance  and  the  reuse  of
synchronization constraints may be found in [63] [60] and [16].

56

Concurrency in Object-Oriented Programming Languages

2.4.3.1 A Brief Overview of Related Research
Eiffel// [26][27] and Guide [34][48] were two of the earliest proposals that attempted to
combine inheritance and synchronization constraints by removing the constraints from
the bodies of methods. 

These approaches presented some shortcomings with respect to the ability to extend the
synchronization constraints to account for new methods introduced by subclasses. The
problems were independently identiﬁed by Kafura and Lee [45] and Tomlinson and Singh
[83], who in turn proposed their own approaches for overcoming them. A common aspect
of these proposals is that constraints are speciﬁed by associating sets of methods to ab-
stractions of the object state in which they can be executed. The main idea was that the set
of methods would be extended in subclasses with the additional methods. 

Matsuoka et al. [62], however, showed that there existed certain cases, called inherit-
ance anomalies, where new state abstractions would have to be introduced in subclasses,
consequently requiring extensive redeﬁnition of inherited methods. Matsuoka later pro-
posed his own approach, where he retained the idea of sets of acceptable methods, and
provided a combination of guards and accept sets allowing the best technique to be used
for the problem at hand.

 The issue of extending and combining inherited constraints was also addressed in var-
ious other proposals, notably: Synchronizing Actions [69], Scheduling Predicates [59],
Ceiffel [57], Frølund’s framework [37], PO [29], SINA [16] and SPN [74]. It is important
to note that Synchronizing Actions and SPN are two of the very few proposals to consider
the issue of suspending method execution, which is important for reply scheduling.

The language DRAGOON [13] [14] supports the speciﬁcation of generic synchroniza-
tion constraints and provides a special inheritance mechanism separate from class inher-
itance of sequential aspects of classes for reusing these synchronization constraints. 

Meseguer [67] has proposed a somewhat different approach for avoiding the problems
related to the use of inheritance in COOPLs. He proposes to eliminate the synchronization
code which causes inheritance anomalies. His language is based on a concurrent rewriting
logic; the use of appropriate rewrite rules allows the speciﬁcation of synchronization with-
out introducing inheritance anomalies.

Synchronizers [38] is an approach for the speciﬁcation of synchronization constraints
that allows constraints to be associated to objects dynamically. An interesting point about
this proposal is that constraints may depend on the state and computation history of sever-
al other objects.

Binding Mechanisms for Synchronization Constraints

2.4.3.2
The most direct way to associate synchronization constraints to methods is to specify
them together as part of a class deﬁnition. Constraints deﬁned in a class are inherited by
the  ordinary  class  inheritance  mechanism.  Such  an  approach  is  followed  by  most
COOPLs, such as Guide, PO, PROCOL and ACT++, to name a few. This approach, how-
ever, has the shortcoming that it may be difﬁcult to apply constraints to different classes.
A ﬁrst problem is with method names: if constraints refer to particular method names of
the class in which they are deﬁned, it will be difﬁcult to apply them to classes where meth-

Exploring the Language Design Space

57

with SIMPLE;
class UNI_BUFFER
      introduces
           procedure PUT(I : in SIMPLE.ITEM);
           procedure PEEK (NB: out INTEGER);

end UNI_BUFFER;

(a)

class body UNI_BUFFER is

   ... deﬁnition of the instance variables and
        implementation of the operations...

end UNI_BUFFER;

(b)

(c)

(d)

behavioural class READERS_WRITERS is
ruled  WOP, ROP;
where
           per (WOP) <=> active(WOP) + active(ROP) = 0;
           per(ROP) <=> (active(WOP) = 0) and (requested(WOP) = 0);

end READERS_WRITERS;

class READERS_WRITERS_UNI_BUFFER

inherits UNI_BUFFER
ruled by READERS_WRITERS
where 

PUT => WOP, 
PEEK => ROP

end;

Figure 2.6   Constraint deﬁnition in DRAGOON.

ods have different names. Another problem comes from the use of class inheritance for
reusing constraints. If one uses class inheritance to reuse the constraints, the methods
deﬁned in the class are also inherited. Below we examine some approaches that have been
proposed for addressing these problems. 

Genericity of Synchronization Constraints in DRAGOON

DRAGOON [13] [14] is an example of a language that supports the speciﬁcation of gener-
ic synchronization constraints and of one that dissociates inheritance from the mechanism
used for binding synchronization constraints to a class’s methods. Generic constraints are
deﬁned as behavioural classes (b-classes). The constraints may be applied to a sequential
class having no associated constraints, through the b-inheritance (behavioural) mecha-
nism. This mechanism is independent from the inheritance mechanism (f-inheritance)
used for sequential classes. Figure 2.6 shows an example of the use of the constraint deﬁ-
nition and binding mechanism in DRAGOON. A class UNI_BUFFER is deﬁned in (a) and
(b) with methods PUT and PEEK used to insert a new element into the buffer and to exam-
ine the number of elements in the buffer. In (c) a generic constraint READERS_WRITERS

58

Concurrency in Object-Oriented Programming Languages

is deﬁned for controlling execution of the methods of a class according to the readers, and
writers,  scheduling  policy  [81]. This  synchronization  constraint  is  bound  to  the  class
UNI_BUFFER in (d) where PUT is associated with the constraints for writers and PEEK with
the ones for readers.

Using the Inheritance mechanism of Beta

A similar effect for specifying and binding constraints may be achieved by using the inner
mechanism of Beta. In Beta a method in a subclass is associated with the superclass meth-
od it specializes. Instead of the subclass method explicitly invoking the superclass method
through the use of super mechanism, as in Smalltalk, the superclass method is always in-
voked, and subclasses may only introduce additional behaviour at the point where the key-
word inner occurs. In a sense, the execution of the superclass method is wrapped around
the invoked subclass method. First are executed the actions in the superclass method that
precede inner, then the subclass method is executed, then the actions of the superclass
method that follow inner are executed.

This feature may be combined with low-level synchronization mechanisms, such as
semaphores, to implement classes that encapsulate generic synchronization policies that
can be applied to methods deﬁned in subclasses in a way similar to how it is done in DRA-
GOON.

Assume there is a class ReaderWriterSched (not shown) with methods reader and writer
that use semaphores to implement a reader/writer scheduling policy for the methods read-
er and writer. This synchronization may be applied to a class SynchedBuffer with operations
empty, get, put as follows:

SynchedBuffer: @ |   ReaderWriterSched
(# .... instance variables....

peek: 
get:
put:

Reader(# ...implementation of peek... #)
Writer(# ...implementation of get... #)
Writer(# ....implementation of put..#)

#)

This allows the execution of peek to be constrained according the synchronization con-
straints of a reader, whereas get and put are synchronized according to the synchronization
constraints that apply to writers. More on the use of inheritance in Beta to deﬁne generic
synchronization policies can be found in [58].

Method Sets and Abstract Classes in ABCL/AP100

The method set feature provided in this language may be combined with abstract classes
to deﬁne generic synchronization constraints that can be applied to several classes. Meth-
od sets are speciﬁed as part of class deﬁnitions, and are associated with synchronization
constraints. Method sets can be inherited and modiﬁed in subclasses. Systematic use of

Exploring the Language Design Space

59

methods sets solves the problem of applying constraints to classes with different method
names. The possibility of combining method sets with abstract classes (classes where not
all methods are deﬁned) can be used to provide facilities similar to those of DRAGOON.
Abstract classes, making systematic use of method sets in synchronization constraints,
can be used to represent generic constraints similar to DRAGOON’s b-classes. However,
in contrast to DRAGOON, programmers have to use the features provided by the language
in a disciplined way. Another interesting feature of this language, discussed below, is that
it is possible to combine synchronization constraints.

Polymorphism and Synchronization Constraints

2.4.3.3
Polymorphism of synchronization constraints is concerned with the potential applicabili-
ty of constraints to different classes provided that the language supports an appropriate
binding mechanism. There are two potential deﬁciencies with respect to this issue in ap-
proaches for specifying synchronization. The ﬁrst is related to the use of instance varia-
bles in conditions constraining the activation of methods. The second concerns the use of
constraints that specify mutual exclusion among methods in languages that support intra-
object concurrency.

The  ﬁrst  deﬁciency,  also  discussed  by  Bergmans  [16],  occurs  in  the  proposals  of
Frølund [37] and Matsuoka [63], and in Guide and PROCOL, to cite a few examples. In
these languages the conditions that are used in their constraints reference the object’s in-
stance variables. This makes it difﬁcult to apply the constraints to classes implemented in
a way that does not require these instance variables. Moreover, it makes it difﬁcult to
change the implementation of a class without having to consider the instance variables ref-
erenced in the constraints and, eventually, modifying the constraints as well. The problem
may also be more severe than just modifying the constraints of a single class, as the con-
straints to be modiﬁed may be used by other subclasses as well. This could cause the re-
examination and adjustment of the constraints of several subclasses of the class that was
modiﬁed.

Two approaches have been be followed for alleviating this problem. First, instead of ac-
cessing directly the instance variables, conditions could be speciﬁed through a function
that accesses the object state indirectly. If the implementation had to be modiﬁed, only
these functions would need to be modiﬁed to account for the changes in the object state.
This approach is followed for this precise reason by Sina in the way conditions are speci-
ﬁed in wait ﬁlters [16] as well as in the speciﬁcation of state predicates [74]. A second
approach is to use condition variables to maintain an abstract state that is separate from the
actual  class  implementation  and  is  used  purely  for  synchronization  purposes.  This
approach is followed Synchronizing Actions, DRAGOON and PO.

The second potential deﬁciency occurs in languages with intra-object concurrency. In
several languages with intra-object concurrency, such as Guide, DRAGOON and PO, syn-
chronization constraints specify mutual exclusion properties among methods. The main
reason for imposing mutual exclusion constraints on method executions is that method
implementations access common instance variables. However, a different or modiﬁed im-
plementation of a class may use a different set of instance variables and may have different

60

Concurrency in Object-Oriented Programming Languages

needs for mutual exclusion. Consequently, constraints that specify mutual exclusion prop-
erties among methods may ﬁnd limited applicability to classes with a different implemen-
tation. Also,  modifying  the  implementation  of  a  class  to  which  such  constraints  are
attached, as discussed above for guards that reference instance variables, may cause the
modiﬁcation of the constraints attached to several classes. This problem, however, has not
received any attention by other work in the area.

Extensibility and Compositionality 

2.4.3.4
In languages such as DRAGOON, the issue of combining synchronization constraints is
avoided by the way the language is designed; inheritance is not allowed among classes that
are associated with synchronization constraints, r-classes, or the classes (b-classes) that
are  use  to  describe  the  constraints  themselves.  This  approach  has  advantages  and
disadvantages. The separation of constraints from classes allows the use of inheritance
between f-classes without having to be concerned how the associated constraints would
have to be combined. The disadvantage is that there is no support for reusing constraints
in the deﬁnition of new ones.

In other languages the issue of combining constraints is addressed either because class
inheritance mechanism is tight up to the constraint binding mechanism or to allow con-
straints to be deﬁned incrementally. 

Frølund [37] proposed an approach for combining constraints of a class with those in-
troduced in subclasses based on the view that constraints should become stricter in sub-
classes.  The  proposed  approach  for  combining  constraints  supports  this  view  by
incrementally combining conditions that disable method execution. This way conditions
may only become more strict in subclasses. 

Matsuoka [63] provides a more elaborate way of combining constraints through modi-
ﬁcation of method sets and by the fact that method sets are recomputed in a subclass taking
into account the full set of methods including the methods inherited from all superclasses.
For instance, the method set all-except(LOCKED), where LOCKED is another method set de-
ﬁned elsewhere, denotes all the object’s methods except the ones in LOCKED. This method
set is recomputed in subclasses to account for additional methods deﬁned in the subclass
or inherited from other superclasses. Such features enable the deﬁnition of mixins that can
be combined with the constraints of other classes to obtain the synchronization behaviour
speciﬁed by the mixin. An example of such a mixin class is presented in [63].

A powerful way of composing synchronization constraints is also provided by wait ﬁl-
ters in Sina. In order to get accepted, messages are matched against patterns of wait ﬁlters.
Wait ﬁlters are associated with conditions, a form of guards, that must be true to let match-
ing messages go through the ﬁlter. Filters can be stacked at the interface of an object and
messages have to traverse all of them before being accepted by the object. Bergmans
shows in [16] how this approach can be used for the locking mixin and for other constraint
composition examples. The locking mixin discussed above can be realized by a class that
provides a wait ﬁlter that matches all messages but unlock and is associated with a condi-
tion, Unlocked, that is true only when the object is unlocked. Lock and Unlock methods
change the state of a lock object so as to render the Unlock condition false and true respec-

Exploring the Language Design Space

61

tively. A lock object can be used in the deﬁnition of another class in such a way that mes-
sages have to go through its ﬁlter ﬁrst. In this way the synchronization constraint deﬁned
by lock can be reused in other classes.

PO [29] also supports the composition of constraints deﬁned in superclasses of a class.
In contrast to the proposals of Frølund and Matsuoka, where objects are single-threaded,
PO constraints are designed for objects with internal concurrency. Constraints on the par-
allel execution of methods are partially ordered in a lattice with fully parallel execution of
methods at the top and mutual exclusion among all methods at the bottom of the lattice.
When incompatible constraints are inherited from different superclasses, they are com-
pared according to this order and the more strict constraint is retained.

2.4.3.5 Combining Inheritance with Request/Reply Scheduling
In most work on the design of mechanisms for the speciﬁcation and reuse of synchroniza-
tion constraints, little attention has been paid to the eventuality that methods may have to
be suspended halfway through their execution. However, as we discussed in section 2.4.2
this may be necessary to support reply scheduling. The possibility of suspending methods
using mechanisms designed for the reuse of synchronization constraints is addressed in
Synchronizing Actions [69] and in the design of the state predicate [74] mechanism. 

Synchronizing Actions are based on multi-thread objects. The execution of a method
may be suspended by calling, through self, another method with a pre-action such that the
call is delayed. This approach may be used to support request and reply scheduling for the
administrator as shown in ﬁgure 2.7. The administrator calls workers by creating proxy
objects that do the actual call. After creating a proxy the administrator thread is suspended
by calling the method suspend. The proxy calls the worker and when the call returns it calls
the workerDone method to cause the administrator thread to be resumed. Figure 2.7 illus-
trates the implementation of the administrator concentrating on the synchronization as-
pects.  Other  languages  that  support  internally  concurrent  objects  and  ﬂexible
speciﬁcation of synchronization constraints, for instance Guide or Sina, could be used in
a  similar  way. This  approach,  however,  has  some  shortcomings.  First,  its  complexity
would make it difﬁcult to use in practice. Second, it relies on the assumption that methods
invoked through self are subject to the same constraints as invocations from other objects.
This may not be appropriate when self is used in conjunction with inheritance to reuse al-
gorithms deﬁned in abstract superclasses. 

The state predicate approach [74] provides a simpler and more direct way for suspend-
ing method execution based on a state predicate. The effect is similar to the one achieved
by the approach discussed above. However, the resulting code is simpler as thread suspen-
sion and resumption is supported by the language and the complications deriving from the
need to call the objects methods through self are avoided. 

2.4.4 Summary

 Below we present our observations with respect to reuse issues resulting from our explo-
ration of language design approaches. 

62

Concurrency in Object-Oriented Programming Languages

class Admin;
concurrency_control:

boolean worker_ﬁnished := false, 

admin_idle := true;

method suspend()
matching (true)
pre { admin_idle := true }
action{ 

self!waitWorker ()

 }
post { admin_idle := false}

method waitWorker()

matching (worker_ﬁnished );
pre { worker_ﬁnished := false;admin_idle := false
}
action { }
post { };

method workerDone()

matching (true)
pre { worker_ﬁnished := true }
action {  }
post { }

method request()

matching ( admin_idle )
pre { admin_idle := false}
action {

do some local processing...
request := worker_proxy.doWork();
self!waitWorker ();
...some more processing...

}
post { admin_idle := true };

Figure 2.7    Request/reply scheduling with synchronization constraints.

Object-Based Features

• Homogeneous object models promote reuse: Concurrent applications can safely re-
use objects developed for sequential applications; efﬁciency need not be sacriﬁced.
• Sequential objects with strict RPC are inadequate: Request scheduling and internal
concurrency can only be implemented by sacriﬁcing the RPC interface; the solution
is either to support concurrent threads or to relax the strict RPC protocol.

• One-way message passing is expressive but undesirable: Since higher-level request-
reply protocols must be explicitly programmed, development and reuse of objects is
potentially more error-prone.

• Acceptance of concurrent requests is handled well either by concurrent threads or by

explicit request/reply scheduling. 

• Issuing concurrent requests is handled well by one-way message passing, by proxies
or by internal concurrency: The combination of both concurrent threads and non-
blocking communication primitives may be appropriate for handling the separate
issues of accepting and issuing concurrent requests.

•  Built-in proxies used by sequential objects with non-blocking request issuing mech-
anisms provide adequate support for reply scheduling but are weak at combining
reply and request scheduling.

•  Both concurrent objects and multi-object approaches are useful for internal concur-
rency: These approaches for internal concurrency are both useful for different pur-
poses. Concurrent threads make it easy to implement objects that may service several
concurrent requests that do not modify the objects state. Multi-object approaches are

Conclusion

63

interesting when the implementation of a new object class, with internal concurren-
cy, may be realized by using several concurrently executing instances of existing
object classes.

Inheritance and Synchronization Constraints

• Synchronization constraints should not be hardwired in methods: If the synchroniza-
tion code that schedules the execution of methods is hardwired in methods, it will be
necessary to modify the method code in order to meet the constraints of other classes. 
• Multiple threads are needed to cope with reply scheduling: To support reply sched-
uling it is important to be able to suspend the execution of a method. However, it
seems difﬁcult to do this if synchronization code is kept separate from methods to
support inheritance.

• Method suspension and resumption should be taken into account by synchronization
constraints: Taking into account the suspension of method execution by the mecha-
nism that implements the synchronization constraints makes it simpler to program
reply scheduling problems without compromising the reusability of methods.

• Speciﬁcation of mutual exclusion may lead to non-polymorphic constraints: Mutual
exclusion properties of methods are often related to the way methods access instance
variables.  Such  constraints  may  thus  not  be  applicable  to  classes  with  different
instance variables or in which methods access instance variables in a different way.
Including mutual exclusion speciﬁcations in constraints makes them less reusable.
• It is advantageous to separate the reuse of constraints from inheritance. It is easier to
reuse synchronization constraints is they are speciﬁed generically and if their appli-
cation to different classes is not accomplished through class inheritance. 

2.5 Conclusion 

Integrating concurrency and object-oriented programming is not as easy as it may seem at
a ﬁrst sight. There is no major difﬁculty in introducing both object-oriented and concur-
rency features in a single language. However, arbitrary combinations of concurrency and
object-oriented features do not allow programmers draw the beneﬁts of object-oriented
programming for the development of concurrent systems. These difﬁculties have fostered
substantial research in the past few years in the design of languages that gracefully in-
tegrate both kinds of features. However, the interference of the features occurs in several
aspects of language design and the various proposals are not equally successful in all these
aspects.

In this chapter we have discussed a number of issues that should be addressed in various
aspects of language design, and we have formulated some criteria to use in evaluating de-
sign choices. We have used these criteria to evaluate various proposals, and we have illus-
trated the issues by examining speciﬁc languages. The languages discussed were chosen
to illustrate particular points rather than to present a complete survey of all existing pro-

64

Concurrency in Object-Oriented Programming Languages

posals. It was not our intention to compare individual languages; other issues not dis-
cussed  in  this  chapter  would  have  to  be  considered  in  such  an  endeavour.  Different
considerations come in to play, for example, when designing a language for rapid proto-
typing or a language for programming embedded systems.

We have presented some guidelines for the design of languages that support the basic
object-oriented features promoting reuse. Although these seem to be necessary conditions
more is needed to achieve reuse at a larger scale. These are research issues which are dis-
cussed in other chapters. The further development and the use of techniques for reuse at a
larger scale for developing concurrent systems may provide more criteria for evaluating
language features and may result in more requirements on language design.

References

[1] Gul Agha, ACTORS: A Model of Concurrent Computation in Distributed Systems, MIT Press, Cam-

bridge, Mass., 1986.

[2] Gul Agha and C. J. Callsen, “ActorSpace: An Open Distributed Programming Paradigm,” Proceed-
ings 4th ACM Conference on Principles and Practice of Parallel Programming, ACM SIGPLAN No-
tices, vol. 28, no. 7, 1993, pp. 23–323

[3] Alfred V. Aho, Ravi Sethi and Jeffrey D. Ullman, Compilers Principles, Techniques and Tools, Addi-

son-Wesley, Reading, Mass., 1986.

[5]

[4] Mehmet Aksit, Ken Wakita, Jan Bosch, Lodewijk Bergmans and Akinori Yonezawa, “Abstracting Ob-
ject Interactions Using Composition Filters,” Proceedings of the ECOOP ’93 Workshop on Object-
Based Distributed Programming, ed. R. Guerraoui, O. Nierstrasz, M. Riveill, Lecture Notes in Com-
puter Science, vol. 791, Springer-Verlag, 1994, pp. 152–184 
Pierre America, “Inheritance and Subtyping in a Parallel Object-Oriented Language,” Proceedings
ECOOP ’87, ed. J. Bézivin, J-M. Hullot, P. Cointe and H. Lieberman , Lecture Notes in Computer Sci-
ence, vol. 276, Springer-Verlag, Paris, 1987, pp. 234–242. 
Pierre America, “POOL-T: A Parallel Object-Oriented Language,” in Object-Oriented Concurrent
Programming, ed. A. Yonezawa and M. Tokoro, MIT Press, Cambridge, Mass., 1987, pp. 199–220.
Pierre America,  “A  Behavioural Approach  to  Subtyping  in  Object-Oriented  Programming  Lan-
guages,” in Proceedings of the Workshop on Inheritance Hierarchies in Knowledge Representation
and Programming Languages, Viareggio, Italy, Feb. 1989, pp. 141–156.
Pierre America and Frank van der Linden, “A Parallel Object-Oriented Language with Inheritance
and Subtyping,” Proceedings OOPSLA’90, ACM SIGPLAN Notices, vol. 25, no. 10, ACM Press, Oct.
1990, pp. 161–168.

[8]

[6]

[7]

[9] American National Standards Institute, Inc., The Programming Language Ada Reference Manual,

Lecture Notes in Computer Science, vol. 155, Springer-Verlag, 1983.

[10] S. Andler, “Predicate Path Expressions,” in Proceedings of 6th ACM POPL, ACM SIGPLAN Notices,

1979.

[11] Gregory R. Andrews and Fred B. Schneider, “Concepts and Notations for Concurrent Programming,”

ACM Computing Surveys, vol. 15, no. 1, March 1983, pp. 3–43.

[12] Gregory R. Andrews, R.A. Olsson and M. Cofﬁn, “An Overview of the SR Language and Implemen-

tation,” TOPLAS, vol. 10, no. 1, Jan. 1988, pp. 51–86.

[13] Colin Atkinson, Stephen Goldsack, Andrea Di Maio and R. Bayan,“Object-Oriented Concurrency

and Distribution in DRAGOON,” Journal of Object-Oriented Programming, March/April 1991.

References

65

[14] Colin  Atkinson,  Object-Oriented  Reuse,  Concurrency  and  Distribution,  Addison-Wesley/ACM

Press, 1991. 

[15] Henri E. Bal, J.G. Steiner and Andrew S. Tanenbaum, “Programming Languages for Distributed

Computing Systems,” ACM Computing Surveys, vol. 21, no. 3, Sept. 1989, pp. 261–322.

[16] Lodewijk Bergmans, “Composing Concurrent Objects,” Ph.D. Thesis, University of Twente, 1994.
[17] Ted Biggerstaff and C. Richter, “Reusability Framework, Assessment and Directions,” IEEE Soft-

ware, vol. 4, no. 2, March 1987, pp. 41–49.

[18] Anders Bjornerstedt and Stefan Britts, “AVANCE: An Object Management System,” Proceedings

OOPSLA’88, ACM SIGPLAN Notices, vol. 23, no. 11, San Diego, Nov. 1988, pp. 206–221.

[19] Andrew Black, Norman Hutchinson, Eric Jul and Henry Levy, “Object Structure in the Emerald Sys-

tem,” Proceedings OOPSLA’86, ACM SIGPLAN Notices, vol. 21, no. 11, Nov. 1986, pp. 78–86.

[20] Toby Bloom, “Evaluating Synchronisation Mechanisms,” in Proceedings of the Seventh Symposium

on Operating System Principles, ACM-SIGOPS, Dec. 1979.

[21] Per Brinch Hansen, “The Programming Language Concurrent Pascal,” IEEE Transactions on Soft-

ware Engineering, vol. SE-1, June 1975, pp. 199–207.

[22] Jean-Pierre Briot and Akinori Yonezawa, “Inheritance and Synchronisation in Concurrent OOP,” Pro-

ceedings ECOOP 87, Paris, June 1987, BIGRE, no. 54, June 1987, pp. 35–43.

[23] Jean-Pierre Briot, “Actalk: A Testbed for Classifying and Designing Actor Languages in the Small-
talk-80 Environment,” in Proceedings ECOOP 89, ed. S. Cook, British Computer Society Workshop
Series, Cambridge University Press, 1989.

[24] Roy H. Campbell and A.Nico Habermann, “The Speciﬁcation of Process Synchronisation by Path Ex-
pressions,” Lecture Notes in Computer Science, vol. 16, Springer-Verlag, New York, 1974, pp. 89–
102.

[25] Luca Cardelli and Peter Wegner, “On Understanding Types, Data Abstraction, and Polymorphism,”

ACM Computing Surveys, vol. 17, no. 4, Dec. 1985, pp. 471–523.

[26] Denis Caromel,”A General Model for Concurrent and Distributed Object-Oriented Programming,”
Proceedings ACM SIGPLAN OOPSLA 88 workshop on Object-Based Concurrent Programming,
ACM SIGPLAN Notices, vol. 24, no. 4, April 1989, pp. 102–104.

[27] Denis Caromel, “Concurrency and Reusability: From Sequential to Parallel,” Journal of Object-Ori-

ented Programming, Sept./Oct. 1990.

[28] William Cook, “A Proposal for Making Eiffel Type-Safe,” in Proceedings ECOOP 89, ed. S. Cook,

British Computer Society Workshop Series, Cambridge University Press, 1989.

[29] Antonio Corradi and L. Leonardi, “Parallelism in Object-Oriented Programming Languages,” Pro-
ceedings of IEEE International Conference on Computer Languages, March 1990, New Orleans,
IEEE Computer Society Press, pp. 261–270.

[30] P. Courtois, F. Heymans and D. Parnas, “Concurrent Control with Readers and Writers,” Communica-

tions of the ACM, vol. 14, no. 10, Oct. 1971, pp. 667–668.

[31] Brad J. Cox, Object Oriented Programming: An Evolutionary Approach, Addison-Wesley, Reading,

Mass., 1986.

[32] Stefano Crespi Reghizzi, G. Galli de Paratesi and S. Genolini, “Deﬁnition of Reusable Concurrent
Software Components,” Lecture Notes in Computer Science, vol. 512, Springer-Verlag, July 1991,
Proceedings of ECOOP 91, Geneva, pp. 148–166.

[33] S. Danforth and Chris Tomlinson, “Type Theories and Object-Oriented Programming,” ACM Com-

puting Surveys, vol. 20, no. 1, March 1988, pp. 29–72.

[34] Dominique Decouchant, Sacha Krakowiak, M. Meysembourg, Michel Rivelli and X. Rousset de Pina,
“A Synchronisation Mechanism for Typed Objects in a Distributed System,” Proceedings ACM SIG-
PLAN OOPSLA 88 workshop on Object-Based Concurrent Programming, ACM SIGPLAN Notices,
vol. 24, no. 4, April 1989, pp. 105–107.

66

Concurrency in Object-Oriented Programming Languages

[35] L. Peter Deutsch, “Reusability in the Smalltalk-80 Programming system,” in IEEE Tutorial on Soft-

ware Reusability, 1987.

[36] L. Peter Deutsch, “Design Reuse and Frameworks in the Smalltalk-80 system,” in Software Reusabil-

ity, ed. T. J. Biggerstaff and A. J. Perlis, vol. 2, ACM Press, 1989, pp. 57–71.

[37] Svend Frølund, ‘‘Inheritance of Synchronization Constraints in Concurrent Object-Oriented Pro-
gramming Languages,’’ Proceedings ECOOP 92, ed. O. Lehrmann Madsen, Lecture Notes in Com-
puter Science, vol.615, Springer-Verlag, Utrecht, June/July 1992, pp. 185–196. 

[38] Svend Frølund and Gul Agha, “A Language Framework for Multi-Object Coordination,” Proceedings

ECOOP’ 93, Lecture Notes in Computer Science, vol. 707, July 1993, pp. 346–360.

[39] Morven Gentleman, “Message Passing Between Sequential Processes: the Reply Primitive and the

Administrator Concept,” Software—Practice and Experience, vol. 11, 1981, pp. 435–466.

[40] Adele Goldberg and David Robson, Smalltalk-80: The Language and its Implementation, Addison-

Wesley, Reading, Mass., 1983.

[41] C. A. R. Hoare, “Proof of correctness of data representations,” Acta Informatica, vol. 1, Feb. 1972, pp.

271–281.

[42] C. A. R. Hoare, “Monitors: An Operating System Structuring Concept,” Communications of the ACM,

vol. 17, no. 10, Oct. 1974, pp. 549–557.

[43] C. A. R. Hoare, “Communicating Sequential Processes,” Communications of the ACM, vol. 21, no. 8,

Aug. 1978, pp. 666–677.

[44] Ralph E. Johnson and Brian Foote, “Designing Reusable Classes,” Journal of Object-Oriented Pro-

gramming, June/July 1988, pp. 22–35.

[45] Dennis G. Kafura and Kueng Hae Lee, “Inheritance in Actor Based Concurrent Object-Oriented Lan-
guages,” in Proceedings ECOOP’ 89, ed. S. Cook, British Computer Society Workshop Series, Cam-
bridge University Press, 1989.

[46] Alan H. Karp, “Programming for Parallelism,” IEEE Computer, 1987, pp. 43–577
[47] Dimitri Konstantas, Oscar M. Nierstrasz and Michael Papathomas, “An Implementation of Hybrid,”
in Active Object Environments, ed. D. Tsichritzis, Centre Universitaire d’Informatique, University of
Geneva, 1988, pp. 61–105.

[48] Sacha Krakowiak, M. Meysembourg, H. Nguyen Van, Michel Riveill, C. Roisin and X. Rousset de
Pina, “Design and Implementation of an Object-Oriented Strongly Typed Language for Distributed
Applications,” Journal of Object-Oriented Programming, vol. 3, no. 3, Sept./Oct. 1990, pp. 11–22 

[49] Chris Laffra, “PROCOL: A Concurrent Object Language with Protocols, Delegation, Persistence and

Constraints,” Ph.D. thesis, Erasmus University, Rotterdam, 1992.

[50] Butler W. Lampson and D.D. Redell, “Experience with Processes and Monitors in Mesa,” Communi-

cations of the ACM, vol. 23, no. 2, 1980, pp. 105–117.

[51] Henry Lieberman, “Using Prototypical Objects to Implement Shared Behavior in Object Oriented
Systems,” Proceedings OOPSLA ’86, ACM SIGPLAN Notices, vol. 21, no. 11, Nov. 1986, pp. 214–
223.

[52] Barbara Liskov, Alan Snyder, Robert Atkinson and Craig Schaffert, “Abstraction Mechanisms in

CLU,” Communications of the ACM, vol. 20, no. 8, Aug. 1977, pp. 564–576.

[53] Barbara Liskov and S. Zilles, “Programming with Abstract Data Types,” Proceedings of the ACM

Symposium on Very High Level Languages, ACM SIGPLAN Notices, vol. 9, no. 4, 1974, pp. 50–59.

[54] Barbara Liskov, Maurice Herlihy and L. Gilbert, “Limitations of Synchronous Communication with
Static Process Structure in Languages for Distributed Computing,” in Proceedings of the 13th ACM
POPL, St Petersburg, Fla., 1986.

[55] Barbara Liskov, “Distributed Programming in Argus,” Communications of the ACM, vol. 31, no. 3,

1988, pp. 300–313.

[56] A. Lister, “The Problem of Nested Monitor Calls,” ACM Operating Systems Review, July 1977, pp. 5–

7.

References

67

[57] Peter Löhr, “Concurrency Annotations for Reusable Software,” Communications of the ACM, vol. 36,

no. 9, Sept. 1993, pp.81–89.

[58] Ole Lehrmann Madsen, Birger Møller-Pedersen and Kristen Nygaard, Object-Oriented Program-

ming in the Beta Programming Language, Addison-Wesley, Reading, Mass., 1993.

[59] Ciaran McHale, Bridget Walsh, Sean Baker and Alexis Donnelly,”Scheduling Predicates,” Proceed-
ings  of  the  ECOOP’91  workshop  on  Object-Based  Concurrent  Computing,  ed.  M.  Tokoro,  O.
Nierstrasz and P. Wegner, Lecture Notes in Computer Science , vol. 612, 1992, pp. 177–193.

[60] Ciaran  McHale,  Bridget  Walsh,  Sean  Baker  and  Alexis  Donnelly,  “Evaluating  Synchronisation
Mechanisms: The Inheritance Matrix,” Technical Report, TCD-CS-92-18, Department of Computer
Science, Trinity College, Dublin 2, July 1992, (presented at the ECOOP’92 Workshop on Object-
Based Concurrency and Reuse).

[61] Pattie Maes, “Concepts and Experiments in Computational Reﬂection,” in Proceedings OOPSLA’87,

ACM SIGPLAN Notices, vol. 22, no. 12, Dec. 1987.

[62] Satoshi Matsuoka, Ken Wakita and Akinori Yonezawa, “Analysis of Inheritance Anomaly in Concur-
rent Object-Oriented Languages,” (Extended Abstract), Proceedings of OOPSLA/ECOOP’90 work-
shop on Object-Based Concurrent Systems, ACM SIGPLAN Notices, 1990.
 Satoshi Matsuoka, Kenjiro Taura and Akinori Yonezawa,“Highly Efﬁcient and Encapsulated Re-use
of  Synchronisation  Code  in  Concurrent  Object-Oriented  Languages,”  Proceedings  OOPSLA’93,
ACM SIGPLAN Notices, vol. 28, no. 10, Oct. 1993, pp. 109–129 

[63]

[64] Bertrand Meyer, Object-Oriented Software Construction, Prentice Hall, New York, 1988.
[65] Bertrand Meyer, “Reusability: The Case for Object-Oriented Design,” IEEE Software, vol. 4, no. 2,

March 1987, pp. 50–64.

[66] Bertrand Meyer, “Systematic Concurrent Object-Oriented Programming,” Communications of the

ACM, vol. 36, no. 9, Sept. 1993, pp. 56–80.

[67] José Meseguer, “Solving the Inheritance Anomaly in Object-Oriented Programming,” in Proceedings
ECOOP’93, Lecture Notes in Computer Science, vol. 707, ed. O.M. Nierstrasz, Springer-Verlag 1993.
[68] J. Eliot B. Moss and Walter H. Kohler, “Concurrency Features for the Trellis/Owl Language,” Pro-

ceedings of ECOOP ’87, BIGRE, no. 54, June 1987, pp. 223–232.

[69] Christian Neusius, “Synchronizing Actions,” Proceedings of ECOOP’91, Lecture Notes in Computer

Science, vol. 512, Springer-Verlag, July 1991, pp. 118–132.

[70] Oscar Nierstrasz, “Active Objects in Hybrid,” Proceedings OOPSLA’87, ACM SIGPLAN Notices, vol.

22, no. 12, Dec. 1987, pp. 243–253.

[71] Oscar Nierstrasz, “A Tour of Hybrid — A Language for Programming with Active Objects,” Advances
in Object-Oriented Software Engineering, ed. D. Mandrioli and B. Meyer, Prentice Hall, 1992, pp.
167–182. 

[72] Michael Papathomas and Dimitri Konstantas, “Integrating Concurrency and Object-Oriented Pro-
gramming: An Evaluation of Hybrid,” in Object Management, ed. D. Tsichritzis, Centre Universitaire
d’Informatique, University of Geneva, 1990, pp. 229–244.

[73] Michael Papathomas, “Concurrency Issues in Object-Oriented Languages,” in Object Oriented De-
velopment, ed. D. Tsichritzis, Centre Universitaire d’Informatique, University of Geneva, 1989, pp.
207–245.

[74] Michael Papathomas, “State Predicate Notiﬁers: A Concurrent Object Model,” Lancaster University

Report, April 1994.

[75] David L. Parnas, “A Technique for Software Module Speciﬁcation with Examples,” Communications

of the ACM, vol. 15, no. 5, May 1972, pp. 330–336.

[76] David L. Parnas, “On the Criteria to be Used in Decomposing Systems into Modules,” Communica-

tions of the ACM, vol. 15, no. 12, Dec. 1972, pp. 1053–1058.

[77] David L. Parnas, “The Non-Problem of Nested Monitor Calls,” ACM Operating Systems Review, vol.

12, no. 1, 1978, pp. 12–14.

68

Concurrency in Object-Oriented Programming Languages

[78] Geoffrey A. Pascoe, “Encapsulators: A New Software Paradigm in Smalltalk 80,” in Proceedings of

OOPSLA ’86, ACM SIGPLAN Notices, Sept. 1986.

[79] Alan Snyder, “Encapsulation and Inheritance in Object-Oriented Programming Languages,” ACM

SIGPLAN Notices, vol. 21, no. 11, Nov. 1986, pp. 38–45.

[80] Bjarne Stroustrup, The C++ Programming Language, Addison-Wesley, Reading, Mass., 1986.
[81] T. J. Teorey and T. B. Pinkerton, “A Comparative Analysis of Disk Scheduling Policies,” Communi-

cations of the ACM, vol. 15, no. 3, March 1972, pp. 177–184.

[82] Tom Thompson, “System 7.5: A Step Toward the Future,” Byte, August 1994.
[83] Chris Tomlinson and Vineet Singh, “Inheritance and Synchronisation with Enabled Sets,” Proceed-

ings OOPSLA ’89, ACM SIGPLAN Notices, vol. 24, no. 10, Oct. 1989, pp. 103–112.

[84] Anand Tripathi and Mehmet Aksit, “Communication, Scheduling, and Resource Management in Si-

na,” Journal of Object-Oriented Programming, Nov./Dec. 1988, pp. 24–36.

[85] Jan Van Den Bos and Chris Laffra, “PROCOL: A Parallel Object Language with Protocols,” Proceed-

ings OOPSLA ’89, ACM SIGPLAN Notices, vol. 24, no. 10, Oct. 1989, pp. 95–102.

[86] Takuo Watanabe and Akinori Yonezawa, “Reﬂection in an Object Oriented Concurrent Language,”

ACM SIGPLAN Notices, vol. 23, no. 11, 1988, pp. 306–315.

[87] Peter Wegner, “Dimensions of Object-Based Language Design,” in Proceedings OOPSLA ’87, ACM

SIGPLAN Notices, vol. 22, Orlando, Florida, Dec. 1987, pp. 168–182.

[88] Peter Wegner and Stanley B. Zdonik, “Inheritance as an Incremental Modiﬁcation Mechanism or
What Like Is and Isn’t Like,” in Proceedings ECOOP’88, Lecture Notes in Computer Science, vol.
322, Springer-Verlag, 1988, pp. 55–77.

[89] Peter Wegner, “Concepts and Paradigms of Object-Oriented Programming,” ACM OOPS Messenger,

vol. 1, no. 1, August 1990.

[90] William E. Weihl, “Linguistic Support for Atomic Data Types,” ACM Transactions on Programming

Languages and Systems, vol. 12, no. 2, 1990.

[91] Rebecca J. Wirfs-Brock and Ralph E. Johnson, “Surveying Current Research in Object-Oriented De-

sign,” Communications of the ACM, vol. 33, no. 9, Sept. 1990, pp. 104–123.

[92] Yasuhiko Yokote and Mario Tokoro, “Concurrent Programming in ConcurrentSmalltalk,” in Object-
Oriented Concurrent Programming, ed. M. Tokoro, MIT Press, Cambridge, Mass., 1987, pp. 129–
158.

[93] Yasuhiko Yokote and Mario Tokoro, “Experience and Evolution of ConcurrentSmalltalk,” in Pro-
ceedings OOPSLA ’87, ACM SIGPLAN Notices, vol. 22, Orlando, Florida, Dec. 1987, pp. 168–182.
[94] Akinori Yonezawa, Etsuya Shibayama, T. Takada and Yasuaki Honda, “Modelling and Programming
in an Object-Oriented Concurrent Language ABCL/1,” in Object-Oriented Concurrent Program-
ming, ed. M. Tokoro, MIT Press, Cambridge, Mass., 1987, pp. 55–89.

Chapter 3
Interoperation of
Object-Oriented 
Applications

Dimitri Konstantas

Abstract    One of the important advantages of the object-oriented design and
development methodology is the ability to reuse existing software modules.
However  the  introduction  of  many  programming  languages  with  different
syntax,  semantics  and/or  paradigms  has  created  the  need  for  a  consistent
inter-language interoperability support framework. We present a brief overview
of the most characteristic interoperability support methods and frameworks
allowing  the  access  and  reuse  of  objects  from  different  programming
environments  and 
interface  bridging  object-oriented
interoperability support approach.

focus  on 

the 

3.1

Reusing Objects from Different Environments

One of the problems that people face when travelling from one country to another con-
cerns the operation of electric appliances, like electric razors and coffee machines. A per-
son living in Switzerland, for example, travelling to Germany will not be able to “plug in”
and use his coffee machine as he is used in doing when back home. The reason is simply
that the “interfaces” for connecting to the electricity distribution network, that is the plug
of the appliance and the wall socket, are different. Our traveller will need to employ a
small inexpensive adaptor in order to bridge the differences of the “interfaces”. But things
are not always that simple. If the same person is travelling to North America he will dis-
cover that not only is his (Swiss) plug different from the (North American) wall socket, but
also that the electricity voltage differs. Fortunately also in this case a simple solution ex-
ists: the use of a transformer that will convert the North American voltage (110 V) to the
Swiss standard (220 V).

Dimitri Konstantas, “Interoperation of Object-Oriented Applications,” Object-Oriented Software Composition, O. Nierstrasz and D. 
Tsichritzis (Eds.), pp. 69-95, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

70

Interoperation of Object-Oriented Applications

In object-oriented programming where the reuse of objects is highly encouraged we
face similar problems when we wish to access or reuse objects that are programmed in
different programming languages. A programmer implementing an application in C++
cannot easily (re)use (if at all) objects and code written in Smalltalk [5] or even replace,
without  resorting  to  extensive  reprogramming,  a  C++  object  with  some  other  one
performing the same function but under a different interface. What we need are concepts
similar to the electricity transformer and plug adaptor that will allow us to bridge the dif-
ferences between the interfaces and paradigms of objects programmed in different lan-
guages.

In general we can classify the problems of bridging the differences between objects into
three categories. The ﬁrst category includes the computation differences between the ob-
jects, like the low-level data representations; the second category includes the syntactic
particularities of the object interfaces, like the operation names and the required parame-
ters; the third category includes the differences of the semantic and functional behaviour
of the objects, like the representation of a collection of objects as an array or as a linked
list. We will refer to the bridging of all these differences for the reuse and access of objects
written in one or more languages as the interoperability support problem.

Interoperability is the ability of two or more entities, such as programs, objects, appli-
cations or environments, to communicate and cooperate despite differences in the imple-
mentation language, the execution environment or the model abstractions. The motivation
in the introduction of interoperability support between entities is the mutual exchange of
information and the use of resources available in other environments. 

During the past few years several approaches have been taken for the introduction of in-
teroperability support. We classify these approaches in two ways. First depending on the
way that they solve the interface differences’ problem and second on the point at which the
interoperability support is handled.

For the ﬁrst classiﬁcation, interface differences, we identify two general categories:
• The interface bridging approaches bridge the differences between interfaces. They
are characterized by the notions of offered and requested interface and deﬁne an in-
terface transformation language. The interface transformation language requires the
existence of two interfaces and allows one to express how the offered (requested) in-
terface can be transformed to the requested (offered) interface. Note that the interface
transformation language is programming language dependent.

• The interface standardization approaches standardize the interface under which a
service (functionality) is offered. They are characterized by an interface deﬁnition
language that allows one to express in a programming language independent way a
speciﬁc interface. From the abstract deﬁnition of an interface a compiler will produce
the necessary stub-interface in the implementation language selected. The compiler
will always generate the same stub-interface for the selected target programming
language.

For the second classiﬁcation depending on the point at which interoperability support

is handled, we also identify two categories:

Procedure-Oriented Interoperability

71

• The procedure-oriented interoperability approaches that handle interoperability at

the point of the procedure call.

• The object-oriented interoperability approaches that handle interoperability at the

point of the object.

In the rest of this chapter we present a brief overview of some representative projects
from different interoperability approaches, discussing their advantages and disadvantag-
es, and describe in detail the object-oriented interoperability approach of the Cell frame-
work [12].

3.2

Procedure-Oriented Interoperability

The problem of interface matching between offered and requested services has been iden-
tiﬁed by many researchers [6][15][18][21][22][25][26] as an essential factor for a high-
level interoperability in open systems (see also chapter 12). Nevertheless, most of the
approaches taken in the past are based on the remote procedure call (RPC) paradigm and
handle interoperability at the point of procedure call. We call this type of interoperability
support approach procedure-oriented iteroperability (POI). In POI support it is assumed
that the functionality offered by the server’s procedures matches exactly the functionality
requested by the client. Thus the main focus of the interoperability support is the adaption
[21] of the actual parameters passed to the procedure call at the client side to the requested
procedures at the server side. 

3.2.1 Interface bridging

An example of this approach is the one taken in the Polylith system [21]. The basic as-
sumption of the approach is that the interface requested by the client (at the point of the
procedure call) and the interface offered by the server “fail to match exactly”. That is the
offered and requested parameters of the operation calls differ. A language called NIMBLE
has been developed that allows programmers to declare how the actual parameters of a
procedure call should be rearranged and transformed in order to match the formal param-
eters of the target procedure. The supported parameter transformations include coercion
of parameters, e.g. ﬁve integers to an array of integers, parameter evaluation, e.g.the trans-
formation of the strings “male” and “female” to integer values, and parameter extensions,
i.e. providing default values for missing parameters. The types of the parameters that are
handled are basic data types (integers, strings, Booleans, etc.) and their aggregates (arrays
or structures of integers, characters, etc.). The programmer speciﬁes the mapping between
the actual parameters at the client side and the formal parameters at the server side using
NIMBLE and the system will then automatically generate code that handles the transfor-
mations at run-time.

72

Interoperation of Object-Oriented Applications

3.2.2 Interface standardization

Whereas NIMBLE focuses on bridging the differences between the offered and requested
service interfaces, the Speciﬁcation Level Interoperability (SLI) support of the Arcadia
project [25] focuses on the generation of interfaces in the local execution environment
through which services in other execution environments can be accessed. The major ad-
vantage of SLI is that it deﬁnes type compatibility in terms of the properties (speciﬁcation)
of the objects and hides representation differences for both abstract and simple types. This
way SLI will hide, for example, the fact that a stack is represented as a linked list or as an
array,  making  its  representation  irrelevant  to  the  interoperating  programs  sharing  the
stack. In SLI the speciﬁcations of the types that are shared between interoperating pro-
grams are expressed in the Unifying Type Model (UTM) notation. UTM is a unifying mod-
el in the sense “that it is sufﬁcient for describing those properties of an entity’s type that
are relevant from the perspective of any of the interoperating programs that share instanc-
es of that type”[25]. SLI provides a set of language bindings and underlying implementa-
tions that relate the relevant parts of a type deﬁnition given in the language to a deﬁnition
as given in the UTM. With SLI the implementer of a new service will need to specify the
service interface with UTM and provide any needed new type deﬁnitions for the shared
objects and language bindings that do not already exist. In doing so the user will be assist-
ed by the automated assistance tools which allow him or her to browse through the exist-
ing UTM deﬁnitions, language bindings and underlying implementations. Once a UTM
deﬁnition for a service has been deﬁned the automated generation tool will produce the
necessary interface in the implementation language selected plus any representation and
code needed to affect the implementation of object instances. This way the automated
generation tool will always produce the same interface speciﬁcation from the same UTM
input. However, SLI can provide different bindings and implementations for the generated
interface allowing a service to be obtained from different servers on different environ-
ments, provided that they all have the same UTM interface deﬁnition.

An approach similar to SLI has been taken in the Common Object Request Broker Ar-
chitecture (CORBA) [18] of the Object Management Group (OMG). The Object Request
Broker (ORB) “provides interoperability between applications on different machines in
distributed environments”[18] and it is a common layer through which objects transpar-
ently exchange messages and receive replies. The interfaces that the client objects request
and the object implementations provide are described through the Interface Deﬁnition
Language (IDL). IDL is the means by which a particular object implementation tells its
potential clients what operations are available and how they should be invoked. An inter-
face deﬁnition written in IDL speciﬁes completely the interface and each operation’s
parameters. The IDL concepts are mapped accordingly to the client languages depending
on the facilities available in them. This way, given an IDL interface, the IDL compiler will
generate interface stubs for the client language through which the service can be accessed
using the predeﬁned language bindings.

Object-Oriented Interoperability

73

3.2.3 Advantages and Disadvantages

Although the above approaches can provide interoperability support for a large number of
applications, they have a number of drawbacks that severely restrict their interoperability
support. The ﬁrst drawback is the degeneration of the “interface” for which interoperabil-
ity support is provided to the level of a procedure call. A service is generally provided
through an interface that is composed of a set of interrelated procedures. What is of impor-
tance is not the actual set of the interface procedures but the overall functionality they pro-
vide. By reducing the interoperability “interface” to the level of a procedure call, the inter-
relation of the interface procedures is lost, since the interoperability support no longer sees
the service interface as a single entity but as isolated procedures. This will create problems
in approaches like Polylith’s that bridge the differences between the offered and requested
service interface, when there is no direct one-to-one correspondence between the inter-
face’s procedures (interface mismatch problem). 

Interoperability approaches like SLI and CORBA, on the other hand, do not suffer from
the interface mismatch problem, since the client is forced to use a predeﬁned interface.
Nevertheless,  the  enforcement  of  predeﬁned  interfaces  (i.e.  sets  of  procedures  with
speciﬁed functionality) makes it very difﬁcult to access alternative servers that provide the
same service under a different interface. This is an important interoperability restriction
since we can neither anticipate nor we can enforce in an open distributed environment the
interface through which a service will be provided. With the SLI and CORBA approaches,
the service’s interface must also be embedded in the client’s code. Any change in the serv-
er’s interface will result in changes in the client code. 

Another restriction of the above interoperability approaches is that they require the
migration of the procedure parameters from the client’s environment to the server’s envi-
ronment. As a result only migratable types can be used as procedure parameters. These are
the basic data types (integers, strings, reals, etc.) and their aggregates (arrays, structures,
etc.), which we call data types. Composite non-migratable abstract types, like a database
or  keyboard  type,  cannot  be  passed  as  procedure  parameters.  This  nevertheless  is  a
reasonable restriction since the above approaches focus in interoperability support for
systems based on non-object-oriented languages where only data types can be deﬁned. 

The need for allowing non-migratable objects as parameters to operation calls was
identiﬁed in the CORBA and a special data type was introduced called object reference.
CORBA object references are data types that encapsulate a handle to a (non-migratable)
object and are globally valid. However object references are a low level primitives which
must be explicitly referenced and de-referenced by the server and the client. A higher-
level primitive allowing direct access to object is clearly needed if we wish to have con-
sistent access in an object-oriented environment.

3.3 Object-Oriented Interoperability

Although procedure-oriented interoperability provides a good basis for interoperability
support between non-object-oriented language based environments, it is not well suited

74

Interoperation of Object-Oriented Applications

for a high level interoperability support for environments based on object-oriented lan-
guages. The reason is that in an object-oriented environment we cannot decompose an ob-
ject into a set of independent operations and data and view them separately, since this will
mean loss of the object’s semantics. For example, a set of operations that draw a line, a rec-
tangle and print characters on a screen, have a different meaning if they are seen independ-
ently or in the context of a window server object where the rectangle can represent a
window into which the characters that represent the user/machine interactions are printed.
In object-oriented environments it is the overall functionality of the object that is of impor-
tance and not the functionality of the independent operations. We call this type of interop-
erability where the semantics of the objects as a whole are preserved object-oriented
interoperability (OOI).

3.3.1 Interface Bridging

An example of interface bridging in object-oriented interoperability is the one provided
by the Cell framework [12] (where the concept of OOI was also introduced). The Cell is a
framework for the design and implementation of “strongly distributed object-based sys-
tems”. The purpose of the Cell is to allow objects of different independent object-based
systems to communicate and access each other’s functionality regardless of possible in-
terface differences. That is, the same functionality can be offered with a different interface
from different objects found either on the same or on different environments. The bridging
of the interface differences is done via the Interface Adaption Language (IAL). From the
speciﬁcation given in the IAL a compiler generates the required stub objects that support
the requested interface and translate the incoming operation invocations to the invocations
of the target object interface. 

A more detailed presentation of the Cell interoperability approach is given in section

3.5. 

3.3.2 Interface Standardization

The most important example of interface standardization in object-oriented interoperabil-
ity is version 2 of CORBA. In contrast to the ﬁrst version of CORBA, which was oriented
towards C and C procedure calls, the second version is oriented towards a C++ environ-
ment and objects. Otherwise the functionality of CORBA and the basic elements are the
same as described in section 3.2.2. 

3.3.3 Summary

Object-oriented interoperability is a generalization of procedure-oriented interoperability
in the sense that it will use, at its lower levels, the mechanisms and notions of POI. How-
ever OOI has several advantages over POI. First of all it allows the interoperation of appli-

Comparison of Interoperability Support Approaches

75

cations in higher-level abstractions, like the objects, and thus supports a more reliable and
consistent interoperation. A second advantage is that it supports fast prototyping in appli-
cation development and experimentation with different object components from different
environments. The programmer can develop a prototype by reusing and experimenting
with different existing objects in remote (or local) environments without having to change
the code of the prototype when the reused object interfaces differ. A last advantage is that
since OOI is a generalization of POI, it can be used to provide interoperation between both
object-oriented and conventional (non-object-oriented) environments. Furthermore when
IB-OOI support is used for non-object-oriented environments it provides a more general
frame than POI and can also handle cases where the requested and offered service inter-
faces do not match.

In table 3.1 we give a summary of the different approaches presented above and their

position in the two classiﬁcations. 

Procedure-oriented 
interoperability (POI)

Object-oriented 

interoperability (OOI)

Interface standardization (IS)

SLI, CORBA v. 1

CORBA v. 2

Interface bridging (IB)

NIMBLE

Cell 

Table 3.1   Classiﬁcation of interoperability support approaches.

3.4 Comparison of Interoperability Support Approaches

The interface bridging approaches provide a more general solution than the interface
standardization approaches for the access and reuse of objects from different program-
ming  environments  since  they  do  not  enforce  any  speciﬁc  interface.  The  application
designer can choose the interface that he wants to use for accessing a service and use it for
accessing not only the target server but also alternative servers offering the same service
under different interfaces. 

Another advantage of the interface bridging approaches is that they make no assump-
tions about the existence and semantics of types in the interoperating environments. Each
type, even the simplest and most banal integer type, must be explicitly related to a type on
the remote environment. This way they provide ﬂexibility in the interconnection of di-
verse environments based on different models and abstractions.

One of the disadvantage of the interface bridging approaches comes from the fact that
they do not enforce a common global representation model for expressing the interopera-
bility bindings. Each execution environment is free to choose its own language. As a result
the interoperability interface adaption speciﬁcations for a server need to be deﬁned inde-
pendently by the programmer for each execution environment in an interface adaption
language that is specially tailored for the programming languages of the two environ-
ments. However, bilateral mappings can offer a higher ﬂexibility when the interoperating

76

Interoperation of Object-Oriented Applications

languages support special features. For example, a common interface deﬁnition language,
like the CORBA IDL, does not include the notion of a transaction; thus, even when the in-
teroperating languages support transactions, like Argus [16] and KAROS [4], their IDL-
based interoperation will not be able to use transactions.

Object-oriented  interoperability  and  procedure-oriented  interoperability  approaches
cannot be directly compared since they are designed for different programming environ-
ments: the ﬁrst for object-oriented environments and the second for non-object-oriented
environments. Nevertheless OOI is a generalization of POI using at its lower levels the
same mechanisms as POI. Thus the major advantage of OOI over POI is that it can be ap-
plied as well to both types of programming environments and serve as bridge between ob-
ject-oriented and non-object-oriented environments.

Although the interface bridging and interface standardization approaches are distinct in
the way they approach the interoperability problem, they are not exclusive. An interoper-
ability support system can very well support both approaches and give the programmers
maximum ﬂexibility in the reuse and access of objects in different programming environ-
ments. As an example we can consider CORBA which is an interface standardization in-
teroperability support system. In a large CORBA-based open distributed system it will be
difﬁcult for all service providers to agree on a common interface for the servers they de-
velop. As a result a number of different server interfaces will be available providing the
same  or  similar  services.  However,  applications  being  developed  to  access  a  speciﬁc
server interface will not be able to access any other server even if the interface differences
are minor. In addition, since it is not possible to anticipate the interfaces of future servers,
applications will not be able to take advantage of newer, more advanced services. What is
needed is to introduce interface bridging interoperability support. This can be easily done
with the introduction of an interface adaption service that will allow a client to adapt its
requested service interface to a speciﬁc offered interface and dispatch the service requests
accordingly.

3.5

Interface Bridging — Object-Oriented 
Interoperability

We identify two basic components necessary for the support and implementation of inter-
face bridging OOI (IB-OOI): interface adaption and object mapping. Interface adaption
provides the means for deﬁning the relations between types on different execution envi-
ronments based on their functionality abstraction, and object mapping provides the run-
time support for the implementation of the interoperability links. 

3.5.1 Terminology

In the rest of this section we use the term client interface to specify the interface through
which the client wishes to access a service, and the term server interface to specify the ac-

Interface Bridging — Object-Oriented Interoperability

77

tual interface of the server. In addition we will use the term node to specify the execution
environment of an application (client or server), e.g. the Hybrid [7] execution environ-
ment or the Smalltalk [5] execution environment. In this sense a node can span over more
than one computer, and more than one node can coexist on the same computer. Although
we will assume that the client is in the local node and the server in the remote node, local
and remote nodes can very well be one and the same. By the term parameter we mean the
operation call parameters and the returned values, unless we explicitly state differently.
Finally we should note that by the term user we mean the physical person who interacts
and maintains the interoperability support system.

3.5.2 Interface Adaption

In a strongly distributed environment [24] a given service will be offered by many servers
under different interfaces. As a result a client wishing to access a speciﬁc service from
more than one server will have to use a different interface for each server. Although we can
develop the client to support different interfaces for the accessed services, we might not
always be able to anticipate all possible interfaces through which a service can be offered,
or force service providers to offer their services via a speciﬁc interface. IB-OOI approach-
es this problem by handling all interface transformations, so that a client can use the same
interface to access all servers offering the same service. The interface adaption problem
consists of deﬁning and realizing the bindings and transformations from the interface that
the client uses (requested interface), to the actual interface of the service (offered inter-
face).

Ideally we would like to obtain an automatic solution to the interface adaption problem.
Unfortunately in the current state of the art this is not possible. The reason is that we have
no way of expressing the semantics of the arbitrary functionality of a service or an opera-
tion in a machine-understandable form. In practice the best we can do is describe it in a
manual page and choose wisely a name so that some indication is given about the func-
tionality of the entity. Nevertheless, since nothing obliges us to choose meaningful names
for types, operations or their parameters, we cannot make any assumptions about the
meaning of these names. Furthermore even if the names are chosen to be meaningful, their
interpretation depends in the context in which they appear. For example a type named
Account has a totally different meaning and functionality when found in a banking envi-
ronment and when found in a system administrator’s environment. Thus any solution to
the interface adaption problem will require, at some point, human intervention since the
system can automatically deduce neither which type matches which, nor which operation
corresponds to which, or even which operation parameter corresponds to which between
two matching operations. What the system can do is assist the user in deﬁning the bind-
ings, and generate the corresponding implementations.

We distinguish three phases in providing a solution to the interface adaption problem.
In the ﬁrst phase, which we call the functionality phase, the user speciﬁes the type or types
on the remote environment providing the needed functionality (service). The system can

78

Interoperation of Object-Oriented Applications

assist the user in browsing the remote type hierarchy and retrieving information describ-
ing the functionality of the types. This information can be manual pages, information ex-
tracted from the type implementation or even usage examples.

In the second phase, which we call the interface phase, the user deﬁnes how the opera-
tions of the remote type(s) should be combined to emulate the functionality represented
by the client’s operations. This can a be a very simple task if there is a direct correspond-
ence between requested and offered operations, or a complicated one if the operations
from several remote types must be combined in order to achieve the needed result. As in
the functionality phase the system can assist the user by providing information regarding
the functionality of the operations.

The third phase is the parameter phase. After specifying the correspondence between
the requested and remote interface operations the user will need to specify the parameters
of the remote operations in relation to the ones that will be passed in the local operation
call. This might require not only a deﬁnition of the correspondence between offered and
requested parameters, but also the introduction of adaption functions that will transform
or preprocess the parameters. The system can assist the user by identifying the types of the
corresponding parameters, reusing any information introduced in the past regarding the
relation between types and standard adaption functions, and prompt the user for any addi-
tional information that might be required.

Type Relations

3.5.2.1
In IB-OOI we distinguish three kinds of type relations, depending on how the local type
can be transformed to the remote type. Namely we have equivalent, translated and type
matched types.

Migrating an object from one node to another means moving both of its parts, i.e.data
and operations, to the remote node, while preserving the semantics of the object. However,
moving the object operations essentially means that a new object type is introduced on the
remote node. This case is presently of no interest to IB-OOI since we wish to support in-
teroperability through the reuse of existing types. Thus in IB-OOI, migrating an operation
call parameter object means moving the data and using them to initialize an instance of a
pre-existing equivalent type. This is a common case with data types, like integers, strings
and their aggregates, where the operations exist on all nodes and only the data need to be
moved. In IB-OOI when this kind of a relation exists between a type of the local node and
a type of the remote node we say that the local type X has an equivalent type X´ on the re-
mote node.

Although data types are the best candidates for an equivalence relation, they are not the
only ones. Other non-data types can also exist for which an equivalent type can be found
on a remote node. For example, a raster image or a database type can have an equivalent
type on a remote node and only the image or database data need to be moved when migrat-
ing the object. In general, two types can be deﬁned as equivalent if their semantics and
structure are equivalent and the transfer of the data of the object is sufﬁcient to allow the
migration of their instances. In migrating an object to its equivalent on the remote node,
the IB-OOI support must handle the representation differences of the transferred data. In

Interface Bridging — Object-Oriented Interoperability

79

this sense the type equivalence of IB-OOI corresponds to representation level interopera-
bility [25].

In an object-oriented environment we are more interested in the semantics of an object
rather than its structure and internal implementation. For example, consider the Hybrid
[17] type string and the CooL* [1] type ARRAY OF CHAR. In the general case the semantics
of the two types are different: the string is a single object, while the ARRAY OF CHAR is an
aggregation of independent objects. Nevertheless when in CooL an ARRAY OF CHAR is
used for representing a string, it becomes semantically equivalent and can be transformed
to a Hybrid string, although the structure, representation and interfaces of the two types are
different. In IB-OOI this type relation is deﬁned as type translation.

Translation of the local type to the remote type is done with a user-deﬁnable translation
function. This way the particularities of the semantic equivalence can be handled in a case-
speciﬁc way. The user can specify different translations according to the semantics of the
objects. For example, if the local node is a CooL node and the remote a Hybrid node, then
we can deﬁne two different translations for an ARRAY OF CHAR — the ﬁrst when the AR-
RAY OF CHAR represents a character string and is translated to a string, and the second
when the ARRAY OF CHAR represents a collection of characters that need to be treated in-
dependently and which is translated to a Hybrid array of integer (in Hybrid characters are
represented via integers).

Type translation can be compared to speciﬁcation level interoperability, where the in-
teroperability support links the objects according to their speciﬁcations. Nevertheless,
type translation is more ﬂexible than SLI since it allows multiple translations of the same
type according to the speciﬁc needs and semantics of the application.

A local type for which bindings to a remote type or types have been deﬁned, as a solu-
tion to the interface adaption problem (i.e. bindings and transformations from the inter-
face that the client uses, to the actual interface of the service), is said to be type matched to
the remote node. We can have two kinds of type matched types: multi-type matched and
uni-type matched types. Multi-type-matched types are the ones that are bound to more
that one type on the remote node, when for example one part of the requested functionality
is offered from one type and another part from a second type, and uni-type matched types
are the ones that are bound to a single type on the remote node. 

The target of IB-OOI is to allow access to objects on remote nodes. The basic assump-
tion being that the object in question cannot be migrated to the local node. However, the
access and use of the remote object will be done with the exchange of other objects in the
form of operation call parameters. The parameter objects can, in their turn, be migrated to
the remote node or not. Parameter objects that cannot be migrated to the remote node are
accessed on the local node via a type match, becoming themselves servers for objects on
the remote node.

Type relations are speciﬁc to the node for which they are deﬁned and do not imply that
a reverse type relation exists, or that they can be applied for another node. For example, if
the local node is a Hybrid node and the remote is a C++ node, the Hybrid type boolean has

* CooL is a an object-oriented language designed and implemented in the ITHACA ESPRIT [20] project

80

Interoperation of Object-Oriented Applications

as equivalent in the C++ node an int (integer) (Booleans in C++ are represented by inte-
gers), while the reverse is, in general, false.

To Type-Match or not to Type-Match?

3.5.2.2
Type matching is a general mechanism for interoperability support and can be used in all
cases in place of equivalence and translation of types. However, the existence of transla-
tion and equivalence of types is needed for performance reasons since accessing objects
through the node boundary is an expensive operation. If an object is to be accessed fre-
quently on the remote node, then it might be preferable to migrate it, either as equivalent
or translated type. For example, it is preferable to migrate “small” objects, like the data
types, rather than access them locally. Nevertheless the user always has the possibility of
accessing any object locally, even an integer if this is needed, as might be the case with an
integer that is stored at a speciﬁc memory address which is hard-wired to an external sen-
sor (like a thermometer) and which is continuously updated. This can be done by deﬁning
a type match and using it in the parameter’s binding deﬁnitions.

A typical scenario we envisage in the development of an application with IB-OOI sup-
port is the following. The user (application programmer) will ﬁrst deﬁne a set of type
matchings for accessing objects on remote nodes. These will be used in the development
of the application prototype. When the prototype is completed the user will measure the
performance of the prototype and choose for which types a local implementation is to be
provided. For these types an equivalency or translation relation will also be established,
possibly on both nodes, so that they can be migrated and accessed locally. This way the
performance of the prototype will be improved. This process can be repeated iteratively
until the performance gains are no longer justiﬁable by the implementation effort.

One of the major advantages of the IB-OOI approach is that in the above scenario the
application prototype will not be modiﬁed when local implementations of types are intro-
duced* and the type relations change. The new type relations are introduced in the IB-OOI
support and do not affect the application programs.

3.5.3 Object Mapping

Whereas interface adaption maintains the static information of the interoperability tem-
plates, object mapping provides the dynamic support and implementation of the interop-
erability links. We distinguish two parts in object mapping: the static and the dynamic. The
static part of object mapping is responsible for the creation of the classes that implement
the interoperability links as speciﬁed by the corresponding type matching. The dynamic
part, on the other hand, is responsible for the instantiation and management of the objects
used during the interoperation.

* With the exception of a possible recompilation if dynamic linking is not supported.

Interface Adaption

81

Inter-Classes and Inter-Objects

3.5.3.1
The essence of object mapping is to dynamically introduce in the local node the services
of servers found on other nodes. This, however, must be done in such way so that the ac-
cess of the services is done according to the local conventions and paradigms. In an object-
oriented node this will be achieved with the instantiation of a local object that represents
the remote server, which in IB-OOI we call an inter-object. An inter-object differs from a
proxy, as this is deﬁned in [23], in three important respects. First in contrast with a proxy,
an inter-object and its server can belong to different programming and execution environ-
ments and thus they follow different paradigms, access mechanisms and interfaces. The
second difference is that while a proxy provides the only access point to the actual server,
i.e. the server can be accessed only via its proxies, this is not the case with inter-objects.
Objects on the same node with the server can access it directly. An inter-object simply pro-
vides the gateway for accessing the server from remote nodes. Finally, while a proxy is
bound to a speciﬁc server, an inter-object can dynamically change its server or even access
more than one server, combining their services to appear as a single service on the local
node.

An inter-object is an instance of a type for which a type match has been deﬁned. The
class (i.e. the implementation of a type) of the inter-object is created by the object mapper
from the type match information and we call it an inter-class. An inter-class is generated
automatically by the object mapper and it includes all code needed for implementing the
links to the remote server or servers. 

3.5.3.2 Dynamic Support of the Object Mapping
After the instantiation of an inter-object and the establishment of the links to the remote
server, the controlling application will start invoking the operations of the inter-object,
passing other objects as parameters. IB-OOI allows objects of any type to be used as
parameters  at  operation  calls.  The  object  mapper  will  handle  the  parameter  objects
according to their type relations with the remote node. This way objects for which an
equivalent or translated type exists on the remote node will be migrated, while objects for
which a type match exists will be accessed through an inter-object on the remote node.

In the case where no type relation exists for the type of a parameter object, the object
mapper will invoke the type matcher and ask the user to provide a type relation. This way
type relations can be speciﬁed efﬁciently, taking into account the exact needs and circum-
stances of their use. In addition the dynamic deﬁnition of type relations during run-time
relieves the user from the task of searching the implementation type hierarchy for unde-
ﬁned type relations. Also the incremental development and testing of a prototype becomes
easier since no type relations need to be deﬁned for the parts of the prototype that are not
currently tested.

3.6

Interface Adaption

Expressing the relations and transformations between two (or more) interfaces can be
done using a language which we call Interface Adaption Language (IAL). IAL, just like

82

Interoperation of Object-Oriented Applications

the existing interface deﬁnition languages (like the CORBA IDL) that allow the expres-
sion of an interface in an abstract language independent way, allows the expression of the
relations and transformations required for the adaption of one interface to another in an
abstract language independent way. 

An IAL for the object-oriented interoperability support of the Cell framework proto-
type [8][9][11] was designed and implemented at the University of Geneva. The main goal
of the Cell framework is to allow the objects of a node transparently to access and use serv-
ices found on other heterogeneous nodes using the OOI support. IAL allows the user to ex-
press the interface relations between object types of the different nodes. The syntax of the
IAL is very similar to the Hybrid language syntax [7][10][17], in which the Cell prototype
was implemented. 

 In the rest of this section we give an overview of the implemented IAL using examples
for the adaption of interfaces between Hybrid object types and CooL [1] object types. A
complete description of IAL can be found in [13].

3.6.1 Type Relations

A type relation in IAL is deﬁned for a speciﬁc remote cell which is identiﬁed by its name.
For the examples given below we assume that the local Hybrid cell is named HybridCell and
the remote CooL cell is named CooLCell. The general syntax of a type relation on the Hy-
brid cell is

IdOfRemoteCell :: <TypeRelation> ;

where  TypeRelation  can  be  either  equivalent,  translated  or  type  matched  and
IdOfRemoteCell is the id of the remote cell, which in the case of the CooL cell is CooLCell.

Equivalent and Translated types

3.6.1.1
In both CooL and Hybrid, integers and Booleans are equivalent types. On the Hybrid cell
this is expressed as

CooLCell :: integer => INT ;
CooLCell :: boolean => BOOL ;

Although the notion of a string exists in both languages, in CooL, strings are represented
as arrays of characters while in Hybrid they are basic data types. Thus the relation between
them is of a translated type

CooLCell :: string +> ARRAY OF CHAR : string2arrayOfChar ;

In the CooL cell the corresponding deﬁnitions will be:

HybridCell :: INT => integer ;
HybridCell :: BOOL => boolean ;
HybridCell :: ARRAY OF CHAR +> string : arrayOfChar2string ;

In  the  deﬁnition  of  translated  types  we  specify  a  translation  function,  like
string2arrayOfChar and arrayOfChar2string, which performs the data translation. 

Interface Adaption

83

type windowServer : abstract {

newWindow : (integer #{ : topLeftX #}, integer #{ : topLeftY #}, 

        integer #{ : botRightX #}, integer #{ : botRightY #}) -> integer #{: windowId #} ;

newSquareWin : (integer #{ : topLeftX #}, integer #{ : topLeftY #}, integer #{ : side #} )

-> integer #{ : windowId #} ;

refreshDisplay : (display ) -> boolean ;
readCoordinates : ( mouse, keyboard, touchScreen, integer #{ : scaleFactor #} ) -> point ;
windowSelected : (mouse, keyboard, touchScreen ) -> integer ;

} ;

Figure 3.1   Hybrid type windowServer.

Type-Matched Types.

3.6.1.2
A type can be matched to either a single remote type or to a collection of remote types
(multi-type match). For example, if we have on the local Hybrid cell a type windowServer,
which is matched to the type WINDOW_CONTROL of the remote cell, the type match will
be expressed as

CooLCell :: windowServer -> WINDOW_CONTROL {<operation bindings>*} ; 

while a multi-type match will be expressed as

CooLCell :: windowManager -> < WINDOW_CONTROL, SCREEN_MANAGER >

{ <operation bindings>} ;

When an object of the local nucleus in its attempt to access a service creates an instance
of a type-matched type (an inter-object), a corresponding instance of the target type will
be instantiated on the remote cell. However, there are cases where we do not want a new
instance to be created on the remote cell but we need to connect to an existing server. In
IAL this is noted with the addition of @ at the of remote type name:

CooLCell :: personnel -> PERMANENT_PERSONEL_DB @ { <operation bindings>} ; 

3.6.2 Description of the Running Example

In order to describe the IAL syntax we use as examples a Hybrid type windowServer and a
CooL type WINDOW_CONTROL. The Hybrid windowServer deﬁnes in the Hybrid cell the
interface through which a window server is to be accessed (requested interface), while the
CooL WINDOW_CONTROL provides an implementation of a window server (offered inter-
face). For simplicity we assume that the operation names of the two types describe accu-
rately the functionality of the operations. That is, the operation named newWindow creates
a new window, while the operation get_Position returns the position pointed to by the point-
ing devices.

The Hybrid type windowServer (ﬁgure 3.1) has ﬁve operations. Operations newWindow
and newSquareWin return the id of the newly created window or zero in case of failure. Op-

* The syntax of the operation bindings is described in detail in section 3.6.3.

84

Interoperation of Object-Oriented Applications

TYPE WINDOW_CONTROL =

OBJECT

METHOD create_win ( IN botRightX : INT, IN botRightY : INT,

 IN topLeftX : INT, IN topLeftY : INT, IN color : INT ) : INT

METHOD redisplay_all (IN display : DISPLAY) : INT
METHOD get_Position (IN inDevices : IO_DEVICES, IN scaling : INT) : POSITION
METHOD select_Window (IN position : POSITION) : INT

BODY
...
END OBJECT

Figure 3.2   CooL type WINDOW_CONTROL.

eration  refreshDisplay  returns  true  or  false,  signifying  success  or  failure.  Operation
readCoordinates returns the coordinates of the active point on the screen as read from the
pointing devices and operation windowSelected returns the id of the currently selected win-
dow or zero if no window is selected.

The  CooL  type  WINDOW_CONTROL  (ﬁgure  3.2)  has  four  methods.  The  methods
create_win and select_Window return the id of the newly created window and of the window
into which the speciﬁc position is found, or −1 in case of an error. Method redisplay_all re-
turns 0 or 1, signifying failure or success, and method get_Position returns the position
pointed by the I/O devices (i.e. keyboard, mouse, touch-screen) as adapted by the scaling
factor.

3.6.3 Binding of Operations

Although type WINDOW_CONTROL provides all the functionality that type windowServer
requires, this is done via an interface different to the one that windowServer expects. In
general in the IAL we anticipate two levels of interface differences — ﬁrst in the required
parameters (order, type, etc.) and second in the set of supported operations, i.e. different
number of operations with aggregated, segregated or slightly* different functionality. The
resolution of these differences corresponds to the parameter and interface phases of the in-
terface adaption deﬁnition.

Parameter Phase

3.6.3.1
Assuming that the functionality of the provided operation corresponds to the requested
functionality, the differences between the parameters passed to the local operation call
(offered parameters) and of the parameters required by the remote operation (requested
parameters) can fall into one or more of the following categories:

• Different order of parameters. For example, the ﬁrst parameter of the local operation

might correspond to the second on the remote operation.

* The term is used loosely and it is up to the user to define what is a “slight” difference in functionality.

Interface Adaption

85

• Different representation of the information held by the parameter. For example a
boolean condition TRUE or FALSE can be represented locally by an integer while on
the remote operation the string “TRUE” or “FALSE” might be expected.

• Different semantic representation of the information. For example if we have a Hy-
brid array with ten elements indexed from 10 to 19, an equivalent array in CooL will
be indexed 1 to 10. Thus an index, say 15, of the Hybrid array should be communi-
cated as 6 to the CooL cell.

• Different number of parameters. The requested parameters might be more or less
than the offered ones. In this case the parameters offered might include all informa-
tion needed or more information might be required.

The IAL anticipates all the above differences and allows the user to specify the needed
transformations for handling them.
Migrated parameters
In our example we consider ﬁrst the operations newWindow and create_win which have the
same functionality speciﬁcation. The binding of newWindow to create_win is expressed in
IAL as follows:

newWindow : create_win($3, $4, $1, $2, 17 ) ^ RET ;

Operation newWindow offers four parameters which are identiﬁed by their position with a
positive integer ($1 to $4). Method create_win will be called with these parameters trans-
posed. Its ﬁrst parameter will be the third passed by newWindow, the second will be the
fourth and so on. The ﬁfth parameter of create_win is an integer that speciﬁes the colour of
the new window. This information does not exists in the offered parameters. Nevertheless,
in this case, we can use a default value using a integer literal, like in the example the
number 17. The returned value from create_win, noted as RET in IAL, is passed back to the
Hybrid cell and becomes the value that newWindow will return.

In the above operation binding deﬁnition we assume that a relation for the CooL and

Hybrid integers exists. That is we assume that on the Hybrid cell we have

CooLCell :: integer => INT ;

and on the CooL cell

HybridCell :: INT => integer ;

This way migration of the parameters and returned values will be handled automatically.
Operation newSquareWin does not exist in the interface of WINDOW_CONTROL but its
functionality can be achieved by operation create_win called with speciﬁc parameter val-
ues. That is we can have

 newSquareWin : create_win (bottomRX($1, $3), bottomRY($2, $3), $1, $2, 17) ^ RET;

where functions bottomRX and bottomRY are adaption functions. Adaption functions are
user-deﬁned functions, private to the speciﬁc interface adaption. They provide the means
through which the user can adapt the offered parameters to a format compatible to the re-
quested parameters. They can be called with or without parameters. The parameters to be
passed to the adaption functions can be any of the offered parameters or even the result of

86

Interoperation of Object-Oriented Applications

another adaption function. In the type matching deﬁnition of the IAL the adaption func-
tions are included at the end of the interface adaption deﬁnition between @{ and @}. Thus
for the previous example we have the following adaption functions: 

@{

@} 

bottomRX : (integer : topLeftX, side ) -> integer ;

{ return (topLeftX + side ) ; }

bottomRY : (integer : topLeftY, side ) -> integer ;

{ return (topLeftY - side ) ; }

The adaption functions will be invoked locally (i.e. in our example, in the Hybrid cell)
and their result will be passed as parameter to the remote call (create_win). An adaption
function is effectively a private operation of the inter-class and as such it can access its in-
stance variables or other operations.
Mapped Parameters

When the parameter cannot be migrated to the remote cell, i.e. when there is no corre-
sponding equivalent or translated type, it should be accessed on the local cell. This will be
done via a mapping of a remote object to the local parameter according to an existing type
match.  In  our  example  this  will  need  to  be  done  for  the  refreshDisplay  operation  and
redisplay_all method. 

The parameter passed to refreshDisplay is an object of type display which cannot be
migrated to the CooL cell. Thus it must be accessed on the Hybrid cell via a mapping on
the CooL cell. For this a type match must exist on the CooL cell to the Hybrid display type.

HybridCell :: DISPLAY -> display { .... } ;

This way the binding of refreshDisplay to redisplay_all is expressed as

refreshDisplay : redisplay_all ( $1 : display <- DISPLAY ) ^ int2bool(RET) ;

meaning that the ﬁrst parameter of the method redisplay_all will be an object mapped to the
ﬁrst parameter passed to the operation refreshDisplay, according to the speciﬁed type match
on the CooL cell. In addition the returned value of redisplay_all, which is an integer, is
transformed to a Boolean via the adaption function int2bool which is deﬁned as follows:

@{

@}

int2bool : ( integer : intval ) -> boolean ;

{ return ( intval ~=? 0); }

Multi-type mapped parameters

In IAL we also anticipate the case where the functionality of a type is expressed by the
composite functionality of more than one type on the remote cell. In our example this is
the case for the CooL type IO_DEVICES, which corresponds to the composite functionality
of the Hybrid types mouse, keyboard and touchScreen. 

HybridCell :: IO_DEVICES -> < keyboard @, mouse @, touchScreen @ > { ... } ;

Object Mapping

87

Note that in this example the IO_DEVICES inter-object will be connected to the existing
keyboard, mouse and touchScreen objects on the Hybrid cell.

The deﬁnition of multi-type match operation bindings is similar to that of single type
match bindings, but with the deﬁnition of the operation’s type. If, for example, we assume
that type IO_DEVICES has a method read_keyboard which corresponds to the operation
readInput of the Hybrid keyboard type, the binding would be expressed as

read_keyboard : keyboard.readInput (...) ^ ... ;

In fact this syntax is the general syntax for the deﬁnition of an operation binding and can
be used in both single- or multi- type matchings. Nevertheless for simplicity in single-type
matchings the deﬁnition of the corresponding type can be omitted since there is only one
type involved.

In our example, the binding of the Hybrid operation readCoordinates to the operation

get_Position will be expressed as

readCoordinates : get_Position ( 

 

< $2, $1, $3 > : < keyboard, mouse, touchScreen > <- IO_DEVICES, 
$4 ) ^ RET

assuming that we have on the CooL cell the relation

HybridCell :: POSITION +> point ;

Interface Phase

3.6.3.2
When deﬁning the operation bindings between two types from different environments
there will be cases where the functionality of the local operation is an aggregation of the
functionality of more than one remote operation. Adapting a requested operation interface
to an offered one might require anything from simple combinations of the operations up
to extensive programming. In order to simplify the user’s task, IAL allows the deﬁnition
of simple operation combinations in the type match speciﬁcation. For example, the func-
tionality of the Hybrid operation windowSelected can be obtained with the combination of
the CooL methods get_Position and select_Window. The operation binding is thus:

windowSelected : select_Window ( WINDOW_CONTROL.get_Position (

< $2, $1, $3 > : < keyboard, mouse, touchScreen > <- IO_DEVICES, $4 ) ) ^ RET ;

This deﬁnes that the method get_Position will ﬁrst be called on the remote CooL cell and
its result will not be returned to the calling Hybrid cell but it will be used as the ﬁrst param-
eter to the select_Window method. Since the result of the get_Position method is not re-
turned to the Hybrid cell, there is no need for a type relation of the CooL type POSITION to
exist on the Hybrid cell.

3.7 Object Mapping

Whereas  interface  adaption  provides  the  means  to  express  in  an  implementation  lan-
guage-independent way the relations between heterogeneous interfaces, object mapping
provides the required language-dependent run-time interoperability support. The ﬁrst task

88

Interoperation of Object-Oriented Applications

Hybrid cell

CooL cell

Nucleus

Membrane

Membrane

Nucleus

windowServer
Inter-Object

newWindow
newSquareWin
refreshDisplay
readCoordinates
windowSelected

WINDOW_CONTROL

create_win

redisplay_all

get_Position

select_Window

Figure 3.3   Object mapping.

of  object  mapping  is  to  generate  from  the  interface  adaption  speciﬁcations  the  inter-
classes at the client side. Instances of an inter-class provide the client with the requested
service interface and their principal task is to forward the operation invocation to the target
server according to the speciﬁed interface transformations and adaptions.

In the following we describe the functionality of object mapping via the previously de-
scribed example of interface adaption between the Hybrid WindowServer and the CooL
WINDOW_CONTROL. In ﬁgure 3.3 we present the binding between the operations of the
Hybrid inter-object and the CooL server and describe the actions taken when an operation
of the windowServer inter-object is called. For our example we consider the operation
readCoordinates, which is called with four parameters — a keyboard object, a mouse object,
a touchScreen object and an integer (ﬁgure 3.4) — and which is bound to the method
get_Position.

readCoordinates : get_Position ( 

< $2, $1, $3 > : < keyboard, mouse, touchScreen > <- IO_DEVICES, 
$4 ) ^ RET 

From the four parameters passed to operation readCoordinates, the ﬁrst three (keyboard,
mouse and touchScreen) cannot be migrated to the CooL cell but must be accessed locally
via a multi-type match of the CooL type IO_DEVICES. The fourth parameter is an integer
for which an equivalent type exists on the CooL cell and thus it can be migrated to it. The
object mapping server will thus instantiate on the CooL cell two objects: an inter-object of
type IO_DEVICES connected to the Hybrid objects keyboard, mouse and touchScreen, and
an INT object initialized to the value of the integer parameter (ﬁgure 3.5). 

Object Mapping

89

Hybrid cell

CooL cell

Nucleus

Membrane

Membrane

Nucleus

keyboard

integer

readCoordinates

mouse

touchScreen

windowServer

WINDOW_CONTROL

get_Position

Figure 3.4   Operation call forwarding.

Hybrid cell

CooL cell

Nucleus

Membrane

Membrane

Nucleus

keyboard

integer

windowServer

readCoordinates

mouse

touchScreen

IO_DEVICES

WINDOW_CONTROL

get_Position

INT

Figure 3.5   Parameter transfer.

When the transfer of the parameters has been completed the object mapping server will
proceed with the invocation of the remote operation. The operation get_Position will be in-
voked with the IO_DEVICES inter-object and the INT object (ﬁgure 3.6) as parameters. The

90

Interoperation of Object-Oriented Applications

Hybrid cell

CooL cell

Nucleus

Membrane

Membrane

Nucleus

keyboard

windowServer

readCoordinates

mouse

touchScreen

IO_DEVICES

WINDOW_CONTROL

get_Position

INT

Figure 3.6   Remote operation invocation.

result, an object of type POSITION, will then need to be returned to the Hybrid caller. Be-
cause for the CooL type POSITION there exists a translation to the Hybrid type point, the
object mapping server will instantiate an object of type point on the Hybrid cell which will
be initialized to the translated value of the POSITION object. This object will be the result
returned to the caller of the readCoordinates operation.

During the transfer of parameters the object mapping server might encounter a type for
which no type relation has been deﬁned. For example, it might be that on the CooL cell
there is no type relation for the type IO_DEVICES. In this case when the instantiation of an
IO_DEVICES inter-object is requested, the type-matching server will dynamically request
the deﬁnition of the type match. The user will be required to deﬁne on the ﬂy a type match
for the IO_DEVICES type. Once this is done the object-mapping server will resume the
transfer of the parameters. This way an application can be started even without any type
relations deﬁned. The object-mapping server will prompt the user to deﬁne all needed type
relations during the ﬁrst run of the application.

3.8 Conclusions and Research Directions

One of the important advantages of object-oriented design and development methodology
is the ability to reuse existing software modules. However, the introduction of many pro-
gramming languages with different syntaxes, semantics and paradigms severely restricts
the reuse of objects programmed in different programming languages. Although adhoc

Conclusions and Research Directions

91

solutions can be given to solve speciﬁc inter-language reuse cases, different interoperabil-
ity support methods provide the framework for consistent inter-language access and reuse
of objects.

We classify the interoperability support approaches in two ways: ﬁrst depending on the
way that they solve the problem of the different interfaces, and second on the point at
which the interoperability support is handled. For the ﬁrst classiﬁcation we distinguish the
interface standardization approaches, which standardize the interface under which a serv-
ice (functionality) is offered, and the interface bridging approaches, which bridge the
differences between interfaces. For the second classiﬁcation we distinguish the proce-
dure-oriented interoperability approaches, which handle interoperability at the point of
the procedure call, and the object-oriented interoperability approaches, which handle in-
teroperability at the point of the object.

From  the  above  approaches  the  interface  bridging  object-oriented  interoperability
(IB-OOI) approach is the most ﬂexible one since it does not impose predeﬁned interfaces
and can be applied equally well to both object-oriented and non-object-oriented environ-
ments. The Cell framework, which we describe in detail, provides an example of the
IB-OOI approach.

Because the IB-OOI is by no means incompatible with other interoperability approach-
es, its ideas and concepts can be incorporated into other interoperability frameworks, e.g.
the CORBA, and signiﬁcantly enhance their openness and interoperability support. Fur-
thermore the ﬂexibility and generality of the IB-OOI ideas can provide a framework for
the solution of software integration and software evolution problems related to legacy
systems.

3.8.1 Openness of Interoperability Platforms

One of the major disadvantages of existing interoperability frameworks, the most promi-
nent of which is CORBA, is that they are closed to themselves. That is, client and server
applications interacting via the interoperability platform must be implemented making
use the speciﬁc platform interfaces. As a result, taking CORBA as an example, existing
applications cannot be incorporated in the CORBA “world” (non-CORBA clients cannot
use CORBA services, and non-CORBA servers cannot offer their services to CORBA
clients), nor can CORBA applications be moved to a non-CORBA environment.

Designing an interface adaption service for CORBA that will allow C++, for example,
client applications to access CORBA services via their IDL interface will signiﬁcantly en-
hance the openness and acceptability of CORBA and will allow almost any application to
take advantage of the services CORBA offers.

3.8.2 Interoperability and Legacy System Migration

One of the major problems that companies are facing due to the rapid advances of the com-
puter software and hardware technologies is the migration of their legacy systems to a new

92

Interoperation of Object-Oriented Applications

platform. Most of the given solutions are adhoc case-dependent solutions; only recently
has some kind of methodology started appearing [2][3]. However, although the problem
of legacy system migration is in effect an interoperability problem, it has not been recog-
nized as such. The reason is that most of the work and research done in the area of inter-
operability support focuses on the interoperability support of new applications using the
interface standardization approach and does not consider existing legacy applications.

A prominent framework for the support of legacy system migration can be provided
with the interface bridging object-oriented interoperability (IB-OOI) approach. A smooth
incremental migration of a legacy system can be achieved by identifying its components
and their interfaces and using an IB-OOI support to replace the legacy components with
new ones, which most probably have a different interface [14]. This way new components
can be incrementally added to the system without affecting the remaining legacy ones.

References

[1] Denise  Bermek  and  Hugo  Pickardt,  “HooDS  0.3/00  Pilot  Release 

Information,”

[2]

ITHACA.SNI.91.D2#4, Deliverable of the ESPRIT Project ITHACA (2705), 28 Aug. 1991.
Thomas J. Brando and Myra Jean Prelle, “DOMIS Project Experience: Migrating Legacy Systems to
CORBA Environments,” Technical Report, The MITRE Corporation, Bedford, Mass., 1994.

[3] Michael L. Brodie and Michael Stonebraker, “DARWIN: On the Incremental Migration of Legacy In-
formation Systems,” DOM Technical Report, TR-0222-10-92-165, GTE Laboratories Inc., March
1993. 

[4] Rachid Guerraoui, Programmation Repartie par Objets: Etudes et Propositions, Ph.D. thesis, Univer-

site de Paris-Sud, Oct. 1992.

[5] Adele Goldberg, Smalltalk-80, Addison-Wesley, Reading, Mass. 1984.
[6] Yoshinori Kishimoto, Nobuto Kotaka, Shinichi Honiden, “OMEGA: A Dynamic Method Adaption
Model for Object Migration,” Laboratory for New Software Architectures, IPA Japan, Working Paper,
April 1991.

[7] Dimitri Konstantas, Oscar Nierstrasz and Michael Papathomas, “An Implementation of Hybrid,” in
Active Object Environments, ed. D. Tsichritzis, Centre Universitaire d’Informatique, University of
Geneva, 1988, pp. 61–105.

[8] Dimitri Konstantas, “Cell: A Model for Strongly Distributed Object Based Systems,” in Object Com-

position ed. D. Tsichritzis, CUI, University of Geneva, 1991, pp. 225–237.

[9] Dimitri Konstantas, “Design Issues of a Strongly Distributed Object Based System,” Proceedings of
2nd International Workshop for Object-Orientation in Operating Systems (I-WOOOS ’91), IEEE,
Palo Alto, Oct. 17–18, 1991, pp. 156–163.

[10] Dimitri Konstantas, “Hybrid Update,” in Object Frameworks, ed. D. Tsichritzis, Centre Universitaire

d’Informatique, University of Geneva, 1992, pp. 109–118.

[11] Dimitri Konstantas, “Hybrid Cell: An Implementation of an Object Based Strongly Distributed Sys-
tem,” Proceedings of the International Symposium on Autonomous Decentralized Systems ISADS ’93,
Kawasaki, Japan, March 1993.

[12] Dimitri Konstantas, “Cell: A Framework for a Strongly Distributed Object Based System,” Ph.D. the-

sis No. 2598, University of Geneva, May 1993.

References

93

[13] Dimitri Konstantas, ‘‘Object-Oriented Interoperability,’’ Proceedings ECOOP ’93, ed. O. Nierstrasz,
Lecture Notes in Computer Science, vol. 707, Springer-Verlag, Kaiserslautern, Germany, July 1993,
pp. 80–102. 

[14] Dimitri Konstantas, “Towards the Design and Implementation of a Safe and Secure Interoperability
Support Layer in CHASSIS,” CHASSIS SPP project technical report, University of Geneva, March
1994.

[15] Jintae Lee and Thomas W. Malone, “How Can Groups Communicate when they use Different Lan-
guages? Translating Between Partially Shared Type Hierarchies,” Proceedings of the Conference on
Ofﬁce Information Systems, March 1988, Palo Alto, CA.

[16] Barbara Liskov, Dorothy Curtis, Paul Johnson and Robert Scheiﬂer, “Implementation of Argus,” in
Proceedings of the 11th ACM Symposium on Operating Systems Principles, ACM, Austin, Tex., Nov.
1987, pp. 111–122.

[17] Oscar Nierstrasz, ‘‘A Tour of Hybrid — A Language for Programming with Active Objects,’’ Advanc-
es in Object-Oriented Software Engineering, ed. D. Mandrioli, B. Meyer, Prentice Hall, 1992, pp.
167–182. 

[18] Object Management Group and X Open, The Common Object Request Broker: Architecture and Spec-

iﬁcation, Document Number 91.12.1 Revision 1.1

[19] Object Management Group, Object Management Architecture Guide, OMG TC Document 92.11.1,

Revision 2.0, Sept. 1992.

[20] Anna-Kristin Pröfrock, Dennis Tsichritzis, Gerhard Müller and Martin Ader, “ITHACA: An Integrat-
ed Toolkit for Highly Advanced Computer Applications,” in Object Oriented Development, ed. D.
Tsichritzis, Centre Universitaire d’Informatique, University of Geneva, July 1989, pp. 321–344.

[21] James M. Purtilo and Joanne A. Atlee, “Module Reuse by Interface Adaption,” Software Practice &

Experience, vol. 21 no. 6, June 1991.

[22] Ken  Sakamura,  “Programmable  Interface  Design  in  HFDS,”  Proceedings  of  the  Seventh  TRON

Project Symposium, Springer-Verlag, Tokyo, 1990.

[23] Marc Shapiro, “Structure and Encapsulation in Distributed Systems: The Proxy Principle,” 6th Inter-

national Conference on Distributed Computing Systems, Boston, Mass., May 1986. 

[24] Peter Wegner, ‘‘Concepts and Paradigms of Object-Oriented Programming,’’ ACM OOPS Messenger,

vol. 1, no. 1, Aug. 1990, pp. 7–87. 

[25] Jack C. Wileden, Alexander L. Wolf, William R. Rosenblatt and Peri L. Tarr, “Speciﬁcation Level In-

teroperability,” Communications of ACM, vol. 34, no. 5, May 1991. 

[26] Daniel M. Yellin and Robert E. Strom, “Interfaces, Protocols, and the Semi-Automatic Construction
of Software Adaptors,” proceedings of the 9th annual conference on Object Oriented Programming
Systems, Languages and Applications — OOPSLA’94, Portland, Oreg., 23–27 Oct. 1994.

94

Interoperation of Object-Oriented Applications

Annex I: Interface Adaption Language

typeMatchDef 

: remoteCellId ‘::’ typeMatch ‘;’

typeMatch   

: localType ‘->’ remoteTypes typeMatchSpec 
| localType ‘=>’ remoteType [ ‘:’ transFunction ]
| localType ‘+>’ remoteType [ ‘:’ transFunction ]

remoteTypes

: ‘<’ remoteTypeList ‘>’

remoteTypeList

: remoteType [‘@’] [‘,’ remoteTypeList]

typeMatchSpec

: ‘{’ operMatchList ‘}’ [ adaptDefList ]

adaptDefList

: ‘@{’ Program ‘@}’ [adaptDefList]

operMatchList

: operMatch [operMatchList]

operMatch 

: localOpName ‘:’ remoteOpDef ‘(’argMatchList ‘)’ ‘^’ returnValDef ‘;’

remoteOpDef

: remoteType ‘.’ remoteOpName

argMatchList

: argMatch [‘,’ argMatchList]

argMatch  

: localArgId
| adaptFunct ‘(’ localArgId ‘)’
| localArgId ‘:’ localType ‘<-’ remoteType
| ‘<’ localArgIdList ‘>’ ‘:’ ‘<’ localTypeList ‘>’ ‘<-’ remoteType
| remoteOpDef ‘(’ argMatchList ‘)’

returnValDef

: RET
| adaptFunct ‘(’ RET ‘)’
| RET ‘:’ localType ‘->’ remoteType

localArgIdList

: localArgId [‘,’ localArgIdList]

localTypeList

: localType [ ‘,’ localTypeList]

localArgId   

: ‘$’SMALL_INTEGER
| INTEGER_LITERAL

localType   

remoteType  

: STRING

: STRING

remoteOpName

: STRING

remoteCellId 

transFunction

adaptFunct

Program

: STRING

: STRING

: STRING

: Program code in Native Language.

Annex II: Type Match Deﬁnition Example

95

Annex II: Type Match Deﬁnition Example

CooLCell :: windowServer -> WINDOW_CONTROL  { 

newWindow : create_win($3, $4, $1, $2, 17 ) ^ RET ;
newSquareWin : create_win ( bottomRX($1, $3), bottomRY($2, $3), $1, $2, 17 ) 

^ RET ;

refreshDisplay : redisplay_all ( $1 : display <- DISPLAY ) ^ int2bool(RET) ;
readCoordinates : get_Position

 (< $2, $1, $3 >  : < keyboard, mouse, touchScreen >  <- IO_DEVICES,
 $ 4 ) ^ RET

windowSelected : select_Window ( 

WINDOW_CONTROL.get_Position

 ( < $2,  $1, $3 >  : < keyboard, mouse, touchScreen >  <- IO_DEVICES, 1) 

 )  ^ RET ;

}
@{

bottomRX : (integer : topLeftX, side ) -> integer ;

{ return (topLeftX + side ) ; }

bottomRY : (integer : topLeftY, side ) -> integer ;

{ return (topLeftY - side ) ; }

int2bool : ( integer : intval ) -> boolean ;

 

  

{ 

}

@} ; 

return (intval ~=? 0) ;

96

PART III

Speciﬁcation and 
Composition

98

Chapter 4
Regular Types for
Active Objects*

Oscar Nierstrasz

Abstract        Previous  work  on  type-theoretic  foundations  for  object-oriented
programming  languages  has  mostly  focused  on  applying  or  extending
functional type theory to functional “objects.” This approach, while beneﬁting
from a vast body of existing literature, has the disadvantage of dealing with
state change either in a roundabout way or not at all, and completely side-
stepping  issues  of  concurrency.  In  particular,  dynamic  issues  of  non-uniform
service  availability  and  conformance  to  protocols  are  not  addressed  by
functional types. We propose a new type framework that characterizes objects
as  regular  (ﬁnite  state)  processes  that  provide  guarantees  of  service  along
public channels. We also propose a new notion of subtyping for active objects,
based on Brinksma’s notion of extension, that extends Wegner and Zdonik’s
“principle  of  substitutability”  to  non-uniform  service  availability.  Finally,  we
formalize what it means to “satisfy a client’s expectations,” and we show how
regular types can be used to tell when sequential or concurrent clients are
satisﬁed.

4.1

Introduction

Much of the work on developing type-theoretic foundations for object-oriented program-
ming languages has its roots in typed lambda calculus. In such approaches, an object is
viewed as a record of functions together with a hidden representation type [10]. While this
view has the advantage of beneﬁting from a well-developed body of literature that has a
great deal to say of relevance to OOP about polymorphism and subtyping — see, for ex-
* This chapter is a revised and corrected version of a previously published paper.  ACM. Proceedings 
OOPSLA  ’93, Washington DC, Sept. 26 – Oct. 1, 1993, pp. 1–15. Permission to copy without fee all or part 
of this material is granted provided that the copies are not made or distributed for direct commercial advan-
tage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that 
copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, 
requires a fee and/or specific permission.

Oscar Nierstrasz, “Regular Types for Active Objects,” Object-Oriented Software Composition, O. Nierstrasz and D. Tsichritzis (Eds.), pp. 
99-121, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

100

Regular Types for Active Objects

ample, chapter 6 of this book — the fact that objects in real object-oriented languages
change state is typically dealt with in an indirect way.

The mismatch is even more acute in concurrent object-oriented languages. In such lan-
guages, “active objects” may have their own thread of control and may delay the servicing
of certain requests according to synchronization constraints [20]. Such objects may fur-
thermore require a particular protocol to be obeyed (such as an initialization protocol) for
them to behave properly. Chapter 2 of this book presents a survey of such languages and a
thorough discussion of issues. See also chapter 12 for an example of an object-oriented
framework in which “gluons” encapsulate protocols to facilitate dynamic interconnection
of components. Existing notions of object types coming from a functional setting do not
address the issues of non-uniform service availability or conformance to a service proto-
col. (Although these issues are also relevant for passive objects and sequential OOPLs, we
draw our main motivation from object-based concurrency, and so we will refer in a general
way to “active” objects.)

We argue that, in order to address these issues, it is essential to start by viewing an object
as a process, not a function. (See [26] for other reasons.) By “process” we mean an abstract
machine that communicates by passing messages along named channels, as in Milner’s
CCS [24] or the polyadic π-calculus [25]. Processes naturally model objects since they
represent pure behaviour (i.e. by message passing). Behaviour and “state” are indistin-
guishable in such an approach, since the current state of a process is just its current behav-
iour. Unfortunately there has been considerably less research done on type models for
processes than for functions, and the work that has been done focuses primarily on typing
channels, not processes (see, for example [25] [33]).

Although processes in general may exhibit arbitrary behaviour, we can (normally) ex-
pect objects to conform to fairly regular patterns of behaviour. In fact, we propose on the
one hand to characterize the service types associated with an object in terms of types of re-
quest and reply messages, and on the other hand to characterize the availability of these
services by regular types that express the abstract states in which services are available
and when transitions between abstract states may take place. Services represent contracts
or “promises” over the message-passing behaviour of the object: in a given state the object
will accept certain types of requests over its public channels, and promises to (eventually)
send a reply along a private channel (supplied as part of the request message). When pro-
viding a particular service, an object may (non-deterministically) change its abstract state
to alter the availability of selected services.

Subtyping in our framework is based on a generalization of Wegner and Zdonik’s “prin-
ciple of substitutability” [34]: services may be reﬁned as long as the original promises are
still upheld (by means of a novel application of intersection types [5] [31]), and regular
types may be reﬁned according to a subtype relation — based on Brinksma’s extension re-
lation for LOTOS processes [7] — that we call “request substitutability.”

In section 4.2 we shall brieﬂy review what we mean by “type” and “subtype,” and how
we may understand the notion of substitutability in the context of active objects. In section
4.3 we introduce service types as a means to characterize the types of request messages un-

Types, Substitutability and Active Objects

101

derstood by an object and their associated replies, and we show how intersection over
service types provides us with a means to reﬁne these speciﬁcations.

In section 4.4 we deﬁne request substitutability for transition systems and we demon-
strate its relationship to failures equivalence. In section 4.5 we introduce regular types as
a means to specify the protocols of active objects. In section 4.6 we propose to use request
substitutability as a subtype relationship for regular types, and we demonstrate a simple
algorithm for checking that one regular type is request substitutable for another. Next, we
formalize a client’s expectations in terms of request satisﬁability, and we show how regu-
lar types relate to this notion.

In section 4.8 we summarize a number of open issues to be resolved on the way to prac-
tically applying our type framework to real object-oriented languages. We conclude with
some remarks on unexplored directions.

4.2

Types, Substitutability and Active Objects

Before we embark on a discussion of what types should do for active objects, we should
be careful to state as precisely as possible (albeit informally) what we believe types are
and what they are for. Historically, types have meant many things from templates for data
structures and interface descriptions, to algebraic theories and retracts over Scott’s seman-
tic domains. We are interested in viewing types as partial speciﬁcations of behaviour of
values in some domain of discourse. Furthermore, types should express things about these
values that tell us how we may use them safely. Naturally, we would also like these speci-
ﬁcations to (normally) be statically checkable.

Subtyping is a particular kind of type reﬁnement. The interpretation of a type for some
value space determines which values satisfy the type. A subtype, then, is simply a stronger
speciﬁcation and guarantees that the set of values satisfying the subtype is a subset of
those that satisfy the supertype. If T is a type (expression) and U is some universal value
space of interest, then we shall write x:T to mean x satisﬁes T, and [[T]] to mean { x  x:T }
(i.e. where U is understood). Another type S is a subtype of T, written S≤T, if x:S ⇒ x:T, i.e.
[[S]]⊆[[T]].

But speciﬁcally what kinds of properties should types specify? It is worthwhile to recall

Wegner and Zdonik’s principle of substitutability:

An instance of a subtype can always be used in any context in which an instance of a 
supertype was expected. [34]

It is important to recognize that “can be used” implies only “safely,” and nothing more.
It does not imply, for instance, that an application in which a type has been replaced by
some subtype will exhibit the same behaviour. We are not concerned with full behavioural
compatibility, but only with safe usage.

What does type safety mean in an object-oriented setting? First of all, that objects
should only be sent messages that they “understand.” We must therefore be able to specify
the types of request and reply messages exchanged by objects. If we think of objects as

102

Regular Types for Active Objects

Accept requests

Send reply

Accept requests

Send requests

Receive replies

Figure 4.1   Non-uniform service availability.

“servers,” then the services they provide are promises that they understand certain types
of requests, and that, in response to a particular request, they will eventually send a certain
type of reply. Subtyping of services can then be deﬁned in a fairly conventional way, in that
a subtype at least guarantees the promises of the supertype: at least the same requests are
understood (possibly more) and consequent replies to those requests are guaranteed to be
of the right type.

Services may not always be available, however. If requests must be sent in a certain or-
der, or if certain services may be temporarily unavailable, then, we argue, the object’s type
should describe this. Type safety, in this case, means that clients (or, more generally, envi-
ronments) that interact with such objects do not deadlock because of protocol errors. Type
substitutability is correspondingly deﬁned so that sequences of interactions that are valid
for a supertype are also valid for a subtype. A client will never be unexpectedly starved of
service because a subtype instance has been substituted. 

In order to explain our type approach, we will adopt an object model that views objects
as certain kinds of communicating processes [4][8][17][24]. (Although we could formal-
ize our model in process-theoretic terms, as in, for example, [30], for the purposes of this
presentation we will attempt to be rigorous and precise without being excessively formal.)
Figure 4.1 depicts an object’s behaviour in an idealized fashion. The large circles rep-
resent the object in its various states and the small circles represent its communication
channels, white for input and black for output. The input channels on the left side are for
receiving requests. Note that the set of “enabled” input requests changes over time.

In our object model, every object receives requests along uniquely identiﬁed channels,
one per request name. Each request consists of a message containing a number of argu-
ments and a unique reply address (also a channel name). The arguments must be of the cor-
rect type. (We will not be concerned with what kinds of values may be passed, but the

Intersecting Service Types

103

reader  may  assume  that  any  reasonable  value  —  objects,  object  identiﬁers,  channel
names, etc. — is fair game.)

An object, then, accepts requests addressed to it through its (public) request channels,
and it may issue requests to other objects it is acquainted with via their request channels.
All replies, however, are communicated along private channels that are temporarily estab-
lished by clients of requests. When an object accepts a request, it implicitly guarantees to
(eventually) send a reply (of the correct type) to the client. This reply may be delivered by
a third party to which the reply address has been forwarded. Furthermore, the object may
vary the requests accepted over time by selectively listening only to certain request chan-
nels. When an object is ready to accept a message addressed to one of its request channels,
we say that the request is enabled, and that the corresponding service is available. We as-
sume that the complete set of public request channels is ﬁnite and ﬁxed in advance for any
object.

We will now separately discuss the issues of specifying types of services associated
with an object (section 4.3), and specifying when those services are available (section
4.4).

4.3

Intersecting Service Types

We will start by introducing the following syntax for service types:

S ::= all  none  M(V)→V  S^S
V ::= all  none  (V,...)  ...

where M is a request name and V is a value type (i.e. types for argument and return values).
“→” binds more tightly than “^”. We assume that V includes some base types, the types all
and none, and tuples over value types.

We will write x : m(A)→R to mean that object x may receive a value a of type A together
with a reply address along a request channel xm and will consequently promise to return a
value r of type R. We may also write x.m(a) : R to say that x understands the message m(a)
and returns a value of type R. We call the type expression m(A)→R a service of x, and we
say that x offers this service. Note that this does not imply anything about other services
that x may or may not offer.

We may reﬁne these expressions by the intersection operator for types (^). Intersection
types have been studied extensively in functional settings (see [31] for a bibliography).
Here we propose to assign an interpretation to them for objects in a process setting. If we
write x:S1^S2, we wish that to mean precisely that x:S1 and x:S2. In set-theoretic terms,
then:

[[S1^S2]] = [[S1]] ∩ [[S2]]

As speciﬁcations, we mean that both S1 and S2 are true statements about x. As we shall
see, this device allows us not only to attribute sets of services to objects, but also permits
us to reﬁne their types in interesting ways.

104

Regular Types for Active Objects

The expressions all and none represent, respectively, the set of all objects and the empty
set. That is, all tells us nothing about the services of an object, and none demands so much
that no object can possibly satisfy it. (all and none are the “top” and “bottom” of our type
hierarchy.)

Let us now brieﬂy look at the subtyping properties of service types. Some facts are

clear:

1. T ≤ all (i.e. for any value or service type T)
2. none ≤ T
3. m(none)→T = all (since no such request can ever be received)
4. R1 ≤ R2 ⇒ m(A)→R1 ≤ m(A)→R2
5. A2 ≤ A1 ⇒ m(A1)→R ≤ m(A2)→R (i.e. a contravariant rule)
Now, considering intersections, the following are straightforward:

6. S1^S2 ≤ S1 and S1^S2 ≤ S2
7. S ≤ S1 and S ≤ S2 ⇒ S ≤ S1^S2
8. S1 ≤ S2 ⇒ (S1^S2) = S1 (follows from (6) and (7))

Now consider:

9. m(A1)→R1 ^ m(A2)→R2 ≤ m(A1^A2)→(R1^R2)

Normally we may expect to write type expressions like:

put(all)→(Ok) ^ get()→(all)

but nothing prevents us from writing:

inc(Int)→Int ^ inc(Real)→Real

or even:

update(Point)→Point ^ update(Colour)→Colour

If an incoming message satisﬁes more than one request type in the intersection, then the
result must satisfy each of the result types. Our (informal) semantics of intersection types
requires that all applicable service guarantees must hold. In this case, if:

cp:ColouredPoint,

where ColouredPoint = Point^Colour
then x.update(cp):Point and x.update(cp):Colour. The result, therefore, must have type Col-
ouredPoint.

Notice that as a corollary of (9), via (6) , (4) and (7), we also have:
10. m(A)→(R1^R2) = m(A)→R1 ^ m(A)→R2

This also means, however, that we must take care not to intersect services with abandon.
For example, suppose Int and Real are disjoint types. Then:

size(Point)→Int ^ size(Colour)→Real
≤ size(ColouredPoint) → (Int^Real)
= size(ColouredPoint) → none

Request Substitutability

105

Since the two size services have contradictory result types, their intersection yields the re-
sult type none.

As a ﬁnal remark, notice that type-safe covariance is naturally expressed:

update(Point) → Point ^ update(ColouredPoint) → ColouredPoint

is a subtype of both update(Point)→Point and update(ColouredPoint)→ColouredPoint. A cli-
ent supplying an instance of ColouredPoint as an argument can be sure of getting a Coloured-
Point back as a result, whereas clients that supply Point arguments will only be able to infer
that the result is of the more general type Point.

4.4

Request Substitutability

Service types tell us what types of requests are understood by an object and what types of
reply values it promises to return, but they do not tell us when those services are available.
In  particular,  we  are  interested  in  specifying  when  an  object’s  request  channels  are
enabled. The sequences of requests that an object is capable of servicing constitute the
object’s protocol. An object that conforms to the protocol of another object is safely sub-
stitutable for that second object, in the sense that clients expecting that protocol to be sup-
ported will receive no “unpleasant surprises.”

Before tackling the issue of how to specify protocols, let us ﬁrst try to formalize the ap-

propriate substitutability relation.

According to our abstract object model, objects can do four things: accept requests, is-
sue requests, receive replies and send replies. Since the behaviour of objects should be
properly encapsulated, clients should only need to know about the ﬁrst and the last of
these, i.e. the requests accepted and the replies sent. If we can safely assume that an object
that accepts requests promises to deliver replies according to service type speciﬁcations,
then the only additional thing a client needs to know about an object’s protocol is when it
will accept requests. We therefore adopt an abstract view of an object’s protocol that only
considers requests received along its request channels, and ignores all other messages.
(Later, in section 4.7, we will model clients’ protocols by considering only requests is-
sued.)

In this view we model an object as a transition system where each state of interest rep-
resents a stable state of the object, in which it blocks for acceptance of some set of re-
quests. A transition takes places upon the receipt of some request and leads to a new stable
state. If an object in state x can accept a request r leading to a new state x′, we would write:

x →r

 x′

Note that we ignore all intervening communications leading to the new state. If these
communications are purely internal to the object, we can view it as a closed system, but if
some of these communications are with external acquaintances, then an element of non-
determinism is introduced, since the transitions to new stable states may depend upon the
current state of the environment. In cases like this, we feel it is correct to view the object’s

106

Regular Types for Active Objects

protocol as inherently non-deterministic, since it would be unreasonable to expect clients
to monitor the environment to know the state of an object’s protocol.

Clients are typically interested not just in issuing a single request, but in issuing series
of related requests. Suppose s is such a sequence r1,r2,... of requests. If an object in state x
can accept such a sequence, leading to state x′, then we write:

x ⇒s x′

An important part of the protocol of an object is the set of sequences of requests that it
may accept. This is conventionally captured by the notion of set of traces [8] of a transition
system:
Definition 1  traces(x) ≡ { s  ∃x′, x ⇒s

x′ }.

Suppose we wish to express that an object in state x is request substitutable for an object
in state y, which we will write x:<y. Then clearly we must have traces(y) ⊆ traces(x), for if
a client of y expects y to accept a sequence of requests s, and we substitute x for y, then x
must accept the same sequence s. x may accept additional sequences, but since the client
does not expect* them, they are of no concern to us.

But the inclusion of traces is not enough to guarantee request substitutability, for sup-
pose that after a sequence of requests s, y will move to state y′, but x will move to either
state x′ or x′′. Furthermore, suppose that state x′ is identical to y′ — i.e. behaviour from that
point on is identical — and x′ permits a request r to be accepted, but x′′ denies it. Then it is
possible that traces(y) ⊆ traces(x), but nevertheless the client may receive a nasty surprise
if x is substituted for y and the request r is refused after the sequence s. Traces tell us what
sequences are acceptable, but they do not tell us if they are necessarily acceptable! For
this, we need the help of a ﬁner notion of failures [8].

First, we need to deﬁne the initials of an object — the requests which are initially ena-

bled:
Definition 2  init(x) ≡ { r  ∃x′, x →r
Definition 3  The set of failures of an object x is

 x′ }.

failures(x) ≡ { (s,R)  ∃x′, x ⇒s

x′, R is ﬁnite, R ∩ init(x′) = ∅ }.

That is, (s,R) is a failure of x if x may simultaneously refuse all of the requests in the set
R after accepting the sequence s. It may be the case that x will reach a state in which some
or all of the requests in R will be accepted, but we know that it is possible that they will all
be refused. (NB: It is also important that the state x′ be stable for the set R to be well-
deﬁned, but we have already assumed that.)

Now, suppose that we want x:<y and we know that (s,R) is a failure of x. Furthermore,
suppose that s is a sequence of requests in traces(y). Then a client will be satisﬁed only if
it expected that (s,R) was also a failure of y. Note that if s is not a sequence in the protocol
of y, then the client is unconcerned whether (s,R) is a failure of x or not, since it is in any

* Although we have not yet formalized clients’ expectations, we are implicitly assuming here that clients 
are sequential, i.e. they only issue a single request at a time. Later, when we define request satisfiability, we 
will see how request substitutability relates to concurrent clients.

Request Substitutability

107

case not expected to be handled. To express this notion of relative failures, we need the fol-
lowing deﬁnition:
Definition 4  The set of relative failures of an object in state x with respect to an object

in state y is: failuresy(x) ≡ { (s,R) ∈ failures(x) s ∈ traces(y)}.

Now we come to the deﬁnition of request substitutability:

Definition 5  An object in state x is request substitutable for an object in state y, written

x:<y iff:

(i)
(ii)

traces(y) ⊆ traces(x)
failuresy(x) ⊆ failures(y).

(This turns out to be identical to the extension relation introduced by Brinksma [7]. See
also Cusack [13] for a discussion of various conformance relations, including extension,
in the context of CSP [8].)

That is, a client expecting x to follow the protocol of y will expect that all sequences of
requests supported by y will also be accepted by x, and that any requests refused by x after
accepting one of those sequences might also have been refused by y. Note that x may (1)
accept additional sequences of requests that the client does not expect and therefore will
not use, and (2) may eliminate some non-determinism in y by providing fewer possible
transitions between states. On the other hand, x may introduce new transitions and states
as long as they can be explained from the viewpoint of y. In general, either x or y may have
more or less states or transitions.

Note also that the set of failures of an object tells us all we need to know in order to de-
termine request substitutability, since the traces can be derived from the failures set by
projections, and relative failures can be determined from the failures of one object and the
traces of another.
Proposition 1  Request substitutability is a pre-order.
Proof  

(i) :< is reflexive: ∀x, x:<x — immediate, since failuresx(x) = failures(x).
(ii) :< is transitive: Suppose x:<y and y:<z. Then traces(z) ⊆ traces(y) ⊆ traces(x).
Next, suppose (s,R) ∈ failuresz(x). Then s ∈ traces(z) ⊆ traces(y),
so (s,R) ∈ failuresy(x) ⊆ failures(y). But then (s,R) ∈ failuresz(y) ⊆ failures(z),
so we conclude x:<z. ❑

There exists a vast literature on process equivalences and pre-orders (see, for example,
[1][14] for some interesting comparisons). Interestingly, the equivalence induces by re-
quest substitutability is the same as failures equivalence [7][8].
Definition  6    Objects  in  states  x  and  y  are  failures  equivalent  iff  failures(x)  =

failures(y). 

Proposition 2  x and y are failures equivalent iff x:<y and y:<x.
Proof  
⇒)

failures(x) = failures(y) ⇒ traces(x) = traces(y)
⇒ failures(x) = failuresy(x) = failuresx(y) = failures(y) ⇒ x:<y and y:<x.
 x:<y and y:<x ⇒ traces(x) = traces(y).

⇐)

108

Regular Types for Active Objects

Hence failuresy(x) = failures(x) ⊆ failures(y).
By symmetry, failures(x) = failures(y). ❑

Although failures equivalence is exactly request equivalence, the inclusion of failures

sets does not imply request substitutability, nor vice versa. It sufﬁces to consider:

a

b

x =

a

a

y =

It is easy to see that x:<y (but not the reverse, since y does not permit a.b) and failures(y) ⊆
failures(x) (but not the reverse, since (a.b,{a,b}) is a failure of x but not of y). See also Brin-
skma [7] for a detailed discussion.

4.5

Viewing Objects as Regular Processes

We now have a plausible deﬁnition of protocol conformance in terms of request substitut-
ability — what we still need is a way to specify protocols, and a way to check that an object
conforms to a protocol, or that one protocol conforms to another. In the most general case,
unfortunately, request substitutability will be undecidable since failures equivalence is
undecidable in general [18]. (If request substitutability were decidable, we could use its
decision procedure to check if two processes were failures equivalent according to propo-
sition 2.)

We therefore propose to specify protocols as regular processes, i.e. processes with a ﬁ-
nite number of “states” or behaviours [6][11][15][23]. A regular process is essentially a ﬁ-
nite  state  machine  (hence  the  adjective  “regular”),  where  transitions  take  place  upon
communications with other processes. We will call the speciﬁcation of such a process a
regular type, since we intend to use it to specify object protocols. It turns out that by re-
stricting ourselves to ﬁnite state protocols, request substitutability is decidable by a simple
procedure.

Furthermore, although we cannot specify all protocols exactly with a ﬁnite number of
states, we can approximate inﬁnite state protocols by non-deterministic regular processes.
These approximations can then be used in many cases to check request substitutability.

Let us consider a few canonical examples using various kinds of “container” objects
(bounded buffers, stacks, variables) each supporting (at least) put and get requests. We can
associate with these objects a number of abstract states, each corresponding to a set of cur-
rently enabled requests. Since we assume that the total set of possible services is ﬁnite, a
ﬁnite number of abstract states sufﬁces to characterize all the possible combinations of en-
abled requests (and normally only a few of these combinations should be needed). From
the client’s point of view, transitions may take place when services are provided (since this
is all the client may observe).

Viewing Objects as Regular Processes

109

First, consider a one-slot bounded buffer.

Buf =

put

get

It has two abstract states: one in which only a put is accepted, and one in which only a get
is allowed. Upon accepting a put or a get request, the object changes state. We express this
by the protocol (regular type) Buf.

Now consider an uninitialized variable with the protocol Var.

put

Var =

put, get

Its protocol requires that a put must ﬁrst be requested, but then put and get requests may be
interleaved arbitrarily. In this case, we see that Var:<Buf since a client that expects an object
to obey the Buf protocol will never be “disappointed” if an object obeying Var is substitut-
ed. The reverse does not hold, because Buf will refuse the sequence put.get.get, whereas Var
will not.

In these two cases, the transitions are deterministic, since Buf and Var are really ﬁnite

state protocols.

Now consider a stack (with put and get instead of push and pop). Initially only a put is
possible. Then both put and get are enabled. Further put requests will not change this, but
a get may bring us back to the initial state. The corresponding regular type is speciﬁed be-
low as NDStack. 

NDStack =

put

get

put, get

It resembles Var except that after a get, we do not necessarily know what state we are in.
Clearly, such a description is an approximation because we are attempting to express the
service availability of a deterministic process (the object) by means of a non-deterministic
one (the regular type).

We can try to add another intermediate state, as in NDStack2:

NDStack2 =

put

get

put

get

put, get

but after two put requests and a get we again do not know what state we are in. In fact, we
would need an inﬁnite number of states to describe completely the Stack protocol.

As we argued before, however, non-determinism is inherent in some protocols, because
objects are not, in general, closed systems. Furthermore, the non-deterministic regular

110

Regular Types for Active Objects

types are still useful to us. We can determine, for example, that an object conforming to the
NDStack regular type also conforms to Buf since NDStack:<Buf.

Choosing a simple and readable syntax for specifying regular types is somewhat prob-
lematic. For the purpose of this chapter we will opt for simplicity. We specify a regular
type by a pair, (x1,E) consisting of a ﬁnite system of equations E of the form:

E = { x=t, ...}

where x1 is a distinguished start state, and the t are regular type expressions of the form:

t ::= r.x  t + t

r is a request name and x is a state name. Every x used in E must have exactly one deﬁning
equation in E (except for nil, which stands for a dead state with no transitions). Regular
types have the following interpretation as transition systems:

init(nil) = ∅
r.nil →r

 nil

1.
2.
3. x=t ∈ E ⇒ r.x →r
4.
5.
With this simple syntax, then, we could specify the various regular types we have seen

t1  →r1 t1′ ⇒ t1+t2  →r1 t1′
t2  →r2 t2′ ⇒ t1+t2  →r2 t2′

 t

as follows:

Buf = (b1, { b1=put.b2, b2=get.b1 })
Var = (v1, { v1=put.v2, v2=put.v2+get.v2 })
NDStack = (s1, { s1=put.s2, s2=put.s2+get.s2+get.s1 })
NDStack2 = (s1, { s1=put.s2, s2=put.s3+get.s1,

s3=put.s3+get.s2+get.s3 })

At this point the reader may wonder why we cannot simply use regular expressions to
specify regular types. The reason is that regular expressions stand for regular languages,
i.e. sets of strings, not regular processes. Regular expressions can consequently tell us
about the traces of a transition system but not its failures. Consider, for example, the reg-
ular types Var and NDStack. If we consider any state to be a valid ﬁnal state, then they rec-
ognize exactly the same regular language, namely:

ε + put.(put+get)*

But this does not tell us that after accepting a put followed by a get, NDStack may refuse an-
other get, whereas Var never will. (A similar argument is elaborated in [16] to introduce the
difference between language and process equivalence.) For precisely the same reason, it
is not generally possible to convert a non-deterministic regular process into a determinis-
tic one without losing information.

4.6

Subtyping Regular Types

We now propose to use request substitutability as a subtyping relationship over regular
types. We are justiﬁed in this since we have shown that request substitutability is a pre-
order, so if Var:<NDStack and NDStack:<Buf, then we can conclude that Var:<Buf.

Subtyping Regular Types

111

The fact that regular types have ﬁnite states means that a simple algorithm exists for
checking the subtype relationship (not surprisingly, the algorithm is similar to that for
checking equivalence of ﬁnite state automata [2]). To derive the algorithm, we must intro-
duce a multi-state variant of request substitutability. First let us extend init() and → to
work with sets of states:
Definition 7  init(X) ≡ { r  ∃x∈X, x′, x →r
Definition 8  X →r

 x′ }.
 X′ iff X′ = { x′  ∃x∈X, x →r

 x′ }.

Note in particular that → for sets of states is a function, not just a relation. In effect, we
are turning a non-deterministic transition system into a deterministic one in the traditional
way by expanding single states into sets of reachable states [2].

Now let us consider the following deﬁnition:

Definition 9  A set of object states X is multi-state request substitutable for a set of

states Y, written X:<<Y, iff:

init(Y) ⊆ init(X)

(i)
(ii) ∀x∈X, ∃y∈Y, init(y) ⊆ init(x)
(iii) ∀r∈init(Y), if X →r

 X′ and Y →r

 Y′, then X′:<<Y′.

Condition (i) guarantees that all transitions possible from some state of Y are also pos-
sible from some state of X. Condition (ii) says that any failure possible in some state of X
can be explained by a failure of some corresponding state of Y (some y has the same or few-
er initial transitions possible). Condition (iii) is simply the recursive case.
Proposition 3  { x } :<< { y } ⇔ x:<y.
Proof  

⇒ ) Suppose that { x } :<< { y }, then traces(y) ⊆ traces(x) by 9(i) and 9(iii).
Next, suppose (s,R) ∈ failuresy(x). Then ∃x′, x ⇒s
y′,
init(y′) ⊆ init(x′) by 9.ii and 9.iii so (s,R) ∈ failures(y) and failuresy(x) ⊆ failures(y)
hence x:<y.
⇐ ) Similar argument in reverse. ❑

x′, init(x′) ∩ R = ∅ and ∃y′, y ⇒s

Note that this result is independent of whether we restrict our attention to ﬁnite state
transition systems or not. If the sets of reachable states are ﬁnite, however, i.e. if x and y are
regular types, then proposition 3 provides us with a simple procedure to check whether
x:<y by simply generating all the sets of states reachable from {x} and {y} by transitions in
traces(y) and checking conditions 9(i) and 9(ii) for all the comparable sets. Since the state
space is ﬁnite, the set of reachable state sets must also be ﬁnite, and so the comparison
must terminate in ﬁnite time.

The following iterative algorithm suggests itself: we maintain a LIST of comparable
sets of states and possible transitions, of the form (X,Y,R), where X and Y are the sets of
states of x and y reachable from some common trace s of y, and R is the set of possible tran-
sitions (requests) from Y that the algorithm must traverse. We follow each possible request
to new comparable state sets until we have exhausted all transitions and checked all com-
parable state sets, or until we fail to satisfy one of the conditions in deﬁnition 9.

112

Regular Types for Active Objects

If possible, select some (X,Y,R) from LIST where R is not empty, else SUCCEED

1. Verify that init(y) ⊆ init(x), else FAIL
2. Add ({x},{y},init(y)) to LIST
3.
4. Select some r in R and replace (X,Y,R) by (X,Y,R\{r}) in LIST
5. Compute X′ and Y′, where X →r
6.
7.
8.

If (X′,Y′,R′) for some R′ is already in LIST, then go to step 3, else continue
If init(Y′) ⊆ init(X′), then continue, else FAIL
If for each xi ∈ X′ there exists some yj ∈ Y′ such that
init(yj) ⊆ init(xi), then continue, else FAIL

 X′ and Y →r

 Y′

9. Add (X′,Y′,init(Y′)) to LIST and go to step 3.

Note that steps 2 and 7 guarantee that X′ generated in step 5 will never be empty.

Since there is a ﬁnite number of reachable sets X and Y to compare, the algorithm clearly
terminates. In the worst case, there will be (2n–1)×(2m–1) comparisons (i.e. the size of
LIST), where n and m are the number of states reachable from x and y respectively, but nor-
mally there will be far fewer, since not all subsets of states will be generated, and not all
possible combinations will need to be compared. In the special case that one compares two
deterministic regular types, the maximum number of comparisons is just n×m, but may be
even as little as m (in case of success, that is).

Let us brieﬂy look at an example that compares Buf to the regular type of a stack that

supports an additional swap operation:

put, get, swap

s1

put

get

s2

NewNDStack = (s1, { s1=put.s2,

s2=put.s2+get.s2+get.s1+swap.s2 })

We wish to check whether NewNDStack:<Buf. We start with: ({s1},{b1},{put}). Both s1 and

b1 permit a put, and they have the same requests enabled, so we can add this to our list:

({s1},{b1},{put})

The  only  possible  transition  is  put,  so  we  remove  it  from  LIST  and  generate:
({s2},{b2},{get}). s2 enables at least the requests that b2 enables, so we add this to our list:

({s1},{b1},{put})
({s2},{b2},{get})

Now only a get is possible, so we generate: ({s1,s2},{b1},{put}). We verify that s1 and s2 each
enable at least the requests of b1 and add this to our list:

({s1},{b1},{put})
({s2},{b2},{get})
({s1,s2},{b1},{put})

Request Satisﬁability

113

Buf =

put

get

put

FaultyStack =

put, get

get

put, get

put

get

NDStack =

put, get

Buf2 =

put

put

get

get

NDStack2 =

put

put

get

get

put

Var =

put, get

NewNDStack =

put, get,swap

put

get

Figure 4.2   Some subtype relationships between regular types.

Now we can perform a put, but this just generates ({s2},{b2},{get}), which is already repre-
sented in the list. There is nothing left to check, so we SUCCEED. (In the reverse direction
we would quickly FAIL in step 7 after a single put because b2 enables neither put nor swap.)
Note that the total number of comparisons (3) is far less than the worst case possible (9).
Note that NewNDStack is request substitutable for Buf even though it is, in a sense, less
deterministic than Buf. The key point is that it is safe to use wherever we are expecting Buf-
like behaviour.

Figure 4.2 shows the subtype relationships between a few of the regular types we have
seen. Curiously, NDStack and NDStack2 are not related (to see why, consider the sequence
put.get.get,  which  is  in  traces(NDStack)  but  not  in  traces(NDStack2),  and  the  failure
(put.put.get,{get}), which is in failures(NDStack), but not in failures(NDStack2)).

4.7

Request Satisﬁability

Up to now our discussion has focused on the protocols of service providers. Request sub-
stitutability tells us when an object obeying some protocol can be safely substituted by
some second object, assuming that the ﬁrst object satisﬁes the client’s expectations. But
we have not yet formalized what it means to satisfy a client. It turns out that we need to de-
ﬁne a new relation, called request satisﬁability, which expresses this idea.

114

Regular Types for Active Objects

If the protocol of a service provider expresses when its services are available, then the
protocol of its client expresses when those services are requested. We propose that a client
is satisﬁed if its requests are always honoured. Up to now we have implicitly assumed that
clients issue at most one request at a time. In general, however, a client may issue multiple
requests simultaneously (particularly if the “client” is actually an environment consisting
of multiple concurrent clients) — in such cases, we do not ask that all of the requests be
honoured together, just that the client be guaranteed to make progress, i.e. at least one re-
quest must always be accepted. Since the current state of the client may not necessarily be
deterministic, the object must be prepared for the client to be in any one of its reachable
states. The object is allowed to terminate (i.e. refuse all further requests) only if it can be
sure that the client will issue no more requests. In short, we must ensure that an object can
only fail if the client makes no more offers.

We can formalize this as follows:

Definition 10  The set of offers of a transition system c is:

offers(c)  ≡ { (s,R)  ∃c′, c ⇒s c′, R = init (c′) }.

So, if (s,R) is an offer of c, then we know that c may issue the sequence of requests s and
then may issue the set of requests R. It is also possible that c may issue some other set of
requests R′, if (s,R′) is also an offer of c.
Definition 11  An object x is request satisﬁable for a client c, written x   c, iff:

(s,R) ∈ failures(x)∩offers(c) ⇒ R = ∅

If both client and server protocols are speciﬁed as regular types, then request satisﬁability
can be determined by an algorithm along the lines of the one we demonstrated for check-
ing request substitutability.

4.7.1 Sequential Clients

How does request substitutability relate to request satisﬁability? Clearly, we would expect
that if x:<y and y   c, then x   c. It turns out that if c is sequential, then this is in fact the case.
Definition 12  A client c is sequential if (s,R)∈offers(c) ⇒ |R| ≤ 1.
Lemma 4  If c is sequential, then y   c⇒ traces(c) ⊆ traces(y).
Proof  By induction on the length of traces of c. ❑
Proposition 5  If c is sequential, then x:<y and y   c ⇒ x   c.
Proof  (s,R) ∈ failures(x)∩offers(c) ⇒ s ∈ traces(c) ⊆ traces(y)

⇒ (s,R) ∈ failuresy(x) ⊆ failures(y) ⇒ R = ∅. ❑

We are taking advantage of the fact that c is sequential to conclude that y completely sat-
isﬁes the expectations of c. (Note that it also sufﬁces to require that traces(c) ⊆ traces(y)
for the same result to go through.) But if there are different ways of satisfying a client (par-
ticularly a concurrent one), then it is no longer true that the client will necessarily be sat-

Request Satisﬁability

115

isﬁed by a request substitutable service provider. Some additional preconditions must be
imposed.

4.7.2 Concurrent Clients

Let us consider a simple example of a concurrent client consisting of a producer and a con-
sumer connected by a bounded buffer. The producer and the consumer each have their own
view of the buffer, but we are interested in the requirements posed by their concurrent
composition.

Presently we might separately specify expectations of the producer and consumer re-

spectively as:

Prod =

put

Cons =

get

We might write their concurrent composition as Prod&Cons, where:

 c1′&c2

c1 →r

 c1′ ⇒ c1&c2 →r

and

c2 →r

 c2′ ⇒ c1&c2  →r  c1&c2′

So we can conclude:

Prod&Cons =

put, get

Note that Prod&Cons is not sequential according to deﬁnition 12.

It is easy to check that Buf 

 Prod&Cons, since Buf never refuses both put and get. But
what is the role of request substitutability now? Since we know that Var:<Buf can we
necessarily conclude also that Var   Prod&Cons? Unfortunately this is not quite right. The
reason is that a regular subtype may introduce additional behaviour that can perturb the
client’s expectations. Consider, for example, a deletable buffer:

DelBuf =

put

get

del

It is clear that DelBuf:<Buf. But suppose that we now compose the producer and consum-

er with a malevolent object whose only goal is to try to delete the buffer:

Del =

del

 Prod&Cons&Del but it is not the case that DelBuf 

 Prod&Cons&Del. In the ﬁrst
Now Buf 
case only Del will be starved out because Buf provides no delete operation, but the client as
whole will still be satisﬁed since Prod&Cons continues to make progress.

116

Regular Types for Active Objects

In the second case, however, the delete operation may succeed, then causing the client

as a whole to deadlock, and thus remain unsatisﬁed.

What we need to do in order to be sure that DelBuf can be safely substituted for Buf is to

restrict its behaviour to that allowed by Buf:
Definition 13  x/Y →r
What we mean to capture by x/Y is that some object in state x is restricted to accept only
the requests allowed by a second object whose state is some y∈Y. We do not know precise-
ly which state the second object is in, so we keep track of the set of possible states.

 x′/Y′ iff x →r

 x′ and Y →r

 Y′.

Usually the initial state of the second object is known, so we will simply write x/y in-

stead of x/{y}.
Proposition 6  x:<y ⇒ x/y :< y.
Proof  
(i) 

traces(x/y) = traces(x) ∩ traces(y). But x:<y ⇒ traces(y) ⊆ traces(x),
so traces(x/y) = traces(y).

x′, { y } ⇒s

(ii)  (s,R) ∈ failures(x/y) ⇒ ∃x′, x ⇒s

Y′, such that R ∩ init(x′) ∩ init(Y′) = ∅
⇒ R ∩ init(x′) ∩ ∪{ init(y′)  y′∈Y′} = ∪ { R ∩ init(x′) ∩ init(y′)  y′∈Y′} = ∅.
But x:<y ⇒ { x } :<< { y } ⇒ ∃y′ ∈ Y′, init(y′) ⊆ init(x′)
⇒ ∃y′ ∈ Y′, R ∩ init(y′) = ∅ ⇒ (s,R) ∈ failures(y) ⇒ failures(x/y) ⊆ failures(y).
But failuresy(x/y) = failures(x/y), so x/y :< y. ❑

Finally, the result we want:

Proposition 7  x:<y and y   c⇒ x/y   c.
Proof  x:<y ⇒ x/y :< y (by proposition 6), so failures(x/y) ⊆ failures(y).

Now (s,R) ∈ failures(x/y) ∩ offers(c) ⇒ (s,R) ∈ failures(y) ∩ offers(c) ⇒ R = ∅.
Hence x/y   c. ❑

So, for example, we can conclude that:

DelBuf/Buf   Prod&Cons&Del

since we effectively hide the additional behaviour introduced by DelBuf from the client.

This is not as strong a result as we might have hoped for, but it is a natural consequence
of the fact that multiple concurrent clients may interfere with one another if their expecta-
tions are not consistent. This is essentially the observation of Liskov and Wing [22] who
propose a new deﬁnition of subtyping that requires view consistency. Brieﬂy, the idea is
that a type that extends the behaviour of another type may only be considered a subtype of
the second if the additional behaviour can always be explained in terms of behaviour that
was already there in the supertype.

In some cases we may get this consistency for free. Note, for example, that if the sub-
type’s behaviour is properly included in the supertype’s, in the sense that failures(x) = fail-
ures(x/y), then the subtype will be request substitutable for the supertype. We must be sure,
though, that the subtype behaviour is consistent with the restriction imposed by the super-
type. This leads to the following result:

Open Problems

117

Proposition 8  If traces(x) = traces(y) and

failures(x) ⊆ failures(y), then y   c ⇒ x   c.

Proof  Follows from proposition 7 since

failures(x) = failures(x/y). ❑

It may still be the case that a subtype provides additional behaviour that does not perturb
the client. But to be sure that the subtype is truly substitutable, it is necessary to know more
about the client’s expectations. We have previously explored interaction equivalence with
respect to the expectations of particular sets of observers, and found that equivalence with
respect to all possible observers (also) reduces to failures equivalence [27]. We expect that
relativizing request substitutability with respect to the expectations of speciﬁc classes of
clients will lead to more general and more useful results for the case of multiple concurrent
clients.

4.8 Open Problems

We have proposed service types as a means of characterizing the services an object pro-
vides, and regular types as a means to express non-uniform service availability. In both
cases we have presented an approach to subtyping. Furthermore, we have formalized what
it means to satisfy a client’s expectations, and we have shown the role that subtyping plays
in determining substitutability.

Although regular types appear to be a novel and promising approach for reasoning
about some of the dynamic (type) properties of concurrent object-oriented programs,
there remains much to be studied before we can claim to have a pragmatically acceptable
approach for type-checking object-oriented languages. Let us brieﬂy summarize some of
these considerations.

4.8.1 Regular Service Types

So far we have treated the typing of services and their availability as orthogonal issues.
Service types express types of requests and replies, and regular types tell us when requests
are enabled. There is nothing to prevent us from proposing a syntax for regular service
types that simply expands request names in regular types to the complete service type
speciﬁcation corresponding to that request. For example, an integer variable could be as-
signed the regular service type:

IntVar = (v1, {

v1 = put(Int)→Ok.v2,
v2 = put(Int)→Ok.v2 + get→Int.v2

})

Since this is somewhat verbose (the type of the put service must be given twice), it
seems more desirable to keep the type speciﬁcations of services and their protocols sepa-
rate.

118

Regular Types for Active Objects

It is conceivable, however, that the type of a service may itself change with time. In par-
ticular, the result types associated with certain requests may depend on the argument types
of earlier requests (as is the case with all of the container objects we have seen). To handle
this case, it would seem necessary to introduce term variables into regular types to express
the dependencies between services in the protocol (i.e. à la “dependent types” [32]). It is
not clear, however, what effect this would have on the determination of request substitut-
ability.

It may also be interesting to consider bounded polymorphism in our framework, since
the integration of intersection types and bounded polymorphism has been previously stud-
ied [31], but only in a functional setting. Finally, we have not considered the issue of re-
cursively deﬁned types, in which the regular type of an object may contain services whose
argument and return types refer to the object’s own type. Previous work on “F-bounded”
quantiﬁcation [9] addresses subtyping for such types [3], and is likely to be relevant to our
framework.

4.8.2 Applying Regular Types to Object-Oriented Languages

We have presented our type model without giving any concrete interpretation for types.
The objects to which we wish to assign types have been described only informally by
means of a very general model of objects as transition systems. The next step would be to
provide a concrete syntax for objects, either in terms of a programming language or a
process calculus that can model objects in a straightforward way.

We have been working towards an object calculus that incorporates those features of
process calculi that are most needed for expressing the semantics of concurrent object-
oriented languages [28]. We intend to use the object calculus as an (executable) abstract
machine for a pattern language for (typed) active objects [29], and assign regular types to
the expressions of this language.

Since the type expressions we are dealing with can become rather unwieldy, it is espe-
cially important that we be able to do as much type inference as possible. In languages that
directly represent abstract states of objects (such as ACT++ [20]) this job will be easier.
The main difﬁculty will be in determining what transitions between the abstract states are
possible.

We have already pointed out that objects may satisfy many different regular types, and,
since regular types are only approximations, in some cases they may be reﬁned ad nause-
am. In order to assign regular types automatically to objects, it is necessary to generate
some type assignment which is perhaps not the ﬁnest possible but which assigns at least
one abstract state to every reachable subset of available services. (Recall that our ﬁrst ND-
Stack was such a minimal representation, whereas NDStack2 had two distinct states with
the same services available.)

Another consideration, however, is whether a deterministic regular type can be as-
signed to an object. If such a type speciﬁcation exists (e.g. Var and Buf), then this is in any
case to be preferred to a non-deterministic regular type that may have less states. Such

Concluding Remarks

119

types not only completely describe service availability for an object, but are well-behaved
during type-checking since the sets of reachable nodes for a given trace are always single-
tons. (So LIST stays small.)

4.9 Concluding Remarks

We have proposed a type framework for object-oriented languages that expresses the serv-
ices of an object as an intersection of service types characterizing request and reply mes-
sages, and non-uniform service availability in terms of regular types over a ﬁnite number
of abstract states associated with subsets of services. Subtyping of regular types is deﬁned
by introducing request substitutability, a novel pre-order over processes that has special
interest for object-oriented applications. Subtyping is easy to determine for regular types,
and a simple algorithm is presented. Satisfaction of client’s expectations is formalized as
request satisﬁability, and we show how request substitutability relates to it.

A number of technical issues must ﬁrst be resolved before the framework can be prac-
tically applied to real object-oriented languages. In particular, we seek some results that
will simplify reasoning about substitutability with respect to multiple concurrent clients.
We expect that it will be easier to reason about regular types in the presence of concur-
rency if we interpret them either using a temporal logic or a modal process logic (such as
Hennessy–Milner logic with recursion [21]). A logical characterization of the concepts
we have presented will be the topic of further research.

Despite a number of open research problems, the approach seems to hold a great deal of
promise, since numerous tools and algorithms exist not only for analysing properties of
ﬁnite  state  processes  [11][15][23]  but  also  for  reasoning  about  processes  in  general
[12][19]. This suggests that regular types may be more generally useful for reasoning
about temporal properties of concurrent objects.

We have concentrated on client–server-based protocols in which requests eventually
entail replies. Can we accommodate other kinds of communication protocols (to support,
for example, transactions)? If so, must we modify our model of regular types to incorpo-
rate bidirectional communications (instead of just enabling of request channels)? Can we
easily accommodate exceptions in our framework by, for example, allowing replies to be
union types?

Finally, our approach considers only objects with ﬁxed sets of known services. Can we
accommodate reﬂective objects that acquire new services with time? In such a setting,
would we have to consider not only services, but also types as ﬁrst-class values?

Acknowledgements

Many thanks are due to José Rolim, Didier Buchs, Laurent Dami, Michael Papathomas,
and to the anonymous referees for their help and suggestions in the preparation of the orig-
inal version of this work published in OOPSLA ’93. I would also like to thank Benjamin

120

Regular Types for Active Objects

Pierce, Egil Andersen, William Ferreira and Patrick Varone for their careful reading of the
manuscript, and for uncovering various technical errors and deﬁciencies.

References

[1]

Samson Abramsky, “Observation Equivalence as a Testing Equivalence,” Theoretical Computer Sci-
ence, vol. 53, North-Holland, 1987, pp. 225–241.

[2] Alfred V. Aho, John E. Hopcroft and Jeffrey D. Ullman, The Design and Analysis of Computer Algo-

rithms, Addison-Wesley, Reading, Mass., 1974.

[3] Roberto M. Amadio and Luca Cardelli, ‘‘Subtyping Recursive Types,’’ Proceedings POPL ’91, pp.

[4]

[5]

[6]

[7]

[8]

[9]

104–118. 
Jos C.M. Baeten and Peter Weijland, Process Algebra, Cambridge University Press, Cambridge,
1990.
Franco Barbanera and Mariangiola Dezani-Ciancaglini, “Intersection and Union Types,” in Proceed-
ings Theoretical Aspects of Computer Software (TACS ’91), ed. T. Ito and A.R. Meyer, Lecture Notes
in Computer Science 526, Springer-Verlag, Sendai, Japan, Sept. 1991, pp. 651–674.
Jan A. Bergstra and J.W. Klop, “The Algebra of Recursively Deﬁned Processes and the Algebra of
Regular Processes,” in Proceedings ICALP ’84, ed. J. Paredaens, Lecture Notes in Computer Science
172, Springer-Verlag, Antwerp, pp. 82–95.
Ed Brinksma, Giuseppe Scollo and Chris Steenbergen, ‘‘LOTOS Speciﬁcations, Their Implementa-
tions and Their Tests,’’ Protocol Speciﬁcation, Testing and Veriﬁcation VI, ed. G. Bochmann and B.
Sarikaya, North Holland, 1987, pp. 349–360. 
Stephen D. Brookes, C.A.R. Hoare and Andrew W. Roscoe, “A Theory of Communicating Sequential
Processes,” Journal of the ACM, vol. 31, no. 3, July 1984, pp. 560–599.
Peter S. Canning, William Cook, Walter L. Hill, John C. Mitchell and Walter G. Olthoff, “F-Bounded
Quantiﬁcation for Object-Oriented Programming,” Proceedings of the ACM Conference on Function-
al Programming and Computer Architecture, 11–13 Sept. 1989, pp. 273–280. 

[10] Luca Cardelli and Peter Wegner, “On Understanding Types, Data Abstraction, and Polymorphism,”

ACM Computing Surveys, vol. 17, no. 4, Dec. 1985, pp. 471–522.

[11] Edmund M. Clarke, E. A. Emerson and A. P. Sistla, “Automatic Veriﬁcation of Finite-State Concur-
rent Systems Using Temporal Logic Speciﬁcations,” ACM TOPLAS, vol. 8, no. 2, April 1986, pp. 244–
263.

[12] Rance Cleaveland, Joachim Parrow and Bernhard Steffen, “The Concurrency Workbench,” in Auto-
matic Veriﬁcation Methods for Finite State Systems: Proceedings, ed. Joseph Sifakis, Lecture Notes
in Computer Science 407, Springer-Verlag, 1989, pp. 24–37.

[13] Elspeth Cusack, ‘‘Reﬁnement, Conformance and Inheritance,’’ Formal Aspects of Computing, vol. 3,

1991, pp. 129–141. 

[14] Rocco De Nicola, “Extensional Equivalences for Transition Systems,” Acta Informatica, vol. 24,

1987, pp. 211–237.

[15] Suzanne Graf and Joseph Sifakis, “A Logic for the Speciﬁcation and Proof of Regular Controllable

Processes of CCS,” Acta Informatica, vol. 23, no. 5, 1986, pp. 507–528.

[16] Matthew Hennessy, “Acceptance Trees,” Journal of the ACM, vol. 32, no. 4, Jan. 1985, pp. 896–928.
[17] Matthew Hennessy, Algebraic Theory of Processes, MIT Press, Cambridge, Mass., 1988.
[18] Hans Hüttel, “Decidability, Behavioural Equivalences and Inﬁnite Transition Graphs,” Ph.D. thesis,

ECS-LFCS-91-181, Computer Science Dept., University of Edinburgh, Dec. 1991.

References

121

[19] Paola Inverardi and Corrado Priami, “Evaluation of Tools for the Analysis of Communicating Sys-

tems,” Bulletin of EATCS, vol. 45, Oct. 1991, pp. 158–185.

[20] Dennis G. Kafura and Keung Hae Lee, “Inheritance in Actor Based Concurrent Object-Oriented Lan-
guages,” in Proceedings ECOOP ’89, ed. S. Cook, Cambridge University Press, Nottingham, 10–14
July, 1989, pp. 131–145.

[21] Kim G. Larsen, “Proof Systems for Hennessy-Milner Logic with Recursion,” in Proceedings CAAP
’88, ed. M. Dauchet and M. Nivat, Lecture Notes in Computer Science 299, Springer-Verlag, Nancy,
March 1988, pp. 215–230.

[22] Barbara Liskov and Jeannette Wing, “A New Deﬁnition of the Subtype Relation,” in Proceedings
ECOOP ’93, ed. O. Nierstrasz, Lecture Notes in Computer Science 707, Springer-Verlag, Kaiserslau-
tern, Germany, July 1993, pp. 118–141.

[23] Robin Milner, “A Complete Inference System for a Class of Regular Behaviours,” Journal of Compu-

ter and System Sciences, vol. 28, Academic Press, 1984, pp. 439–466.

[24] Robin Milner, Communication and Concurrency, Prentice-Hall, 1989.
[25] Robin Milner, “The Polyadic π Calculus,” ECS-LFCS-91-180, Computer Science Dept., University

of Edinburgh, Oct. 1991.

[26] Oscar Nierstrasz and Michael Papathomas, “Viewing Objects as Patterns of Communicating Agents,”

Proceedings OOPSLA/ECOOP ’90, ACM SIGPLAN Notices, vol. 25, no. 10, Oct. 1990, pp. 38–43.

[27] Oscar Nierstrasz and Michael Papathomas, “Towards a Type Theory for Active Objects,” ACM OOPS
Messenger, Proceedings OOPSLA/ECOOP ’90 Workshop on Object-Based Concurrent Systems,
vol. 2, no. 2, April 1991, pp. 89–93.

[28] Oscar Nierstrasz, “Towards an Object Calculus,” in Proceedings of the ECOOP ’91 Workshop on Ob-
ject-Based Concurrent Computing, ed. M. Tokoro, O. Nierstrasz and P. Wegner, Lecture Notes in
Computer Science 612, Springer-Verlag, 1992, pp. 1–20.

[29] Oscar Nierstrasz, ‘‘Composing Active Objects,’’ Research Directions in Concurrent Object-Oriented
Programming, ed. G. Agha, P. Wegner and A. Yonezawa, MIT Press, Cambridge, Mass., 1993, pp.
151–171.

[30] Michael Papathomas, “A Unifying Framework for Process Calculus Semantics of Concurrent Object-
Oriented Languages,” in Proceedings of the ECOOP ’91 Workshop on Object-Based Concurrent
Computing, ed. M. Tokoro, O. Nierstrasz and P. Wegner, Lecture Notes in Computer Science 612,
Springer-Verlag, 1992, pp. 53–79.

[31] Benjamin C. Pierce, ‘‘Intersection Types and Bounded Polymorphism,’’ Conference on Typed Lamb-

da Calculi and Applications, March 1993, pp. 346–360. 

[32] Simon Thompson, Type Theory and Functional Programming, International Computer Science Se-

ries, Addison-Wesley, 1991.

[33] Vasco T. Vasconcelos and Mario Tokoro, ‘‘A Typing System for a Calculus of Objects,’’ Object Tech-
nologies for Advanced Software, First JSSST International Symposium, Lecture Notes in Computer
Science, vol. 742, Springer-Verlag, Nov. 1993, pp. 460–474. 

[34] Peter Wegner and Stanley B. Zdonik, “Inheritance as an Incremental Modiﬁcation Mechanism or
What Like Is and Isn’t Like,” in Proceedings ECOOP ’88, ed. S. Gjessing and K. Nygaard, Lecture
Notes in Computer Science 322, Springer-Verlag, Oslo, Aug. 15–17, 1988, pp. 55–77. 

122

Chapter 5
A Temporal Perspective of 
Composite Objects

Constantin Arapis

Abstract    For the development of object-oriented applications, the description
of temporal aspects of object behaviour often turns out to be an important issue.
We present a collection of notions and concepts intended for the description of
the temporal order in which messages are sent to and received from an object.
We also propose notions for the description of the temporal order of messages
exchanged  between  cooperating  objects  related  with part-of  relationships.
Using propositional temporal logic as the underlying formalism of our approach,
we show how to verify the consistency of object speciﬁcations.

5.1

Introduction

The increasing popularity of object-oriented systems [7] [12] [18] [22] over the past dec-
ade, within both the research and commercial/industrial computer science communities,
have promoted the use of the object-oriented approach for requirements analysis and sys-
tem design. Thus, several object-oriented analysis and design methodologies [4] [5] [6]
[15] [20] [21] [23] [24] are currently available to assist the early phases of the object-ori-
ented application development process.

An important activity during object-oriented design often turns out to be the description
of temporal aspects of object behaviour. Indeed, the design of many applications may con-
tain objects whose behaviour exhibits important temporal traits. As Booch states [4] “for
some objects, this time ordering of operations is so pervasive that we can best formally
characterize the behaviour of an object in terms of a ﬁnite state machine.” It must be
stressed that even for applications which are not designed for processing temporal infor-
mation, their development requires several objects whose behaviour exhibits important
temporal aspects. Yet the description of temporal properties of objects, either considered
in isolation or in cooperation with other objects, is not exclusively relevant to concurrent

Constantin Arapis, “A Temporal Perspective of Composite Objects,” Object-Oriented Software Composition, O. Nierstrasz and D. 
Tsichritzis (Eds.), pp. 123-152, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

124

A Temporal Perspective of Composite Objects

environments. Often, the description of temporal properties of objects is deemed critical
and even mandatory in sequential environments.

5.1.1 Specifying Temporal Aspects of Object Behaviour

A number of object-oriented design methodologies [4] [20] [21] integrate notions and
concepts for the description of temporal properties of objects. We will call the temporal
component of an object-oriented design method the collection of notions and concepts
intended for the description of temporal aspects of object behaviour. The underlying for-
malisms upon which the various temporal components of object-oriented design method-
ologies are founded are ﬁnite state machines (FSMs) or extensions of FSMs [13]. The
preponderance of FSMs over other formalisms is attributed to the following two reasons:
ﬁrst, FSMs are easy to understand, and second, a FSM can be easily depicted by means of
a state transition diagram.

In general, object-oriented design methodologies use FSMs in the following way: a
FSM Mc models temporal aspects of the behaviour of an instance of class C. Transitions of
Mc are labelled with operations that an instance of C is expected to carry out. States of Mc
correspond to the various possible states of an instance of C. A transition of Mc, labelled p,
from state s1 to state s2, models the fact that operation p can be requested of an instance o
of C when the current state of o is s1. After p is carried out, the current state of o becomes
s2. Thus, by means of FSMs, temporal aspects of object behaviour are ultimately de-
scribed in terms of sequences of pairs: (state, operation).

Note that the role of the temporal component of an object-oriented design methodology
is limited to the description of sequences of operations and state transitions of objects. The
temporal component is not designed for specifying how an object will carry out an opera-
tion.  In  addition,  the  design  and  integration  of  a  temporal  component  within  an
object-oriented design methodology should guarantee harmonious synergy between the
various other parts of the methodology. The above requirement suggests that the temporal
component should be complementary and orthogonal to the fundamental principles of the
object-oriented approach.

We will present a temporal component which has been designed independently of any
design methodology and is founded on the theory of propositional temporal logic (PTL).
The aim of the temporal component is to enhance existing design methodologies lacking
or offering limited support for the description of temporal properties of objects. We shall
introduce the temporal component in terms of a speciﬁcation model called the Temporal
Speciﬁcation  Object  Model  (TSOM).  The  specification  model  blends  fundamental
notions of the object-oriented approach and temporal notions, thus illustrating the de-
pendence and/or orthogonality existing between them.

In contrast with temporal components founded on FSMs, TSOM emphasizes the de-
scription of temporal properties of an object o in terms of sequences of messages which
are sent to and received from o. Thus, the user is not compelled to devise states that are not
necessarily relevant to the description of an object’s behaviour and whose only purpose is

Introduction

125

to complete the FSM under development. However, TSOM provides the concept of at-
tribute by means of which the user may introduce states he considers relevant for the de-
scription of an object’s behaviour and may also describe the various conditions that should
be veriﬁed for enabling state transitions to occur.

Another important point that TSOM emphasizes is the description of the temporal order
of messages exchanged between a collection of cooperating objects related by part-of re-
lationships. The temporal order of messages exchanged between a composite object and
its constituent objects provides a temporal perspective of what has been called the behav-
ioural  composition  of  objects.  Promoted  as  a  fundamental  feature  of  object-oriented
design methodologies, behavioural composition consists of combining and coordinating
the functionality of existing objects to create new objects [8] [14] [19]. A composite object
in TSOM encapsulates and coordinates a collection of objects that cooperate in order to
reach some goal or perform some task. The composite object plays the role of a coordina-
tor  taking  into  account  the  various  temporal  properties  and  constraints  speciﬁed  for
constituent objects. Furthermore, TSOM enables an incremental speciﬁcation of object
coordination.  In  particular,  a  composite  object  may  become  a  constituent  of  another
composite object, which in turn may become a constituent of another composite object,
and so on.

5.1.2 Design Choices for TSOM

First and foremost, let us justify our decision for TSOM to be founded on a formal theory
rather than developing a temporal component founded on some informal basis, for exam-
ple a natural language. Establishing a formal basis upon which a temporal component is
founded permits us not only to test the consistency of the various notions it integrates but
also to test the consistency of user-provided speciﬁcations. Indeed, the early detection and
correction of design errors is critical for the whole application development activity. Fail-
ing to correct design errors causes their harmful effects to be ampliﬁed and disseminated
throughout the subsequent stages of the application development process.

From a number of candidate formalisms the language of PTL appears as the most suit-
able formalism for TSOM. Indeed, temporal properties can be very easily speciﬁed by
means of PTL formulas. Formalisms like FSMs and Petri nets have been characterized as
low level in the following sense: by means of FSMs and Petri nets we can specify how a
system operates and then verify which properties are satisﬁed by the modelled system. In
temporal logic the contrary is done. The desirable properties of a system are speciﬁed ﬁrst.
A system satisfying the speciﬁed properties is derived subsequently.

Another important argument in favour of PTL is the fact that it has been used as a foun-
dation for various investigations performed in the area of concurrent systems, concerning
the synthesis of a collection of parallel communicating processes [9] [17]. Synthesis of
communicating processes bears many similarities with object behaviour composition: the
collection of communicating processes can be seen as a collection of cooperating objects
which should be synchronized in order to perform a particular task. We have borrowed the

126

A Temporal Perspective of Composite Objects

main ideas proposed for synthesizing communicating processes from [17] whilst we have
adapted and tailored them when necessary to meet our speciﬁc needs.

We have acknowledged the veriﬁcation of speciﬁcations to be an important and even a
mandatory activity of the design process. However, verifying speciﬁcations is in general
a difﬁcult and lengthy process carried out without computer assistance. Automated sup-
port for the veriﬁcation of speciﬁcations, relieving users from laborious and error-prone
procedures, has been selected among the most important requirements. An appealing
property of PTL is the existence of algorithms for testing the satisﬁability of a temporal
logic formula [2] [16] [17]. These algorithms may be used in a straightforward manner to
provide an automated procedure for verifying the consistency of object speciﬁcations.
The decidability of PTL outweighed substantial arguments for choosing a more powerful
formalism, in particular predicate temporal logic [1]. Since the satisﬁability test of predi-
cate temporal logic is no longer decidable the design of an automated procedure for veri-
fying speciﬁcations could be seriously compromised.

5.1.3 Layout

In the following section we provide a brief introduction to the temporal logic system we
shall be using. In section 5.3 we describe the speciﬁcation of temporal properties of ob-
jects in TSOM. Section 5.4 presents the veriﬁcation procedure of object speciﬁcations.
The last section presents our concluding remarks.

5.2

Propositional Temporal Logic

PTL  is  an  extension  of  propositional  logic  (PL)  in  which  atomic  propositions  have
time-varying truth value assignments. The time-varying truth value assignment is ob-
tained by associating each time-point with a world. A world is a particular interpretation
in the sense of classical PL. Thus, the truth value of an atomic proposition p at instant t
would be the truth value assigned to p in the world associated with t.

Several temporal logical systems have been developed. They differ in the properties at-
tributed to time, i.e. whether it is discrete or continuous, with or without start or end points,
or viewed as containing linear or branching past and future. The logical system we shall
use considers time to be discrete, with a starting point, and linear [11].

Another important extension characterizing PTL is the collection of temporal operators
which, in addition to the usual operators of PL, are used for forming PTL formulas. Dif-
ferent collections of temporal operators may be encountered depending on the logical sys-
tem used. The logical system we have chosen to use has the following temporal operators:
called the always in the future operator, meaning that f is satisfied* in the
current and all future worlds,

 f

* We say that an atomic proposition p or a formula f is satisfied in a world w if p or f is assigned the truth 
value true in w.

❑
Propositional Temporal Logic

127

◊ f

 f 

called the eventually in the future operator, meaning that f is satisfied in
the current or in some future world,
called the next operator, meaning that f is satisfied in the next world,

f1 U f2 called the until operator, meaning that either f1 is satisfied in the current
and all future worlds or f1 is satisfied in the current and all future worlds
until the world when f2 is satisfied.

The ﬁrst three operators are unary, while the last is binary. Note that for the until opera-
tor we do not claim f2 will eventually be satisﬁed in some future world. The above opera-
tors deal only with future situations. We can extend the system with symmetric operators
for the past:
I f

N f

G f

◗  f

called the always in the past operator, meaning that f is satisfied in the
current and all previous worlds,
called the eventually in the past operator, meaning that f is satisfied in the
current or in some past world,
called the previous operator, meaning that the current world is not the
starting point and f is satisfied in the previous world,
called the weak-previous operator, meaning that either f is satisfied in the
previous  world  or  the  current  world  is  the  starting  point;  the  weak
previous  operator  has  no  symmetric  future  operator  and  has  been
included because of our assumption that time has a starting point,

f1 S f2 called the since operator, meaning that either f1 is satisfied in the current
and all past worlds or f1 is satisfied in the current and all past worlds since
the world when f2 was satisfied.
Figure 5.1 illustrates the meaning of each temporal operator over the time axis τ. A
time-point t which is labelled with a PTL formula f means that f is satisﬁed at t. Operators
until and since require two alternative time axes for representing their meaning, so each
pair of time axes is enclosed within a rectangular box.

5.2.1 Syntax of PTL

Given:

1. P = {p1, p2, p3, …} the set of atomic propositions
2. non-temporal operators: ¬, ∧, ∨, ⇒, ⇔
3.

, U, I, N, G, ◗ , S

temporal operators: ❑

, ◊, ❍
formulas are formed as follows:

1. An atomic proposition is a formula.
2.

If f1 and f2 are formulas then

(f1), ¬f1, f1 ∧ f2, f1 ∨ f2, f1 ⇒ f2, f1 ⇔ f2 are formulas, and
 f1, ◊ f1, ❍

 f1, f1 U f2, I f1, N f1, G f1, ◗  f1, f1 S f2 are formulas.

3. Every formula is obtained by application of the above two rules.

❍
❑
128

A Temporal Perspective of Composite Objects

τ

τ

τ

τ

τ

τ

τ

τ

τ

τ

τ

or

or

f

f

f

…

f    

f

f

f

f

f

 

❑   f 

◊     f
 

f

 
❍   f

f
1

f
1

f
1

f
1

f
1

f
1

f
1

…

   

f
1

f
1  u  f 2 
 

 
 

 
 

 
 

 

 
 

f
1

f
1

f
1

f
1

f
2

1  u  f 2 
f
 

 
 

 
 

 
 

 
 

 

 
 

f

f

f

f

f

f

I  f

 

N  f

 

f

G  f
 

f

 

◗   f   ⇔   true

 

 

f
1

f
1

f
1

f
1

f
1

f
1

f
1  s  f 2 
 

 
 

 
 

 
 

 
 

 
 

 

 
 

 

 
 

 
 

 
 

 
 

 
 

 

 
 

f
2

f
1

f
1

f
1

1  s  f 2 
f
 

 
 

 
 

 
 

 

Figure 5.1   

The meaning of temporal operators over the time axis.

Propositional Temporal Logic

129

Examples of well-formed formulas (wff) of PTL include:

 ∨
 ∧
 
 ((
)
)
 
q
p
r
 
⇒
N
)
 
 
 (
q
p
 ∧
 (
 
 (
 
))
U
r
p
q
The ﬁrst wff says that in all time-points either 
 and 
 is satisﬁed. The
p
r
 must have been satisﬁed
second wff says that for any time-point 
 is satisﬁed, 
 in which 
q
p
tp
 ≤
 is
in some time-point 
 either 
, 
 
r
tp
t
t
 ≥
, where
satisﬁed for all time-points 
t
 ∧ 
q

. The last wff says that from the next time-point 
q
 

 is satisﬁed and for all t, tnext ≤ t < tp ∧ q, r is satisﬁed.
p

 or there exists a time-point

 are satisﬁed or 
q

tnext
 ≥
 

 tnext

tnext

 
tp

 tp

q
 

 ∧

 ∧

,

5.2.2 Semantics of PTL

The time-varying truth value assignment of atomic propositions and the time-based mean-
ing attributed to temporal operators leads to a deﬁnition of the notion of satisﬁability
where the truth or falsity of PTL formulas is evaluated over sequences of worlds. To be
more precise, let σ = w0, w1, w2, w3, … be an inﬁnite sequence of worlds, each wi ∈ W be-
ing an element of the powerset 2P, W the set of all worlds and P the set of atomic proposi-
tions.
The  satisﬁability  of  a  formula  f  in  a  world  wi ∈ W  of  a  sequence  σ  is  denoted  by
(σ, wi) 

 f2 and ∀ k, i ≤ k < j, (σ, wk) 
 f1
 f1

 
 
 
 

 
 
 
 

 
 
 
 

 
 

 

 

 

 

 

 

 

 

 

 f1

 

 

 

 

 

 

 

 
 

 

 

 

 

 

 

 
 

 

 

 

 

 

 

 

 

 

 
 

 

 

 

 

 

 

 
 

 

 
 

 

 

 

 
 

 

 

 

 

 

 

 

 

 
 
 
 

 f1

 f2
 f2

p ∈ wi
p ∉ wi
(σ, wi) 
(σ, wi) 
not (σ, wi) 
(σ, wi) 
(σ, wi) 

 f1 and (σ, wi) 
 f1 or (σ, wi) 
 (¬f1) ∨ f2
 (f1 ⇒ f2) ∧ (f2⇒ f1)

 p
iff
 p
iff
 f1 ∧ f2 iff
 f1 ∨ f2 iff
 ¬f1
iff
 f1⇒ f2 iff
 f1⇔ f2 iff
iff ∀ j, j ≥ i, (σ, wj) 
 ❑
 f1
iff ∃ j, j ≥ i, (σ, wj) 
 ◊ f1
 ❍
iff
 f1
 f1 U f2 iff

f and can be deduced by the following rules:
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 
(σ, wi) 

(σ, wi+1) 
either ∀ j, j ≥ i, (σ, wj) 
or ∃ j, j ≥ i, (σ, wj) 
iff ∀ j, 0 ≤ j ≤ i, (σ, wj) 
iff ∃ j, 0 ≤ j ≤ i, (σ, wj) 
i > 0 and (σ,wi-1) 
 f1
iff
i > 0 and (σ,wi-1) 
 f1 or i = 0
iff
either ∀ j, 0 ≤ j ≤ i, (σ, wj) 
iff
 f1
or ∃ j, 0 ≤ j ≤ i, (σ, wj) 

 I f1
 N f1
 G f1
 ◗  f1
 f1 S f2

 f1
 f1

 f1

 f1

 f2 and ∀ k, j < k ≤ i, (σ, wk) 
A formula f is initially satisﬁed or simply satisﬁed by a sequence σ iff (σ, w0) 

 f1
 f. A
formula f is satisﬁable iff there exists a sequence satisfying f. Such a sequence is a model
of f. A formula is valid iff it is satisﬁable by all possible sequences.

❑
❑
❍
130

A Temporal Perspective of Composite Objects

In order to check the satisﬁability of PTL formulas we can use one of the tableau-based
algorithms presented in [2] [16] or [17]. Such algorithms we will call satisﬁability algo-
rithms. The algorithm takes as input a formula F and outputs a graph representing all mod-
els satisfying F. Such a graph we will call a satisﬁability graph. If F is not satisﬁable the
algorithm signals that it is unable to produce a graph.

The main idea of the algorithm presented in [2] consists of building up the satisﬁability
graph in the following way. Start with an initial node labelled with the input formula F. For
the initial node and all other nodes the following procedure is applied until no more nodes
remain unprocessed. The formula labelling a node N is decomposed into disjunctive nor-
mal form, each disjunct being of the form:

current-instant-formula ∧ ❍  next-instant-formula  ∧ G previous-instant-formula

The  previous-instant-formula  speciﬁes  what  should  have  been  veriﬁed  the  previous
time-point. For any node N´ from which an edge points to N, the formula labelling N´
should  satisfy  previous-instant-formula.  Otherwise  node  N  and  all  edges  pointing  to  N
should be deleted. The next-instant-formula speciﬁes what should be veriﬁed the next time
point. Let N´´ be the node labelled with next-instant-formula. If there exists no node labelled
with next-instant-formula then a new node N´´ is created with label next-instant-formula. Then
an edge from N to N´´ labelled with current-instant-formula is introduced in the graph. The
current-instant-formula  speciﬁes  what  should  be  veriﬁed  the  current  time-point  and  is
always a formula of PL. Thus edges are labelled with formulas of PL while nodes are
labelled with formulas of PTL. The following remark ensures that the process stops. When
transforming a formula f into disjunctive normal form, each conjunct within a disjunct is
a conjunction of either subformulas of f or negated subformulas of f. Thus the maximum
number of nodes that possibly will be generated equals the number of formulas that are
conjunctions of either subformulas of F or negated subformulas of F.

Given a satisﬁability graph corresponding to a formula F, a possible model µ of F is
identiﬁed by traversing the graph. Initially µ is empty. Starting at the initial node, each
time an edge is traversed, a world satisfying the formula labelling that edge is concatenat-
ed to the sequence of worlds forming the model µ. In general, several worlds may satisfy
a formula but a single world should be chosen to be concatenated in µ. In other words, a
formula labelling an edge identiﬁes a world wi of some model µ. The formula labelling
each node identiﬁes the rest of the sequence of worlds of µ, that is wi+1, wi+2, … Note that
the graph produced from the satisﬁability algorithm may not be minimal in the sense that
the models of the input formula could be identiﬁed with a graph with less nodes and edges.
 ((p ∧ q) ⇒ ❍  r) is shown in ﬁg-
ure 5.2. Each node is divided into two parts: the lower part of the node contains the formula
in disjunctive normal form equivalent to the formula labelling the upper part of the node.
The node drawn with a thick line is the initial node. Note that the current-instant-formula is
missing from the second disjunct of the formula labelling the lower part of the initial node.
In such cases any non-contradictory PL formula can be taken as the current-instant-formula.
We use the symbol ⊥ to denote any non-contradictory PL formula. The various worlds sat-
isfying the formulas labelling the edges of the satisﬁability graph are:

The satisﬁability graph corresponding to the formula ❑

Propositional Temporal Logic

131

¬  ( p  ∧  q ) 
 
 

r

p  ∧  q )  ⇒  ❍   r ) 

 ((
 
¬
p  ∧  q )  ∧  ❍ ❑
 
 
 
(
[
 
❍   r  ∧  ❍ ❑
 
 
 
[

 

⊥

❑   ((  p  ∧  q )  ⇒  ❍   r )  ∧  r 

 

¬
p  ∧  q )  ∨  ❍   r )]   ∨ 
 
(
 (
¬
 ∧  q )  ∨  ❍   r )]
 
p
(
 (

¬  ( p  ∧  q )  ∧  r
 

r  ∧  ¬ 
[
 
 
 

 
(  p  ∧  q )  ∧  ❍ ❑
 
 
 
 
 
r  ∧  ❍   r  ∧  ❍ ❑
 
 
[

 

¬
p  ∧  q  )  ∨  ❍   r )]   ∨ 
 
(
 (
¬
 ∧  q )  ∨  ❍   r )] 
 
 
 
 
 
 
 
 
 
p
(
 (

Figure 5.2   

Satisﬁability graph corresponding to the formula 

 ∧
 ((p

 q) 

⇒
❍ 
 

r).

(a)

(b)

(c)

{p, q}

{r}

{r}

{q, r}

{p, q, r}

{r, q}

{r} 

{p, r}

{p, q}

{p, q}

{p, r}

{q, r} 

{r}

{r}

{p, q, r}

{r} 

{p, q}

{p}

{r}

{p, q}

{p, q, r}

{r, q}

{r} 

Figure 5.3 Sequences (a) and (b) satisfy ❑ ((p ∧ q) ⇒ ❍ r); 
((p ∧ q) ⇒ ❍ r)).

Sequence (c) does not satisfy ❑

[{p}, {q}, {r}, {p, r}, {q, r}]
[{r}, {p, r}, {q, r}, {p, q, r}]
[{r}, {p, r}, {q, r}]
[{p}, {q}, {r}, {p, q}, {p, r}, {q, r}, {p, q, r}]

satisfy the formula ¬ (p ∧ q),
satisfy the formula  r,
satisfy the formula ¬ (p ∧ q) ∧ r,
satisfy ⊥

Each world is represented by enclosing within curly brackets the atomic propositions hav-
ing truth value true and assuming that all other propositions have truth value false.

Figure 5.3 shows three sequences of worlds relative to the formula ❑

 ((p ∧ q) ⇒ ❍  r).
 ((p ∧ q) ⇒ ❍  r). Sequence (c) does not satisfy
Sequences (a) and (b) satisfy the formula ❑
 ((p ∧ q) ⇒ ❍  r). The world which causes the sequence to be excluded from the set of
 ((p ∧ q) ⇒ ❍  r) is the third one in which the atomic proposition r is not satis-
models of ❑
ﬁed while in the previous world the formula (p ∧ q) was satisﬁed.

❑
❑
❑
132

A Temporal Perspective of Composite Objects

5.3

The Speciﬁcation of Temporal Properties

In TSOM objects are intended for modelling the various entities of an application. Each
object is associated with a unique object identiﬁer (oid) permitting one to identify the
object independently of its behaviour and the values of its instance variables. An object
communicates with other objects by sending and receiving messages. Messages sent from
an object (sender) to another object (receiver) may be interpreted as requests for the re-
ceiver to perform some task or simply as requests to send back some information to the
sender. The reaction of the receiver may result in a modiﬁcation of its internal state, a
number of messages being sent to other objects, the return of a value to the sender, or some
combination of the above cases. The internal state of an object stored in its instance varia-
bles and how it reacts to messages is assumed to be hidden from other objects.

Although we qualify TSOM as object-oriented, the notion of inheritance is not part of
it. TSOM is the object-based part of the speciﬁcation model presented in [2] and [3]. We
shall not discuss any further the absence of inheritance in TSOM. However, the interested
reader is referred to [2] where the notions of role and role playing can replace, at the
speciﬁcation level, the notion of inheritance.

 
 

 

 

 

 

 

 

 

 

 

 

 and 

composite objects

We distinguish between 

. The difference be-
tween the two kinds of objects lies in the deﬁnition of their structural aspects. An elemen-
tary  object  is  deﬁned  independently  of  other  objects. A  composite  object  consists  of
references to one or several elementary objects or composite objects. When a composite
z is a component of o. Note that a composite
object 
object is not the exclusive owner of its components. A component may be shared among
several composite objects.

 references an object 
o

elementary objects

z 

we say that 

Objects are instantiated from classes. A class deﬁnition comprises the following items:

• Public messages, which can be sent to and received from an instance of the class. To
indicate whether a message is to be sent to (incoming message) or received from (out-
going  message)  an  instance,  the  message  identiﬁer  is  sufﬁxed  with  a  left ←  or
right → arrow respectively. In an object-oriented system, the effect of an incoming
message deﬁned in a class C would be implemented by an operation deﬁned in C. The
effect of an outgoing message msg of C is expected to be implemented by an opera-
tion deﬁned in another class C´. The deﬁnition of msg as outgoing message in C sim-
ply afﬁrms that an instance of C will send message msg to an instance of C´.

• Attributes of an instance o store values representing either abstract states or simply
characteristic aspects which o wishes advertise to other objects. Each attribute is as-
sociated with a ﬁnite domain from which it can be assigned values. For example, in a
class CAR two attributes can be deﬁned, speed and engine_status with associated do-
mains {stopped, moving_slowly, moving_fast} and {turned_on, turned_off} respectively.

• Public constraints describe the set of legal sequences of public messages and at-

tribute-value assignments.

The Speciﬁcation of Temporal Properties

133

• Components identify the parts of a composite object. Each component κ is associat-
ed with a class C, noted κ: C, requiring the value of κ to be a reference to an instance
of C.

• Component messages which can be exchanged between the composite object and its
components. As with public messages we distinguish between incoming and out-
going component messages.

• Component constraints describe the set of legal sequences of public messages, com-

ponent messages and attribute-value assignments.

• Implementation is the part of the class deﬁnition containing the various programs im-

plementing the behaviour of instances of the class.

All items listed above, with the exception of attributes, should be present in the deﬁni-
tion of a composite object class. Items components, component messages and component
constraints are absent from the class deﬁnition of elementary objects. In the remainder of
this section we will describe in more detail each of the above items with the exception of
the implementation item.

5.3.1 Public Messages

An  example  of  a  class  deﬁnition  of  elementary  objects  is  given  in  ﬁgure  5.4.  Class
CTRL_TOWER models the control tower of an airport. Public messages req_take_off and
req_land have been deﬁned as incoming messages. They model requests for taking off and
landing  which  can  be  addressed  to  the  control  tower  by  some  object.  Messages
perm_take_off and perm_land have been deﬁned as outgoing messages. They model per-
missions for taking off and landing which are granted to those objects that had previously
made a corresponding request to the control tower.

In most object-oriented systems it is recommended for suppliers of classes to hide out-
going messages of objects from their clients*. We decided to allow the deﬁnition of outgo-
ing messages in an object’s interface to ease the design of objects cooperating on the basis
of asynchronous communication. Indeed, many real-world situations are naturally mod-
elled as a collection of objects asynchronously communicating between them. Thus asyn-
chronous communication has been reported as an important object cooperation technique
which should be directly supported by object-oriented design methodologies. Deﬁning an
outgoing message msg for an object o implies that o is expected to cooperate with some ob-
ject z which deﬁnes msg as an incoming message and to which o will send msg. Most often,
o is informed which object will be the receiver of msg, by assigning the oid of z to some
parameter of an incoming message of o.

The ability to include outgoing messages among public messages of a class C does not
imply that all messages exchanged with an instance o of C have to be deﬁned as public.

* For a class C, we use the term supplier for naming the person who has defined and implemented C. We 
use the term client for indicating the person or object using the services of C.

134

A Temporal Perspective of Composite Objects

class CTRL_TOWER {
public messages

req_take_off ←, req_land ←,
perm_take_off →, perm_land →

public constraints

req_take_off ∨ req_land;
 (req_take_off ⇒ (◊ perm_take_off));
 (req_land ⇒ (◊ perm_land));

implementation

req_take_off (perm_receiver: oid, …)
{ … };
req_land (perm_receiver: oid, …)
{ … };
…

} 

Figure 5.4   Class CTRL_TOWER modelling the lifecycle of a control tower of an airport.

Only messages that are part of the interface of o should be included in the list of public
messages. For example, assuming that o is an instance of CTRL_TOWER, the four public
messages deﬁned in class CTRL_TOWER are all meaningful for clients of o. The imple-
mentation of o could use a hidden component, plane_list, having the functionality of type
LIST. The usefulness of plane_list would be to represent the list of aeroplanes that have
made a request for taking off or landing and for which the corresponding permission has
not been yet granted. In contrast with the collection of public messages of CTRL_TOWER,
messages exchanged between o and plane_list, like insert_into_list and delete_from_list, are
meaningless for clients of o and should not appear in the list of public messages of class
CTRL_TOWER.

5.3.2 Public Constraints

Public constraints associated with a class are speciﬁed in a language resembling PTL.
More precisely, for a class C, we associate with each public message p an atomic proposi-
tion p in PTL. We model the fact that a public incoming (outgoing) message p is sent to (re-
ceived from) an instance of C at time-point t by associating with t a world where p is
satisﬁed. Mapping messages to atomic propositions implies that the distinction between
incoming and outgoing messages is essentially informative for the user since it is neither
captured nor enforced in PTL. However, the relevance for distinguishing between the two
kinds of messages will be fully appreciated when the notion of composite object is de-
scribed in detail.

Concerning the speciﬁcation of constraints we assume that only one message at a time
can be sent to or received from an object. In other words, in each world of a sequence of
worlds we require that exactly one atomic proposition is satisﬁed and all others are unsat-

❑
❑
The Speciﬁcation of Temporal Properties

135

(a)

(b)

req_take_off

req_land

req_take_off

perm_take_off

perm_land

perm_take_off

req_land

req_land

perm_land

req_take_off

perm_land

perm_take_off 

Figure 5.5   Sequences of public and state messages relative to the class CTRL_TOWER.

isﬁed. Assuming that n messages msgi are deﬁned in a class, the above requirement is
expressed in PTL with the formula:

 ((∨ msgk) ∧ ( ∧ ¬(msgi ∧ msgj))
   1 ≤ k ≤ n            1 ≤ i ≠ j ≤ n

 Public constraints deﬁned in class CTRL_TOWER (ﬁgure 5.4) formally describe the be-
haviour of a control tower. Let o be an instance of CTRL_TOWER. The ﬁrst constraint says
that the ﬁrst message to be sent to o must be either req_take_off or req_land. The second con-
straint says that whenever message req_take_off is sent to o, then sometime in the future
message perm_take_off will be received from o. The last constraint says that whenever
message req_land is sent to o, then sometime in the future message perm_land will be re-
ceived from o. Figure 5.5 shows two sequences of public messages satisfying the temporal
constraints deﬁned in class CTRL_TOWER.

Class CTRL_TOWER constitutes an example of a class deﬁnition expecting to cooperate
with its clients on the basis of asynchronous communication. Indeed, an instance o of
CTRL_TOWER will send message perm_land to those objects whose oid has been assigned
to some parameter, e.g. perm_receiver, of the incoming message req_land. Similarly, the
parameter  perm_receiver  of  req_take_off  will  be  used  for  determining  the  receivers  of
perm_take_off messages. Note, however, that the above relationships involving senders
and receivers of messages, and parameters of messages cannot be described in PTL and
therefore they cannot be explicitly speciﬁed in the constraint deﬁnition language we are
proposing. They have to be annotated as comments. Nevertheless, in the case of composite
objects (see below), messages exchanged with internal components are preﬁxed with the
identiﬁer of the involved component, thus allowing at least some form of constraint spec-
iﬁcation on internal messages.

Whether public constraints associated with a class are or are not violated is the re-
sponsibility  of  both  the  supplier  and  the  client.  For  example,  not  receiving  message
perm_take_off from an instance CTRL_TOWER after having sent message req_take_off is the

❑
136

A Temporal Perspective of Composite Objects

class PLANE {

public messages

land ←, take_off ←;

public constraints

take_off;

(take_off ⇒ (❍
(land ⇒ (❍
implementation

 land));
 take_off));

 …

}

Figure 5.6   Speciﬁcation of class PLANE.

responsibility  of  the  supplier.  Consider  now  the  class  deﬁnition  PLANE  (ﬁgure  5.6),
modelling the lifecycle of an aeroplane. Its public constraints require the two incoming
messages take_off and land to be sent to an instance o of PLANE alternately, the ﬁrst mes-
sage being take_off. In this case it is the responsibility of the client to ensure that take_off
and land messages will be send to o in the speciﬁed order.

5.3.3 Shifting from Local Time to Global Time

Public  constraints  specify  the  temporal  behaviour  of  an  object  o  in  local  time,  i.e.
time-points are identiﬁed with messages that are sent to and received from o. However, the
speciﬁcation of public constraints in local time does not take into account that o may
cooperate with a collection of objects. More precisely, o may become a component of a
composite object, the various cooperating objects being the composite object and its com-
ponents. In that case, between any pair of messages deﬁned in o, one or several messages
deﬁned in other cooperating objects may be interleaved. In other words, public constraints
of o should have been speciﬁed in global time in which case time-points are identiﬁed with
messages that are sent to and received from any of the cooperating objects. Fortunately,
constraints speciﬁed in local time can be easily transformed to constraints in global time
in such a way that their initial meaning is “preserved.” The transformation of public con-
straints from local time to global time is called universalization and will be formally de-
scribed in subsection 5.4.2.1. There are two reasons for preferring the deﬁnition of public
constraints in local time rather than the deﬁnition in global time. First, it is easier to specify
constraints in local time than in global time, and second, the resulting constraints are sim-
pler and easier to understand.

Even though the universalization of constraints preserves their initial meaning, some-
times the user wishes to specify a constraint directly in global time rather than in local
time. TSOM provides the user with such a facility. Enclosing a formula or a subformula f
within angle brackets “<” and “>” excludes f from the transformation process of univer-
salization.

❑
❑
The Speciﬁcation of Temporal Properties

137

class PLANE {
attributes

pl_status: {operational, maintenance};

public messages

public constraints

land ←, take_off ←;
pl_status := (operational ∨ maintenance);
(take_off ⇒ ((pl_status == operational) ∧ ❍  land));
(land ⇒ (G take_off ∧ ❍  ((pl_status := maintenance) ∨ take_off)));
((pl_status == maintenance) ⇒ (❍  (pl_status := operational)));

implementation

 …

}

Figure 5.7   Enhanced version of class deﬁnition PLANE.

Let us elucidate with an example of both the usefulness for providing the above facility
and the meaning of “preserves” in the deﬁnition of universalization. Consider the con-
 (p ⇒ ❍  q) deﬁned in a class C requiring every message p to be immediately fol-
straint ❑
lowed by message q. The universalization of the above constraint would require after p, the
next message among those deﬁned in C to be q, yet permitting zero or more messages msgi
to be interleaved between p and q, provided that messages msgi have not been deﬁned in C.
 (p ⇒ ❍  q) in public constraints, its meaning in global
Thus when specifying a formula ❑
time would be the second one, i.e. the meaning corresponding to its universalized version.
 <(p ⇒ ❍  q)> will ensure, even in global time, that
However, specifying the constraint ❑
every message p be immediately followed by message q, without allowing any message be
interleaved between p and q.

5.3.4 Attributes

Figure 5.7 presents a more elaborate version of the class PLANE presented in subsection
5.3.2 (ﬁgure 5.6). Its deﬁnition includes an attribute pl_status with associated domain {op-
erational, maintenance}. Value maintenance is assigned to pl_status during a maintenance
period for the aeroplane. Value operational assigned to pl_status indicates that the aeroplane
can travel.

The main reason for providing attributes in class deﬁnitions is to enhance the readabil-
ity of constraints and ease their speciﬁcation. Indeed, attributes are very useful when we
want to express the fact that one or several actions on a particular object can be undertaken
depending on the current values of one or several attributes of that object.

Let o be an instance of PLANE. The ﬁrst of the public constraints says that the attribute
pl_status should be assigned either the value operational or the value maintenance*. The sec-
ond constraint says that whenever o receives message take_off the value of pl_status should

❑
❑
❑
138

A Temporal Perspective of Composite Objects

be operational and the next message to be sent to o should be land. The third constraint says
that o may receive message land if the previous message received is take_off. In addition,
whenever message land is received, then either the next message to be sent to o should be
take_off or the attribute pl_status should be assigned the value maintenance. In other words,
after a ﬂight the aeroplane can either continue travelling or begin a maintenance period.
The last constraint says that if the value of attribute pl_status is maintenance, then the next
action should be the assignment of value operational to pl_status.

In order to treat attributes and messages within the same framework we associate with
each value val belonging in the domain of attribute at a message assign_at_val. Let us call
these messages assignment messages. Sending the assignment message assign_at_val to
an object o models the assignment of value val to the attribute at of o. Thus, whenever an
assignment of the form at := val appears within constraint deﬁnitions, it is intended as a
shorthand for the assignment message identiﬁer assign_at_val. In addition, whenever a test
equality of the form at == vali appears within constraint deﬁnitions it is intended as a short-
hand for the formula

(N assign_at_vali) ∧ (¬ (∨ assign_at_valj) S assign_at_vali)
                                                    1 ≤ i ≠ j ≤ n 

where {val1, …, valn} is supposed to be the domain associated with at. This expresses that
at a given instant the current value of attribute at is vali.

What differentiates an assignment message from a public message is that the sender and
receiver of an assignment message should be the same object. It is not possible for two ob-
jects to exchange any assignment message, which implies that values of attributes deﬁned
in an object o can only be updated by o itself. Attribute-value updates constitute an exam-
ple where the supplier of a class C is responsible for providing an implementation of C that
satisﬁes the temporal order of attribute assignment deﬁned in C’s public constraints.

Figure 5.8 shows two sequences of public and assignment messages relative to the class
PLANE. The ﬁrst is a legal sequence satisfying the temporal constraints in ﬁgure 5.7. The
second is an illegal sequence since message take_off follows the assignment of value main-
tenance to attribute pl_status thus violating the second and fourth public constraints.

5.3.5 Components

An example of a class deﬁnition of a composite object modelling the ﬂight of an aeroplane
is given in ﬁgure 5.9. Class FLIGHT contains three components: pl, ctt and ctl. Component
pl is constrained to be assigned an instance of PLANE modelling the aeroplane making a
trip. Components ctt and ctl are constrained to be assigned instances of CTRL_TOWER.

*  If y is an attribute with associated domain {x1, …, xn} then

y := (x1 ∨ … ∨ xk) with k ≤ n is a shorthand for y := x1 ∨ … ∨ y := xk and 
y == (x1 ∨ … ∨ xk) with k ≤ n is a shorthand for y == x1 ∨ … ∨ y == xk

“:=” is used for assigning a value to an attribute
“==” is the test-equal-value operator

The Speciﬁcation of Temporal Properties

139

assign_
pl_status_
operational

take_off

land

take_off

land

take_off

land 

(a)

(b)

assign_
pl_status_
operational

take_off

land

assign_
pl_status_
maintenance

take_off

Figure 5.8 Sequences of public and state messages relative to the class PLANE

((a) legal sequence; (b) illegal sequence).

They represent the control towers of airports from which the plane respectively takes off
and lands.

Even though an object w may be a shared component of several composite objects, w
cannot be referenced from two different components κ1 and κ2 of the same composite ob-
ject. Indeed, PTL does not permit us to distinguish whether the sender or receiver of a mes-
sage referenced by components κ1 and κ2 is the same object or not. Thus TSOM assumes
that different components of a composite object reference distinct objects.

Let us call the environment of a composite object o the set of all objects existing at a giv-
en point in time excluding o and its components. Public messages, attributes and public
constraints are considered to be the interface of a composite object for its environment.
Public messages are exchanged between the composite object and the environment of the
composite object. Public constraints may not contain component message identiﬁers; they
describe the behaviour of a composite object as if the communication between itself and
its components has been ﬁltered out. For example, an instance o of FLIGHT may receive
messages start_ﬂight and displ_report from its environment. The effect of the start_ﬂight
message would be to set up a cooperation between the aeroplane and the two control tow-
ers necessary for an aeroplane to make a trip. The effect of the displ_report message would
be to display a complete report once the ﬂight has been completed. Messages start_ﬂight
and displ_report can be sent to o depending on the current abstract state of o. Domain values
of attribute ﬂ_status model the various abstract states of o, which are: comp_pb when there
is a problem encountered with some of o’s components and the ﬂight cannot be carried
out; ready when there is no problem with any of o’s components and the coordination proc-
ess between components can be started; started when the plane has taken off but not yet
landed; completed when the plane has landed.

140

A Temporal Perspective of Composite Objects

class FLIGHT {
attributes

ﬂ_status: {comp_pb, ready, started, completed};

public messages

start_ﬂight ←, displ_report ←

public constraints

ﬂ_status := (ready ∨ comp_pb)
 (start_ﬂight ⇒ 

[(ﬂ_status == ready) ∧ ❍  ((ﬂ_status := started) ∧

 ((ﬂ_status == started) U (ﬂ_status := completed)))]);

 (displ_report ⇒ (ﬂ_status == completed));
 ((ﬂ_status == (completed ∨ pl_maintenance)) ⇒

¬ (ﬂ_status := (started ∨ comp_pb ∨ ready ∨ completed)));

components

ctt: CTRL_TOWER;
ctl: CTRL_TOWER;
pl: PLANE;

component messages

ctt$req_take_off →, ctt$perm_take_off ←,
ctl$req_land →, ctl$perm_land ←,
pl$take_off →, pl$land →;

component constraints

…

implementation

perm_take_off(sender: oid, …)
{ … };
perm_land(sender: oid, …)
{ … };
…

}

Figure 5.9   Class FLIGHT modelling the ﬂight of an aeroplane.

5.3.6 Component Messages

Component messages are exchanged between the composite object and its components.
The deﬁnition of each component message msg should indicate the component which is
the sender or receiver of msg. This is achieved by preﬁxing the message identiﬁer with the
component identiﬁer and separating the two identiﬁers with the character “$”. For exam-
ple, the deﬁnition of component message ctt$req_take_off means that message req_take_off
can be sent from an instance of FLIGHT to component ctt. In addition, assuming the com-
ponent deﬁnition κ: C, each incoming (outgoing) component message κ$msg, should
match an outgoing (incoming) public message msg deﬁned in class C. For example, for the
deﬁnition  of  the  incoming  component  message  ctl$perm_land ←  in  class  FLIGHT,  the

❑
❑
❑
The Speciﬁcation of Temporal Properties

141

outgoing  message  perm_land →  should  appear  in  the  list  of  public  messages  of  class
CTRL_TOWER.

Implementing a component incoming message κ$msg would require certifying that the
sender of msg is κ, therefore necessitating a comparison between the sender’s oid and κ’s
oid. However, in most object-oriented systems, the sender of a message is not known to the
receiver of the message. A simple solution for identifying the sender of an incoming com-
ponent message κ$msg ← would be the assignment of the sender’s oid to a particular pa-
rameter of msg. In particular, for any outgoing public message msg deﬁned in a class C, it
would be a good practice to anticipate a parameter for the sender of msg. Indeed, a com-
ponent deﬁnition κ: C in a class CC enables the deﬁnition of the incoming component
message κ$msg ←. The implementation of msg in CC needs the oid of the sender of msg.
An example of the above strategy is illustrated with the implementation of messages
perm_take_off  and  perm_land  in  class  FLIGHT  (Figure  5.9).  Message  perm_take_off
(perm_land) uses the parameter sender for identifying the sender of the message while ex-
pecting  instances  of  CTRL_TOWER  to  assign  their  oid  to  sender  when  sending
perm_take_off (perm_land).

5.3.7 Component Constraints

Component constraints specify the legal sequences of public and component messages
exchanged between the composite object, components of the composite object and the en-
vironment of the composite object. For all component messages the composite object is
involved either as sender or receiver. A direct communication between two components of
a composite object cannot be deﬁned. From the above restriction it becomes obvious that
a composite object acts as a coordinator for its components. Temporal dependencies in-
volving different components must be described by means of messages exchanged with
the composite object. Component constraints in ﬁgure 5.10 describing the communi-
cation between an instance o of FLIGHT and o’s components pl, ctl and ctt, constitute an
example of such a dependency.

The ﬁrst component constraint requires attribute ﬂ_status to be initialized either with
value ready or pl_maintenance depending on the value assigned to the attribute pl_status of
component pl. More precisely, ﬂ_status will be initialized to ready (comp_pb) if pl_status is
assigned  value  operational  (maintenance).  The  second  constraint  says  that  message
start_ﬂight may be sent to o if the current value of ﬂ_status is ready. In addition, if start_ﬂight
is sent to o then the next instant component message req_take_off should be sent to compo-
nent ctt from the composite object. The purpose of the communication between the com-
posite object and component ctt is to grant permission to take off. Once the permission to
take off is granted, the command to take off for the aeroplane is issued from the composite
object. This is expressed by the third component constraint. It says that whenever message
perm_take_off is received from component ctt, then the next message to be sent is take_off
with sender the composite object and receiver pl. In addition, attribute ﬂ_status is assigned
value started immediately after message pl$take_off has been sent to pl. The fourth and ﬁfth

142

A Temporal Perspective of Composite Objects

class FLIGHT {

...

component constraints

((pl$pl_status == operational) ⇒ (ﬂ_status := ready)) ∧

((¬ (pl$pl_status == operational)) ⇒ (ﬂ_status := comp_pb));

 (start_ﬂight ⇒ ((ﬂ_status == ready) ∧ ❍
 (ctt$perm_take_off ⇒ ❍  (pl$take_off ∧ ❍

 ctt$req_take_off));

 (ﬂ_status := started)));

 ((ﬂ_status == started) ⇒ ◊ ctl$req_land)));
 (ctl$perm_land ⇒ ❍

 (pl$land ∧ ❍

 (ﬂ_status := completed)));

 (displ_report ⇒ (ﬂ_status == completed));
 ((ﬂ_status == (completed ∨ pl_maintenance)) ⇒

¬ (ﬂ_status := (started ∨ comp_pb ∨ ready ∨ completed)));

…

}

Figure 5.10   Component constraints of class FLIGHT.

component constraints specify an analogous communication between the composite ob-
ject and component ctl. More precisely, the fourth constraint requires that component mes-
sage req_land to be sent to ctl sometime in the future after the value of ﬂ_status is started.
The ﬁfth constraint speciﬁes that once the permission to land is granted (component mes-
sage perm_land is sent to the composite object from component ctl), the command to land
(component message pl$land) for the aeroplane is issued from the composite object. In
addition, for indicating that the aeroplane has landed the value completed is assigned to
attribute ﬂ_status. The sixth constraint says that message disp_report may be sent to o if the
current value of ﬂ_status is completed. Finally, the last component constraint ensures that
once ﬂ_status has been assigned one of the values comp_pb or completed it cannot be later
updated.

Let us now clarify the rationale for introducing both public constraints and component
constraints in composite object class deﬁnitions. To test consistency of a composite ob-
ject’s speciﬁcation, the speciﬁcation of the temporal behaviour of its components must be
taken into account. As we will describe in the next section, this is achieved by testing the
satisﬁability of the logical conjunction of public constraints of components and compo-
nent constraints of the composite object. Taking the conjunction of public constraints
without regard to component constraints of a component v of a composite object o permits
irrelevant details of the eventual composition of v from other objects to be abstracted away.
If o is in turn a component of a composite object z, the satisﬁability of the conjunction of
component constraints of z and public constraints of o should be tested in order to conﬁrm
either the consistency or inconsistency of z’s speciﬁcations.

Figure 5.11 depicts the use of public and component constraints for composing objects.
Ovals represent class deﬁnitions. An edge labelled κ connecting a class C with a class C´

❑
❑
❑
❑
❑
❑
The Speciﬁcation of Temporal Properties

143

...

...

...

C6

Public constraints

Component constraints

κ4

κ5

C5

C4

Public constraints

Component constraints

Public constraints

Component constraints

κ1

C1

κ2

C2

κ3

...

C3

Public constraints

Public constraints

Public constraints

C4 composition =

component- constraints- C  4     ∧ 
 
 
public- constraints- C  2      ∧ 

public- constraints- C  1     ∧ 

public- constraints- C  3 

C6 composition =

component- constraints- C  6  
public- constraints- C  5 

   ∧ 

public- constraints- C  4     ∧ 

Figure 5.11   

Using public and component constraints to compose objects.

indicates that component κ: C´ is deﬁned within the deﬁnition of C. For class C4 the con-
junction of component constraints of C4 with public constraints of classes C1, C2 and C3
should be made. Then for the composition of C6 the conjunction of public constraints of
classes of C4 and C5 with the component constraints of C6 should be made.

The above schema of object composition requires public and component constraints of
the same object to be related by some compatibility rule. In fact, we must ensure that for
any sequence σ satisfying component constraints there exists a sequence σ´ of public mes-
sages satisfying public constraints such that when component messages are eliminated
from σ we get a sequence identical to σ´. We will call the above compatibility rule between
component constraints and public constraints of the same composite object the corre-

144

A Temporal Perspective of Composite Objects

spondence property
formula:

. The correspondence property requires us to verify the validity of the

 
component constraints

⇒
 

 
universalized
public constraints

The universalization of public constraints is necessary for taking into account that one or
several component messages can be interleaved between any pair of public messages. In
other words the universalization of public constraints corresponds to a shift from local
time to global time. In this case time-points in local time are identiﬁed with the composite
object’s public and assignment messages whereas time-points in global time are identiﬁed
with the composite object’s component, public, and assignment messages.

5.4

Veriﬁcation

To verify the consistency of object speciﬁcations we make the following assumptions con-
 owns an inﬁnite number of oids. An oid
cerning the object model of TSOM. Each class 
C
. An instance
 becomes an instance of 
C
o
 receives the predeﬁned message 
 is
 is deleted when 
 of 
o
o
o
 to only be able to accept 
modelled by restricting 
o
delete_C

 when it receives the predeﬁned message 
delete_C
 messages.

create_C
. The deletion of 

C

5.4.1 Veriﬁcation of Elementary Objects

 

 
 
 

 
 
 
 

 
 
 
 

 
 
 
 

 

 
 
 

 
 
 
 

 

 

 

 

 
 

 

 

 

 
 

 

 

 

 

 

 

 

 
 

 

 

 

 

 

 

 

 

 

, 

C

 

 

 

 

 

 

 

 
 

 

 
 

 

 
 

 

 

 

 

 
 

 

 

 

 

 

 ❍

 
 

 

m1

U
) 

¬
(

 m
n

…, 

 
 
 
∧
 create_C) 
 ∧

The consistency of a class deﬁnition 
 
 
 
 
can be veriﬁed by giving as input to the satisﬁability algorithm the formula:

 ∨
∨
… ∨
 
 m
 (delete_C 
1
 ⇒
 ❍
 public_constraint_C)
 (create_C
 ⇒
 ∧
❍ ❑
 (
 (create_C
 ⇒
 (delete_C
mn

, from which elementary objects are instantiated,
 
 
(4.1)
(4.2)
(4.3)
(4.4)
In the previous formula 
 is assumed to be the set of public and assignment mes-
*
 stands for the conjunction of constraints deﬁned in
sages deﬁned in 
C
class 
 message can be sent
to an object prior to its creation. Conjunct (4.2) says that after the creation of an object its
public constraints must be veriﬁed. Conjunct (4.3) forbids an object to be created more
than once. Finally conjunct (4.4) ensures that after accepting a delete_C message, an ob-
ject will then only be able to accept further delete_C messages.

. Conjunct (4.1) says that no public message nor the 

 create_C))

 ¬
 delete_C)

. 
public_constraint_C

For a class C we will name LCpublic_C† the conjunction of (4.1), (4.2), (4.3) and (4.4).
The output of the satisﬁability algorithm corresponding to the formula LCpublic_C deter-
mines the consistency of C. If no graph is produced, the deﬁnition of C is inconsistent. If a
satisﬁability graph is produced, the deﬁnition of C is consistent. This satisﬁability graph

delete_C

C

* Assignment messages are indirectly defined via attribute definitions.
† LCpublic stands for lifecycle according to public constraints.

❑
❑
❑
Veriﬁcation

145

…

co: CC

$q

ξ
$p, 

component messages
     χ
component constraints
χ
 ❑ 
$p
((
     start 

χ
$p
(

∧ 

❍ 

 ∧

 ∧

 ❍

ξ
 

$q) 

∨ 

ξ
(

 ∧

$q

 ❍

χ
$p)))
 

ξ

: C
2

 
❑  (q  ∨  r)
 

 
 

 

 
 

 

 

 
 
 
 

 
 

 
 
 

 

 

 
 
 

 
 

 

 

 
 

 
 
 

 

 

 
 

 

 
 

χ
: C
1

❑  p

Environment of co

Figure 5.12   

A composite object and component speciﬁcations.

then represents all legal sequences of public and assignment messages that can be sent to
and received from an instance of C.

5.4.2 Veriﬁcation of Composite Objects

To describe the veriﬁcation of a composite object’s speciﬁcation let us assume the situa-
tion presented in ﬁgure 5.12. An object is depicted by a rectangle. A rectangle correspond-
ing to an elementary object is labelled with a formula describing its public constraints.
Rectangles corresponding to composite objects are divided into two horizontal parts. The
upper part is used for listing the public constraints of the composite object. The lower part
is used for listing the list of component messages and component constraints.

A grey arrow connecting two rectangles is drawn when the two objects are assumed to
exchange messages. A black arrow connecting two rectangles x and y, leaving x and lead-
ing to y, is drawn when y is a component of x. Thus co in ﬁgure 5.12 is assumed to be a com-
posite object having two components χ and ξ. Let components χ and ξ be assigned
instances of classes C1 and C2 respectively. co is assumed to be an instance of CC.

Component constraints of co say that the ﬁrst message to be sent to co must be the public
message start. Immediately after the reception of start, messages p and q should be sent to
components χ and ξ alternately, starting with a p message. Public constraints of compo-
nents are very simple. Component χ expects always to receive message p. Component ξ
expects always to receive either message q or message r.

146

A Temporal Perspective of Composite Objects

 …

, 

The basic idea for testing the consistency of a composite object’s speciﬁcation is to give
as input to the satisﬁability algorithm the conjunction of the object’s and its components’
κ
speciﬁcations.  If  a  class  deﬁnition 
,
i: Ci
 = 
,
1
i

  contains  the  deﬁnitions  of  components 

, the input to the satisﬁability algorithm would be the formula:
n
∧
 LCcomponent_CC 
 create_C
n

∧
… ∧
∧
(4.5)
LCpublic_C
 
 
 LCpublic_C
 
1
n
∧ (¬
∧ …
(4.6)
 U
 create_CC
) 
 create_C
 
1
 ∨
¬
… ∨
(4.7)
 (s
 s
 (
 
1
j
 specify lifecycles corresponding to components
,
 LCpublic_Cn
 speciﬁes the lifecycle of the

Conjuncts 
LCpublic_C1
κ
 …
, 
 = 
,
1
i
i: Ci
composite object and stands for the formula:

, 
, respectively. Conjunct 
n

*
LCcomponent_CC

 create_CC

…
, 

 ∧
)

(¬

CC

 U

))

 (delete_C ∨ m1 ∨ … ∨ mn) U create_CC) ∧
¬
(
 
 
 
 
 (create_CC ⇒ ❍  component_constraint_CC) ∧
 
 

 

 
 
 ¬ create_CC)) ∧

 (create_CC ⇒ (❍ ❑

 (delete_CC ⇒ ❍  delete_CC) ∧

 

 

 

 

 

 

 
 

 

 

 

 

 
 

 

 

 
 

 

 

 

 

 

 
 

 

 
 

 

 
 
 
 

 

 

 

 
 

 

 

 
 

 

 

 

 

 

 
 

 

 

 

 

 
 

 

 

 

 

 

 

 

 

 

 
 

 

 

 

where m1, …, mn is assumed to be the list of public, assignment and component messages
deﬁned in CC and component_constraint_CC stands for the conjunction of component con-
straints deﬁned in CC. Conjuncts ¬ create_CC U create_Ci, i = 1, …, n, say that all compo-
nents  must  have  been  created  before  the  creation  of  the  composite  object.  The  last
conjunct says that component messages not deﬁned in CC cannot be exchanged. Thus, si,
i = 1, …, j, are all such messages identiﬁers of the form κ$msg such that the component
deﬁnition κ: C appears in CC, msg is a public message deﬁned in C and  κ$msg does not
appear in the list of component messages of CC.

The constraint on component creation we have expressed with conjunct (4.6) is merely
introduced for expository reasons. Its omission would not represent any signiﬁcant beneﬁt
for the description of object lifecycles at the speciﬁcation level but additional complexity
for the various formulas formalizing the notions we are proposing. Indeed, modelling sit-
uations where an object z could be created either before or after a composite object o and
then z be assigned to a component of o requires the introduction of lengthy and complicat-
ed formulas.

For the composite object co in ﬁgure 5.12, the input to the satisﬁability algorithm would

be the formula:

LCpublic_C1 ∧ LCpublic_C2 ∧ LCcomponent_CC ∧

(¬ create_CC U create_C1) ∧ (¬ create_CC U create_C2) ∧

(4.8)
(4.9)
(4.10)
Conjuncts LCpublic_C1, LCpublic_C2 and LCcomponent_CC correspond to components χ,
ξ and to the composite object co respectively.

 (¬ ξ$r)

However, the conjunctions of formulas (4.5), (4.6) and (4.7) cannot be directly given as
input to the satisﬁability algorithm. A number of transformations must be applied in ad-
vance. The rationale for these transformations and their exact nature is the subject of the

* LCcomponent stands for lifecycle according to component constraints.

❑
❑
❑
❑
❑
Veriﬁcation

147

following  subsections.  The  various  transformations  can  be  carried  out  automatically,
meaning that the whole veriﬁcation process can be automated.

The output of the algorithm will determine the consistency of the composite object’s
speciﬁcation. If no graph is produced, the speciﬁcation is inconsistent. If a satisﬁability
graph is produced, the speciﬁcation is consistent. The graph produced represents all legal
sequences of public, assignment and component messages exchanged between the com-
posite object, the various components of the composite object and the environment of the
composite object.

Transformations on Component Deﬁnitions

5.4.2.1
In this subsection we describe the various transformations that should be performed on
conjuncts LCpublic_C1, …, LCpublic_Cn of formula (4.5).
Message Renaming

To achieve the matching between component messages deﬁned for a composite object and
public  messages  of  component  κ: Ci  each  message  msg  appearing  within  conjunct
LCpublic_Ci of (4.5) should be renamed κ$msg. Thus, if a class speciﬁcation contains the
component deﬁnitions κ1: C and κ2: C (i.e. both components κ1 and κ2 are associated
with the same class C), the component which is the sender or receiver of msg can be distin-
guished since msg is renamed either κ1$msg or κ2$msg. The formula resulting from that
transformation will be named κ$LCpublic_Ci. For example, according to the public con-
straints of component χ in ﬁgure 5.12, χ$LCpublic_C1 stands for the formula:

(¬ (χ$delete_C1 ∨ χ$p) U χ$create_C1) ∧
 ¬ χ$create_C1)) ∧
 (χ$create_C1 ⇒ (❍ ❑

 (χ$create_C1 ⇒ ❍  ❑
 χ$p) ∧
 (χ$delete_C1 ⇒ ❍  χ$delete_C1)

Sharing Components
To take into account that component κ: Ci may be shared between the composite object co
and  the  environment  of  co,  each  message κ$msg  within  the  conjunct κ$LCpublic_Ci,
should be replaced by the formula:

κ$msg ∨ env$κ$msg

(4.11)
Messages exchanged between a component and the environment (named environment
messages) are preﬁxed with “env$”. Messages exchanged between a component and the
composite object are not renamed. Replacing a message κ$msg with the formula (4.11)
implies that the sender or receiver of a message msg could be either co or an object from
the  environment  of  co.  The  resulting  formula  from  that  transformation  is  named
env$κ$LCpublic_Ci.
For example, for component χ in ﬁgure 5.12, env$χ$LCpublic_C1 would stand for the

formula:

❑
❑
❑
148

A Temporal Perspective of Composite Objects

(¬ (χ$delete_C1 ∨ env$χ$delete_C1 ∨ χ$p ∨ env$χ$p) U env$χ$create_C1) ∧

 (env$χ$create_C1 ⇒ ❍  ❑

 (env$χ$create_C1 ⇒ (❍ ❑

 (χ$p ∨ env$χ$p)) ∧
 ¬ env$χ$create_C1)) ∧

 ((χ$delete_C1 ∨ env$χ$delete_C1) ⇒ ❍  (χ$delete_C1 ∨ env$χ$delete_C1))

Recall that assignment messages cannot be exchanged between objects. Therefore only
environment-assignment messages can exist since a composite object cannot be the send-
er of an assignment message to any of its components. Thus, any assignment message
κ$msg should be simply renamed env$κ$msg. In addition, the composite object cannot
send a creation message to a component κ: C, since components should exist before the
creation  of  the  composite  object. Therefore  any κ$create_C must  be  simply  renamed
env$κ$create_C.
Universalization of Public Constraints of Components
Let us assume that m1, …, mn is the collection of public messages deﬁned in a class C and
that  κ: C is a component deﬁnition appearing in a class deﬁnition for composite objects.
Then we introduce the following shorthand expressions:

≡
public_msg_C
κ$public_msg_C
≡
env$κ$public_msg_C ≡
κ$env_pub_msg_C
≡

m1 ∨ … ∨ mn ∨ delete_C
κ$m1 ∨ … ∨ κ$mn ∨ κ$delete_C
env$κ$m1 ∨ … ∨ env$κ$mn ∨ env$κ$delete_C
κ$public_msg ∨ env$κ$public_msg ∨ κ$create_C

The rationale for the universalization of conjunct env$κ$LCpublic_C corresponding to
component κ: C has been described in subsection 5.3.1. The universalization consists of
the following transformations:

by ¬ κ$env_pub_msg_C U p
by ¬ κ$env_pub_msg_C U (κ$env_pub_msg_C ∧ ❍  f)
by ¬ κ$env_pub_msg_C S (κ$env_pub_msg_C ∧ G f)
where p is an atomic proposition and f a wff of PTL appearing within env$κ$LCpublic_C.
Applying the universalization of env$χ$LCpublic_C1 we will obtain the following for-

replace
replace
replace

 f
G f

p

 (¬ χ$env_pub_msg_C1 U env$χ$create_C1 ⇒

(¬ χ$env_pub_msg_C1 U

(χ$env_pub_msg_C1 ∧

❍ ❑

 (¬ χ$env_pub_msg_C1 U ¬ env$χ$create_C1)))) ∧

mula:

(¬((¬ χ$env_pub_msg_C1 U

(χ$delete_C1 ∨ env$χ$delete_C1 ∨ χ$p ∨ env$χ$p)) U

(¬ χ$env_pub_msg_C1 U env$χ$create_C1)) ∧

 (¬ χ$env_pub_msg_C1 U env$χ$create_C1 ⇒

(¬ χ$env_pub_msg_C1 U

(χ$env_pub_msg_C1 ∧

 ❑

 (¬ χ$env_pub_msg_C1 U (χ$p ∨ env$χ$p))))) ∧

❑
❑
❑
❍
❑
❍
❑
Veriﬁcation

149

 ((¬ χ$env_pub_msg_C1 U (χ$delete_C1 ∨ env$χ$delete_C1)) ⇒

(¬ χ$env_pub_msg_C1 U

(χ$env_pub_msg_C1 ∧

 (¬ χ$env_pub_msg_C1 U (χ$delete_C1 ∨ env$χ$delete_C1))))))

In the above formula we have used the equivalence:

f U (f1 ∨ f2) ⇔ (f U f1) ∨ (f U f2)
while χ$env_pub_msg_C1 is the shorthand for the formula:

 χ$delete_C1 ∨ env$χ$delete_C1 ∨ χ$p ∨ env$χ$p ∨ env$χ$create_C1

5.4.2.2

Universalization of Component Constraints of Composite 
Objects

Let us assume that q1, …, qp are the various component messages deﬁned in a class CC.
Then we introduce the following shorthand expressions:

q1 ∨ … ∨ qp 
public_msg_CC ∨ component_msg_CC ∨ create_CC

component_msg_CC
msg_CC
The universalization of conjunct LCcomponent_CC in (4.5) is required to take into ac-
count that one or several environment messages may be interleaved between a pair of
component, assignment or public messages in which the composite object is either the
sender or the receiver. The universalization of LCcomponent_CC consists of the following
transformations:

≡
≡

replace
replace
replace

p

 f
G f

by ¬ msg_CC U p
by ¬ msg_CC U (msg_CC ∧ ❍
 f)
by ¬ msg_CC S (msg_CC ∧ G f)

where p is an atomic proposition and f a wff of PTL appearing within LCcomponent_CC.

5.4.2.3 Veriﬁcation of the Correspondence Property
According to the shorthand expressions we have already introduced, the correspondence
property for a class CC for composite objects is easily formalized by requiring the follow-
ing formula to be valid:

component_constraint_CC ⇒ (universalization of public_constraint_CC)

The universalization of public_constraint_CC consists of the following transformations:

replace
replace
replace

p

 f
G f

by ¬ public_msg_CC U p
by ¬ public_msg_CC U (public_msg_CC ∧ ❍
 f)
by ¬ public_msg_CC S (public_msg_CC ∧ G f)

where p is an atomic proposition and f a wff of PTL appearing within public_constraint_CC.
As an example consider a composite object for which one public message p and one
component message κ$q have been deﬁned, the formula ❑
 p being its public constraint
and the formula
❑  ((p ∧ ❍  κ$q) ∨ (κ$q ∧ ❍  p))

its component constraint. The correspondence property requires us to test the validity of
the formula:

❑
❍
❍
❍
150

A Temporal Perspective of Composite Objects

 ((p ∧ ❍  κ$q) ∨ (κ$q ∧ ❍  p)) ⇒ ❑

 (¬ p U p)

Using the satisﬁability algorithm of PTL, the validity of the above formula is easily veri-
ﬁed.

5.5 Concluding Remarks

We have presented a formal approach, founded on PTL, for the description of temporal
aspects of an object’s behaviour and its composition with other objects. An object’s tem-
poral properties are speciﬁed by means of a collection of component and public con-
straints.  The  former  specify  the  temporal  order  of  messages  exchanged  between  a
composite object and its components. The latter specify the behaviour of an object as if the
communication between it and its internal components has been ﬁltered out. We described
an automated procedure for verifying the consistency of object speciﬁcations based on the
satisﬁability algorithm of PTL.

A signiﬁcant source of inﬂuence for the various ideas we have presented has been the
work of Manna and Wolper who investigated the composition of synchronized collections
of concurrent processes [17]. For Manna and Wolper a process speciﬁcation (an object in
our approach) consists of a collection of PTL formulas (public constraints) describing the
temporal order of its input/output communication operations (incoming/outgoing mes-
sages). The consistency of a concurrent system consisting of a synchronizer process S (a
composite object) communicating with a collection of processes Pi, 1 ≤ i ≤ n (components
of a composite object), is veriﬁed by giving as input to the satisﬁability algorithm of PTL
the composition of S and Pi speciﬁcations. Even though one may ﬁnd strong similarities
concerning both the behaviour speciﬁcation of a process (object) and the veriﬁcation
procedure for consistency, the two approaches are characterized by different modelling
prerequisites and divergent objectives. An important prerequisite emphasized in our ap-
proach is the ability of specifying composite objects having a nested structure of arbitrary
depth (composite objects having components that are other composite objects). The nest-
ed structure of composite objects necessitated the distinction between public and compo-
nent constraints and the validation of the correspondence property. In addition, the fact
that an object may be a shared component of several composite objects led us to introduce
“env” messages. None of the above modelling issues have been investigated in [17]. Final-
ly, there is an important distinction concerning the objectives of the two approaches. In our
approach we ended up with a procedure for verifying an object’s temporal speciﬁcations.
In [17] the satisﬁability graph corresponding to the composition of S and Pi speciﬁcations
is further used for deriving the synchronization parts of code of S and the Pi’s. More pre-
cisely, for each process, Pi and S, Manna and Wolper derive from the set of all possible se-
quences of communication operations a subset which satisfies the specified constraints.
Several improvements can be envisaged for TSOM along various directions. First and
foremost, there is a need for providing the speciﬁer with assistance for translating TSOM
speciﬁcations into some object-oriented language. Assessing the various alternatives for
providing higher-level assistance than that of guidelines, we ended up investigating the

❑
References

151

eventuality of enriching an existing object-oriented language with constructs that would
directly support most of the notions integrated in TSOM. Further evidence to support the
validity of this approach is given by Nierstrasz (see chapter 4). There, a type system for ob-
ject-oriented languages is proposed which enables users to describe temporal aspects of
object behaviour and provides rules for analyzing the type-consistency of such descrip-
tions. Even though the formalism upon which that type system has been developed is dif-
ferent from PTL, it is likely that most of the ideas and results could also be applied for
PTL. Thus, the proposed type system could serve as the starting point for enhancing ob-
ject-oriented languages with constructs directly supporting most of TSOM’s notions.

Another important direction along which additional efforts are necessary for improving
TSOM concerns the veriﬁcation procedure. The satisﬁability algorithm of PTL, upon
which the veriﬁcation procedure is based, may generate a number of nodes that grows ex-
ponentially with the number of temporal operators of the input formula. By operating the
algorithm the way we have described, i.e. applying the algorithm to each object speciﬁca-
tion separately and not to the composition of all constraints of those objects participating
in a whole part-of hierarchy, the size of input formulas is considerably minimized. How-
ever, the exponential nature of the satisﬁability algorithm still remains a serious efﬁciency
handicap  for  its  computer  implementation.  Restricted  forms  of  PTL  may  reduce  the
number of nodes of the satisﬁability algorithm to polynomial size [10]. However, whether
such restrictions of PTL are still suitable for TSOM remains to be investigated.

References

[1] Constantin Arapis, “Temporal Speciﬁcations of Object Interactions,” Proceedings Third Internation-
al Workshop on Foundations of Models and Languages for Data and Objects, Aigen, Austria, Sept.
1991, pp. 15–35.

[2] Constantin Arapis, “Dynamic Evolution of Object Behaviour and Object Cooperation,” Ph.D. thesis

no 2529, Centre Universitaire d’Informatique, University of Geneva, 1992.

[3] Constantin Arapis, “A Temporal Logic Based Approach for the Description of Object Behaviour Ev-

olution,” Journal of Annals of Mathematics and Artiﬁcial Intelligence, vol. 7, 1993, pp. 1–40.

[4] Grady Booch, Object-Oriented Design with Applications, Benjamin/Cummings, 1991.
[5]

Peter Coad and Edward Yourdon, Object-Oriented Analysis, 2nd edn., Prentice-Hall, Englewood
Cliffs, 1991.
Peter Coad and Edward Yourdon, Object-Oriented Design, Prentice Hall, Englewood Cliffs, 1991.

[6]
[7] Brad Cox, Object-Oriented  Programming An  Evolutionary Approach, Addison Wesley, Reading,

Mass., 1987.

[8] Vicki De Mey, Betty Junod, Serge Renfer, Marc Stadelmann and Ino Simitsek, “The Implementation
of Vista  —  A Visual Scripting Tool,” in Object Composition, ed. Dennis Tsichritzis, Centre Univer-
sitaire d’Informatique, University of Geneva, June 1991, pp. 31–56.

[9] Allen Emerson and Edmund Clarke, “Using Branching Time Temporal Logic to Synthesize Synchro-

nization Skeletons,” Science of Computer Programming, vol. 2, 1982, pp. 241–266.

[10] Allen Emerson, Tom Sadler and Jai Srinivasan, “Efﬁcient Temporal Reasoning,” Proceedings 16th

ACM Symposium on Principles of Programming Languages, 1989, pp. 166–178.

152

A Temporal Perspective of Composite Objects

[11] Dov Gabbay, Amir Pnueli, Saharon Shelah and Jonathan Stavi, “On the Temporal Analysis of Fair-
ness,” Proceedings 7th ACM Symposium on Principles of Programming Languages, 1980, pp. 163–
173.

[12] Adele Goldberg and David Robson, Smalltalk-80: The Language and its Implementation, Addison-

Wesley, Reading, Mass., 1983.

[13] David Harel, “On Visual Formalisms,” Communications of the ACM, vol. 31, no. 5, May 1988, pp.

514–530.

[14] Richard Helm, Ian Holland and Dipayan Gangopadhyay, “Contracts: Specifying Behavioural Com-
positions in Object-Oriented Systems,” Proceedings of the ECOOP/OOPSLA Conference, Ottawa,
Oct. 1990, pp. 169–180.
Ivar Jacobson, Object-Oriented Software Engineering, Addison-Wesley, Reading, Mass., 1992.

[15]
[16] Orna Lichtenstein and Amir Pnueli, “The Glory of The Past,” Proceedings of the Workshop on Logic
of Programs, Brooklyn, Lecture Notes in Computer Science, vol. 193, Springer-Verlag, 1985, pp. 97–
107.

[17] Zohar Manna and Pierre Wolper, “Synthesis of Communicating Process,” ACM Transactions on Pro-

gramming Languages and Systems, vol. 6, no. 1, June 1984, pp. 68–93.

[18] Bertrand Meyer, Object-oriented Software Construction, Prentice Hall, 1988.
[19] Oscar Nierstrasz, Dennis Tsichritzis, Vicki De Mey and Marc Stadelmann, “Objects + Scripts = Ap-
plications,” in Object Composition, ed. Dennis Tsichritzis, Centre Universitaire d’Informatique, Uni-
versity of Geneva, June 1991, pp. 11–29.

[20] James Rumbaugh, M. Blaha, W. Premerlani, F. Eddy and W. Lorensen, Object-Oriented Modeling

and Design, Prentice Hall, 1991.

[21] Sally Shlaer and Stephen Mellor, OBJECT LIFECYCLES: Modeling the World in States, Prentice

Hall, Englewood Cliffs, NJ, 1992.

[22] Bjarne Stroustrup, The C++ Programming Language, Addison-Wesley, Reading, Mass., 1986.
[23] Anthony Wassermann, P. Pircher and R. Muller, “The Object-Oriented Structured Design Notation

for Software Design Representation,” IEEE Computer, vol. 23, no. 3, March 1990, pp. 50–63.

[24] Rebecca Wirfs-Brock, Brian Wilkerson and Laurent Wiener, Designing Object-Oriented Software,

Prentice Hall, Englewood Cliffs, NJ, 1990.

Chapter 6
Functions, Records and 
Compatibility in the λN 
Calculus

Laurent Dami

Abstract    Subtyping, a fundamental notion for software reusability, establishes a
classiﬁcation of data according to a compatibility relationship. This relationship is
usually associated with records. However, compatibility can be deﬁned in other
situations, involving for example enumerated types or concrete data types. We
argue that the basic requirement for supporting compatibility is an interaction
protocol  between  software  components  using  names  instead  of  positions.
Based on this principle, an extension of the lambda calculus is proposed, which
combines  de  Bruijn  indices  with  names.  In  the  extended  calculus  various
subtyping situations mentioned above can be modelled; in particular, records
are encoded in a straightforward way. Compatibility is formally deﬁned in terms
of an operational lattice based on observation of error generation. Unlike many
usual orderings, errors are not identiﬁed with divergence; as a matter of fact,
both are even opposite since they respectively correspond to the bottom and
top elements of the lattice. Finally, we brieﬂy explore a second extension of the
calculus,  providing  meet  and  join  operators  through  a  simple  operational
deﬁnition,  and  opening  interesting  perspectives  for  type  checking  and
concurrency.

6.1

Introduction

The lambda calculus is a widely used tool for studying the semantics of programming
languages. However, there are at least two categories of programming features that cannot
be modelled in the lambda calculus. One is concurrent programming, in which the non-
determinism  introduced  by  operations  taking  place  in  parallel  cannot  be  captured  by
lambda  expressions. The  other  is  subtyping,  which  plays  a  prominent  role  in  object-

Laurent Dami, “Functions, Records and Compatibility in the Lambda N Calculus,” Object-Oriented Software Composition, O. Nierstrasz 
and D. Tsichritzis (Eds.), pp. 153-174, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

154

Functions, Records and Compatibility in the λN Calculus

oriented systems, and is interesting for software reuse in general. Subtyping is based on a
classiﬁcation of data according to collections of valid operations; an operation valid for
one type is also valid for its subtypes. The term plug compatibility is sometimes used to
express this relationship. In the lambda calculus, functional application is the only opera-
tion, and provides no support for such a classiﬁcation. Therefore, the lambda calculus
must be extended to deal with subtyping: the common approach is to use records [9][10].
In this paper we argue that subtyping does not reduce to record systems. We propose an
extended lambda calculus λN (lambda calculus with names) which can encode records —
and therefore objects as well — but is more general since it also supports plug compatibil-
ity on enumerated types and concrete data types. 

Our calculus is based on the observation that reusability in record systems is mainly due
to the use of names for accessing ﬁelds, instead of positions in simple Cartesian products;
the difference is important when considering extensibility. A product type can be extended
in one direction, by adding a new component in the last position: any projections valid for
the original product are still valid for the extended product. In that view, the type (Int × Int)
can be seen as a supertype of (Int × Int× Colour) . However, this ordering based on positions
can only have a tree structure. By contrast, an ordering based on names can be any partial
order. A well-known example is the ordering of various types of points in a record system:

2DPoint = (x: Int; y: Int)

3DPoint = (x: Int; y: Int; z: Int)

2DColouredPoint = (x: Int; y: Int; c: Colour)

3DColouredPoint = (x: Int; y: Int; z: Int; c: Colour)

Like Cartesian products, functions use positional information to identify parameters;
this is the basis for the currying property, which allows any function of n arguments to be
encoded as a hierarchy of n lambda abstractions, with one single argument at each abstrac-
tion level. However, functions cannot be ordered in a tree structure: there is no plug-com-
patibility relationship between a function with three arguments and a function with only
two arguments. This can be illustrated with a simple example: consider the Church encod-
ing of Booleans and the not function in standard λ calculus[5]:

True 
False
Not

= 
= 
=

λt.λf.t
λt.λf.f
λb.λt.λf.b f t

and imagine we now want a three-valued logic, with an unknown value. We must add a
new argument, and everything has to be recoded:

= 
TrueU 
FalseU
= 
UnknownU= 
NotU
=

λt.λf.λu.t
λt.λf.λu.f
λt.λf.λu.u
λb.λt.λf.λu.b f t u

The new encoding is incompatible with the previous one. In particular, it does not make
sense to apply NotU to True: it can only be applied to TrueU. In a software reusability per-

Introduction

155

spective, this implies that any existing component producing True or False values needs to
be modiﬁed to be usable with the new logic.

In order to get a compatibility relationship on functions, we propose a simple extension
of the lambda calculus, inspired from records: functions are allowed to have multiple
parameters at the same abstraction level, and those parameters are distinguished by their
name. It then becomes necessary to specify which name is being bound in a functional ap-
plication, but this is precisely the basis for reusability and subtyping: binding more names
than those actually used by the function does no harm, and therefore a function with argu-
ments (x y) is compatible with a function with arguments (x y z), because both can accept
a sequence of bindings on names x, y and z.

A consequence of this approach is that names participate in the semantics of functions,
and it is no longer possible to consider lambda expressions modulo α-equivalence (re-
naming of bound variables). However, α-renaming is important in the standard lambda
calculus to avoid the well-known problem of name capture in substitutions. The difﬁculty
is avoided by using de Bruijn indices [8] to indicate unambiguously the relationship be-
tween an applied occurrence of a variable and its corresponding abstraction level, and fur-
thermore using names to distinguish between multiple variables at the same abstraction
level. A variable, then, is a pair containing both a name and an index.The  λN encoding of
Booleans is:

True
False
Not

=
=
=

λ (t, 0)
λ (f, 0)
λλ (b, 1)(t→(f, 0))(f→(t, 0))!

For example, (t, 0) in True is a variable. The 0 index tells that this variable is bound by the
closest  abstraction  level  (the  closest  ‘λ’). The  other  component  of  the  pair  tells  that,
among the parameters associated with that abstraction level, the one with name t is to be
chosen. Parameter binding is done through the notation a(x→b), where a and b are terms,
and x is a name. So in the Not function, the variable (b, 1), which refers to the outermost ab-
straction level, receives two bindings on parameters t and f. The exclamation mark at the
end “closes” the sequence of bindings and removes an abstraction level.

As for the de Bruijn calculus, notation involving indices is convenient for machine
manipulations, but hard for humans to read. Fortunately, indices can be hidden easily, by
using a higher-level syntax with a simple translation function into the low-level represen-
tation. This higher-level syntax will be used for all programming examples in this chapter,
while the low-level syntax is retained for presenting the semantics of the calculus. In high-
level syntax, the expressions above become:

True
False
Not 

 =  λ(t) t
 =  λ(f) f
= 

λ(b) λ(t, f) b(t→f)(f→t)!

Informally, the names in parenthesis following a λ are parameters, so now they are explic-
itly declared instead of being implicitly recovered from indices. As an example of a deri-
vation, consider the application of Not to True:

Not(b→True)! =

(λ(b) λ (t, f) b(t→f)(f→t)!) (b→λ(t) t)!

156

Functions, Records and Compatibility in the λN Calculus

The outermost binding on b is reduced, substituting the internal reference to b by True, and
removing b from the parameter list:

(λ() λ(t, f) (λ(t) t)(t→f)(f→t)!)!

Then, by reducing the outermost ‘!’, one abstraction level (one ‘λ’) is removed:

λ(t, f) (λ(t) t)(t→f)(f→t)!

The binding on t substitutes t by f and removes t from the parameter list:

λ(t, f) (λ() f)(f→t)!

The binding on f is simply dropped, because the abstraction to which it is applied has no f
parameter:

λ(t, f) (λ() f)!

Finally, one ‘λ’ is removed because of the ‘!’:

λ(t, f) f

and although this ﬁnal result declares both t and f as parameters instead of only f, it is
equivalent to False, because its translation into low-level syntax with indices is also λ(f, 0).
Now the interesting point about this calculus is that, in order to get an augmented logic,

we just write:

Unknown  = 
NotU 
= 

λ(u) u
λ(b) λ(t f u) b(t→f)(f→t)(u→u)!

Not is recoded (which is normal), but we can keep the original encodings of True and False.
This cannot be done in the standard lambda calculus, and is interesting for reusability: any
other module based on the original encoding is still compatible with our new logic and
does not need modiﬁcation. 

To the best of our knowledge, the idea of using names in a lambda calculus setting was
not studied much in the literature. Two related systems are John Lamping’s uniﬁed system
of parameterization [19] and Garrigue and Aït-Kaci’s label-selective lambda calculus
[3][16]. However, both calculi treat names (or “labels”) and variables as orthogonal con-
cepts, whereas we unify them through the use of de Bruijn indices. 

6.2

A Lambda Calculus with Named Parameters

It is well known that names in the standard lambda calculus are only useful to express a
relationship between binding occurrences and applied occurrences of variables. Once that
relationship is established, i.e. with bound variables, names can be replaced by other
names through α substitution, or can even be removed altogether: in [8] de Bruijn pro-
posed a modiﬁed lambda calculus in which variables are simply denoted by indices. A de
Bruijn index is a non-negative integer expressing the distance between an applied occur-
rence of a variable and the abstraction level to which it refers. For example, the not func-
tion, written 

Not

=

λb.λt.λf.b f t

A Lambda Calculus with Named Parameters

157

x, y, z ∈ Names
i, j ∈ Nat
a, b, ... ∈ Terms

a

:=
|
|
|

λ a
(x, i)
a(x→b)
a!

abstraction
variable
bind operation
close operation

Figure 6.1   Abstract syntax.

in the standard calculus, becomes

Not

=

λλλ 2 0 1

in de Bruijn notation (here we start indices with 0, while some authors start with 1; the dif-
ference is not signiﬁcant). There is a straightforward translation from usual lambda ex-
pressions  to  their  de  Bruijn  version.  The  de  Bruijn  notation  provides  a  canonical
representation: all α-equivalent lambda expressions have the same translation. Further-
more, the well-known problem of name capture is avoided. Both in standard and de Bruijn
calculi, each abstraction level (each ‘λ’) introduces exactly one variable. Our proposal is
to allow several variables at the same abstraction level. To do so, de Bruijn indices are re-
tained, but in addition names are used to distinguish between different variables at the
same level. This section deﬁnes the calculus; the next section shows that this extension
provides support for plug-compatibility.

6.2.1 Abstract (Low-level) Syntax

Figure 6.1 presents the abstract syntax of λN. The language is built over a (ﬁnite) set of
names.

An  abstraction  corresponds  to  the  traditional  notion  of  abstraction.  Like  in  the  de
Bruijn lambda calculus, abstractions need not introduce names for their parameters: the
connection between variables and their corresponding abstraction level directly comes
from the indices associated with variables (see below).

A variable is a name together with a de Bruijn index. This means that an abstraction can
have several parameters, all with the same index, which are distinguished by their name.
The index indicates the abstraction level (which ‘λ’) a variable is referring to: an index of
0 refers to the closest abstraction, and higher numbers refer to farther abstraction levels.
A bind operation partly corresponds to the usual notion of application. However, since
an abstraction may have several parameters, it is necessary to specify which of them is
bound in the expression. Therefore the construct a(x->b) means: “bind b to the parameter

158

Functions, Records and Compatibility in the λN Calculus

FVk((x, i))
FVk(λa)
FVk(a(x→b))
FVk(a!)

FV(a)

parameters(λa)

=
=
=
=

if i = k then {(x, i)} else {}
{(x, i) | (x, i+1) ∈ FVk+1(a)}
FVk(a) ∪ FVk(b) 
FVk(a) 

FVk(a)

= ∪
k ≥ 0 
FV0(a)

=

a closed

⇔ FV(a) = {}

Figure 6.2   Free and bound variables .

with name x in a”, or, expressed differently: “substitute b for every occurrence of (x, 0) in
a (modulo index renumbering, as deﬁned below)”. The parameters of an abstraction may
be bound separately, and in any order.

A close operation closes a sequence of bindings, and removes an abstraction level (re-

moves one ‘λ’).

Notions of parameters, free and bound variables are as in the de Bruijn calculus; a for-

mal deﬁnition is given in ﬁgure 6.2.

6.2.2 Reduction Rules

In the de Bruijn calculus, β-reduction involves some renumbering of indices: whenever
the number of ‘λ’s above a subterm changes, its free variables have to be adapted in con-
sequence. One way to express it is 

(λa) b  →β ↓0[a [0 := ↑0[b]]

where ‘↑’ (lift) is an operation incrementing all free variables by 1, ‘↓’ (unlift) is the re-
verse operation, and a[i := b] is the substitution of b for all occurrences of i in a (again
modulo index renumbering). 

The reduction rules for λN, given in ﬁgure 6.3, are very similar, since they also involve
index manipulation operations. There are two kinds of reductions, called bind reduction
(β) and close reduction (γ). Basically, the operations performed by β-reduction in the
standard lambda calculus have been split in two: binding reductions substitute values for
variables, and close reductions “remove the lambda” and unlift the result, i.e. they remove
an abstraction level. The deﬁnitions for lifting and substitution operations are given in ﬁg-
ure 6.4

A Lambda Calculus with Named Parameters

159

(λa)(x→b)  →β λ(a[(x, 0) : = ↑0[b]])
(λa)! 

→γ ↓0[a]

Figure 6.3   Reduction rules.

Lifting/Unlifting 
↑k[(x, i)]
↓k[(x, i)]
k [λa]
k [a(x→b)]
k [a!]

= 
= 

= 
=
=

if (i < k) then (x, i) else (x, i+1)
if (i < k) then (x, i) else if (i=k) then err else (x, i-1)
λ (k+1 [a])
k [a](x→k [b])
(k [a])!

where ‘’ is either ‘↓’ or ‘↑’

err =def

E(x→E)!

Substitution
(y, j)[(x, i) := b]
(λa) [(x, i) := b]
(a(y→c)) [(x, i) := b]
(a!)[(x, i) := b]

where E = λλ (x, 1)(x→(x, 1))!

=
=
=
=

if ((x, i) = (y,j)) then b else (y, j)
λ(a[(x, i+1) := ↑0[b]])
(a[(x, i) := b])(y→c[(x, i) := b])
(a[(x, i) := b])!

Figure 6.4   Lifting and substitution operations.

Careful readers will have noticed that in λN we may need to unlift a 0 index, a situation
which never occurs in the de Bruijn calculus. Consider de Bruijn’s β-reduction rule above:
all 0 indices are substituted in a, so the expression passed to ‘↓’ contains no 0 index. By
contrast, the λN expression (λ (x, 0))! reduces to ↓0[ (x, 0) ], which intuitively corresponds
to an error (we are trying to access a parameter that has not been bound). As a matter of
fact, in such situations the deﬁnition of ‘↓’ yields err, a speciﬁc term representing errors.
This will be discussed in detail in section 6.4; for the time being it sufﬁces to know that err
is not an additional syntactic construct, but rather is deﬁned as a usual term in the lan-
guage, with the property that further binding or close operations on err yield err again.

A binding reduction can never introduce new parameters in an abstraction, because the
term passed in the substitution is lifted. Therefore if several successive bindings are done,
the ﬁnal result does not depend on the order of the substitutions. This amounts to say that
bindings are commutative, i.e. expressions of the form

 a(x→b)(y→c) and 

a(y→c)(x→b)

derive to the same thing, provided that x and y are different names. If x and y are the same

160

Functions, Records and Compatibility in the λN Calculus

name, all references to that name are substituted in the ﬁrst binding, so the second binding
is just ignored, and those bindings are not commutative.

6.2.3 Reduction Example

For illustrating the rules, we use again the expression Not(b→True)!. The derivation was
given in an informal way in the introduction, using high-level syntax (without indices).
Here, the low-level syntax is used; at each step, the lambda and the bind or close operation
involved in the next reduction step are underlined. 

1
2
3
4
5
6

(λλ (arg, 1) (true→(false, 0))(false→(true, 0))!)(arg→λ(true, 0))!
(λλ (λ(true, 0))(true→(false, 0))(false→(true, 0))!) ! 
λ (λ(true, 0))(true→(false, 0))(false→(true, 0))!
λ (λ(false, 1))(false→(true, 0))!
λ (λ(false, 1)) ! 
λ (false, 0)

The ﬁnal result is False. Notice at line 4 that the binding of false simply gets eliminated:
this is because the abstraction (λ(false, 1)) has no parameter called false; it indeed uses a
variable with that name, but since the index is not 0 this is a free variable, not a parameter.
 At some intermediate stages (e.g. at line 2) several reductions could occur; the se-
quence shown here corresponds to normal-order reduction (choosing leftmost outermost
redex first). It is therefore legitimate to ask whether a different reduction sequence would
yield the same result (whether the language is confluent). The answer is yes, and has been
established in [13]. So, as in the standard lambda calculus, results are independent from
the reduction sequences through which they were obtained; furthermore, if an expression
does have a result, then the normal-order reduction strategy is guaranteed to yield that re-
sult (i.e. not to diverge). 

Notice that if we “forget” to supply an argument to Not before applying a close opera-

tion, as in Not!, we have the reduction

(λλ (arg, 1) (true→(false, 0))(false→(true, 0))!) ! 
λ err (true→(false, 0))(false→(true, 0))!
λ err (false→(true, 0))!
λ err ! 
λ err

which is equivalent to err, i.e. an error is produced. 

6.2.4 Higher-level Syntax

Indices were necessary for deﬁning the calculus, but are difﬁcult to read. In order to work
practically with the calculus, we will use a higher-level syntax, given in ﬁgure 6.5, in
which the indices need not be explicitly written. There is a straightforward translation T
from this syntax into the original syntax, which is formally deﬁned in ﬁgure 6.6. In this

A Lambda Calculus with Named Parameters

161

v

a

:=
|

:=
|
|
|

x 
 \v
λ(x1 … xn) a
v
a(x→b)
a!

simple variable
“outer” variable

abstraction
variable
bind operation
close operation

Figure 6.5   Higher-level syntax.

λ (TV' [a])

V' ={(x, i+1) |  (x, i) ∈ V} ∪ {(x1, 0), ..., (xn, 0)}
where i is the number of ‘\’

TV [λ(x1 … xn) a]  = 
where

TV [\...\x ]
TV [a(x→b)]
TV [a!]
matchVar V (x, i)

=  matchVar V  (x, i) 
TV [a](x→ TV [b])
= 
= 
(TV [a])!
let J={j | (x, j) ∈ V, j ≥ i} in
= 
then err
else (x, min(J))

if (J = {})

Figure 6.6   Translation function.

new notation, the parameters of an abstraction are declared as a list of names in parenthe-
sis. A variable is written simply as a name: the index is recovered by looking for the closest
abstraction which declares the same name. In case the same name is used at several ab-
straction levels, and one wants to override the default variable matching scheme, the name
of the variable can be preceded by a collection of backslashes. This tells the translation
function to start looking for a declaration, not at the next abstraction level, but one or sev-
eral levels higher (according to the number of backslashes). The parameter list following
a lambda can be empty, as in

λ() Not(arg→True)!

This is like a closure, i.e. a function that needs no arguments but is not evaluated yet (as-
suming a lazy interpretation as in section 6.4.1). Forcing evaluation is then done with the
‘!’ operator.

The translation T from this syntax into the original syntax is like translating the standard
lambda calculus into de Bruijn notation (see [12]). The ﬁrst argument to the translation
function is a set of currently declared variables; at each abstraction level this set is updat-
ed. The translation is deﬁned for closed terms by taking the initially empty set of variables.
Variables which are not declared at any level are translated into an error by the matchVar
function. As an example of a translation, consider the expression

162

Functions, Records and Compatibility in the λN Calculus

λ(x y) λ(x z) x + y + z + \x + \y + \z + \\x

(assuming that inﬁx addition is part of the language). After crossing the two abstraction
levels, the set V of declared variables is

V={(x, 1), (y, 1), (x, 0), (z, 0)}
and therefore the translation is

λλ (x, 0) + (y, 1) + (z, 0) + (x, 1) + (y, 1) + err + err

This shows how the backslash can be used to distinguish between parameters with the
same name, but at different levels. Notice that x and \x are different variables, while both
y and \y are translated into (y, 1), because there is no y parameter at the inner abstraction
level. Furthermore, both \z and \\x are translated into err, because no corresponding varia-
ble declaration can be found.

6.3

The Calculus at Work

In this section we show how several common programming constructs are encoded in λN.
To make the examples more appealing, we assume that integers, Booleans and strings
have been added to the language, with corresponding operations (integer arithmetic, if ex-
pression, etc.). Such extensions are common for the lambda calculus and can be shown to
be conservative, i.e. expressions in the extended language are always convertible into the
original language. As a matter of fact, an encoding of Booleans has been seen already, and
an encoding of integers is given in section 6.3.4. In consequence, the semantics of the lan-
guage does not change. We start with a discussion on functions and recursion, just to give
a clearer map of the relationship between λN and the standard lambda calculus. Then the
speciﬁcity of λN, namely the encoding of extensible constructs, is demonstrated through
enumerated types, concrete data types and records.

6.3.1 Functions

It can be seen easily that λN contains the usual lambda calculus. Any expression e of the
pure lambda calculus can be encoded in a straightforward way, by choosing a single arbi-
trary name (say arg) to be associated with variables:

• Take the de Bruijn encoding of e.
• Replace every application MN by M(arg→N)!, i.e. a binding of arg immediately fol-

lowed by a close operation.

• Replace every variable i by (arg, i).

For example, the lambda expression λf x y. f(x + y) has de Bruijn encoding λλλ 2(1+0) and
becomes here

λλλ(arg, 2)(arg→(arg, 1)+(arg, 0))!

which corresponds to 

The Calculus at Work

163

λ(arg) λ(arg) λ(arg) \\arg(arg→\arg+arg)!

in the higher-level notation. Now how does this compare to the expression:

λ(f x y) f(arg→(x+y))!

which intuitively seems more natural? In both formulations, the arguments can be bound
and the ﬁnal result evaluated. The difference appears with partial bindings. When argu-
ments are declared at the same abstraction level, as we do in the second formulation, they
can be bound separately, in any order, and even if all arguments are supplied, the internal
expression is not evaluated until a close operation takes place. This can be useful, as we
will see later, for building lazy data structures. Furthermore, such functions are poly-
morphic, in the sense that any context which binds more arguments than just f, x and y will
accept this abstraction without generating an error. However, if we want to do partial bind-
ings, leaving the other arguments open, the close operation cannot be inserted, which im-
plies that we lose the currying property, i.e. the possibility to bind one single argument and
get in return another function over the remaining arguments. This is because usual func-
tional application corresponds here to a binding and a close operation. When writing a
function, there is therefore a choice to make about how to organize its arguments. The
methodological issues involved in such choices have not been explored yet. Our choices
in the coming examples are guided by some heuristics acquired during our various ex-
periences in using the system.

6.3.2 Recursion

A ﬁxed-point operation over a functional λ(x)a yields a recursive function, as in the lamb-
da calculus; however, the name x must be taken into account in the ﬁxed-point operation.
So for each name x we deﬁne a corresponding ﬁxed-point operator
λ(x) (λ(x) \x(x→x(x→x)!)!)(x→ (λ(x) \x(x→x(x→x)!)!))!

=

Yx

This is like the usual combinator Y, specialized to bind name x. It can be checked that for
f=λ(x)a we have

Yx(x→f)! →*

f(x→Yx(x→f)!)!

In order to facilitate such recursive deﬁnitions we introduce some syntactic sugar: an

expression with recursion over parameter x is written µ(x)a and is translated into

Yx(x→λ(x)a)!

With this extension we can write

 Factorial =

µ(f) λ(arg) if (arg > 1) then arg*f(arg→(arg-1))! else 1

6.3.3 Extensible Enumerated Types and Case Selection

We already have seen an encoding of Boolean values, which is a simple enumerated type
with two values. The approach can be generalized to n-ary enumerated types:

164

Functions, Records and Compatibility in the λN Calculus

Green
Orange
Red

=
=
=

λ(green) green
λ(orange) orange
λ(red) red

Each colour in the encoding above is a kind of identity function on a particular name. The
way to use such values is to perform case selection:

trafﬁcLight

=

λ(colour) colour(green→Go)(orange→Stop)(red→Stop)!

Here we assume two deﬁned driving actions Go and Stop. Depending on the colour, the
appropriate driving action is chosen. Observe that case selection is just a sequence of bind-
ings. The set of colours can be extended easily:

Blue
Violet
Yellow
complement = λ(colour) colour(green→Red)(blue→Orange)(violet→Yellow)

λ(blue) blue
λ(violet) violet
λ(yellow) yellow

=
=
=

(red→Green)(orange→Blue)(yellow→Violet)!

so the ﬁrst three colours are “reused” here in a different context, without breaking the orig-
inal encoding of trafﬁcLight. As explained in the introduction, this can not be done in the
standard lambda calculus.

6.3.4 Extensible Concrete Data Types

A direct extension from previous section is the encoding of concrete data types. Concrete
data types are built through a ﬁnite number of constructors, which can take arguments.
Functions using such data types then have to perform case selection over the constructors.
We will consider the example of natural numbers, with two constructors:

Zero 
Succ

=
=

λ(zero) zero
λ(n) λ(positive) positive(pred→n)!

The names zero and positive are used to distinguish constructors. Case selection is done as
with enumerated types, except that constructors with arguments must be able to pass the
corresponding values to the function using the data type, so there must be a convention be-
tween the constructor and its users about which name to use for that purpose. In the case
of Succ, the conventional name is pred. An example of using the data type is the addition
function:
Add

µ(add) λ(left right) left

=

(zero→right)
(positive→λ(pred) add(left→pred)(right→Succ(n→right)!)!)!

which proceeds by decomposition of the left argument.

The encoding can be extended easily to include negative numbers as well:

Pred= λ(n) λ(negative) negative(succ→n)!
Inc=  λ(n) n(zero→Succ(n→n)!)(positive→Succ(n→n)!)(negative→λ(succ)succ)!
Dec= λ(n) n(zero→Pred(n→n)!)(positive→λ(pred)pred)(negative→Pred(n→n)!)!

The Calculus at Work

165

Add= µ(add) λ(left right)     left(zero→right)

(positive→λ(pred) add(left→pred)(right→Inc(n→right)!)!)
(negative→λ(succ) add(left→succ)(right→Dec(n→right)!)!)!

Again, functions using only positive numbers need not be recoded because of that exten-
sion.

Generally speaking, the encoding of data types given here is pretty low-level. However,
syntactic sugar for data type constructors and pattern matching, as in most modern func-
tional languages, could be added easily. 

6.3.5 Records 

A more interesting example of extensibility and polymorphism is the encoding of records.
We extend the syntax with a record constructor and a ﬁeld selection operation; the trans-
lation of these constructs is given in ﬁgure 6.7. The translation can be understood more

T [{x1=a1 … xn=an}]
T [a.x]

=
=

λ(sel) sel(x1→↑0[a1])…(xn→↑0[an])!
a(sel→λ(x)x)!

Figure 6.7   Records

easily through a comparison with the encoding of binary products (pairs) in the standard
lambda calculus:

(a, b) =
fst =
snd =

 λsel. sel a b
 λpair. pair (λﬁrst. λsecond. ﬁrst)
 λpair. pair (λﬁrst. λsecond. second)

The encoding of a pair is a function which takes a selector and then binds both members
of the pair to that selector. A selector is just a function taking two arguments and returning
one of them, so the fst projection function applies a selector which extracts the ﬁrst argu-
ment, while the snd function applies a selector which extracts the second argument. Sim-
ilarly,  a  record  in  λN  is  a  function  which  takes  a  selector,  and  binds  all  ﬁelds  to
corresponding named parameters in that selector. Since one abstraction level was added
because of the sel argument, all internal ﬁelds are lifted in order to protect free variables
from being captured. A selector for ﬁeld x is just an identity function on that name, so a
ﬁeld selection operation simply binds the appropriate selector to the sel argument of the
record. Here are some examples:

{x=5}
{x=3 y=2}
{x=5}.x 
{x=3 y=2}.x
{x=3 y=2}.z

=
= 
=
=
=

λ(sel) sel(x→5)!
λ(sel) sel(x→3)(y→2)!
(λ(sel) sel(x→5)!)(sel→(λ(x)x))!
→*  5
(λ(sel) sel(x→3)(y→2)!)(sel→(λ(x)x))!→*  3
(λ(sel) sel(x→3)(y→2)!)(sel→(λ(z)z))!→*  (λ(z)z)! → err

166

Functions, Records and Compatibility in the λN Calculus

T [〈x1 … xn〉] =

µ(rec)λ(x1 … xn) {

get={x1=x1 … xn=xn}
set={x1= λ(arg) rec(x1→arg)(x2→x2)…(xn→xn)!
…
xi= λ(arg) rec(x1→x1)…(xi→arg)…(xn→xn)!
…
xn= λ(arg) rec(x1→x1)…(xi→xi)…(xn→arg)!
}
(T [〈x1 … xn〉])(x1→a1)…(xn→an)!

}
=

T [〈x1=a1 … xn=an〉]
T [a〈x := b〉]

=

a.set.x(arg→b)!

Figure 6.8   Updatable records.

We see that “.x” is a polymorphic operation that can be applied to any record containing at
least an x ﬁeld. 

The same encoding can support more general operations on records, like a form of “ex-
ecute in context” operation, similar to quoted expressions in LISP or to the blocks of
Smalltalk: for example an expression like

r.[x + y +z]

= 

r(sel→λ(x y z)x + y + z)!

asks record r to add its ﬁelds x, y and z and return the result.
Moreover recursion can be used to get recursive records:

Seasons= µ(rec) 

{name=”spring”

spring=
summer= {name=”summer”
autumn= {name=”autumn”
winter=

{name=”winter”

next= rec.summer}
next= rec.autumn}
next= rec.winter}
next= rec.spring}

{

}

so for example Seasons.autumn.next.next.name yields “spring”. Seasons can be seen as a
recursive record, but also as a memory with four locations. Expressions like rec.summer
work as “pointers” in the memory ﬁxed by Seasons. Here we have a ﬂat space of memory
locations, but the approach can be easily extended to deﬁne hierarchical memory spaces
with corresponding ﬁxed-point operations at different levels. Pointers in the hierarchical
space simply would use variables with different indices (using the ‘\’ syntax). 

6.3.6 Updatable Records (Memories)

The next step is to deﬁne updatable records, or, seen differently, writable memories. This
can be done using the previous constructs, as pictured in ﬁgure 6.8. An updatable record is
a recursive function, with one named parameter for each ﬁeld; internally it consists of a
simple record with a get ﬁeld, which returns the internal values, and a set ﬁeld, which re-

Compatibility Relationship

167

turns a record of update functions. An update function for ﬁeld xi takes one argument arg,
and uses recursion to return the same updatable record, in which all ﬁelds are bound to
their current values except the one being updated which takes the new value. Updating a
record consists of selecting the appropriate update function, and binding the new value to
its arg parameter. Functions using this encoding are naturally polymorphic: the function

ZeroX

=

λ(aRecord) aRecord〈x := 0〉

can be applied to any record containing an x ﬁeld and returns the original record, with only
ﬁeld x being updated. 

Updatable records give full ﬂexibility for modelling local state of objects and object
identiﬁers. In languages using a ﬂat domain of object identiﬁers, like Smalltalk or Objec-
tive-C, each object would have its own updatable record, representing local state, and then
all objects would be stored in a global record, representing the space of object identiﬁers.
Some other languages have a more complex structure: for example in C++, an object can
be contained in the memory space of another object (so the implementation structure re-
ﬂects the “has-a” relationship). Modelling such structures in λN would involve hierarchi-
cal updatable records, in which some ﬁelds contain sub-records.

6.3.7 Field Overwriting

The encoding presented in the previous subsection supports modiﬁcation of an existing
ﬁeld, but not addition of new ﬁelds. An alternative approach to updatable records is to con-
sider ﬁeld overwriting. Here is how it can be done:

r[x←a]

=

λ(sel) r(sel→sel(x→a))!

This creates a new record from r in which ﬁeld x has value a, whether or not x was already
present in r. Observe that the encoding is based on the fact that the selector received as a
parameter is immediately bound to a on name x, without a close operation, before being
passed to the record r. This explains why any binding on x in r will be ignored. Given a
ﬁeld overwriting operation, it is possible to implement record concatenation “for free”,
following Rémy’s technique [26]: one would start with an empty record

λ(sel) sel!

and then consider each record as a “record-modifying function”, adding the desired ﬁelds;
such functions can be combined by functional composition. 

6.4 Compatibility Relationship

Several examples of extensible and reusable constructs have been shown, but so far we
have no formal deﬁnition of a compatibility relationship. In this section such a relation-
ship is studied, through an observational classiﬁcation of λΝ expressions. In the standard
lambda calculus, the only observable property of terms is their termination behaviour:

168

Functions, Records and Compatibility in the λN Calculus

λa ⇓ λa @ 0

a(x→b) ⇓ λ(a' [(x, 0) := ↑0[b]]) @ m+1

a ⇓ λa' @ m

a ⇓ λb@ m

↓0[b] ⇓ c @ n

a! ⇓ c @ m+n+1

Figure 6.9   Convergence to weak normal form.

errors never occur, since all values are functions. Here, we have seen that errors can be
generated during a computation, and therefore errors also represent a valuable observa-
tion. So, as a complement to the usual approximation ordering, which compares terms on
the basis of convergence, we also consider a compatibility ordering, comparing terms on
the basis of error generation. This section is mainly inspired from operational orderings in
Scott Smith’s work [28], who himself draws from a vast body of literature on observation-
al relations (see for example [20][1]). However, Smith identiﬁes errors with divergence,
whereas we treat them as distinct observations.

6.4.1 Errors and Lazy Operational Semantics

Now it is time to justify our encoding of errors, as it was given in ﬁgure 6.4. The complex
expression deﬁning err could be written, in high-level notation, as µ(x) λ() x, i.e. as an
abstraction  without  any  parameters,  containing  itself.  Such  a  term  can  consume  any
sequence of bind or close operations, but always reduces back to itself. In a classical
lambda calculus, a similar behaviour is displayed by the term

(λx.λy.xx)(λx.λy.xx)

which consumes any input without ever using it. Under a usual interpretation, this is just
identiﬁed with the bottom element (divergence); however, in a lazy interpretation, it be-
comes the top element. Boudol [7] calls this an “ogre”, while Abramsky and Ong [1] say
“a term of order ∞”. Usually the “ogre” is not considered very interesting, because it does
not interact with its environment. However, this is precisely the behaviour of a run-time er-
ror: once it occurs, the “continuation” of the program is ignored, and the ﬁnal result is the
error. So the ogre is a natural choice for representing run-time errors. In consequence, we
deﬁne in ﬁgure 6.9 a lazy convergence relation, where a⇓b @ m means “a converges to b
in m steps of computation”. We simply write a⇓ if there are a', m such that a ⇓ a' @ m, and
a⇑ if ¬(a⇓). 

Compatibility Relationship

169

Definition 14  A term a is erroneous (written a?) iff it converges and any binding or

close operation on it yields an erroneous term again. Formally:

a?

⇔ a⇓ and (a!)? and ∀b. (a(x→b))?

Another way to state this is to say that a is erroneous iff ∀o, ao⇓, where o is a
sequence of bind or close operations. We write a¿ whenever ¬(a?). It is an easy
exercise to check that (err?).

6.4.2 Approximation and Compatibility

Definition 15  The approximation ordering, written ≤⊥, is

a ≤⊥ b

⇔  ∀C[–]. C[a]⇓ ⇒ C[b]⇓ 

where a context C[–] is a term with “holes”, which can be ﬁlled by another term a
through the context-ﬁlling operation C[a].

Definition 16  The compatibility ordering, written ≤err, is

a ≤err b

⇔  ∀C[–]. C[b]¿ ⇒ C[a]¿ 

Observe that here a and b are in reverse order in the implication. The ﬁrst preorder
states that whenever a converges, b also converges. The second preorder states that
whenever b does not generate an error, a does not either. It may seem strange that
these deﬁnitions are in opposite directions, but this corresponds to standard practice
in semantic domains and subtype orderings. In semantic domains, the least deﬁned
element (representing the divergent program) is at the bottom, and more deﬁned
elements are higher up in the ordering. In type systems, the least deﬁned type (type
of anything) is usually at the top, and more reﬁned types are lower. It can be checked,
for example, that NotU ≤err Not , i.e. our extended version of the not operation for a
three-valued logic, is indeed compatible with the not operation on Boolean values
only.

In [14] we have deﬁned similar orderings for a pure lambda calculus with records (but
without extensible records), and we have shown that both orderings coincide, i.e. approxi-
ma and compatibility are the same when err is chosen as the top element. The proof can be
transposed to λN without difﬁculty. So we have a formal framework for reasoning not only
about equivalence of software components, as in usual semantics, but also about their
plug-compatibility relationships. Some consequences of this result are discussed in the
rest of this section.

170

Functions, Records and Compatibility in the λN Calculus

6.4.3 Lattice Structure

Deﬁne  ⊥ = µ(x) x. This is the divergent term [observe the difference with err = µ(x) λ() x].
⊥ is smaller than any term: a divergent term never generates an error, and never reduces to
a WNF in any relevant context. On the other hand, err is a greatest element in both order-
ings, since it never diverges and is an error. This implies that the order is a lattice with top
element err and bottom element ⊥.

The fact that we get a lattice is interesting in many respects. Lattices were originally
considered by Scott for solving domain equations. Then the presence of a top element was
criticized, in particular by Plotkin [25], because this element fails to satisfy some intuitive-
ly natural identities about the conditional function: for example we expect a phrase like 

if a then b else c

always to give either b or c; however, this does not hold when a is the top element, and it is
not clear then what the answer should be: it could be TOP itself, or it could be the upper
bound of b and c, but none of these solutions seems to make sense in usual interpretations.
Therefore the semantics community moved to algebraic CPO models instead of lattices. 
Since our approach is purely operational, there is no reason here to argue for or against
a particular model. Nevertheless, it is worth noticing that the operational lattice has some
natural properties. In particular, interpreting the top element as an error, it is quite natural
that we should have

 if err then b else c = err

The answer is neither b nor c, but this does not contradict our intuitive understanding of
the conditional statement: if the ﬁrst argument is an error, then the whole statement pro-
duces an error.

A more recent discussion about lattice models was written by Bloom [6], partially
based on Plotkin’s previous work. Bloom supports the view that, despite the fact that lat-
tices are mathematically more tractable than CPOs, they have several defects when used
as models for programming languages. One of his main criticisms to lattice models is that
they are not single-valued: for example if we choose the second solution for the condition-
al statement above, namely

if TOP then b else c = b 

 c

we get the upper bound of b and c, which, if not TOP itself, is a “multiple value”. However,
the justiﬁcation for taking single-valuedness as an essential criterion is not strongly estab-
lished. Therefore Boudol [7] criticizes Bloom’s position, and argues that under a different
notion of observation, multiple values make perfect sense. Parallel functions in Boudol’s
paper yield a lattice model. Similarly, powerdomains used for modelling concurrency also
have a lattice structure. These observations lead us to another extension of the calculus
which completes the operational structure by introducing all meets and joins. Full devel-
opment of these constructs would go beyond the scope of this paper; however, a brief ap-
petizer will be given.

Compatibility Relationship

171

  Syntax

a

:=

  Convergence

...
&(a1 … an)
|(a1 … an)

|
|
|

combination
alternation

∃ai. ai ⇓ b @ m

|(a1 … an)⇓ |(a1  … ai-1  b  ai+1…an)@m+1 

∀ai. ai ⇓ bi @ mi

&(a1 … an)⇓ &(b1  … bn)@(m1+ … mn + 1)

θ(a1(x→b) … an(x→b))⇓ a' @ m
θ(a1 … an)(x→b)⇓ a' @ m+1

θ(a1!… an!)⇓ a' @ m
θ(a1 … an)!⇓ a' @ m+1

where θ is either ‘|’ or ‘&’

Figure 6.10   Combinations and alternations.

6.4.4 Meets and Joins

Figure  6.10  introduces  two  n-ary  constructs  called  combination  and  alternation. The
reduction rules are exactly the same for both: any binding or close operation is simply
distributed to the internal members. Therefore they can be seen as an array of non-commu-
nicating processors accepting common operations, in a kind of SIMD architecture. The
difference between combinations and alternations comes observationally from the deﬁni-
tion of convergence: combinations converge if all their members converge, while alterna-
tions converge if at least one member converges. Since convergence is at the foundation of
our approximation/compatibility relationship, we have the following properties:

• The combination is a glb (greatest lower bound, meet) operator.
• The alternation is a lub (least upper bound, join) operator.

This  has  many  interesting  applications,  all  related  to  various  possible  uses  of sets  of
values. 

The alternation operator can be interpreted to model non-determinism. A very similar
proposal has been made by Boudol under the name parallel functions [7]. Boudol mainly
discusses the use of parallel functions for solving the full abstraction problem (relating the

172

Functions, Records and Compatibility in the λN Calculus

operational  ordering  with  the  semantic  ordering). Another  application  is  concurrency
modelling, where all possible outcomes of a computation are grouped together in an alter-
nation, on which further processes can compute: in [13] we discuss an encoding of shared
memory, processes and synchronization primitives using alternations. Yet another possi-
bility is to interpret an alternation as a type, “containing” all its member terms. This opens
very interesting perspectives for typing, since the notions of type membership and subtype
relationship are both captured by the approximation/compatibility ordering, and therefore
values and types are merged into one single concept. Finally, since we deal with sets of
values we can directly apply Scott Smith’s results [28] for proving theorems like ﬁxed-
point induction in a purely operational setting, without going to semantic domains. 

Applications of the combination construct, which in a sense is an “overdeterministic”
operator, are less intuitive. Remembering that err is the top element, combinations can be
used to remove errors in a computation, by taking the lower bound of a set of values. This
can be applied for operations such as record concatenation [10][17]. Moreover, following
the idea of unifying types and values, combinations have the same properties as inter-
section types[4][24]. Interestingly, a connection between record concatenation and inter-
section types as also been proposed by John Reynolds in his Forsythe language[27].

6.5 Conclusion

A lambda calculus with name-based interaction has been described. A few systems using
similar ideas have been mentioned in the introduction [19][16]; the original aspect of  λN
is the uniﬁcation of names with variables through the use of de Bruijn indices. Not only is
this more practical; it also allows us to directly import most of the results established for
the standard lambda calculus. Extensible functions in λN are a good basis for studying
reusability mechanisms (in particular inheritance and subtyping), and the economy of
constructs compares advantageously to other approaches based on records ([9][17]) or ex-
tensible methods [23]. 

The  other  extension  (alternations  and  combinations)  is  perhaps  more  venturing.  It
touches several hot research areas, like observational equivalences and full abstraction for
lambda models [1], parallel functions [7], extensible records [17], and semantics of con-
currency. Most of these issues require further investigation. An exciting challenge is to see
how the π-calculus[21], also based on names, relates to λN.

The issue of typing was mentioned very brieﬂy, and the development of a full type the-
ory for the calculus is under investigation [13][15]. Using the term ordering as a semantic
basis for types seems a promising direction, and has some similarities with type theories
based on the Curry–Howard isomorphism (identiﬁcation of types with logical proposi-
tions)[29],  in  which  the  usual  distinction  between  terms  and  types  is  also  blurred.
Including name-based interaction in such theories would be a promising step towards an
object-oriented logic, and would relate to what Aït-Kaci calls features [2]. Related to this,
the term ordering in  λN can be useful for object-oriented databases, since it gives a query
language for free! 

References

173

Apart from those foundational issues, there are several practical directions in which this
work can be extended. One, which in fact was the original motivation for developing the
calculus, is to use it for explaining the differences between various forms of inheritance
and delegation in object-oriented languages. In addition, many other aspects of program-
ming languages, like modularity, state manipulation or restricted islands of memory loca-
tions [18] can be studied in this framework. Ultimately, it is of course tempting to build
higher-level syntactic constructs on top of the calculus and make it a full programming
language integrating these various aspects. 

Finally, it is worth considering implementation issues for this calculus, and perhaps to
design a name-based abstract functional machine. As noted by Garrigue [16], names can
be translated into offsets in a machine implementation; however, their combination with
de Bruijn indices probably raises some technical problems. Combinations and alterna-
tions are more challenging. Evaluating a combination can be done by sequentially evalu-
ating all of its members, but evaluating an alternation must be done in some form of
parallelism, to be consistent with our notion of WNF.

Acknowledgments

I am grateful to Oscar Nierstrasz, who gave much of his time for examining this work, to
Benjamin Pierce, Christian Breiteneder, John Lamping, and Jacques Garrigue, who com-
mented earlier versions, and to Patrick Varone, who read this version carefully and helped
to correct several points.

References

[1]

Samson Abramsky and C.-H. L. Ong, “Full Abstraction in the Lazy Lambda Calcul,” Information and
Computation, vol. 105, 1993, pp. 159–267.

[2] Hassan Aït-Kaci and Andreas Podelski, “Towards a Meaning of LIFE,” Proceedings PLILP '91, Lec-

ture Notes in Computer Science, vol. 528, Springer-Verlag, 1991, pp. 255–274.

[3] Hassan Aït-Kaci and Jacques Garrigue, “Label-Selective λ-Calculus, Syntax and Confluence,” Pro-
ceedings 13th International Conference on Foundations of Software Technology and Theoretical 
Computer Science, Lecture Notes in Computer Science, vol. 761, Springer-Verlag, 1993, pp. 24–40.

[4]

Franco Barbanera and Mariangiola Dezani-Ciancaglini, “Intersection and Union Types,” Proceed-
ings Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science,
vol. 526, Springer-Verlag, 1991, pp. 651–674.

[5] H. P. Barendregt, The Lambda Calculus, its Syntax and Semantics, vol. 103 of Studies in Logic and the

Foundations of Mathematics, North-Holland, 1985 (2nd printing).

[6] Bard Bloom, “Can LCF Be Topped? Flat Lattice Models of Typed λ-Calculus,” Information and

Computation, vol. 87, 1990, pp. 264–301.

[7] Gérard Boudol, “Lambda-Calculi for (Strict) Parallel Functions,” Information and Computation, vol.

108, 1994, pp. 51–127.

174

Functions, Records and Compatibility in the λN Calculus

[8] N. de Bruijn, “Lambda-Calculus Notation with Nameless Dummies, a Tool for Automatic Formula

[9]

Manipulation,” Indag. Mat., vol. 34, 1972, pp. 381–392.
Luca Cardelli, “A Semantics of Multiple Inheritance,” Information and Computation, vol. 76, 1988,
pp. 138–164.

[10] Luca Cardelli and John C. Mitchell, “Operations on Records,” Proceedings Conference on Mathemat-
ical Foundations of Programming Semantics, Lecture Notes in Computer Science, vol. 442, Springer-
Verlag, 1989, pp. 22–52.

[11] Thierry Coquand and Gérard Huet, “The Calculus of Constructions,” Information and Computation,

vol. 76, 1988, pp. 95–120.

[12] Pierre-Louis Curien, Categorical Combinators, Sequential Algorithms, and Functional Program-

ming, 2nd edn., Birkhäuser, Boston, 1993.

[13] Laurent Dami, “Software Composition: Towards and Integration of Functional and Object-Oriented

Approaches,” Ph.D. Thesis, University of Geneva, 1994.

[14] Laurent Dami, “Pure Lambda Calculus with Records: from Compatibility to Subtyping,” working pa-
[15] Laurent Dami, “Type Inference for λN, and Principal Type Schemes for Record Concatenation,”

per, 1994.

working paper, 1994. 

[16] Jacques Garrigue and Hassan Aït-Kaci, “The Typed Polymorphic Label-Selective λ-Calculus,” 
Proceedings 21st ACM Symposium on Principles of Programming Languages, 1994, pp. 35–47.

[17] Robert Harper and Benjamin Pierce, “A Record Calculus Based on Symmetric Concatenation,” Pro-
ceedings 18th ACM Symposium on Principles of Programming Languages, ACM Press, 1990, pp.
131–142.

[18] John Hogg, “Islands: Aliasing Protection In Object-Oriented Languages,” Proceedings OOPSLA ’91,

ACM SIGPLAN Notices, vol. 26, no. 11, Nov. 1991, pp. 271–285.

ACM Conference on Lisp and Functional Programming, 1988, pp. 316–326.

[19] John Lamping, “A Uniﬁed System of Parameterization for Programming Languages,” Proceedings
[20] Robin Milner, “Fully Abstract Models of Typed λ-Calculi,” Theoretical Computer Science, vol. 4,
[21] Robin Milner, “The Polyadic π-Calculus: A Tutorial,” Tech. Report ECS-LFCS-91-180, University

1977, pp. 1–22.

of Edinburgh, 1991.

[22] Robin Milner, “Elements of Interaction,” (Turing Award Lecture), Communications of the ACM, vol.

36, no. 1, Jan. 1993, pp. 78–89.

[23] John C. Mitchell, Furio Honsell, Kathleen Fisher, “A Lambda Calculus of Objects and Method Spe-

cialization,” Proceedings 8th Annual IEEE Symposium on Logic in Computer Science, 1993.

[24] Benjamin C. Pierce, “Intersection Types and Bounded Polymorphism,” Proceedings Conference on
Typed lambda-calculi and Applications,” Lecture Notes in Computer Science, vol. 664, Springer-Ver-
lag, March 1993, pp. 346–360.

[25] Gordon Plotkin, “Domains,” Course Notes, Department of Computer Science, University of Edin-

burgh, 1983.

[26] Didier Rémy, “Typing Record Concatenation for Free,” Proceedings ACM POPL’92, ACM Press,

1992, pp. 166–176.

[27] John C. Reynolds, “Preliminary Design of the Programming Language Forsythe,” Technical Report

CMU-CS-88-159, Carnegie-Mellon University, 1988.

[28] Scott F. Smith, “From Operational to Denotational Semantics,” Proceedings Conf on Mathematical
foundations of Programming Semantics, Lecture Notes in Computer Science, vol. 598, Springer-Ver-
lag, 1992, pp. 54–76.

[29] Simon Thompson, Type Theory and Functional Programming, International Computer Science Se-

ries, Addison-Wesley, Reading, Mass., 1991.

PART IV

Software Information 
Management

176

Chapter 7
Component Classiﬁcation
in the Software Information 
Base

Panos Constantopoulos and Martin Dörr

Abstract        A  key  component  in  a  reuse-oriented  software  development
environment  is  an  appropriate  software  repository.  We  present  a  repository
system which supports the entire software development lifecycle, providing for
the  integrated  and  consistent  representation,  organization,  storage,  and
management  of  reusable  artefacts.  The  system  can  support  multiple
development  and  representation  models  and  is  dynamically  adaptable  to
new  ones.  The  chapter  focuses  on  the  facilities  offered  by  the  system  for
component  classiﬁcation,  an  important  technique  for  retrieving  reusable
software. It is demonstrated that the inherently delicate and complex process
of classiﬁcation is streamlined and considerably facilitated by integrating it into
a  wider  documentation  environment  and,  especially,  by  connecting  it  with
software static analysis. The beneﬁts in terms of precision, consistency and ease
of use can be signiﬁcant for large scale applications.*

7.1

Introduction

Software reuse is a promising way of increasing productivity, assuring quality and meet-
ing deadlines in software development. There are several, non-exclusive approaches to re-
use, including organizational support, software libraries, object-oriented programming,
AI-based methods for design reuse and process analysis. 

* Work on the SIB was partly funded by the European Commission through ESPRIT project ITHACA. 
Partners in ITHACA were: Siemens-Nixdorf (Germany), University of Geneva (Switzerland), FORTH 
(Greece), Bull (France), TAO (Spain) and Datamont (Italy). 

Panos Constantopoulos and Martin Dörr, “Component Classification in the Software Information Base,” Object-Oriented Software 
Composition, O. Nierstrasz and D. Tsichritzis (Eds.), pp. 177-200, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

178

Component Classiﬁcation in the Software Information Base

A common theme in all these approaches is that reuse concerns not only software code,
but also design, requirements speciﬁcations and development processes. Supporting the
communication of all these aspects of software development between the original devel-
oper and the reuser, and, furthermore, the cooperation within communities of software de-
velopers (“software communities” [14]), is a basic concern of reuse technology. Software
repositories are key components in reuse-oriented software development environments
[9] supporting the organization and management of software and of related information,
as well as the selection and comprehension of relevant software and of development proc-
esses. In an orthogonal manner, object-oriented languages facilitate the development of
reusable software components through encapsulation, data abstraction, instantiation, in-
heritance, genericity and strong typing. For broad, comprehensive surveys of reuse the
reader is referred to [5] [18]. Krueger presents in [18] a taxonomy of reuse methods in
terms of their ability to abstract, select, specialize (adapt) and integrate software artefacts. 
In this chapter we assume that applications are developed using object-oriented tech-
nology, and that the software components of interest are mainly classes speciﬁed in an
object-oriented programming language. As pointed out in [14], the management of large
class collections introduces a number of problems concerning the representation of class-
es, in particular, the expression of structural and descriptive information, the representa-
tion of relationships and dependencies among classes in a collection, the selection and
understanding of classes by appropriate querying and browsing facilities, and the support
of class evolution. 

Small to medium size collections of software classes can be organized by fairly simple
schemes in the style of Smalltalk-80 [15]. Classes are hierarchically organized by inherit-
ance and are grouped by functionality into possibly overlapping categories. The class
browser allows the selection and exploration of reusable classes.

Various approaches have been proposed for addressing the selection problems arising
in large collections. One such is the faceted classiﬁcation scheme developed by Prieto-
Diaz  and  Freeman  [23].  In  this  scheme,  components  are  classiﬁed  according  to  six
descriptors (“facets”), the values of which are hierarchically organized and on which a
conceptual distance is deﬁned. A variant of the faceted classiﬁcation scheme, better suited
for object-oriented software, was developed within the ESPRIT REBOOT project [17].
Other approaches to organizing software collections include: library cataloguing [16];
hypertext (DIF, [13]); object-oriented libraries (Eiffel [20], Objective-C); ER and extend-
ed models (IBM Repository [19], Lassie of AT&T [11]); and hybrid approaches (e.g. SIB
[8]). 

The Software Information Base (SIB) is a repository system, developed within the ES-
PRIT ITHACA project, that stores information about the entire software lifecycle. The
SIB offers a uniform representation scheme for the various artefacts and concepts in-
volved in the different stages of the software lifecycle; the scheme can be extended to ac-
commodate new ones. It also supports multiple forms of presentation, depending on the
tool using the particular artefact. Finally, it provides querying, browsing and ﬁltering
mechanisms for selecting and understanding artefacts, and interfaces to other software de-
velopment tools. 

The Software Information Base

179

In this chapter we ﬁrst give an overview of the SIB and of its concepts in section 7.2. We
examine the querying and browsing capabilities of the SIB in section 7.3. The SIB’s clas-
siﬁcation scheme is described in section 7.4; section 7.5 explains how the classiﬁcation of
software artefacts is automated, whereas section 7.6 reports on our experiences with the
SIB. We conclude with perspectives for future work.

7.2

The Software Information Base

7.2.1 General Concepts

The SIB is structured as an attributed directed graph, with nodes and links respectively
representing  descriptions  of  software  artefacts  (objects)  and  relations  between  them.
There are three kinds of descriptions, namely:

requirements descriptions (RD);

implementation descriptions (ID).

1.
2. design descriptions (DD); and
3.
These descriptions provide three corresponding views of a software object: 
1. an application view, according to a requirements speciﬁcation model (e.g. SADT);
2. a system view, according to a design speciﬁcation model (e.g. DFD); and 
3. an implementation view, according to an implementation model (e.g. set of C++

classes along with documentation). 

Descriptions can be simple or composite, consisting of other descriptions. The term de-
scriptions reﬂects the fact that these entities only describe software objects. The objects
themselves reside outside the SIB (e.g. in a Unix ﬁle storing a C++ program), accessible
from the corresponding descriptions. 

There are several kinds of relationship between descriptions or parts of descriptions

serving a variety of purposes:

• Flexibility in deﬁning or modifying types of artefacts and relationships, or even de-
scription models, accomplished through multiple instantiation and a series of instan-
tiation levels.

• Classiﬁcation of artefacts and relationships in generalization/specialization hierar-

chies supporting multiple strict inheritance. 

• expression of semantic and structural relationships between artefacts, including ag-

gregation, correspondence, genericity and similarity. 

• expression of user-deﬁned and informal links — including links for hypertext navi-

gation, annotations, and for deﬁning version derivation graphs. 

• grouping of software artefacts descriptions into larger functional units. 

180

Component Classiﬁcation in the Software Information Base

An important concept in the SIB is the application frame (AF). Application frames rep-
resent complete systems or families of systems and comprise (hasPart) at least one imple-
mentation  and  optional  design  and  requirements  descriptions.  AFs  are  further
distinguished into speciﬁc and generic (SAFs and GAFs) while the RDs, DDs and IDs of
an AF should be considered as groupings of such descriptions (i.e. other associations). 

A SAF describes a complete system (be it a linear programming package, a text proces-
sor or an airline reservation system) and includes exactly one ID. A GAF is an abstraction
of a collection of systems pertinent to a particular application and includes one RD, one or
more DDs and one or more IDs for each DD. Application frames play a key role in the
reuse-oriented software development lifecycle envisaged in ITHACA. Generic compo-
nents and applications are produced by application engineers. These are represented by
GAFs and constitute a core of, presumably good quality, components and applications
which are conﬁgured and adapted to ﬁt particular needs by application developers. Such
derived, speciﬁc systems are represented by SAFs. For more on the ITHACA application
development methodology and the role of application frames see [10] [9]. 

The representation language employed in the SIB is Telos [21]: a conceptual modelling
language in the family of entity–relationship models [7]. The main reason for choosing
Telos over other E-R extensions, such as those used by the PCTE+ OMS or the IBM
Repository Manager, MVS, is that it supports unlimited instantiation levels and treats at-
tributes as objects in their own right (which, therefore, can also have attributes). These fea-
tures account for great expressiveness and easy schema extension, and are fully exploited
in the SIB. 

7.2.2 Relationships Between Software Artefacts

Relationships are essential for the classiﬁcation and retrieval of software artefacts. We
therefore elaborate on each kind of link and indicate, when appropriate, how they support
the querying and browsing activities in the SIB. 
Attribution

Attribution is represented by attribute links. This is a general, rather unconstrained repre-
sentation of semantic relations, whereby the attributes of a description are deﬁned to be
instances of other descriptions. An attribute can have zero or more values. Consider the
following example:

Description SoftwareObject with 

attributes 
 

author : Person 
version : VersionNumber 

SoftwareObject has attributes author and version whose values are instances of Person and
VersionNumber respectively. Dynamic properties, such as ‘calls’ relations of methods and
procedures, also fall into this category. 

The Software Information Base

181

Aggregation
Aggregation is represented by hasPart links. This relates an object to its components. For
example:

Description SoftwareObject with 

... 
 hasPart 

 components: SoftwareObject 

The components of an object have a distinct role in the function of the object and any pos-
sible changes to them affect the aggregate object as well (e.g. new version). 
Classiﬁcation
Classiﬁcation (converse instantiation) is represented by instanceOf links. Objects sharing
common properties can be grouped into classes. An object can belong to more than one
class. Classes themselves are treated as generic objects, which, in turn, will be instances
of other, more generic objects (so-called “meta-classes”). In fact, every SIB object has to
be declared as an instance of at least one class. Effectively, an inﬁnite classiﬁcation hier-
archy is established starting with objects that have no instances of their own, called tokens.
Instantiation of a class involves instantiating all the associated semantic relations. Thus re-
lations are treated as objects themselves. For example:
Description BankIS instanceOf SoftwareObject with 

author : Panos 
version : 0.1 

 components : CustomerAccounts, Credit, Investments 

The attribute and hasPart links of BankIS are instances of the corresponding attribute and
components links of SoftwareObject. 

Classiﬁcation is perhaps the most important modelling mechanism in the SIB. [33]

gives a detailed account of the construction of models and descriptions in the SIB. 
Generalization 
Generalization (converse specialization) is represented by isA links. This allows multiple,
strict inheritance of properties between classes leading to the creation of multiple gener-
alization hierarchies. A class inherits all the attributes of its superclasses (possibly more
than one — multiple inheritance); however, inherited properties can only be constrained,
not overridden (strict inheritance). 
Correspondence
Correspondence is represented by correspondsTo links. A software object can have zero
or more associated requirements, design and implementation descriptions. Correspond-
ence relations concern the identity of an object described by different descriptions and can
have as parts other correspondence relations between parts of the corresponding descrip-
tions.  Correspondence  links  actually  indicate  that  the  descriptions  they  link  together
describe the same object from different perspectives. The correspondences of the parts
need not be one-to-one. For instance, a requirements speciﬁcation may correspond to

182

Component Classiﬁcation in the Software Information Base

more than one design and a design may have more than one alternative implementation.
Similarly, a single implementation could correspond to more than one design entity. Ap-
plication Frames are an important type of controlled correspondence in the SIB.
Similarity 

Similarity links represent similarity relationships among software objects and provide a
foundation for approximate retrieval from the SIB. Similarity has been studied in psychol-
ogy [32] and AI, most relevantly to this work in case-based reasoning [4]. Within the con-
text of object-oriented systems, similarity has been viewed as a form of generalization
[34]. Alternatively, it has been interpreted as degree of afﬁnity with respect to various re-
lations, providing the foundation for the dynamically changing presentation of related ob-
jects within a browser (see chapter 9). Its applications include the support of approximate
retrieval with respect to a software repository as well as the re-engineering of software
systems [27]. 

We are primarily interested in similarity links that can be computed automatically
from information that is loaded into the SIB. For added ﬂexibility, however, user-deﬁned
similarity links are also supported. Similarity is computed with respect to similarity cri-
teria and expressed in terms of corresponding similarity measures, which are numbers in
the range [0,1]. An aggregate similarity measure with respect to a set of criteria can be
obtained as a weighted aggregate function of single-criterion similarity measures, the
weights expressing the relative importance of the individual criteria in the set. This meas-
ure may be symmetric or directed. For example, similarity with respect to generalization
may be deﬁned as symmetric, whereas similarity with respect to type compatibility of the
parameters of two C routines may be deﬁned as directed. 

Similarity can be used to deﬁne task-speciﬁc partial orders on the SIB, thus facilitating
the search and evaluation of reusable software objects. Moreover, subsets of the SIB can
be treated as equivalence classes with respect to a particular symmetric similarity meas-
ure, provided all pairs of the class are more similar than a given threshold. Such similarity
equivalence  classes  may  span  different  application  domains,  thus  supporting  inter-
domain reuse. For details on the similarity analysis of SIB descriptions see [29]. 
Genericity

Genericity is represented by specialCaseOf links. This relation is deﬁned only between
application frames to denote that one application frame is less parameterized than another.
For example, a bank accounting and a hotel accounting application frame could both be
derived from a more general, parametric accounting application frame. 
Informal and user-deﬁned links

When users have foreseeable needs for other types of links they can deﬁne them using the
attribute deﬁnition facility of Telos. For instance, versioning can be modelled by special
correspondence links labelled derivedFrom. Furthermore, random needs for representa-
tion and reference can be served by informal links, such as hypertext links which allow the
attachment of multimedia annotations to SIB objects. 

Information Retrieval and User Interface

183

Association 
Association is an encapsulation mechanism intended to allow the grouping of descriptions
that together play a functional role [6]. It associates a set of descriptions with a particular
symbol table: 

Association = (setOfDescriptions, symbolTable)

The contents of an association can only be accessed through the entry points supplied
in its symbol table. For example, we may deﬁne as an association the descriptions that
constitute a design speciﬁcation for a hotel information system, or all the classes that
deﬁne an implementation of that same system. The SIB itself is a global association con-
taining all objects included in any association. Its symbol table contains all the external
names of every object. Name conﬂicts can be resolved by a precedence rule.

Associations can be derived from other associations through queries or set operations.
Furthermore, associations can be considered as materialized views. Non-materialized
views, or simply views, differ from associations in that they cannot be updated directly, but
rather, through updates of the associations which they are derived from. 

7.3

Information Retrieval and User Interface

7.3.1 Querying and Browsing

The selection of software descriptions from the SIB is accomplished through the selection
tool  (ST)  in  terms  of  an  iterative  process  consisting  of  retrieval  and  browsing  steps.
Browsing is usually the ﬁnal and sometimes the only step required for selection. The func-
tional difference between the retrieval and the browsing mode is that the former supports
the retrieval of an arbitrary subset of the SIB and presumes some knowledge of the SIB
contents, while the latter supports local exploratory searches within a given subset of the
SIB without any prior knowledge. Operationally, both selection modes evaluate queries
against the SIB. 

The basic selection functions of the SIB are: 

Retrieve:  Queries × Associations → P (Descriptions × Weights) 
Identiﬁers × P (Links × Depths) × Associations → Views 
 Browse: 

The Retrieve function takes as input a (compound, in general non-Boolean) query and
an association, and returns a subset of the associated descriptions with weights attached,
indicating the degree to which each description in the answer set matches the query. Non-
Boolean queries are based on similarity. Queries are formulated in terms of the query
primitives offered by the Programmatic Query Interface. A set of queries of particular sig-
niﬁcance can be preformulated and offered as menu options, thus providing maximum
ease-of-use and efﬁciency for frequent retrieval operations. 

Browsing begins with a particular SIB description which is the current focus of atten-
tion (called the current object) and produces a view of a neighbourhood of the current ob-

184

Component Classiﬁcation in the Software Information Base

ject within a given association. Since the SIB has a network structure, the neighbourhood
of the current object is deﬁned in terms of incoming and outgoing links of interest. More-
over, the size of the neighbourhood can also be controlled. Thus, the Browse function
takes as input the identiﬁer (name) of the current object, a list of names of link classes
paired with depth control parameter values and an association, and determines a local
view centred around the current object. 

When the depth control parameters are all equal to 1, a star view results, showing the
current object at the centre surrounded by objects directly connected to it through links of
the selected types. This is the simplest and smallest neighbourhood of an object, in topo-
logical terms, with a controllable population. Effectively, the Browse function provides a
moving window with controllable ﬁlters and size, which allows navigational search over
subsets of the SIB network. 

When the depth control parameters are assigned values greater than 1, Browse displays
all objects connected to the current object via paths consisting of links of the selected types
(possibly mixed), where each type of link appears in a path up to a number of times spec-
iﬁed by the corresponding depth parameter. This results in a directed graph rooted at the
current object. Finally, when the depth parameters are assigned the value ALL (inﬁnite),
the transitive closure of the current object with respect to one or more link types is dis-
played. Such a browse operation can display, for example, the call graph (forward or back-
ward) of a given routine. 

Queries to the SIB can be classiﬁed from a user’s point of view as explicit or implicit.
An explicit query involves an arbitrary predicate explicitly formulated in a query language
or through an appropriate form interface. An implicit query, on the other hand, is generated
through  navigational  commands  in  the  browsing  mode,  or  through  a  button  or  menu
option, for frequently used, “canned” queries. Browsing commands and explicit queries
can also be issued through appropriate interfaces from external tools. 

7.3.2 Implementation

An application-scale SIB system has been implemented at the Institute of Computer Sci-
ence, FORTH, and is available to other sites for experimentation* (see ﬁgure 7.1).

The  user  interface  supports  menu-guided  and  forms-based  query  formulation  with
graphical and textual presentation of the answer sets, as well as graphical browsing in a
hypertext-like manner. A hypertext annotation mechanism is also provided. Menu titles,
menu layout and domain-speciﬁc queries are user-conﬁgurable. 

A forms-based interactive data entry facility is available for entering data and schema
information in a uniform manner. This facility automatically adapts itself to the structure
of the various classes and subclasses byemploying the schema information. Furthermore,
it is customizable to application-speciﬁc tasks, such as classiﬁcation of items, addition of
descriptive elements, etc. 

* For details, consult the WWW page for this book (see the preface).

Information Retrieval and User Interface

185

Figure 7.1   SIB static analyzer and class management system.

Any item in the SIB may reference a multimedia object, comprising images, video,
sound or text, stored externally. The SIB recognizes such references and automatically
generates calls to the appropriate presentation tools with the respective parameters, which
results in a synchronous display of the multimedia object.

The SIB is optimized for referential access and large amounts of highly structured data,
especially for network structures consisting of a large variety of classes, rather than rela-
tively few classes with large populations per class (typical in a DBMS). Recursive queries
on aggregational hierarchies, classiﬁcation hierarchies, and retrieval of graph structures,
such as ﬂow-charts or state-transition diagrams, play a more important role than access by
value conditions. A transitive closure with cycle detection of a binary tree with 1024 nodes
can be retrieved in 2 seconds on a Sun SPARC Station. The performance of the SIB in
look-up and traversal exceeds that of modern relational systems by one and two orders of
magnitude respectively. This allows for real-time queries that would be prohibitive with
traditional databases. 

Data entry speed is acceptable: 10,000 references are loaded in batch mode in 3 min-
utes, and 500,000 in 2.5 hours on a SPARC. Both examples were measured with real

186

Component Classiﬁcation in the Software Information Base

application data from static analysis of a medium (30.000 code lines) and a very large ap-
plication (2.5 million code lines). The theoretical capacity limit is 1 billion references. The
design of the internal catalogue structures is fully scalable. 

For more on the SIB, the interested reader is referred to [8] [9].

7.4

The Classiﬁcation Scheme 

7.4.1 Principles

Given  a  set  of  entities  (objects,  concepts)  represented  by  descriptors  (keywords),  the
grouping of those entities into disjoint classes according to some criterion of descriptor
matching is called classiﬁcation. Matching may express some kind of semantic similarity.
A classiﬁcation scheme determines how to perform classiﬁcation in a given setting, pre-
scribing the sets of descriptors and possible internal ordering, matching criteria, and rules
for class assignment. 

Depending on the number of descriptors used, a classiﬁcation scheme can be uni- or
multi-dimensional. An example of a unidimensional scheme is the Universal Decimal
Classiﬁcation (see [26]). In library science, multidimensional (faceted) classiﬁcation, was
introduced by Ranghanathan [25], breaking down information into a number of categories
thus addressing corresponding aspects of the classiﬁed entities. These aspects are called
facets. 

Prieto-Diaz and Freeman developed a faceted classiﬁcation scheme for software reuse
[23] [24] in which they use six facets to describe software: function, object, medium/
agent, system type, functional area, and setting. They mainly describe component func-
tionality, the last three facets pertaining to the internal and external environment. Each fac-
et has a term space, i.e. a ﬁxed set of legal values (concepts), in the sense of a controlled
vocabulary, and an extensible set of user terms. Concepts are organized by a directed
acyclic specialization relation, and terms are assigned as leaves to concepts. Subjective
conceptual distances between concepts and terms are deﬁned, to support retrieving soft-
ware components by their degree of matching. 

A variant of the scheme of Prieto-Diaz and Freeman was developed in the ESPRIT
REBOOT project [17] [28] [22] [31]. This scheme comprises four facets, better suited for
describing object-oriented components: abstraction, operation, operates-on and depend-
ency. The ﬁrst three are analogous to subject, verb and object in a natural language sen-
tence describing component functionality, while the fourth is the counterpart of the three
environmental facets of the Prieto-Diaz and Freeman scheme. The term spaces are also
structured by relations such as specialization and synonymy. A conceptual distance be-
tween terms is deﬁned, which, like that of Prieto-Diaz and Freeman, is the outcome of hu-
man assessment. Neither Prieto-Diaz and Freeman nor REBOOT relate the derivation of
classiﬁcation terms to the knowledge of structural dependencies between software com-
ponents. In [28], however, such a connection is suggested as potentially useful.

The Classiﬁcation Scheme

187

In the SIB classiﬁcation scheme the REBOOT facets are adopted, except that facets are
assigned not necessarily to a class as a whole but, rather, to the relevant parts. Speciﬁcally,
the contents of the SIB classiﬁcation facets are as follows: 
Abstraction
Abstraction terms are nouns representing active object types. Typically these abstractions
indicate the role that the object plays in its interactions with other objects of an applica-
tion. An object-oriented software class as a whole is assigned an abstraction, such as
‘String’, ‘Set’, ‘WindowSystem’, ‘Index’ or ‘NameList’. Abstraction terms do not in-
clude expressions that denote processing, such as ‘String concatenation’ or ‘String con-
version’. Since object types are assumed to be active, the Abstraction terms do not reﬂect
processing in general either (e.g. ‘String manipulation’). 
Operation
Operation terms are verbal types representing speciﬁc activities. The active part of a class
comprises its methods. Hence we associate Operation terms with each individual method
responsible for an activity, e.g. ‘Solve’, ‘Invert’, ‘Lock-Unlock’, ‘Open-Close’. Pairs of
inverse properties, such as ‘Open-Close’, are regarded as one term, to keep the term space
small. 
Operates-On
Besides operating on the class to which it belongs, a method operates on its parameters. In
object-oriented  design,  non-trivial  parameters  belong  to  classes.  (Methods  may  also
directly access input/output devices, which may or may not be represented as objects.)
Operates-On terms are nouns representing the object types acted on by methods, includ-
ing Abstractions, basic data types and devices. Note that Operates-On is a superset of
Abstraction and that the abstraction of a class must be a default ‘Operates-On’ for its own
operations. Operates-On represents the role an object type plays with respect to other
types.
Dependency
Dependency terms represent environmental conditions, such as hardware, operating sys-
tem or language. It is good practice in software development groups to test and release
complete libraries for a certain environment. Accordingly we assign Dependency terms to
class libraries as a whole. The classes of the library are then indirectly linked to a depend-
ency through the library itself. Each combination of programming language, system soft-
ware and hardware forms a different environment. Dependency terms are provided in the
SIB which reﬂect single environmental conditions, as well as combinations of those. For
instance,  a  library  tested,  for  example,  on  (SINIX  ODT1.1,  AT&T  C++  3.0B,  SNI
WX200), and (SINIX 5.41, CooL 2.1, SNI WX200) does not necessarily run on (SINIX
5.41, AT&T C++ 3.0B, SNI WX200). Such triples are terms by themselves in the SIB, the
constituents of which represent their immediate higher terms. Thus retrieval is possible by
the triple itself, as well as by simple terms, e.g. SINIX 5.41, Unix, C++, etc. (see ﬁgure
7.2). 

188

Component Classiﬁcation in the Software Information Base

SNIMachine

SNI_WX200

SINIX_5.41

SNI_WX200:SINIX_5.41/Cool2.1

Unix

SINIX

SINIX_ODT1.1

Object-oriented

Language

CooL

CooL2.1

C++

C++3.0B

SNI_WX200:SINIX_ODT1.1/C++3.0B

Figure 7.2   The isA hierarchy of combinatory Dependency terms.

7.4.2 Classiﬁcation Hierarchies in the SIB

Facets are represented as meta-classes in the SIB. The terms, i.e. the values of a facet, are
instances of that facet, and are therefore simple classes. The instances of those classes are
the software objects sharing the functional property the term denotes. The assignment of
a term to a software object is accomplished by declaring the object to be an instance of the
term. 

Note that facet terms reﬂect the functional role of components as they cooperate in a
process, as distinguished from structural relations or user application tasks. For instance,
‘C++ class’, ‘Menu item’, ‘Selection of goods, clients, or accounts’ may be respectively
the structural, functional and application roles of one software object. These other two
roles are also very pertinent for reuse. In the SIB we take advantage of such information
both independently and jointly with functional classiﬁcation, as we shall see below. On the
other hand, some essential functional parts of a software object are and should be hidden
from the user, hence they do not have any application task associated with them.

In addition to a functional classiﬁcation scheme, like the one discussed here, one can
independently develop a classiﬁcation scheme with respect to structural aspects of the
programming language, or other criteria. Concurrent classiﬁcation of software objects ac-
cording to more than one scheme is supported by the SIB. Technically, the assignment of
terms from several schemes is performed by multiple classiﬁcation: a component is de-
clared to be an instance of all the relevant terms.

The term space for each facet is partially ordered by a specialization/generalization re-
lation (isA) which, in the SIB, obeys multiple strict inheritance. This organization has a

The Classiﬁcation Scheme

189

number of advantages. It minimizes the data entry involved in describing a software com-
ponent, since each term inherits all its predecessors. In addition, the probability of in-
consistent classiﬁcation is limited. Multiple isA relations express multiple independent
properties. By contrast, simple isA relations generate pure hierarchical structures which
are not ﬂexible enough for expressing general, multifaceted relationships. If we interpret
the term space as a set of classes semantically ordered by isA relations derived from their
implicit properties, assuming strict inheritance of those properties, the terms lose their
linguistic nature and become concepts. Homonyms, i.e. instances of the same word with
different meanings, must then be assigned different terms. For example, spectral ‘radius’
and circle ‘radius’, law and ‘order’ and warehouse ‘order’ do not share properties. The re-
call of such a concept-based system is superior to a linguistic one (see [30]). 

No distinction in nature is made between leaf terms and higher terms. The granularity
of analysis depends very much on the breadth of the domains classiﬁed, and should be dy-
namically adaptable to the contents of the repository. As is generally accepted in the liter-
ature, term spaces are kept small in order to help the user become quickly acquainted with
the applicable terms for a given problem. Retrieved components can subsequently be re-
viewed efﬁciently by browsing.

In order to combine discipline with linguistic ﬂexibility in developing term spaces, syn-
onyms are introduced. Two different words are synonyms if they have the same meaning,
such as ‘alter’ and ‘change’ in the Unix system call manual. Preferred words are selected
as terms for inclusion in the isA-structured term space. Synonyms are attached to those
through the attribute category synonym speciﬁcally deﬁned in the SIB. Thus access is pos-
sible by all synonymous words and term, while vocabulary control is maintained. 

Multiple  inheritance  expresses  multiplicity  of  nature  of  a  term  itself.  For  instance,
‘Copy’ has the properties of both ‘Put’ and ‘Get’. We adopt the principle that for any group
of terms sharing some implicit property, there should be a higher term with this property:
‘Get’, ‘Put’, ‘I/O’ share a property ‘transfer’, whereas ‘Put’, ‘Update’ share ‘Modify’, etc.
Arbitrary decisions on term placement in a hierarchy can thus be avoided. On the other
hand, as any conceptual distance or similarity is based on some sharing of properties,
those notions become closely related to the higher terms structure. 

Multiplicity of nature at the item level (components), not resulting from intrinsic prop-
erties of the terms, is expressed through multiple instantiation (assignment of terms), e.g.
a method doing ‘Lock’ and ‘Update’. It turns out that the beneﬁts from the specialization
(isA) structure of term spaces are fully obtained if items are only assigned to leaf terms.
Nevertheless, the system is robust to a dynamic reﬁnement of the term space, whereby leaf
terms may become higher terms. Items assigned to higher terms can be treated by the re-
trieval query as possible candidates for all leaf terms under it, with a decreasing priority
according to the number of levels between them. 

The isA organization facilitates exploring, understanding and retrieving terms. Natu-
rally, alphabetical browsing and retrieval by lexical pattern matching are also provided.
Finally, a “conceptual distance” (conversely, similarity) can be deﬁned as a suitable metric
over the term space partially ordered by the isA relation [29]. The advantage of such a met-
ric is that its computation requires no user input, as it effectively relies on the intrinsic

190

Component Classiﬁcation in the Software Information Base

Printer

HWcomponent

Keyboard

TemporalObject

MachineTime

CompoundRepresentation

TimeRepresentation

DistanceRepresentation

Figure 7.3   The isA hierarchy environment of Abstraction ‘TimeRepresentation’.

properties of the common higher terms. To which degree this notion of measure can be ex-
ploited to improve or normalize the hierarchy itself is a topic of further research. 

7.4.3 Example

Let us consider the abstractions of a class ‘Time’, which handles arithmetic with years,
hours, minutes, etc. On the one hand, it has to do with the representation of time values; on
the other hand, it does not relate to actual time. We therefore choose the term ‘TimeRep-
resentation’. This term has two higher terms: ‘TemporalObject’, and ‘CompoundRepre-
sentation’.  By  ‘CompoundRepresentation’  we  denote  systems  of  measurement  using
different units for different orders of magnitude, such as miles, yards, etc. Another special-
ization of ‘TemporalObject’ is ‘MachineTime’.

A ‘TimeRepresentation’ class may be directly used, or in conjunction with a ‘Machine-
Time’ class to measure elapsed time. This conforms to the initial intention of such a class.
Note that we could easily change unit names and conversion factors between units to adapt
such a class to handle miles, yards, etc. In this case we reuse the algorithm or structure of
a speciﬁc solution. This property is intrinsic to a time representation module, and we ex-
press it by the higher term ‘CompoundRepresentation’. 

This example demonstrates how multiple inheritance can serve to bring related terms
together, and how a careful analysis of implicit properties of terms may help to support
reuse in ways the developer did not originally have in mind (see ﬁgure 7.3). Since the
development of generic modules is regarded to be desirable for reuse, any support for de-
tecting candidates to be generalized or parameterized is valuable.

Streamlining the Classiﬁcation Process

191

7.5

Streamlining the Classiﬁcation Process

7.5.1 Static Class Analysis

The SIB stores various kinds of structural and descriptive information about software
components. In particular, at the implementation description level, it stores the results of
static analysis performed by program parsers. Given a programming language, a cor-
responding  implementation  description  model  deﬁnes  a  set  of  entities,  such  as  class,
method, parameter, source ﬁle, and relations between these entities, such as deﬁnes, calls,
user-of. The static analysis data of a given component are entered as instances of the mod-
el concepts. (This information is useful enough in its own right that a version of the SIB
has been developed purely as static analyzer.) Static analysis information is also useful for
streamlining the classiﬁcation process.

We distinguish classiﬁcation into direct, which is assigned explicitly to an entity, and
derived, which is deﬁned by means of queries. Minimizing direct classiﬁcation not only
saves human effort, but also improves consistency when software or term space modiﬁca-
tions take place. Static analysis allows for an automatic mapping of information (methods,
parameters, etc.) to classiﬁcation facets and terms. 

Abstractions are associated to classes, and Operations are associated to methods. Pro-
cedures and operators are treated like methods, if they are connected to a class via friend
declarations. Otherwise, an additional class, such as ‘Procedure_group’ is introduced for
their classiﬁcation. The operations of a class are derived by queries through the links indi-
cating the methods belonging to that class. The explicit correspondence of methods and
Operations facilitates maintenance and consistency of code and classiﬁcation terms. The
Operates-On terms of a class are also derived, and include the abstraction of the class itself
(since its methods can access its instances) and the parameter types of its methods, be they
abstractions (i.e. other classes) or basic data types. (The assignment of terms representing
devices, system calls, etc., to methods is done manually at present.) In a linguistic sense,
Operates-On is the direct object of the Operation verb. Operates-On is at ﬁrst hand a prop-
erty of the method, or even more precisely of the instantiation of a speciﬁc operation in a
method, and only in a wider sense a property of the class as a whole. 

Dependency terms are assigned to libraries and applications. Therefore, the dependen-

cies of a class are derived by relating library ﬁles with the classes they contain. 

7.5.2 Derived Classiﬁcation

A number of derivation paths are used, in either direction, depending on whether the ob-
jective is to ﬁnd a class or the valid terms for a class. An example comprising all those
paths is given in the next section. The following is the complete list of relevant path ele-
ments: 

• From synonyms to established terms through the ‘synonym of’ link.

192

Component Classiﬁcation in the Software Information Base

• From class terms to higher terms through the ‘isA’ link. 
• From Abstraction terms of classes to methods as ‘Operates-On’ through the inverse

‘has parameter’ link. 

• From method terms to classes through the inverse ‘has method’ link. 
• From class terms to derived classes, in the sense of the PL, through the inverse of the

‘has parent’ or ‘has supertype’ link. 

• From Dependency terms to classes through the ‘Library.runs_on’ – ‘Library.has_-

ﬁle’ – ‘class.deﬁned_in’ path. 

Note that the direct assignment of terms is done not to software classes but to more
ﬁnely-grained entities (e.g. methods) that are structurally related to them. In this way it is
sufﬁcient, in most practical cases, to assign one term to each entity. Furthermore, static
analysis information can support the automatic extraction of classiﬁcation terms from
formalized source code comments.

When creating term spaces it is important to maintain semantic links between Opera-

tion terms and Abstraction terms, in particular:

1. which legal operations belong to an abstraction; and 
2. which application domain an operation term is intended for.
The ﬁrst kind of constraint should naturally be represented by linking abstractions with
their legal operations. Creating higher operation terms would be unnecessary. For exam-
ple, Operation’truncate is an operation applicable to both strings and ﬁles. This should be
indicated  by  links  from Abstraction’ﬁle  and Abstraction’string  to  Operation’truncate.
Introducing,  say,  Operation’string_operations  and  Operation’ﬁle_operations  as  higher
terms, to which Operation’truncate would be isA related, conveys no information on the
nature of Operation’truncate. 

The second kind of constraint introduces a problem related to homonyms. These are han-
dled by adding preﬁxes to the terms, so that the homonyms effectively obtain unique names
in the SIB. Besides, they preserve the homonym character in the last part of the word, which
allows access by substring matching. However, great care should be taken not to create sub-
structures in the term space on the basis of homonyms (more precisely: the homonymous
parts of terms), which may prove semantically wrong. For example, a substructure includ-
ing Abstraction’order along with its specializations Abstraction’warehouse_order and Ab-
straction’serial_order  is  not  based  on  common  semantics  as  expected.  By  contrast,
Abstraction’warehouse_order  isA  Abstraction’commerce  and  Abstraction’serial_order
isA Abstraction’memory_management are semantically correct. 

7.6

Experiences

7.6.1 The Classiﬁcation Process

Classiﬁcation is an iterative process. The user understands the functionality of a part of a
component by studying (through the browser) documentation, static analysis data, and/or

Experiences

193

the code itself, supported in each step by the SIB, matching it with terms in the term space.
Term understanding is supported by the linguistic form of the term, its position in the
hierarchy, text comments on its meaning, or use in the classiﬁcation of similar code known
to the user. The user must decide if a given term matches with the component and if the
term is speciﬁc enough. If not, a new term must be introduced in agreement with a group
of developers responsible for the term space maintenance. With use and experience, the
upper parts of the term space become increasingly stable and complete. 

A user should be aware not only of the meaning of terms, but also of their quality (i.e.
for retrieval purposes), which leads to the need to know the principles under which terms
are created. The following general criteria are proposed for selecting terms in a given do-
main of interest [12] [22]:

• Terms should be well-known words, usually technical terms or expressions, widely
accepted in the software engineering community, or at least by experts in the partic-
ular domain of interest (object-oriented development). 

• Terms should have clear meanings, relative and easily associated to the concepts
conveyed by their specializations or generalizations, in the classiﬁcation structure.
Moreover, they should be distinct and precise, in order to facilitate the direct linking
of the component to the corresponding classiﬁcation term. 

• Terms should also be general enough, in the sense that a term may encompass more
than one specialized term in the classiﬁcation structure. In other words, every term
should be used to address more than one component, or a speciﬁc (under some se-
mantic criteria), set of components. Keeping a set of terms general — therefore small
enough, and expressive at the same time, thus useful for the reuse process — is one
of the basic and most difﬁcult tasks in classiﬁcation. Conversely, keeping a large term
space usually means confusion for suppliers and reusers of components, inconven-
ient browsing, poor search performance, etc. 

• Redundancy should be avoided, in the sense that there should be no two terms with
very close meaning in the same classiﬁcation hierarchy. If this happens, then they
should be related only with synonym relationship, with the most representative term
present in the classiﬁcation hierarchy. 

As these criteria are generally conﬂicting, the implementation of an effective term

space requires striking a judicious balance among them: a non-trivial task. 

7.6.2 An Example

We draw an example from the classiﬁcation developed for the Colibri class library [3] of
the CooL language environment. CooL [2] is an object-oriented programming language
developed at Siemens-Nixdorf within the ESPRIT ITHACA project. We demonstrate the
selection and the assignment of terms, and the resulting valid terms by derivation.

Consider the following partial listing of the classes ‘Date’ and ‘DateRepr’:

194

Component Classiﬁcation in the Software Information Base

--
-- Date.t -- 
-- 
-- PURPOSE

 -*- Mode: Cool -*- 

|
|
|
|
|
|

Date is an object type representing a calendar entry
consisting of year, month, and day. This object type
offers methods to construct, modify and actualize an
object and to get information about an object. Further
methods deal with arithmetic operations and
predicates

|
|
|
|
|
|

-- TABLE OF CONTENTS
REFER Duration, Interval, time;
TYPE Date = OBJECT (

IN Year : INT, 
IN Month : INT, 
IN Day : INT)

 
-- ----------------------------------------------------------------------------------------------
-- 2. Actual Date
-- ----------------------------------------------------------------------------------------------
METHOD SetToActualDate;

 -- --------------------------------------------------------------------------------------
 -- Set this date to the actual date.
 -- --------------------------------------------------------------------------------------

-- ----------------------------------------------------------------------------------------------
-- 4. Selective access
-- ----------------------------------------------------------------------------------------------
METHOD GetYear : INT;
METHOD GetMonth : INT;
METHOD GetDay : INT;

 -- --------------------------------------------------------------------------------------
 -- Return the speciﬁc information of this date
 -- --------------------------------------------------------------------------------------

-- ----------------------------------------------------------------------------------------------
-- 5. Arithmetic operations
-- ----------------------------------------------------------------------------------------------
METHOD Add (IN Extent : Duration);
METHOD Subtract (IN Extent : Duration);
-- ----------------------------------------------------------------------------------------------
 -- Add or subtract an extent from this date.
-- ----------------------------------------------------------------------------------------------

END OBJECT;
-- ----------------------------------------------------------------------------------------------

--
-- DateRepr.t -- 
-- 
-- PURPOSE

 -*- Mode: Cool -*- 

|

DateRepr is a sub type of object type Date representing

|

Experiences

195

|
|
|

a calendar entry...together with a format string
containing the presentation description according to
the C library function strftime()...

|
|
|

-- TABLE OF CONTENTS

REFER Date, String;

TYPE DateRepr = Date OBJECT
 

(IN Year : INT, 
 IN Month : INT, 
 IN Day : INT,
 IN Format : STRING)

-- ----------------------------------------------------------------------------------------------
-- 3. Format representation
-- ----------------------------------------------------------------------------------------------
METHOD Present : STRING;

 -- --------------------------------------------------------------------------------------
 -- Return this date formatted with its representation
 -- --------------------------------------------------------------------------------------

END OBJECT;
-- ----------------------------------------------------------------------------------------------

Classiﬁcation of ‘Date’: 

1.
2.

 Object type ‘Date’ under Abstraction ‘TimeRepresentation’. 
 Method ‘SetToActualDate’ under Operation ‘Set-Reset’ and Operates-On ‘Mach-
ineTime’. This method uses internally the Unix system call ‘time()’. 

3. Method ‘Add’ and ‘Subtract’ under Operation ‘Add-Subtract’. 
‘Date’ is not automatically updated to the current date or machine time. Hence ‘Mach-
ineTime’ was not regarded as a good abstraction for it. The methods GetYear, etc., as all
others not listed above, are omitted for the simplicity of the example. 
Classiﬁcation of ‘DateRepr’: 

(4) Method ‘Present’ under Operation ‘Convert’. 

4.
We usually classify within one term the inverse of an operation as well, since such
operations belong semantically together. The method name ‘Present’ denotes the appli-
cation task of the method, not its function within the component. We therefore prefer the
term ‘Convert’.

More examples on reasoning about good terms are given in [12]. We further assume
that, in a previous step, the Colibri library was assigned the Dependency terms (CooL2.1,
SINIX_5.41, SNI_WX200), and ‘Duration’ was assigned the Abstraction ‘TimeRepre-
sentation’. The classiﬁcation of built-in types of the programming language, such as inte-
ger, string, etc., is initially provided in the SIB. Figure 7.4 shows all paths through which
leaf terms for the CooL Object Type ‘DateRepr’ are derived. 

196

Component Classiﬁcation in the Software Information Base

Dependency

Abstraction

SNI_WX200:SINIX_5.41/Cool2.1

TimeRepresentation

Operation

Add-Subtract

runs on

Add

parameter

Duration

Colibri

Date

method

has file

supertype

method

Operation
Set-Reset

DateRepr.t

defined in

DateRepr

SetToActualDate

method

Static analysis data
Structural links
Classification Terms
Term assignment

Operation

Convert

Operates-On

String

Present

parameter

String

Figure 7.4   Leaf terms valid for the CooLObjectType ‘DateRepr’.

The complete list of terms and synonyms for ‘DateRepr’, resulting from the above leaf
term assignment and the term space currently in the SIB, is given in table 7.1. Notice that
these terms are all derived. Having in mind that good object-oriented applications usually
derive some tens of classes from one base class, adding few methods in each derivation
step, the advantage of the SIB system for classifying large class hierarchies becomes ob-
vious.

Once found, terms are easily attached to components or correctly integrated in the term
space by using the SIB facilities. To classify a class with some twenty methods we typical-
ly spend half an hour to one hour. These times, however, vary strongly with the function-
ality of the class. User interface classes or mathematical classes can be much more quickly
classiﬁed than some internal components or components with complex functionality. For
instance, characterizing the SIB query processor in contrast to other query processors is
not straightforward. Evidently, the quality and maturity of existing terminology plays an
important role. These observations raise interesting issues for further work, experimental
as well as on the ﬁeld of terminology. 

Our in-house experience with the SIB classiﬁcation facilities is currently based on three
cases: the class library Colibri for the CooL language environment, the C++ Extended
(APEX 1.0) library [1], and classes of the SIB implementation itself. The term space for
the ﬁrst two examples has been fully developed. The classiﬁcation of the SIB implemen-

Conclusion

197

Facet

Derived leaf terms

Higher terms

Synonyms

Abstraction

TimeRepresentation

TemporalObject
CompoundRepresentation

Time
NonDecimalSystem

Operation

Add-Subtract
Set-Reset
Convert

Operates-On

TimeRepresentation
MachineTime
String

Dependency

SNI_WX200:SINIX_5.41
:CooL2.1

Algebraic

Time
NonDecimalSystem
CurrentTime
DateFormat
ComputerTime
Date
Calendar

StateManipulation
Arithmetic
Mathematical
Format

TemporalObject
CompoundRepresentation
HWcomponent
List
Ordered_Collection
Collection
Bag

Unix
SINIX
SINIX_5.41
SNIMachine
SNI_WX200
CooL
ObjectOrientedLanguage
CooL2.1

Table 7.1   Terms and synonyms for the CooLObjectType ‘DateRepr’.

tation is part of an on-going work to use the SIB for its complete self-documentation. Ex-
perience reports are also expected from users outside our institute. 

7.7 Conclusion 

The SIB classiﬁcation method deﬁnes in an objective way how terms and entities will be
related. This facilitates the consistent usage of the system by a group of users in that there
is a high probability that two users classifying the same object will come up with the same
usage of given terms, that two users will come up with the same higher–lower term order-
ing of given terms, and that users retrieving objects will have the same understanding of
the terms as those who have classiﬁed the objects. These properties are expected to im-
prove considerably the recall of the system. Nevertheless, there is an intellectual invest-
ment in the creation of term spaces, well known from efforts to create thesauri in other
domains as well. A good term space incorporates a lot of experience and knowledge. As
such, it should be subject to speciﬁc developments and exchange between user communi-
ties. In our opinion, this issue has not yet received enough attention in the literature. 

198

Component Classiﬁcation in the Software Information Base

Classiﬁcation of software objects is a time-consuming task. We argue that the various
derivation mechanisms offered in the SIB will reduce considerably the time needed for
classiﬁcation. They further improve the consistency of the code with the terms applied, in
particular the maintenance of the applied terms after updates of the software objects. Both
aspects are essential for the industrial usage of such a system. 

The SIB is different from a series of other approaches in its data modelling capabilities,
which allow it to integrate, without redundancies and in a single tool, the above classiﬁca-
tion mechanism with other organization principles, such as libraries, application frames,
associations and lifecycle information in general. As an open, conﬁgurable system it is
easily adapted to new methodologies and standards embedded into software production
environments. 

Integrating all aspects in a logically consistent way, as discussed above for static anal-
ysis and functional classiﬁcation, gives rise to a bootstrapping and veriﬁcation problem.
The larger the population of the system, the more useful it is, the more important further
organization principles and lifecycle information become, and the better the validity of
their interconnections can be tested. To attract real users of the system, they must be pro-
vided from the very beginning with immediately useful functionalities and usage guid-
ance. The reduction of manual work by importing as much information as possible from
existing sources plays an important role in this context. The incremental development of
further chains of functionality in the SIB, like the static analysis–functional classiﬁcation
presented here, is a main line of our future work. 

References 

[1] C++ Extended Library, APEX 1.0 Information brochure, Siemens Nixdorf Informationssysteme AG,

Berlin, April 1992.

[2] CooL V1.0, Language Reference Manual, Siemens Nixdorf Informationssysteme AG, Berlin, April

1992.

[3] CooL V1.0, CoLibri, Reference Manual, Siemens Nixdorf Informationssysteme AG, Berlin, April

1992. 

[4] Ralph Barletta, “An Introduction to Case-Based Reasoning,” AI Expert, vol. 6, no. 8, Aug. 1991, pp.

[5]

42–49.
Ted J. Biggerstaff and Alan J. Perlis, Software Reusability, Volume I: Concepts and Models, Volume
2: Applications and Experience, Addison-Wesley, Reading, Mass., 1989. 

[6] Michael Brodie and Dzenan Ridjanovic, “On the Design and Speciﬁcation of Database Transactions,”
in On Conceptual Modelling: Perspectives from Artiﬁcial Intelligence, Databases and Programming
Languages, ed. Michael Brodie, John Mylopoulos and Joachim Schmidt, Springer-Verlag, New York,
1984, pp. 277–312. 
Peter P.-S. Chen, “The Entity-Relationship Model: Towards a Uniﬁed View of Data,” ACM Transac-
tions on Database Systems, vol. 1, no. 1, March 1976, pp. 9–36.
Panos Constantopoulos, Martin Dörr and Yannis Vassiliou, “Repositories for Software Reuse: The
Software Information Base,” in Proceedings IFIP WG 8.1 Conference on Information System Devel-
opment Process, Como, Sept. 1993, pp.285–307.

[7]

[8]

References

199

[9]

Panos Constantopoulos, Matthias Jarke, John Mylopoulos and Yannis Vassiliou, “The Software Infor-
mation Base: A Server for Reuse,” The VLDB Journal (to appear). 

[10] Valeria de Antonellis, et al., “Ithaca Object-Oriented Methodology Manual,” ITHACA Report ITH-

ACA.POLIMI-UDUNIV.E.8.6, Politecnico di Milano, 1992. 

[11] Premkumar Devanbu, Ronald J. Brachman, Peter G. Selfridge and Bruce W. Ballard, “LaSSIE: A
Knowledge-Based Software Information System,” Communications of the ACM, vol. 34, no. 5, May
1991, pp. 34–49. 

[12] Martin  Dörr  and  Eleni  Petra,  “Classifying  C++  Reusable  Components,”  ITHACA  Report  ITH-
ACA.FORTH.94.SIB.#2, Institute of Computer Science, Foundation of Research and Technology -
Hellas, Jan. 1994. 

[13] Pankaj Garg and Walt Scacchi, “On Designing Intelligent Hypertext Systems for Information Man-

agement in Software Engineering,” DIF, Proceedings Hypertext ’87, Nov. 1987, pp. 409–431. 

[14] Simon Gibbs, Dennis Tsichritzis, Eduardo Casais, Oscar Nierstrasz and Xavier Pintado, “Class Man-
agement for Software Communities,” Communications of the ACM, vol. 33, no. 9, Sept. 1990, pp. 90–
103. 

[15] Adele Goldberg, Smalltalk-80: The Interactive Programming Environment, Addison-Wesley, Read-

ing, Mass., 1984. 

[16] T. Hopking, C. Phillips, Numerical Methods in Practice: Using the NAG Library, Addison-Wesley,

Reading, Mass., 1988. 

[17] E. A. Karlsson, S. Sorumgard and E. Tryggeseth, “Classiﬁcation of Object-Oriented Components for

Reuse,” Proceedings TOOLS 7, Dortmund, 1992. 

[18] Charles W. Krueger, “Software Reuse,” ACM Computing Surveys, vol.24, no.2, June 1992, pp. 131–

183. 

[19] Colin Low, “A Shared, Persistent Object Store,” Proceedings ECOOP’88, Oslo, Aug. 1988, pp. 390–

410. 

[20] Bertrand Meyer, Eiffel: the Libraries, Prentice Hall, New York, 1990. 
[21] John  Mylopoulos, Alex  Borgida,  Matthias  Jarke  and  Manolis  Koubarakis,  “Telos:  Representing
Knowledge About Information Systems,” ACM Transactions on Information Systems, vol. 8, no. 4,
Oct. 1990, pp. 325–362. 

[22] P. Paul, “Classiﬁcation of Software Components for Reuse,” SIEMENS Technical Report, July 1992.
[23] Ruben Prieto-Diaz and Peter Freeman, “Classifying Software for Reusability,” IEEE Software, vol. 4,

no. 1, Jan.1987, pp.6–16. 

[24] Ruben Prieto-Diaz, “Implementing Faceted Classiﬁcation for Software Reuse,” Communications of

the ACM, vol. 34, no. 5, May 1991, pp. 88–97. 

[25] Sarada R. Ranganathan, “Prolegomena to Library Classiﬁcation,” Garden City Press, Letchworth,

Hertfordshire, 1957. 

[26] Geoffrey Robinson, “UDC: A Brief Introduction,” Technical Report, International Federation of Doc-

umentation, 1979. 

[27] Robert W. Schwanke, “An Intelligent Tool for Re-Engineering Software Modularity,” Proceedings In-

ternational Software Engineering Conference, Austin, Tex., 1991, pp. 83–92. 

[28] L.S. Sorumgard, G. Sindre and F. Stokke, “Experiences from Application of a Faceted Classiﬁcation
Scheme,” Proceedings 2nd International Workshop on Software Reusability 1993 (REUSE’93), Luc-
ca, March 1993. 

[29] George  Spanoudakis  and  Panos  Constantopoulos,  “Similarity  for Analogical  Software  Reuse: A
Computational Model,” Proceedings European Conference on Artiﬁcial Intelligence, Amsterdam,
Aug. 1994. 

[30] E. Svenonius, “Design of Controlled Vocabularies,” Encyclopedia of Library and Information Sci-

ence, Marcel Dekker, New York, 1989 

200

Component Classiﬁcation in the Software Information Base

[31] S. Thunem and G. Sindre, “Development With and for Reuse: Guidelines from the REBOOT Project,”
Proceedings ERCIM Workshop on Methods and Tools for Software Reuse, Heraklion, Crete, Oct.
1992, pp. 2–16.

[32] Amos Tversky, “Features of Similarity,” Psychological Review, July 1977. 
[33] Costis Vezerides, “The Organization of a Software Information Base for Software Reuse by a Com-
munity of Programmers,” Master’s Thesis, Department of Computer Science, University of Crete,
May 1992. 

[34] Peter Wegner, “The Object-Oriented Classiﬁcation Paradigm,” in Research Directions in Object-Ori-

ented Programming, ed. Bruce Schriver and Peter Wegner, MIT Press, Cambridge, Mass., 1987.

Chapter 8
Managing Class Evolution in 
Object-Oriented Systems

Eduardo Casais

Abstract    Software components developed with an object-oriented language
undergo considerable reprogramming before they become reusable for a wide
range  of  applications  or  domains.  Tools  and  methodologies  are  therefore
needed to cope with the complexity of designing, updating and reorganizing
class collections. We present a typology of techniques for controlling change in
object-oriented systems, illustrate their functionality with selected examples and
discuss their advantages and limitations. 

8.1 Object Design and Redesign

8.1.1 The Problem

Nowadays, it is generally assumed that the mechanisms provided by object-oriented lan-
guages  —  namely  classiﬁcation,  encapsulation,  inheritance  and  delayed  binding  —
together with a comprehensive set of interactive programming tools, provide the basic
functionality required for the large-scale production of highly reusable software compo-
nents. However, software developers working with an object-oriented system are fre-
quently led to modify extensively or even to reprogram supposedly reusable classes so that
they fully suit their needs. This problem has been documented during the design of the Eif-
fel [31] and Smalltalk [21] hierarchies, the construction of user interfaces [20], the devel-
opment  of  libraries  for VLSI-design  algorithms  [2],  and  the  development  of  object-
oriented frameworks for operating systems [23]. 

The  ﬁrst  difﬁculty  with  object-oriented  development  is  achieving  a  correct  initial
modelling of an application domain. Because of the variety of mechanisms provided by
object-oriented languages, the best choice for representing a real-world entity in terms of
classes is not always readily apparent. The problem is compounded by the versatility of
the inheritance mechanism, which can serve to denote specialization relationships, to en-

Eduardo Casais, “Managing Class Evolution in Object-Oriented Systems,” Object-Oriented Software Composition, O. Nierstrasz and D. 
Tsichritzis (Eds.), pp. 201-244, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

202

Managing Class Evolution in Object-Oriented Systems

force typing constraints, or to share implementations. Inadequate inheritance structures,
missing abstractions in a hierarchy, overly specialized components or deﬁcient object
modelling may seriously impair the reusability of a class collection. Such defects must be
eliminated through an evolutionary process to improve the robustness and the reusability
of a library [20][22]. 

Even when a class collection embodies stable abstractions that have been reused suc-
cessfully a number of times, repeated reorganizations of the library may still be unavoid-
able. Paradoxically, the high degree of reusability of a library may cause it to undergo
major reorganizations when developers attempting to take advantage of its functionality
stretch its range of application to new domains, thus imposing additional constraints on
the library and invalidating the assumptions that drove its original design. 

Software reuse also raises complex integration issues when teams of programmers
share classes that do not originate from a common, compatible hierarchy. Classes may
require signiﬁcant adaptations, like reassigning inheritance dependencies or renaming
properties, to be exchanged between different environments. 

8.1.2 The Solutions

Among the approaches that have been proposed in recent years to control evolution in
object-oriented systems, we identify the following general categories: 

• Tailoring consists in slightly adapting class deﬁnitions when they do not lead to easy
subclassing. Most object-oriented languages provide built-in constructs for making
limited adjustments on class hierarchies. 

• Surgery. Every possible change to a class can be deﬁned in terms of speciﬁc, primi-
tive update operations. Maintaining the consistency of a class hierarchy requires that
the consequences of applying these primitives be precisely determined. 

• Versioning enables teams of programmers to record the history of class modiﬁca-
tions during the design process, to control the creation and dissemination of software
components, and to coordinate the modelling of variants in complex application do-
mains. 

• Reorganization of a class library is needed after signiﬁcant changes are made on it,
like the introduction or the suppression of classes. Reorganization procedures use in-
formation on “good” library structures to discover imperfections in a hierarchy and
to suggest alternative designs. 

A second problem, related to class evolution, is that instances must be updated after
their representation is modiﬁed. Restarting a program and discarding existing instances is
not always feasible, since objects may be involved in running applications and may con-
tain useful, long-lived information. This is especially true for environments implementing
persistent objects. We consider in detail three techniques to tackle this issue: 

• Change avoidance consists in preventing any impact from class modifications on ex-

isting instances, for example by restricting the kind of changes brought to classes. 

Class Tailoring

203

• Conversion physically transforms objects affected by a class change so that they con-

form to their new class deﬁnition. 

• Filtering hides the differences between objects belonging to several variants of the
same class by encapsulating instances with an additional software layer that extends
their normal properties. 

The remainder of the chapter explains the principles behind these approaches, referring
when appropriate to the research prototypes or industrial products that implement them,
and illustrating their functionality with simple examples. 

8.2 Class Tailoring

8.2.1 Issues

Quite often, object-oriented programming does not follow the ideal scenario where super-
classes, extended with additional attributes, naturally give rise to new object descriptions.
Inherited variables and methods do not necessarily satisfy all the constraints which need
to be enforced in specialized subclasses [9]. Typically, one prefers an optimized imple-
mentation of a method to the general and inefﬁcient algorithm deﬁned in a superclass.
Similarly, a variable with a restricted range may be more appropriate than one admitting
any value. Tailoring mechanisms alleviate these problems by allowing the programmer to
replace unwanted characteristics from standard classes with properties better suited to
new applications. 

8.2.2 Language Mechanisms

Object-oriented languages have always provided simple constructs for tailoring classes.
We present here an overview of the tailoring mechanisms provided by the Eiffel language
[30]. Similar mechanisms are available in many other programming languages. 

• Renaming is the simplest way to effectively modify a class deﬁnition. Renamed var-
iables and methods can no longer be referred to by their previous identiﬁer, but they
keep all their remaining properties, like their type or their argument list. 

• Redeﬁnition  enables  the  programmer  to  actually  alter  the  implementation  of  at-
tributes. The body of a method may be replaced with a different implementation; a
special undeﬁne clause in Eiffel 3 allows the programmer to turn an inherited method
into a deferred deﬁnition in a subclass. Eiffel also allows the type of inherited vari-
ables, parameters and function results to be redeclared, provided the new type is
compatible with the old one. Finally, the pre- and post-conditions of a method may
be redeﬁned, as long as the new pre-condition (or the new post-condition) is weaker
(or stronger) than the original one. 

204

Managing Class Evolution in Object-Oriented Systems

• Interfaces are not statically deﬁned in Eiffel. An attribute declared as private in a
superclass may be made accessible in a subclass; conversely, a previously visible
attribute may be excluded from the subclass interface. 

The following excerpt from the Eiffel 2.1 library illustrates the use of these various tai-
loring mechanisms. Notice the changes in class interfaces, the redeﬁnition of the variable
parent and the renaming and overriding of the operations for creating tree objects.

Trees where each node has a ﬁxed number of children (The number of children is
arbitrary but cannot be changed once the node has been created).

--
--
--
--
class FIXED_TREE [T] 

export

start, ﬁnish, is_leaf, arity, child, value, change_value, node_value, 
change_node_value, ﬁrst_child, last_child, position, parent, ﬁrst, last, 
right_sibling, left_sibling, duplicate, is_root, islast, isﬁrst, go, go_to_child, 
delete_child, change_child, attach_to_parent, change_right, change_left,
wipe_out

inherit
…
feature

parent
Create (n : INTEGER; v : T) is …

FIXED_TREE [T];

:

--

Create node with node_value v and n void children.

end; -- Create
…

end -- class FIXED_TREE

Binary trees.

--
--
--
class BINARY_TREE [T] 

export

start, ﬁnish, is_leaf, arity, child, value, change_value, node_value, 
change_node_value, left, right, has_left, has_right, has_both, has_none, 
change_left_child, change_right_child

inherit

FIXED_TREE [T] 
rename

Create as ﬁxed_Create, ﬁrst_child as left, last_child as right 

redeﬁne

parent 

feature

parent
Create (v : T) is 

:

like Current;

--

Create tree with single node of node value v

do

ﬁxed_Create (2, v)

ensure

node_value = v;

Class Tailoring

205

right.Void and left.Void

end; -- Create
…

end -- class BINARY_TREE [T]

Sometimes, adaptations cannot be limited to local class adjustments; global changes to
the hierarchy are required. Objective-C provides a mechanism where a user-deﬁned class
can “pose” as any other class in the hierarchy [33]. When the “posing” class is installed in
the system, it shadows the original deﬁnition. Objects depending on the “posed” class,
whether by inheritance or by instantiation, do not have to be changed; the method dis-
patching scheme guarantees that a message sent to an object of the posed class actually re-
sults  in  invoking  a  procedure  in  a  posing  object. The  posing  class  may  override  any
method of the posed class and deﬁne additional operations; it has access to all original,
now shadowed, properties. 

8.2.3 Evaluation

Tailoring techniques are useful in performing small adjustments on a class collection. The
overriding of inherited attributes enables the programmer to escape from a rigid inherit-
ance structure that is not always well-suited to application modelling. It facilitates the han-
dling of exceptions locally and does not require the factoring of common properties into
numerous intermediate classes. Tailoring mechanisms correspond to constructs of object-
oriented languages; consequently, they can be implemented efﬁciently within compilers. 
On the other hand, overreliance on tailoring may quickly lead to incomprehensible
structures overloaded with special cases, which are, as far as persistent object-oriented
systems are concerned, difﬁcult to manage efﬁciently with current database technology.
Introducing exceptions in a hierarchy destroys its specialization structure and obscures
the dependencies between classes since a property cannot be assumed to hold in every
object derived from a particular deﬁnition. Renaming and interface redeclaration may
completely  break  down  the  standard  type  relations  between  classes.  When  signature
compatibility is not respected, or when the semantics of a method can be radically altered,
polymorphism becomes impossible; an instance of a class may no longer be used where
an instance of a superclass is allowed. Changing attribute representations also cancels the
beneﬁts of code sharing provided by inheritance. 

If tailoring is allowed, one must be wary of developing a collection of disorganized
classes. Exceptions should not only be accommodated, but also integrated into the type
hierarchy when they become too numerous to be considered as special cases [10]. Unfor-
tunately, the techniques we have described in this section do not really help detect design
ﬂaws in object descriptions. 

206

Managing Class Evolution in Object-Oriented Systems

8.3 Class Surgery

8.3.1 Issues

Whenever changes are brought to the modelling of an application domain, corresponding
modiﬁcations  must  be  applied  to  the  classes  representing  real-world  concepts. These
operations disturb a class hierarchy much more profoundly than tailoring: instead of over-
riding some inherited properties when new subclasses are deﬁned, the structure of existing
classes themselves must be revised. Because of the multiple connections between class
descriptions, care has to be taken so that the consistency of the hierarchy is guaranteed. 

This problem also arises in the area of object-oriented databases, where it has been ex-
tensively  investigated  [3][4][27][32][35].  There,  the  available  methods  determine  the
consequences of class changes on other deﬁnitions and on existing instances, as well, so
that possible integrity violations can be avoided. These methods can be broken down into
a number of steps: 

1. The ﬁrst step consists of determining a set of integrity constraints that a class col-
lection must satisfy. For example, all instance variables should bear distinct names,
no loops are allowed in the hierarchy, and so on. 

2. A taxonomy of all possible updates is then established. These changes concern the
structure of classes, like “add a method”, or “rename a variable”; they may also re-
fer to the hierarchy as whole, as with “delete a class” or “add a superclass to a class”.
3. For each of these update categories, a precise characterization of its effects on the
class hierarchy is given and the conditions for its application are analyzed. In gen-
eral, additional reconﬁguration procedures have to be applied in order to preserve
schema invariants. It is for example illegal to delete an attribute from a class C if this
attribute is really inherited from a superclass of C. If the attribute can be deleted, it
must also be recursively dropped from all subclasses of C.

4. Finally, the effects of schema changes are reﬂected on the persistent store; instances

belonging to modiﬁed classes are converted to conform to their new description. 

We base our discussion on class surgery mainly on the research performed around the
object-oriented database systems GemStone, ORION, O2 and OTGen, although evolu-
tionary capabilities based on this technique have been proposed for many other systems.
We defer the description of instance conversion techniques to the section on change prop-
agation. 

8.3.2 Schema Invariants

Every class collection contains a number of integrity constraints that must be maintained
across schema changes. These constraints, generally called schema invariants in the liter-
ature, impose a certain structure on class deﬁnitions and on the inheritance graph. 

Class Surgery

207

• Representation invariant. This constraint states that the properties of an object (at-

tributes, storage format, etc.) must reﬂect those deﬁned by its class. 

• Inheritance graph invariant. The structure deriving from inheritance dependencies
is restricted to form a connected, directed acyclic graph (so that classes may not re-
cursively inherit from themselves), possibly restricted to be a tree, and having as root
a special predeﬁned class usually called OBJECT. 

• Distinct name invariant. All classes, methods and variables must be distinguished by

a unique name. 

• Full inheritance invariant. A class inherits all attributes from its superclasses, except
those that it explicitly redeﬁnes. Naming conﬂicts occurring because of multiple in-
heritance are resolved manually, or by applying some default precedence scheme. 
• Distinct origin invariant. No repeated inheritance is admissible in ORION and O2: an
attribute inherited several times via different paths appears only once in a class rep-
resentation. 

• Type compatibility invariant. The type of a variable (or of a method argument) rede-
ﬁned in a subclass must be consistent with its domain as speciﬁed in the superclass.
In all systems this means that the new type must be a subclass of the original one. 

• Type variable invariant. The type of each instance variable must correspond to a

class in the hierarchy. 

• Reference consistency invariants. GemStone guarantees that there are no dangling
references to objects in the database; instances can only be deleted when they are no
longer accessible. OTGen requires that two references to the same object before
modiﬁcation also point to the same entity after modiﬁcation.

Schema invariants supported by four object-oriented database systems are summarized

in table 8.1. 

8.3.3 Primitives for Class Evolution

Updates to a schema are assigned to a relevant category in a predetermined taxonomy.
Every deﬁnition affected by these modiﬁcations must then be adjusted. If the invariant
properties of the inheritance hierarchy cannot be preserved, the transformation of the class
structure is rejected. Schema evolution taxonomies are compared in table 8.2. 

• The insertion of an attribute, whether it is a variable or a method, is an operation that
must be propagated to all subclasses of the class where it is initially applied, in order
to preserve the full inheritance invariant. When a naming or a type compatibility con-
ﬂict occurs, or when the signature of the new method does not match the signature of
other methods with the same name related to it via inheritance, one either disallows
the operation (as in O2 and GemStone), or resorts to conﬂict resolution rules. In all
systems, instances of all modiﬁed schemas are assigned an initial value for their ad-
ditional variables that is either speciﬁed by the user or the special nil value.

208

Managing Class Evolution in Object-Oriented Systems

Schema invariants 

GemStone

Representation 

Inheritance graph 

Distinct name 

Full inheritance 

Distinct origin 

Type compatibility 

Type variable 

Reference consistency 











O2











ORION

OTGen























Table 8.1

Schema invariants of four object-oriented database systems. Some 
constraints (like the representation invariant) are implicit in most models. 

• Deleting an attribute is allowed only if the variable or method is not inherited. Be-
cause of the full inheritance and representation invariants, the attribute must also be
dropped from all subclasses of the definition where it is originally deleted. If a sub-
class, or the class itself, inherits another variable or a method with the same name
through another inheritance path, this new attribute replaces the deleted one. Of
course, all instances lose their values for deleted attributes. O2 forbids the suppres-
sion of attributes if the operation results in naming conﬂicts or in type mismatches
with other attributes. 

• Attribute renaming is forbidden if the operation gives rise to ambiguities in the class

or in its subclasses, or, in GemStone, if the attribute is inherited. 

• The type of a variable (or of a method argument) can rarely be arbitrarily modiﬁed
because of the subtype relations imposed by the compatibility invariant. In ORION
and GemStone, the domain of a variable can be generalized. GemStone also allows a
variable to be specialized, except if the new domain causes a compatibility violation
with a redeﬁnition in a subclass. Operations that are neither specializations nor gen-
eralizations are not supported; moreover, type changes are not propagated to sub-
classes. Instances violating new type constraints have their variables reset to nil. 

• Properties like the default value of a variable or the body of a method can also be
modiﬁed. Changing the origin of an attribute is an operation supported only in ORI-
ON. It serves to override default inheritance precedence rules and is logically han-
dled as a suppression followed by the insertion of an attribute. In addition, ORION
provides operations to update shared variables and special aggregation links. 

• Adding a class to an existing hierarchy is a fundamental operation for object-oriented
programming, and, as such, it appears in all systems examined here. Connecting a

Class Surgery

Scope of change 
Instance variables
add a variable
remove a variable
rename a variable
redeﬁne the type of a variable
change the inheritance origin
change the default value
modify other kinds of variables

Methods

add a method
remove a method
rename a method
redeﬁne the signature
change the code
change the inheritance origin

Classes

add a class
remove a class
rename a class
modify other class properties

Inheritance links

add a superclass to a class
remove a superclass
change superclass precedence

GemStone















O2





























209

ORION





































Table 8.2   A comparison of schema evolution taxonomies. 

new  class  to  the  leaves  of  a  hierarchy  is  trivial  —  possible  conﬂicts  caused  by
multiple inheritance are solved with standard precedence rules. GemStone allows for
inserting a class in the middle of an inheritance graph, provided the new class does
not initially deﬁne any property: this basic template may be subsequently augmented

210

Managing Class Evolution in Object-Oriented Systems

by applying the attribute manipulation primitives described in the preceding pages.
With O2, a new class may be connected to only one superclass and one subclass ini-
tially. The deﬁnition must specify how inherited attributes are superseded, and these
redeclarations must comply with subtyping compatibility rules. 

• Removing a class causes inheritance links to be reassigned from the class’s super-
classes to its subclasses. All instance variables that have the deleted class as their type
are assigned the suppressed class’s superclass as their new domain. GemStone as-
sumes that a class which is being discarded no longer deﬁnes any property and that
no associated instances exist in the database. O2 forbids class deletion if it results in
dangling references in other deﬁnitions, if instances belonging to the class still exist,
or if the deletion leaves the inheritance graph disconnected. 

• Renaming a class is allowed only if the new identiﬁer is unique among all class
names in the inheritance hierarchy. As with attributes, each object model may deﬁne
supplementary class properties, such as the indexable classes in GemStone, and their
corresponding manipulation primitives. 

• Adding a superclass to a schema is illegal if the inheritance graph invariant cannot be
preserved. In particular, no circuits may be introduced in a hierarchy. The conse-
quences of this operation are analogous to those of introducing attributes in a class.
• The deletion of a class S from the list of superclasses of a class C must not leave the
inheritance graph disconnected. O2 provides a parameterized modiﬁcation primitive
that enables the programmer to choose where to link a class that has become com-
pletely disconnected from the inheritance graph (by default, it is connected to OB-
JECT). One may also specify whether the attributes acquired through the suppressed
inheritance link are preserved and copied to the deﬁnition of C. In most other sys-
tems, if S is the unique superclass of C, inheritance links are reassigned to point from
the immediate superclasses of S to C. In the other cases, C just loses one of its super-
classes;  no  redirection  of  inheritance  dependencies  is  performed.  Of  course,  the
properties of S no longer pertain to the representation of C, nor to those of its sub-
classes. The primitives for suppressing attributes from a class are applied to convert
the deﬁnition of all classes and instances affected by this change. 

• Reordering inheritance dependencies results in effects similar to those of changing

the precedence of inherited attributes. 

8.3.4 Completeness, Correctness and Complexity

Three issues have to be addressed to ensure that class surgery captures interesting capabil-
ities: 

• Completeness: does the set of proposed operations actually cover all possibilities for

schema modiﬁcations? 

• Correctness: do these operations really generate class structures that satisfy all integ-

rity constraints? 

Class Surgery

211

• Complexity: is it possible to detect violations of schema invariants and subsequently

regenerate a schema conforming to these invariants in an efﬁcient way? 

The ﬁrst two problems have been studied in the context of the ORION methodology,
where it has been demonstrated that a subset of its class transformation primitives exhibits
the desired qualities of completeness and, partially, of correctness. In contrast, the Gem-
Stone approach does not strive for completeness; only meaningful operations that can be
implemented without undue restrictions or loss of performance are provided. An interest-
ing result is provided by the O2 approach, where it is shown that although a set of basic up-
date operations may be complete at the schema level (i.e. all changes to a class hierarchy
can be derived from a composition of these essential operations), this same set may not be
complete at the instance level, when changes are carried out on objects and not on classes.
For example, renaming an attribute is equivalent to deleting the attribute and then reintro-
ducing it with its new name; if the same sequence of operations is applied to a variable of
an object, the information stored in the attribute is lost. 

Ensuring correctness of class changes is much more difﬁcult than it appears at ﬁrst
sight. Since a method implementation may depend on other methods and variables, one
cannot consider the deletion of one attribute in isolation. This operation may have far-
reaching consequences if an attribute is excluded from a class interface. Similarly, intro-
ducing a new method in a class may raise problems because the code of the method may
refer to attributes that are not yet present in the class deﬁnition and because of implicit
changes in the scope of attributes. If the method supersedes an inherited routine, sub-
classes referring to the previous method may become invalid. Not surprisingly, maintain-
ing  behavioural  consistency  across  schema  changes  is  an  undecidable  problem  [39].
Dataﬂow analysis techniques, like those that are used by some compilers to check for type
violations in object-oriented programs, can help detect the parts of the code that become
unsafe because of schema updates, but they are typically pessimistic and might reject legal
programs as incorrect [14]. Enriching the set of schema invariants to detect more (seman-
tical) inconsistencies requires careful selection to avoid turning an efﬁcient test procedure
for constraint satisﬁability into an NP, or even an undecidable problem [26][39]. As a con-
sequence, all aforementioned systems capture relatively simple structural constraints with
their schema invariants and give little support to update methods upon class alterations
[41]. 

8.3.5 Evaluation

Decomposing all class modiﬁcations into update primitives and determining the conse-
quences of these operations has several advantages. During class design, this approach
helps developers detect the implications of their actions on the class collection and main-
tain consistency within class speciﬁcations. During application development, it guides the
propagation of schema changes to individual instances. For example, renaming an in-
stance variable, changing its type or specifying a new default value usually has no impact
on an application using the modiﬁed class. Introducing or discarding attributes (variables

212

Managing Class Evolution in Object-Oriented Systems

or methods), on the other hand, generally leads to changes in programs and requires the
reorganization of the persistent store — although the conversion procedure can be de-
ferred in some situations. 

Depending on its modelling capabilities and on the integrity constraints, an object-
oriented programming environment may provide different forms of class surgery. It is
easy to envision a system where class deﬁnitions are ﬁrst retrieved with a class browser
and then modiﬁed with a structured editor where each editing operation corresponds to a
schema manipulation primitive like those of ORION or GemStone [32]. Such an environ-
ment would nevertheless fall short of providing fully adequate support for the design and
evolution processes. Class surgery forms a solid and rigorous framework for deﬁning
“well-formed” class modiﬁcations. In this respect, it improves considerably over uncon-
trolled manipulations of class hierarchies that are more or less the rule with current object-
oriented programming environments. But, it limits its scope to local, primitive kinds of
class evolution. It gives no guidance as to when the modiﬁcations should be performed
and does not deal with the global management of multiple, successive class changes car-
ried out during software development. 

8.4 Class Versioning

8.4.1 Issues

Ensuring that class modiﬁcations are consistent is not enough; they must also be carried
out in a disciplined fashion. This is of utmost importance in environments where a number
of programmers collectively reuse and adapt classes developed by their peers made avail-
able in a shared repository of software components. The early experiences with the Small-
talk  system  demonstrated  that  the  lack  of  a  proper  methodology  for  controlling  the
extensions and alterations brought to the standard class library quickly resulted in a disas-
trous situation. The incompatibilities between variants of the same class hierarchy were
sufﬁcient to hinder the further exchange of software, or at least to severely reduce its port-
ability. 

In the case of single-user environments, the exploratory way of programming advoca-
ted by the proponents of the object-oriented approach requires some support so that soft-
ware  developers  may  correct  their  mistakes  by  reverting  to  a  previous  stable  class
conﬁguration. When experimenting with several variants of the same class, to test the ef-
ﬁciency of different algorithms, for example, care has to be taken to avoid mixing up class
deﬁnitions and dependencies. 

Because adhoc techniques do not scale well for large, distributed programming envi-
ronments, current approaches favour a structured organization of software development
and a tighter control of evolution based on class versioning. Versioning basically consists
in checkpointing successive and in principle consistent states of a class structure. The cre-
ation and manipulation of versions raises complex issues: 

Class Versioning

213

• How is version management organized with respect to software development? 
• How does one distinguish between different versions of the same class? 
• What are the circumstances that justify the creation of new versions, and how is this

operation carried out? 

• What can be done to handle the relations between different and perhaps incompatible

versions? 

8.4.2 The Organization of Version Management

An environment for version management is divided into several distinct working spaces,
each one providing a speciﬁc set of privileges and capabilities for manipulating different
kinds of versions [15][24]. Three such domains are generally recognized in the literature: 
• A private working space supports the development activities of one programmer. The
information stored in the programmer’s private environment, in particular the soft-
ware components he or she is currently designing or modifying, is not accessible to
other users. 

• All classes and data produced during a project are stored in a corresponding domain
that is placed under the responsibility of a project administrator. They are made avail-
able to all people cooperating in the project, but remain hidden from other users,
since they cannot yet be considered as tested and validated. 

• A public domain contains all released classes from all projects, as well as data on

their status. This information is visible to all users of the system. 

It is natural to associate one kind of version with each working space: 
• Released versions appear in the public domain. They are considered immutable and
can therefore neither be updated nor deleted, although they may be copied and give
rise to new transient versions. 

• Working versions exist in project domains and possibly private domains. They are
considered stable and cannot be modiﬁed, but they can be deleted by their owner, i.e.
the project administrator or the user of a private domain. Working versions are pro-
moted to released versions when they are installed in the public repository; they may
give rise to new transient versions. 

• A transient version is derived from any other kind of version. It belongs to the user
who created it and it is stored in his or her private domain. Transient versions can be
updated, deleted and promoted to working versions.

The principal characteristics of version types are summarized in table 8.3.
A typical scenario begins when a project is set up to build a new application. The pro-
grammers engaged in the development, copy from the public repository class deﬁnitions
they want to reuse or modify for the project. These deﬁnitions are added to their private en-
vironments as transient versions. Each programmer individually updates these classes and
perhaps creates other deﬁnitions (via usual subclassing techniques) in the domain as addi-

214

Managing Class Evolution in Object-Oriented Systems

Characteristics of version types 

Transient 

Working 

Released 

Location

public domain 

project domain 

private domain 

Admissible operations 

update 

delete 

Origin 















from a transient version by 

derivation

promotion

from a working version by 

from a released version by 

derivation

derivation

promotion

Table 8.3 Principal characteristics of version types. Some systems consider only two 
kinds of versions (transient and released) and two levels of domains (private 
and public) for managing their visibility. 

tional transient versions. In order to try different designs for the same class, or to save the
result of the programming activity, programmers may derive new transient versions from
those they is currently working on, while simultaneously promoting the latter to working
versions. When a programmer achieves a satisfactory design for a software component, he
or she installs it as a working version in the project domain. Of course, these working ver-
sions can subsequently be copied by colleagues and give rise to new transient versions in
their respective environments. Once software components have reached a good stage of
maturity in terms of reliability and design stability, they are released by the project admin-
istrator and made publicly available in the central repository.

Since all operations for version derivation and freezing are done concurrently, careful
algorithms are required to ensure that the system remains consistent. Fortunately, all up-
dates are applied to local, transient objects, and not directly to global, shared deﬁnitions.
As a consequence, concurrency control does not have to be as elaborate as traditional
database transaction mechanisms and can use simpler checkin/checkout or optimistic
locking techniques.

Class Versioning

215

8.4.3 Version Identiﬁcation

Class identity is an essential problem to deal with. It is no longer enough to refer to a soft-
ware component by its name, since it might correspond to multiple variants of the same
class. An additional version number, and possibly a domain name, must be provided to
identify a component unambiguously [24]. When the version number is absent from a ref-
erence, a default class is assumed. Typical choices for resolving the dynamic binding of
version references include: 

• The very ﬁrst version of the class referred to. 
• Its most recent version. The idea behind this decision is that this version can be con-
sidered the most up-to-date deﬁnition of a class. This is a good solution to bind ver-
sion references in interactive queries in object-oriented databases. 

• Its most recent version at the time the component which made the reference was cre-
ated. This is the preferred option for dealing with dynamic references in class deﬁni-
tions. 

• A default class deﬁnition speciﬁed by the administrator in charge of the domain. This
deﬁnition, called a generic version, can be coerced to be any element in a version der-
ivation history. 

The default version is ﬁrst searched for in the domain where the reference is initially
discovered to be unresolved; the hierarchy of domains is then inspected upward until the
appropriate deﬁnition is found. Thus, to bind an incomplete reference to a class made in a
project domain (i.e. a reference consisting only in the class name, without additional in-
formation), the system ﬁrst examines the class hierarchy in the current domain; if this do-
main does not contain the class deﬁnition referred to, the search proceeds in the public
repository. No private domain is inspected, for stable versions are not allowed to refer to
transient versions that could be in the process of being revised. Similarly, dynamic refer-
ences to classes in the public domain cannot be resolved by looking for unreleased com-
ponents in a project domain. Naturally, dynamic binding can be resolved at the level of a
private domain for all classes pertaining to it. 

If only the most recent version gives rise to new versions, there is in principle no need
for a complex structure to keep track of the history of classes: their name and version
number sufﬁce to determine their relationship to each other. The situation where version-
ing is not sequential, i.e. where new versions derive from any previous version, requires
that the system record a hierarchy of versions somewhat similar to the traditional class
herarchy. When a version is copied or installed in a domain, the programmer decides
where to connect it in the derivation hierarchy. AVANCE provides an operation to merge
several versions of the same class. With this scheme, the derivation history takes the form
of a directed acyclic graph [8]. 

The information on derivation dependencies is generally associated with the generic
version of a class version set. Version management systems like IRIS and AVANCE im-
plement a series of primitives for traversing and manipulating derivation graphs [5][8].
Programmers can thus retrieve the predecessors and the successors of a particular version;

216

Managing Class Evolution in Object-Oriented Systems

obtain the ﬁrst or the most recent version of a class on a particular derivation path; query
their status (transient, released, date of creation, owner); determine which version was val-
id at a certain point in the past and bind a reference to it; freeze or derive new versions, etc. 
The management of versions and related data obviously entails a signiﬁcant storage and
processing overhead. This is why in most systems one is required to explicitly indicate that
classes are versionable by making them subclasses of a special class from which they in-
herit their properties of versions — that is often called Version, as in AVANCE and IRIS. 

8.4.4 Versioning and Class Evolution

It is evidently impossible to delegate full responsibility to the system for determining
when a transient version should be frozen and a new transient one created, or if a compo-
nent should be released. Such actions must be based on design knowledge that is best mas-
tered  by  the  software  developers  themselves.  Thus,  the  automatic  generation  of  new
versions triggered by update operations on object deﬁnitions is a scheme that has found
limited application in practice. 

Another difﬁculty arises because of the superimposition of versioning on the inherit-
ance graph. For example, when creating a new variant for a class should one derive new
versions for the entire tree of subclasses attached to it as well? A careful analysis of the
differences between two successive versions of the same class gives some directions for
handling this problem [8]. 

• If the interface of a class is changed, then new versions should be created for all class-
es depending on it, whether by inheritance (i.e. its subclasses) or by delegation (i.e.
classes containing variables whose type refers to the now modiﬁed deﬁnition). 

• If only non-public parts are changed, like the methods visible only to subclasses
(such methods are called “protected methods” in C++), the type of its variables, or its
inheritance structure, then versioning can be limited to its existing subclasses. 

• If only method implementations are changed, no new versions for other classes are
required; this kind of change is purely internal and does not affect other deﬁnitions. 
For reasons analogous to those exposed above, some approaches prefer to avoid intro-
ducing a possibly large number of new versions automatically and rely instead on a man-
ual procedure for re-establishing the consistency of the inheritance hierarchy. The users
whose  programs  reference  the  class  that  has  been  updated  are  simply  notiﬁed  of  the
change and warned that the references may be invalid. Two strategies are commonly
adopted to do this: either a message is directly sent to the user, or the classes referencing
the modiﬁed object deﬁnition are tagged as invalid. In the latter case, class version time-
stamps are frequently used to determine the validity of references [15]. Thus, a class
should never have a “last modiﬁcation” date that exceeds the “approved modiﬁcation”
date of the versions referring to it. When this situation occurs, the references to the class
are considered inconsistent, since recent adaptations have been carried out on the compo-
nent, but have not yet been acknowledged on its dependent classes. It is up to the program-

Class Versioning

217

mer to determine the effects of the class changes on other deﬁnitions and to reset the
approved revision timestamp to indicate that the references have become valid again. 

Building consistent conﬁgurations of classes and instances, and maintaining compati-
bility between entities belonging to different versions is a major issue and an object-
oriented system should provide support for dealing with this aspect of version manage-
ment. Application developers may want to view objects instantiated from previous class
versions as if they originated from the currently stable version, or they may want to pro-
hibit objects from older versions from referring to instances of future variants. We de-
scribe  in  more  detail  how  to  achieve  these  effects  in  the  section  devoted  to  update
propagation. 

8.4.5 Evaluation

Versioning is an appealing approach for managing class development and evolution. Re-
cording the history of class modiﬁcations during the design process has several beneﬁts.
It enables the programmer to try different paths when modelling complex application do-
mains and it helps avoid confusion when groups of people are engaged in the production
of a library of common, interdependent classes. Versioning also appears useful when
keeping track of various implementations of the same component for different software
environments and hardware platforms. Besides, the hierarchical decomposition of the
programming environment into workspaces, the attribution of precise responsibilities to
their administrators, and the possibilities afforded by this kind of organization (e.g. the
separation of the long-term improvement of reusable components from the short-term de-
velopment of new applications) are considered to be particularly valuable for increasing
the quality and efﬁciency of object-oriented programming [38]. 

The main drawback of versioning techniques resides in the considerable overhead they
impose on the development environment. Programmers have to navigate through two in-
terconnected structures, the traditional inheritance hierarchy and the version derivation
graph. They have to take into account a greater set of dependencies when designing a
class. The system must store all information needed for representing versions and their re-
ciprocal links, and implement notiﬁcation. Moreover, methods for version management
still lack some support for design tasks: at what point does a version stop being a variant
of an existing class to become a completely different object deﬁnition? 

In spite of their overhead, class and object versioning techniques have proved inval-
uable in important application domains like CAD/CAM, VLSI design and ofﬁce infor-
mation  systems.  They  have  therefore  been  integrated  into  several  object-oriented
environments, including Orwell [38], AVANCE [7], ORION [3] and IRIS [19]. 

218

Managing Class Evolution in Object-Oriented Systems

8.5 Class Reorganization

8.5.1 Issues

The lessons drawn from the construction of collections of reusable classes have led to the
formulation of some principles that serve to improve object-oriented libraries [22]. 

The ﬁrst principle is to make sure that components are really polymorphic. This can be

achieved in a number of ways:

• Adopt a uniform terminology for related classes and standardize the methods mak-

ing up their interface [31]. 

• Eliminate code that explicitly checks the type of an object. Rather than introducing
case statements to execute some actions on the basis of an object’s class, one should
invoke a standard message in the object and let it carry out the appropriate actions. 
• Decrease the number of arguments in a method, either by splitting the method into
several simpler procedures, or by creating a class to represent a group of arguments
that often appear together. A method with a reduced number of parameters is more
likely to bear a signature similar to some other method in a different class. Both meth-
ods may then be given the same name, thus increasing interface standardization. 

A second set of rules aims to increase the degree of abstraction and generality of class-

es: 

• Factorize behaviour common to several classes into a shared superclass. Introduce
abstract classes (with deferred methods) if convenient, to avoid attribute redeﬁni-
tions. 

• Minimize the accesses to variables to reduce the dependency of methods on the in-
ternal class representation [29]. This can be achieved by resorting to special acces-
sors instead of referring directly to variables. 

• Ensure that inheritance links express clear semantic relationships such as specializa-
tion, or even better, relationships with known mathematical properties like conform-
ance or imitation [40]. 

Finally, reorganizations should improve the modularization of functionality in a li-

brary: 

• Split large classes into smaller, cohesive classes that are more resilient to change.
• Separate groups of methods that do not interact. Such sets of methods represent
either totally independent behaviour or different views of the same object, which are
perhaps better represented by distinct classes. 

• Uncouple methods from global attributes or internal class properties by sending mes-

sages to parameters instead of to self or to instance variables. 

These guidelines are very general; the problem is therefore to formulate these empirical

rules rigorously and to make them amenable to a subsequent automation. 

Class Reorganization

219

8.5.2 Refactoring

Issues and Techniques

8.5.2.1
Refactoring is an approach that extends basic class surgery primitives with advanced
redesign mechanisms [23]. Refactoring is based on an object model that is speciﬁcally
tailored to represent and manipulate the rich structure of components developed with an
object-oriented programming language. The schema invariants of class surgery are ex-
tended with additional constraints for preserving behaviour, and the preconditions for
modiﬁcation operations are made more precise or more restrictive to avoid introducing
behaviour and referential inconsistencies in a class collection. The approach proposed in
[34] is intended to support refactoring speciﬁcally for C++ libraries. Four important oper-
ations are discussed in detail. 

• Distributing the functionality of a class over multiple subclasses by splitting methods
along conditional statements. Let us consider a hypothetical class that checks the
rights of users to access a system during weekends and normal working days: 

class ACCESS-CONTROL

methods

CheckPrivileges

begin

-- some general code …
if date = Sunday or date = Saturday then
-- restricted access on week-ends …

else 

-- usual checks during normal working days …

end-if 

end CheckPrivileges; …

end; 

ACCESS-CONTROL is specialized in as many classes as there are branches in its
CheckPrivileges method; CheckPrivileges is itself decomposed so that, in each sub-
class, it contains only the code corresponding to one branch of the original condi-
tional statement. The common part of all CheckPrivileges variants is left in ACCESS-
CONTROL. 

class ACCESS-CONTROL

methods

CheckPrivileges

begin

-- some general code …

end CheckPrivileges; …

end;

class CONTROL-WEEK-END

inherit ACCESS-CONTROL;
methods

CheckPrivileges

begin

super.CheckPrivileges;

220

Managing Class Evolution in Object-Oriented Systems

-- restricted access on week-ends …

end CheckPrivileges; …

end; 

class CONTROL-WORKING-DAYS
inherit ACCESS-CONTROL;
methods

CheckPrivileges

begin

super.CheckPrivileges;
-- usual checks during normal working days …

end CheckPrivileges;

end;

• Creating an abstract superclass. This operation analyses two classes, extracts their
common properties, which are placed in a new component, and then makes both ini-
tial classes subclasses of the new deﬁnition. The extraction of similarities between
two classes is not performed automatically and relies on heuristics to detect common
structures in method signatures and implementations. Additional renaming of varia-
bles and methods, reordering of method parameters and transformations of method
implementations may be carried out to achieve a satisfactory result. However, con-
trary to the incremental reorganization algorithm described in section 8.5.4.3, refac-
toring does not propagate through the inheritance graph. 

• Transforming an inheritance relation into a part-of relation. The following example

shows a class SYMBOL-TABLE that inherits functionality from HASH-TABLE. 

class HASH-TABLE

methods 

Insert …
Delete …

end; 

class SYMBOL-TABLE

inherit HASH-TABLE; …
end;

Rather  than  being  a  subclass  of  HASH-TABLE,  SYMBOL-TABLE  can  refer  to  an
instance of HASH-TABLE via a part-of relation. This requires severing the inherit-
ance link between both classes, introducing a variable of type HASH-TABLE in SYM-
BOL-TABLE, and adding a series of procedures in SYMBOL-TABLE for delegating the
invocations of methods previously inherited from HASH-TABLE to this new variable.
In our simpliﬁed example, the refactoring does not change the superclass. In gen-
eral, it may be necessary to introduce special operations in the superclass to encap-
sulate accesses to its variables, and to change the methods declared in the subclass
so that they manipulate these variables through these operations. 

class SYMBOL-TABLE

variables
store
methods
 

Insert (…)

:

HASH-TABLE; …

Class Reorganization

221

begin

store.Insert (…);

end Insert;

Delete (…)
begin

store.Delete (…); 

end Delete; …

 
 
 
 

end;

• Reshufﬂing attributes among classes. This operation is intended to improve the de-
sign of classes representing aggregations, where a component of an aggregation can
only belong to or be referred to by one object. Redistributing variables denoting ag-
gregation  elements  in  a  behaviour-preserving  way  is  feasible  only  when  several
strong conditions on referencing patterns are satisﬁed. References to the migrated
variables are updated or replaced with invocations to appropriate accessors. 

Evaluation

8.5.2.2
Refactoring is one of the most interesting approaches for providing software developers
with high-level, intuitive operations supporting complex redesign activities. Refactoring
embodies some of the empirical guidelines derived from actual experience with class
evolution; it would therefore be appealing to integrate such a toolkit of operations in an
editing and browsing environment. This approach is not without limitations though; the
decision to carry out speciﬁc refactorings, the optimization goals and the selection of the
classes to modify are left entirely up to the programmer. Thus, refactoring exhibits the
same shortcomings as class surgery. The automatic approaches discussed in the following
sections are based on systematic strategies that are probably more adequate in the context
of large, complex libraries. As with any other restructuring method, refactoring faces in-
tractability problems when trying to achieve all possible transformations or to preserve
behaviour. For example, all interesting situations where a method could be split among
subclasses cannot be detected, and, in fact, the conditional expressions considered are
only of a very elementary nature. 

8.5.3 Restructuring Interattribute Dependencies

Issues

8.5.3.1
Avoiding unnecessary coupling between classes and reducing interattribute dependencies
are two important prerequisites for well-designed objects. Two major issues have to be ad-
dressed: 

• What are the inferior or “harmful” dependencies?
• How can unsafe expressions be automatically replaced with adequate constructs? 
A possible solution to this problem has been proposed by Lieberherr et al. [29] under
the name of “Law of Demeter”, together with a small set of techniques for mechanically
transforming object deﬁnitions so that they comply with this law [12]. 

222

Managing Class Evolution in Object-Oriented Systems

The Law of Demeter

8.5.3.2
The Law of Demeter distinguishes three types of interattribute dependencies and three
corresponding categories of relationships between class deﬁnitions: 

• A class C1 is an acquaintance class of method M in class C2, if M invokes a method
deﬁned in C1 and if C1 does not correspond to the class of an argument of M, to the
class of a variable of C2, to C2 itself, or to a superclass of the aforementioned classes. 
• A class C1 is a preferred-acquaintance class of method M in C2, if C1 corresponds to
the class of an object directly created in M or to the class of a global variable used in
M. 

• A class C1 is a preferred-supplier class of method M in C2, if M invokes a method
deﬁned in C1, and if C1 corresponds to the class of a variable of C2, or to the class of
an argument of M, to C2 itself, to a superclass of the aforementioned classes, or to a
preferred-acquaintance class of M. 

The “class form” of the law states that methods may only access entities belonging to
their preferred-supplier classes. The “object form” of the law does not consider the classes
a method depends on, but rather the objects this method sends messages to. In this context,
a preferred-supplier object is an instance that is either a variable introduced by the class
where the method is deﬁned, or an argument passed to the method, or an object created by
the method, or the pseudo-variable self (identifying the object executing the method). The
“object form” of the law prohibits references to instances that are not preferred-suppliers
of a method. In its weak version, the law considers the classes of inherited variables (or the
variables themselves, in the “object form” of the law) as legitimate preferred-suppliers.
The strict version does not consider the classes of inherited variables (or inherited varia-
bles) as legitimate preferred-suppliers. 

8.5.3.3 Application and Examples
We illustrate the main reorganization aspects dealt with by the Demeter approach for a
group of simple object descriptions [12][29]. Let us consider the following partial class
deﬁnitions: 

class LIBRARY 
variables

Catalog

methods 

:

CATALOG; …

Search-book (title : STRING) returns LIST [BOOK] 

begin 

:

LIST [BOOK]; 

books-found
books-found := Catalog.Microﬁches.Search-book (title); 
books-found.Merge (Catalog.Optical-Disk.Search-book (title));
return (books-found); 

end Search-book; …

end; 

class CATALOG
variables

Optical-Disk

:

CD-ROM; 

Class Reorganization

223

Microﬁches

end; 

class CD-ROM 
variables 

Book-References

methods

:

:

MICROFICHE; …

FILE [BOOK]; …

Search-book (title : STRING) returns LIST [BOOK]

begin

BOOK; 
LIST [BOOK]; 

:
:

book
books-found
books-found.New (); 
Book-References.First (); 
loop 

exit when Book-References.End (); 
book := Book-References.Current (); 
if title.Equal (book.Title) then 
books-found.Add (book) 

end-if; 
Book-References.Next (); 

end loop; 
return (books-found); 

end Search-book; …

end; 

class MICROFICHE 

variables

Book-References

:

FICHES [BOOK]; …

methods

Search-book (title : STRING) returns LIST [BOOK] …

end; 

class BOOK 

variables 
Title

end; 

:

STRING; …

These  deﬁnitions  obviously  do  not  conform  to  the  law:  the  method  Search-book in
LIBRARY accesses internal components of Catalog (the attributes Microﬁches and Optical-
Disk); it sends messages to these variables and receives as a result objects that are neither
components of LIBRARY nor instances of a preferred-supplier class of LIBRARY. We also
note that the algorithm for retrieving all references stored on the optical disk manipulates
the internal structure of books to ﬁnd whether their title matches a speciﬁc search criterion. 
It is clear that the details of scanning microﬁche and CD-ROM ﬁles to ﬁnd a particular
reference should be delegated to the CATALOG class. This makes the querying methods of
LIBRARY immune to alterations in the internal structure of the catalogue — for example
the replacement of the microﬁches with an additional CD-ROM ﬁle. In doing so, we have
to take care that LIST [BOOK], the type of the result of methods Search-book in MICROFICHE
and CD-ROM, is not a preferred-supplier of CATALOG. The introduction of the auxiliary
method Merge-refs in CATALOG solves this problem and makes the dependency between
classes CATALOG and LIST [BOOK] explicit. Finally, ensuring the proper encapsulation of

224

Managing Class Evolution in Object-Oriented Systems

BOOK objects requires that their variables be manipulated through special-purpose acces-
sors; CD-ROM is adjusted accordingly. 

class LIBRARY
variables

Catalog

methods 

:

CATALOG; …

Search-book (title : STRING) returns LIST [BOOK]

begin

return (Catalog.Search-book (title)); 

end Search-book; …

end;

class CATALOG
variables

Microﬁches
Optical-Disk

:
:

MICROFICHE;
CD-ROM; …

methods

Search-book (title : STRING) returns LIST [BOOK]

begin

return (self.Merge-refs (Microﬁches.Search-book (title),
Optical-Disk.Search-book (title)));

 

end Search-book; 

Merge-refs (microﬁche-refs : LIST [BOOK]; cd-rom-refs : LIST [BOOK])

returns LIST [BOOK]
begin

return (microﬁche-refs.Merge (cd-rom-refs));

end Merge-refs; …

end; 

class CD-ROM
variables

Book-References

:

FILE [BOOK]; …

methods

Search-book (title : STRING) returns LIST [BOOK]

begin

LIST [BOOK];

:

books-found
books-found.New ();
Book-References.First ();
loop

exit when Book-References.End ();
if title.Equal (self.RefTitle (Book-References.Current ()))
then books-found.Add (Book-References.Current ());
end-if;
Book-References.Next ();

end loop;
return (books-found); 

end Search-Book;

RefTitle (reference : BOOK) returns STRING

begin

return (reference.Get-Title);

Class Reorganization

225

end GetRefTitle; …

:

STRING; …

end;

class BOOK

variables
Title
methods

Get-Title returns STRING

begin

return (Title);

end Get-Title; …

end;

Evaluation

8.5.3.4
The  Law  of  Demeter  nicely  captures  some  issues  dealing  with  encapsulation  and
coupling; although a fully formal model that would mathematically justify its underlying
assumptions is still lacking [36], its application to the design of modular class libraries has
been found to be beneﬁcial [29]. However, putting the Law of Demeter into practice raises
several difﬁculties [36]. It cannot be completely enforced with languages, such as CLOS
or Smalltalk, that allow expressions to be constructed dynamically and then executed at
run-time. In general, the “class form” of the law does not seem to be fully effective for un-
typed languages; since objects are untyped, violations of the law cannot be discovered by
a static inspection of the source code, but must be monitored during program execution. 
As far as typed languages are concerned, applying the Demeter principles is not always
straightforward either. First, there are some special cases where the spirit of the Law of
Demeter is violated, although all the dependencies formally respect all the Demeter rules
stated in section 8.5.3.2. Fortunately, such anomalies are rare and occur only in very con-
trived situations. More importantly, the law requires signiﬁcant enhancements and refor-
mulation to handle language peculiarities correctly; for example, translating the law of
Demeter into equivalent terms for C++ is far from trivial, because of the hybrid model of
this language and the need to take constructs like friend functions into account. 

8.5.4 Restructuring Inheritance Hierarchies

Issues

8.5.4.1
A frequent problem during the design of inheritance hierarchies is that programmers over-
look intermediate abstractions needed for establishing clean subclassing dependencies,
and develop components too specialized to be effectively reusable. Several approaches
have been proposed to automate the detection and correction of such defects in inheritance
hierarchies. They are distinguished by the way they address a few fundamental issues: 

• What is the scope of the reorganization applied to an inheritance graph?
• What are the criteria driving the reorganization?
• What properties are preserved across reorganizations?

226

Managing Class Evolution in Object-Oriented Systems

c1

AX

(1)

c4

BC

c2

AX

c3

ABFX

c5

ABCDX

c6

ABCEX

(2)

c1

AX

(3)

c2

AX

x3

B

c2

AX

x1

ABX

x1

ABX

c4

BC

c3

ABFX

x2

ABCX

c3

ABFX

x2

ABCX

c5

ABCDX

c6

ABCEX

c5

ABCDX

c6

ABCEX

Figure 8.1 Reorganizing a redundant, non-connected hierarchy (1); capital letters 
represent attributes. (2): after applying the Demeter algorithm; (3): after 
applying the algorithm described in [12]. Class c2 is the concrete 
counterpart of abstract class c1; similar deﬁnitions are merged in (3), but not 
in (2). Class c4 is preserved in (3), but considered as superﬂuous in (2).

The differences between inheritance reorganization methods are best summarized by

grouping these approaches into global and incremental reorganization techniques.

8.5.4.2 Global Reorganization
Global reorganization approaches produce optimal inheritance graphs, without attribute
redundancy and with a minimum number of classes and inheritance links, from pre-exist-
ing hierarchies (ﬁgure 8.1). These techniques can be fully automated. They work globally,
analyzing and recasting an entire class collection at a time. 

The approach proposed in the context of the Demeter project is based on a formalism
that distinguishes between abstract classes, which can be inherited but not instantiated,
and concrete classes, which can be instantiated but cannot be used as superclasses. Classes
correspond to the vertices in a graph. The edges of the graph denote either inheritance re-
lationships between classes, or part-of relationships between classes and their (typed) at-
tributes [28]. This model forms the basis for global reorganization algorithms whose goal

Class Reorganization

227

is to optimize the structural characteristics of an inheritance graph (i.e. to minimize the
number of classes and relations in a library). Redeﬁnitions and attribute structures are not
taken into account. The formal properties of these algorithms have been investigated in de-
tail [28]: 

• Transforming a hierarchy to suppress redundant part-of edges, i.e. forcing classes to

inherit common attributes from a shared superclass, is in P. 

• Minimizing the overall number of edges is NP-complete. When the ﬁnal hierarchy is
actually a tree, efﬁcient (polynomial) algorithms exist for optimizing the hierarchy.
A different method is based on an object model that allows classes to inherit from con-
crete superclasses [12]. The corresponding algorithm proceeds by ﬂattening all class def-
initions present in a hierarchy, then factoring out common structures, relinking all class
deﬁnitions through inheritance, and ﬁnally eliminating redundant inheritance links and
auxiliary class deﬁnitions. Contrary to the Demeter approach, this algorithm does pre-
serve all deﬁnitions that actually differ in the library before the reorganization, it takes re-
deﬁnitions into account and it can be tailored to avoid repeated inheritance in the ﬁnal
hierarchy. 

None of the global algorithms deal with interattribute dependencies or with the preser-
vation of behavioural properties. Global algorithms do not always produce identical re-
sults because of their varying assumptions and goals — as is shown clearly in ﬁgure 8.1.

Incremental Reorganization

8.5.4.3
Adding a subclass is a major step in the development of an object-oriented library, war-
ranting an evaluation, and possibly an improvement of the hierarchy. The evaluation can
be restricted to the relationships between the new class and its superclasses, and the re-
organization can be limited to the location where the new class is introduced. The incre-
mental factorization algorithm proposed in [11] is driven by the analysis of redeﬁnition
patterns between a new class and its superclasses. It attempts to optimize the inheritance
graph within reason while keeping the disturbances to the original library to a minimum.
Behavioural properties can be maintained to a certain extent and classes present in the
hierarchy before the reorganization are not deleted [12]. The algorithm transforms a hier-
archy automatically to eliminate unwanted subclassing patterns, to pinpoint places requir-
ing redesign and to discover missing abstractions. It can take into account renaming and
structural transformations similar to those discussed in 8.5.2. 

The  incremental  reorganization  algorithm  extracts  the  properties  shared  by  several
classes and isolates them in a new, common superclass. Figure 8.2 shows a fragment of the
Eiffel library where class CIRCLE inherits from ELLIPSE. This subclassing operation is ac-
companied by a partial replacement of  ELLIPSE’s behaviour. Simultaneously,  CIRCLE
changes its superclass’s interface in a way that corresponds neither to a restriction (which
would be expected in a specialization relationship) nor to an extension (characteristic of
subtyping relationships). A transformation of the hierarchy eliminates this unnatural sub-
classing pattern by inserting an intermediate deﬁnition containing the properties common

228

Managing Class Evolution in Object-Oriented Systems

CLOSED_FIG

— additional 
operations

— interface

+ orientation 
+ big_side 
+ small_side

CLOSED_FIG

—  new operations
— common interface

— deferred: contains 

display, duplicate

ELLIPSE

Auxiliary class

— replaced methods: 

display contains, 
duplicate

— interface + radius

- small_side
- big_side
- orientation

CIRCLE

CIRCLE

ELLIPSE

— enhanced interface
— concrete methods

— enhanced interface
— concrete methods

Figure 8.2   Factorizing inheritance relationships.

(1)

AB

c1

(2)

AB

c1

ABC

c2

A

A

x3

x2

(3)

A

x3

AB

c1

ABC

c2

ABC

c2

ABCD

c3

AD

x1

AD

x1

ABCD

c3

ABCD

c3

ABCDE

c4

ADE

c4

ADE

c4

Figure 8.3 The new class c4 rejects attributes B and C from c3; this triggers an 

incremental reorganization of the hierarchy whose ﬁnal result is depicted in (3).

to both CIRCLE and ELLIPSE, and by making these two classes subclasses of the new aux-
iliary node. 

In more complex situations, the factorization propagates as high up in a hierarchy as is
needed to eliminate unwanted subclassing patterns and introduces auxiliary deﬁnitions

Class Reorganization

229

Additional auxiliary classes

180

120

60

User interface,

graphics

Cursors

Data 

structures

Introduced classes

100

200

300

400

500

Figure 8.4 Restructuring the Eiffel 2.3 library. A few groups of classes responsible for 

clustered reorganizations are highlighted. Overall, the incremental 
factorization of Eiffel 2.3 adds 166 auxiliary deﬁnitions to the library. 

along the way. A last simpliﬁcation phase suppresses redundant auxiliary nodes and links
(ﬁgure 8.3). 

8.5.4.4 Application of Incremental Reorganization
The incremental reorganization algorithm of [11] is one of the rare approaches whose
effectiveness has been quantitatively assessed on the basis of large-scale experiments
involving the reorganization of versions 2.1 and 2.3 of the Eiffel library (98 and 500 class-
es respectively). Starting from an empty hierarchy, Eiffel classes were added one by one
to  the  library,  triggering  incremental  reorganizations  whenever  redeﬁnition  patterns
amounting to the rejection of inherited methods were detected (ﬁgure 8.4). This study
brought to light several interesting results [13]:

• A large majority (63%) of the problems uncovered by the reorganization algorithm
were caused by the utilization of inheritance for code sharing and by an inadequate
modularization of functionality leading to other improper subclassing relationships.

• In 21% of the cases, the outcome of the reorganization corresponds to what one
would expect from a manual redesign of the library. The restructuring patterns of the
incremental  algorithm  closely  match  empirical  observations  on  the  evolution  of
object-oriented libraries [2], as well as small-scale reorganizations of a limited sub-
set of the Smalltalk hierarchy [17]. 

230

Managing Class Evolution in Object-Oriented Systems

• In 33% of the cases, the incremental algorithm detects, but is not able to correct,
many actual design problems in a library that are best solved by other kinds of re-
organizations, such as transforming inheritance links into part-of relationships. 

• The algorithm is also useful for evaluating and comparing the quality of object-
oriented libraries, especially when it is combined with other incremental techniques
that are sensitive to naming patterns [13]

Evaluation

8.5.4.5
Global reorganizations are a prerequisite when the goal is to put a hierarchy into a “normal
form” free from redundancy. However, global revisions may thoroughly transform a li-
brary. The results are therefore difﬁcult to grasp and to utilize, particularly with libraries
comprising hundreds of classes. Incremental factorization, on the other hand, limits its
scope to the inheritance paths leading to one new class — an approach that also guarantees
better performance in an interactive environment. Besides, it is doubtful that a global re-
organization can achieve signiﬁcant results without additional processing to extract the
structural  similarities  between  class  interfaces  or  method  signatures  that  are  hidden
because of diverging naming and programming conventions [31][34]. Maintaining behav-
ioural  properties  is  a  problem  with  both  global  and  incremental  reorganizations
[6][12][39] and, anyway, many design problems cannot be solved through adjustments of
subclassing relationships alone. Inheritance reorganization techniques must therefore be
enhanced with other methods such as refactoring to support redesign activities effectively.
Automatic approaches are nevertheless essential to reduce the search space for redesign
operations on large libraries to a manageable size before applying interactive, user-driven
surgery or refactoring operations. 

8.6 Change Avoidance

8.6.1 Conﬁning the Effects of Evolution

In principle, modiﬁcations of class speciﬁcations must be propagated to objects instanti-
ated on the basis of old deﬁnitions, so as to maintain the overall consistency of the system.
Nevertheless, in many cases instances need not be updated or enhanced when their class
is modiﬁed. Detecting when these situations arise is important, since one can then avoid
the inconvenience of change propagation without giving up system consistency. 

Change avoidance is easily combined with class tailoring. Tailoring operations are car-
ried out only for the purpose of deﬁning additional subclasses; no matter how inherited
properties are overridden, the modiﬁcations appear and take effect only at the level of the
subclasses performing the redeclarations. New classes obviously have no associated in-
stances, so there is no need to care about ﬁltering or conversion procedures. Thus, object-
oriented systems avoid updating instances when subclassing operations are considered. 

Change Avoidance

231

Several other evolution primitives exhibit no side-effects and can safely be applied
without reorganizing running applications. Among the surgery operations listed in section
8.3.3, the following have no consequences on object structures: 

• Renaming classes, methods and variables only affects the description of classes, not
the structure of instances, although this may not always be true for programs that ex-
plicitly manipulate class or attribute names. 

• Changing the default value of a variable or a shared slot has no effect on instances,

since these values pertain to the class deﬁnitions, not to the objects themselves. 

• The implementation of a method can be changed freely; the code is associated and

kept with a class deﬁnition, to be shared among all individual instances. 

• Because no arbitrary changes to the domain of variables and arguments are allowed,
one can guarantee that the values stored within existing objects remain compatible
with their new type. 

8.6.2 Physical Structures

A technique for conﬁning the effects of class evolution consists of uncoupling the logical
object model from its physical representation, so that instances may be implemented in a
way immune to change. Transposed ﬁles exhibit such desirable characteristics [18]. 

In traditional database systems, the state of an object (i.e. the set of all its variables) is
usually stored in one record (methods are shared and stored in a separate area). Every class
of a hierarchy is associated with a ﬁle which is used as a persistent storage space for its en-
tities, with each record of a ﬁle containing the state of a particular entity (ﬁgure 8.5). When
a variable is added to a class deﬁnition, additional space must be allocated for the corre-
sponding class and its subclasses; the instances affected by the modiﬁcation are subse-
quently copied into the new storage zones. When a variable is suppressed from a class,
special procedures are required for reclaiming unused storage space, a process that gener-
ally entails unloading and reloading entire class extents. 

Transposed ﬁles associate one ﬁle with each variable of a class. Each record contains
the value of the variable for a particular instance. The complete representation of a class is
thus spread among several ﬁles. One reconstitutes the state of an object by ﬁrst accessing
the values of its various variables in their respective ﬁles, and then grouping them together
in the main memory for processing. All values for the variables of an object are stored in
records located at the same rank in the various ﬁles; this is made possible by deriving this
rank directly from the identiﬁer assigned to every object in the system. A simple scheme
is to use a pair 〈class-identiﬁer, rank〉 to identify objects. Because ﬁle management systems
generally allocate disk space not by records but by blocks, a level of indirection is needed
to access the value of a variable. On the other hand, such a structure facilitates the insertion
of objects whose identiﬁers are not strictly sequentially determined (blocks correspond-
ing to unused identiﬁers need not be reserved), and the release of space after the last object

232

Managing Class Evolution in Object-Oriented Systems

class EMPLOYEE

variables

Name
Salary
Function

:
:
:

STRING;
INTEGER;
STRING;

…
end;

File: EMPLOYEE

Mucius Scaevola

5100 Programmer

Julius Nepos

8300 Project Leader

…

Titus Livius

7600 Analyst

Figure 8.5   Traditional storage technique for a hypothetical EMPLOYEE class. 

Transposed file: Name

Transposed file: Salary

Transposed file: Function

1–3

4–6

(7–9)

1–3

4–6

(7–9)

Mucius Scaevola

Julius Nepos

—

…

5100

8300

—

…

1–3

4–6

(7–9)

Programmer

Project Leader

—

…

…

…

—

Titus Livius

214–216

—

214–216

—

7600

—

214–216

…

—

Analyst

—

Figure 8.6 Using a transposed ﬁle organization for storing class EMPLOYEE. 
Rank 2 contains all information relative to employee “Julius Nepos”, 
rank 215 the data relative to “Titus Livius”. No instance corresponds 
to ranks 7–9, so the corresponding block is not allocated.

associated with a particular block is deleted. Resource waste is therefore reduced. The di-
agram of ﬁgure 8.6 represents the simpliﬁed structure of a transposed ﬁle. 

Conversion

233

Transposed ﬁles provide an efﬁcient kernel for implementing many of the class surgery

primitives described in section 8.3.3, for example: 

• Adding a variable to a class does not require reformatting the existing records to
make room for the new attribute. Instead, an additional ﬁle is reserved to contain the
supplementary variable that is initialized to some default value, such as nil or 0, for
existing instances. 

• Suppressing a variable is achieved by deleting the corresponding ﬁle and returning

all the space it occupies to the system. No compaction of the database is required.

• A subclass deﬁnition comprises all its superclass ﬁles plus some additional ﬁles. If a
reorganization of the hierarchy results in the destruction of the subclass, all ﬁles for
the attributes it introduces are deleted, but not those corresponding to the variables of
its superclass. All instances of the subclass automatically become members of the
superclass, without one having to execute any procedure to save, reformat and trans-
fer the objects from one class to the other. The class-identiﬁer part of all object identi-
ﬁers must nevertheless be updated to remain consistent across changes.

Transposed ﬁles have proved very useful in domains such as statistical and econometric
information systems. They have therefore been implemented in special-purpose database
systems geared towards supporting these categories of applications. Their application in
semantic and object-oriented database systems is currently a ﬁeld of active research [18]. 

8.7 Conversion

8.7.1 Issues

Transforming all entities whose class has been modiﬁed seems like the most natural ap-
proach to dealing with change propagation. This technique implies that instances are
physically updated so that their structure matches the description of the class they belong
to. Two important requirements must be met:

• Because there is in general not a direct or a unique correspondence between old and

new class deﬁnitions, care has to be taken to avoid losing information. 

• The conversion process has to be organized in such a way that it interferes as little as

possible with normal system operations. 

A consequence of the ﬁrst requirement is that ad hoc reconﬁguration procedures have
to be programmed to accompany automatic conversion processes whose capabilities to
preserve the semantics of an application domain are evidently limited. The second re-
quirement forces all conversion procedures to behave as atomic transactions (transforma-
tions must be applied completely to the objects involved in the conversion) and puts strong
restrictions on their duration. 

234

Managing Class Evolution in Object-Oriented Systems

8.7.2 Instance Transformation

CLOS provides a good example of how automatic conversion can be enhanced by the pro-
grammer to take supplementary integrity constraints into account [25]. Conversions are
performed according to the rules listed in table 8.4. CLOS deletes from objects all at-

Old slot 

shared

local

none

shared

preserved

initialized

initialized

New slot 

local

preserved

preserved

initialized

none

discarded

discarded

—

Table 8.4 Default conversions carried out by CLOS on objects after a class 

modiﬁcation. A slot corresponds to a variable. Preserved slot values are left 
untouched. Discarded slots are removed and their values are lost. Initialized 
slots are assigned a value determined by the class the instance belongs to. 
This table is reproduced from [25].

tributes that have been deleted in their class, including their associated accessor methods;
it adds and initializes those attributes that have been introduced in the class deﬁnition, and
adapts the attributes whose status has passed from shared to local (or vice versa). These
conversions are carried out by a standard function called  update-instance-for-redeﬁned-
class that is inherited by every class in a hierarchy and can be customized by the program-
mer. Arguments such as the list of attributes added to the class, or the list of attributes dis-
carded from the class or converted from local to shared, with their original values, are
passed to this function. This allows the programmer to take proper actions to correct and
augment the default restructuring and reinitialization procedures provided by CLOS, and
thus to determine freely the mapping from an old to a new object schema.

The OTGen system provides a similar kind of functionality for transforming instances
affected by a class modiﬁcation, although this capability is presented to the user through
a table-driven interface rather than as a programming feature attached to the inheritance
hierarchy [27]. A table lists all class deﬁnitions whose instances have to be converted and
suggests default transformations that apply, which can of course be overridden or extend-
ed by the user. The transformation operations possible with OTGen are as follows: 

• Transfer objects which belong to the old class deﬁnition to the new database. Un-

changed objects are simply copied from a database to another. 
• Delete objects from the database if their class has been deleted. 
• Initialize the variables of an object. When the old and new types of a variable are in-
compatible, the default action taken by OTGen consists of assigning the nil value to

Conversion

235

the variable. The user can override the standard behaviour of the system by providing
its own initial values. 

• Change local variables to shared variables. 
• Perform context-dependent changes. One may initialize variables based on previous
information stored in the objects, or partition the instances from a class into two other
categories based on the information they contain. 

• Move information between classes, for example by shufﬂing variables among class-

es, without losing associated information. 

• Introduce new objects for classes created while updating the hierarchy and initialize

their variables on the basis of information already stored in the database. 

Providing a framework to handle the most common transformations certainly eases the
task of the programmer. It is difﬁcult, however, to guarantee that such a predetermined set
of primitives effectively covers all possibilities for object conversion. When complex ad-
aptations cannot be expressed with these operations, one is eventually forced to resort to
special-purpose routines.

8.7.3 Immediate and Delayed Conversion

A major constraint with conversion concerns the time at which objects must be trans-
formed. 

Immediate conversion consists in transforming all objects at once, as soon as the corre-
sponding class modiﬁcations are committed. This solution does not ﬁnd much favour in
practice, because it may entail the full unloading and reloading of the persistent object
store, and long service interruptions if a signiﬁcant number of entities have to be convert-
ed. On the other hand, this technique provides ample opportunities for optimizing the stor-
age and access paths to objects as part of the conversion process. Immediate conversion
has been implemented in the GemStone object-oriented database system [35]. 

Lazy conversion consists in adapting instances on an individual basis, but only when
they are accessed for the ﬁrst time after a class modiﬁcation. This method does not incur
the drawbacks of system shutdown imposed by immediate conversion at the price of
degraded response time when instances are initially accessed after a class modiﬁcation.
Lazy conversion requires keeping track of the status of each object. When successive
revisions are carried out on the same class, the system must record each associated con-
version procedure, to be able to transform objects that are referenced after a long period of
inactivity. Lazy conversion is nevertheless an appealing approach for applications with
short-lived instances that are rapidly garbage-collected and therefore do not even need to
be converted. This technique has been proposed as the standard mechanism for CLOS. A
version of the O2 system implements both techniques [41], applying immediate conver-
sion to instances present in main memory at the time of the modiﬁcation and resorting to
lazy conversion for objects residing in secondary storage [4]. 

236

Managing Class Evolution in Object-Oriented Systems

8.7.4 Evaluation

Conversion, and in particular lazy conversion, is a very attractive technique for propagat-
ing changes in an object-oriented system. It requires the programming of transformation
functions, even when the environment supports automatic conversion, but there are no
other alternatives for resolving intricate compatibility conﬂicts. When the conversion of
instances is infeasible, scope restriction techniques borrowed from the ﬁltering approach
may prove helpful. 

8.8

Filtering

8.8.1 Issues

Under some circumstances, one may not need to physically convert instances, because
they have become obsolete due to class modiﬁcation, or because they represent informa-
tion that is not allowed to be modiﬁed for legal reasons, like accounting records. In these
situations, it is preferable to ensure a partial compatibility between old and new object
schemas, so that an application may still use them, but without striving to make them per-
fectly interchangeable. 

Filtering (or screening) is a general framework for dealing with this problem. It is most
often used in combination with version management. This can be done by wrapping a soft-
ware layer around objects. The layer intercepts all messages sent to the enclosed object;
these messages are then handled according to the object’s version, to make it conform to
the current or to a previous class description, or to cause an exception to pop up when an
application uses an object with an unsuitable deﬁnition. Three major issues must be exam-
ined with this approach: 

• How does one characterize the degree of compatibility between class versions? 
• How can one map instances from a class version to another? 
• How far can a ﬁltering mechanism hide class changes from the users? 

8.8.2 Version Compatibility

Fundamentally, ﬁltering is a mechanism for viewing entities of a certain class version as
if they belonged to another version of the same class. From the predecessor–successor re-
lationship between versions, we identify two types of compatibility [1]: 

• A version Ci is backwards compatible with an earlier version Cj if all instances of Cj

can be used as if they belonged to Ci. 

• A version Ci is forwards compatible with a later version Cj if all instances of Cj can

be used as if they belonged to Ci. 

Filtering

237

In the ﬁrst case, applications can use old instances as if they originated from new deﬁ-
nitions. With the second form of compatibility, old programs can manipulate entities cre-
ated on the basis of later versions. 

Each class C is associated with the partial ordering of versions { Ci }. We assume that,
at any point in time, some Ci is considered the valid version of class C. Building on these
deﬁnitions, we say that a class version Ci is consistent with respect to version Dj of another
class D (C ≠ D) if one of the following conditions is satisﬁed [1]: 

• Dj was the currently valid version of D when Ci was committed. This is the usual sit-

uation; Ci references up-to-date, contemporaneous properties of D. 

• Dk was the currently valid version of D when Ci was committed, Dj is a later version
of D, and Dk is forwards compatible with Dj. Here Ci references an obsolete deﬁni-
tion of D, but the forwards compatibility property allows it to work with instances
created according to the new schema. 

• Dk was the currently valid version of D when Ci was committed, Dj is an earlier ver-
sion of D, and Dk is backwards compatible with Dj. Here Ci is supposed to manipulate
an up-to-date representation of D; thanks to the backwards compatibility, it is never-
theless able to use instances generated from old versions. 

8.8.3 Filtering Mechanisms

The operations that cause problems when invoked on a non-compatible object can be clas-
siﬁed in a limited number of categories. For example, deleting a method generates access
violations when an object attempts to invoke the deleted method. These effects are sum-
marized in table 8.5. 

A simple way to deal with this problem is to replace each access primitive with a routine
speciﬁcally programmed to perform the mapping between different class structures. Thus,
for each variable that violates compatibility constraints, one provides a procedure that re-
turns the variable’s value, and another procedure for changing its value. These procedures
perform various transformations, like mapping the variable to a set of other attributes [1].
For example, if the “birthday” attribute of a person class has been replaced with an “age”
variable, one has to provide the following procedures to ensure backwards compatibility: 
• A read accessor that determines the age of a person based on the time elapsed be-

tween the recorded birthday and the current date. 

• A write accessor that stores the age of a person as a birthday, computed on the basis

of the current date and the age given as argument to the accessor. 

Similarly, one must deﬁne two symmetrical operations to guarantee forwards compati-
bility. More generally, one can deﬁne so-called substitute functions for carrying out these
mappings between objects with different structures as follows: 

• A substitute read function RCijA(I) is given an instance I of version i of class C. It
maps the values of a group of attributes from this object to a valid value of attribute A

238

Managing Class Evolution in Object-Oriented Systems

Scope of change

Compatibility

Consequences

add a variable

delete a variable

backwards

forwards

undeﬁned variable in old objects

undeﬁned variable in new objects

extend variable type

backwards

writing illegal values into old objects

restrict variable type

add a method

delete a method

forwards

forwards

backwards

backwards

forwards

reading unknown data from new objects

writing illegal values into new objects

reading unknown data from old objects

undeﬁned method in old objects

undeﬁned method in new objects

extend argument type

backwards

passing illegal values to old objects

forwards

getting unknown data from new objects

restrict argument type

forwards

passing illegal values to new objects

backwards

getting unknown data from old objects

change argument list

backwards and forwards

similar to dropping and adding a method

Table 8.5 Consequences of class changes. The middle column indicates which kind of 

compatibility is affected by a modiﬁcation, the right column describes the 
exceptions raised when accessing an object from the old or the new class 
deﬁnition. 

of version j of C. In other words, it makes instances of class version Ci appear as if
they contained the attribute A of class version Cj for reading operations. 

• A substitute write function WCijA(I,V) is given an instance I of version i of class C,
and a value V for attribute A of Cj. It maps the value V into a set of values for a group
of attributes deﬁned in Ci. In other words, this function makes instances of class ver-
sion Ci appear as if they could store information in attribute A, although this informa-
tion is actually recorded in other variables. 

A second approach favours the use of handlers to be invoked before or after a failed access
to the attribute they are attached to, a technique that has been implemented in the EN-
CORE system [37]. Pre-handlers typically take over when attempting to access a non-
existent attribute, or when trying to assign an illegal value to it. A pre-handler may perform
a mapping like those carried out by the substitute functions, coerce its argument to a valid
value, or simply abort the operation. A post-handler is activated when an illegal value is
returned to the invoking object; a common behaviour in this case consists in returning a
default value. 

Filtering

239

8.8.4 Making Class Changes Transparent

Where should ﬁlters be deﬁned? As originally stated, the technique based on handlers re-
quires global modiﬁcations in all versions of the same class [37]. More precisely, 

• Whenever an attribute is added to a class, pre-handlers for the attribute must be intro-

duced in all other versions of the class. 

• Pre-handlers must be added to a version that suppresses attributes of a class.
• When a version extends the domain of an attribute, corresponding pre- and post-

handlers must be introduced in all other versions of the class.

• When the domain of an attribute is restricted, the class version redeclaring the at-

tribute type must be wrapped with a pre-handler and a post-handler. 

This solution is rather inelegant: it requires that old class deﬁnitions be adjusted to re-

ﬂect new developments and leads to a combinatorial explosion of handler complexity. 

The model of substitute functions allows one to exploit the derivation history for map-
ping between versions that have no direct relationships. Thus, one can map a version Ci to
another version Cj if there exist either substitute functions for them (RCijX, WCijX, where
X denotes an attribute of Cj), or a succession of substitute functions that transitively apply
to them (i.e. there are substitute functions for mapping between Ci and Ck, then Ck and Cl
and eventually Cl and Cj for example). Depending on compatibility properties, one can
even relate class deﬁnitions placed in different derivation paths in a version hierarchy. Fur-
thermore, substitute functions are deﬁned only in the newer versions; previous class deﬁ-
nitions remain unchanged. 

When compatibility between versions cannot be achieved, one may install scope re-

strictions that isolate objects pertaining to different deﬁnitions from each other: 

• A forward scope restriction makes instances from a new version inaccessible to ob-

jects from older versions. 

• A backward scope restriction makes instances from older versions unreachable from

objects of more recent versions. 

Scope restrictions and compatibility relationships make it possible to partition a class
extension in such a way that operations may be applied to any object regardless of its ver-
sion. Naturally, interoperability decreases with such a scheme, since the entities from dif-
ferent versions of the same class can no longer be referred to and accessed as members of
one large pool of objects. 

8.8.5 Evaluation

Screening has been implemented in some systems, but its application scope there is nota-
bly reduced. ORION does not immediately convert instances affected by a class change so
as to avoid reorganizing the database [3]. When an instance is fetched, and before its at-
tributes are accessed, deleted variables are made inaccessible (after, if needed, the physi-
cal destruction of the objects they refer to). Default values are automatically supplied to

240

Managing Class Evolution in Object-Oriented Systems

account for the introduction of new properties. Rearrangements of inheritance patterns are
reﬂected by hiding unwanted properties and supplying default values for new inherited at-
tributes. 

From our discussion, it appears that ﬁltering cannot fulﬁl its objective of making class
changes  transparent  without  considerable  complexity  and  overhead. The  programmer
must not only develop a series of special-purpose functions for mapping between the var-
iants of a class, but must also accept a degradation of application performance as these
handlers accumulate, replacing the originally simple and efﬁcient accessors. In practice,
this complexity does not appear fully warranted. With lazy conversion, for example, one
has also to deﬁne ad hoc procedures for transforming entities from one version to another,
but these procedures are called only once for every object. Their execution is therefore not
as expensive as the systematic run-time checks and exception raising implied by screening
techniques. On the positive side, ﬁltering provides a rigorous framework for deﬁning and
dealing with compatibility issues, and it is most adequate during prototyping, when class
modiﬁcations may be cancelled just after being tested. Recent approaches provide im-
proved mechanisms derived from database views that encompass ﬁltering techniques and
that can also be suitable as modelling tools during application development [16].

8.9 Conclusion

Object-oriented development reveals its iterative nature as successive stages of subclass-
ing, class modiﬁcation and reorganization allow software engineers to build increasingly
general and robust classes. We therefore expect object-oriented CASE systems to take
advantage of the large spectrum of tools and techniques available to manage the various
aspects of class evolution (see table 8.6).

Approach

change avoidance

Actual impact
on instances

In charge of controlling
change propagation

Implementation

conﬁnement

logical

storage structures

physical

conversion

ﬁltering

physical

logical

system

system

programmer 

programmer 

side-effect free operations

transposed ﬁles

conversion routines

handlers/wrappers

Table 8.6   The main characteristics of change propagation techniques.

It is appealing to envision an environment where software engineers build new classes
out of reusable components, tailor them to suit their needs, and launch exploratory incre-
mental reorganizations to detect the places in their code most likely to require further re-

241

Approach

Scope

tailoring

surgery

 attributes;
interfaces

 attributes;
inheritance links;
classes

Phase in library
development

Enforced properties

extension

syntactical constraints

redesign

schema invariants

versioning

classes

extension

conﬁguration consistency

reorganization

refactoring

interattribute
dependencies

classes;
 attributes; 
method structures;
inheritance links

redesign

schema invariants; 
preservation of behaviour

method structures

redesign

preservation of behaviour

inheritance
(global)

classes;
inheritance links

inheritance
(incremental)

classes;
inheritance links;
interfaces;
method structures

redesign

extension

preservation of class structures;
global optimality of hierarchy

preservation of class structures;
local optimality of hierarchy;
preservation of behaviour

Table 8.7

The main characteristics of evolution management techniques. Attributes 
refer to methods as well as to variables; method structures correspond to the 
signature and the implementation of methods. 

visions. Software developers may then reﬁne the outcome of automatic reorganizations
with class surgery primitives and perhaps embark on comprehensive refactoring activities.
The results of different reorganizations and their subsequent adjustments are kept as ver-
sions of the hierarchy, that can be further modiﬁed, tested, debugged and possibly can-
celled  by  the  programmers  (see  table  8.7).  Filtering  makes  it  possible  to  test  the
correctness of various class deﬁnitions without having to carry out numerous conversions.
When a satisfactory design for a new component and its related classes is achieved, it can
be frozen and publicly released as the new version of the class library, while the other tem-
porary versions are discarded. If necessary, instances from modiﬁed classes can then be
deﬁnitely converted to conform to their new deﬁnitions.

Some approaches have been partially implemented and already appear, albeit in isola-
tion, in some object-oriented systems; we hope that integrated tools suitable for support-
ing class evolution in industrial and commercial environments will become available in
the near future.

242

Managing Class Evolution in Object-Oriented Systems

References

[1] Matts Ahlsén, Anders Björnerstedt, Stefan Britts, Christer Hultén and Lars Söderlund, “Making Type

Changes Transparent,” SYSLAB report 22, SYSLAB-S, University of Stockholm, 26 Feb. 1984.

[2] Bruce Anderson and Sanjiv Gossain, “Hierarchy Evolution and the Software Lifecycle,” in Proceed-

[3]

ings 2nd TOOLS Conference, ed. J. Bézivin, B. Meyer and J.-M. Nerson, Paris, 1990, pp. 41–50.
Jay Banerjee, Won Kim, Hyoung-Joo Kim and Henry F. Korth, “Semantics and Implementation of
Schema Evolution in Object-Oriented Databases,” SIGMOD Record (special issue on SIGMOD ’87),
vol. 16, no. 3, Dec. 1987, pp. 311–322.

[4] Gilles Barbedette, “Schema Modiﬁcation in the LISPO2 Persistent Object-Oriented Language,” in
Proceedings 5th ECOOP Conference, ed. P. America, Lecture Notes in Computer Science, vol. 512,
Springer-Verlag, Geneva, 15–19 July 1991, pp. 77–96.

[5] David Beech and Brom Mahbod, “Generalized Version Control in an Object-Oriented Database,” in
Proceedings of the 4th IEEE International Conference on Data Engineering, Los Angeles, Feb. 1988,
pp. 14–22.
Paul L. Bergstein and Walter L. Hürsch, “Maintaining Behavioral Consistency during Schema Evolu-
tion,” in Object Technologies for Advanced Software (First JSSST International Symposium), Lecture
Notes in Computer Science, vol. 742, Springer-Verlag, Nov. 1993, pp. 176–193.

[6]

[7] Anders Björnerstedt and Stefan Britts, “AVANCE: An Object Management System,” ACM SIGPLAN

Notices (special issue on OOPSLA ’88), vol. 23, no. 11, Nov. 1988, pp. 206–221.

[8] Anders Björnerstedt and Christer Hultén, “Version Control in an Object-Oriented Architecture,” in
Object-Oriented Concepts, Databases, and Applications, ed. W. Kim and F. H. Lochovsky, Frontier
Series, Addison-Wesley/ACM Press, 1989, pp. 451–485.

[9] Alexander Borgida, “Modelling Class Hierarchies with Contradictions,” SIGMOD Record (special

issue on SIGMOD ’88), vol. 17, no. 3, Sept. 1988, pp. 434–443.

[10] Alexander Borgida and Keith E. Williamson, “Accommodating Exceptions in Databases, and Reﬁn-
ing the Schema by Learning from them,” in VLDB 1985 Proceedings, ed. A. Pirotte and Y. Vassiliou,
Stockholm, 21–23 August 1985, pp. 72–81.

[11] Eduardo Casais, “An Incremental Class Reorganization Approach,” in Proceedings 6th ECOOP Con-
ference, ed. O. Lehrmann Madsen, Lecture Notes in Computer Science, vol. 615, Springer-Verlag,
Utrecht, June 29 – July 3 1992, pp. 114–132.

[12] Eduardo  Casais,  “Managing  Evolution  in  Object-Oriented  Environments:  An  Algorithmic  Ap-

proach,” Ph.D. Thesis, Université de Genève, Geneva, 1991. 

[13] Eduardo Casais, ‘‘Automatic Reorganization of Object-Oriented Hierarchies: A Case Study,’’ Object-

Oriented Systems, vol. 1, no. 2, Dec. 1994., pp. 95–115 

[14] Fabiano Cattaneo, Alberto Coen-Porisini, Luigi Lavazza and Roberto Zicari, “Overview and Progress
Report of the ESSE Project: Supporting Object-Oriented Database Schema Analysis and Evolution,”
in Proceedings 10th TOOLS Conference, Versailles, ed. B. Magnusson and J.-F. Perrot, Prentice Hall,
1993, pp. 63–74 

[15] Hong-Tai Chou and Won Kim, “A Unifying Framework for Version Control in a CAD Environment,”

in 12th VLDB Conference Proceedings, Kyoto, 25–28 August 1986, pp. 336–344.

[16] Stewart M. Clamen, “Type Evolution and Instance Adaptation,” Technical Report CMU-CS-92-113, 

Carnegie-Mellon University, Pittsburgh, June 1992. 

[17] William R. Cook, “Interfaces and Speciﬁcations for the Smalltalk-80 Collection Classes,” ACM SIG-

PLAN Notices (special issue on OOPSLA ’92), vol. 27, no. 10, Oct. 1992, pp. 1–15.

[18] Thibault Estier, Gilles Falquet and Michel Léonard, “F2: An Evolution Oriented Database System,”

Cahiers du CUI no. 69, Centre Universitaire d’Informatique, Genève, January 1993. 

References

243

[19] D. H. Fishman, J. Annevelink, D. Beech, E. Chow, T. Connors, J. W. Davis, W. Hasan, C. G. Hoch, W.
Kent, S. Leichner, P. Lyngbaek, B. Mahbod, M. A. Neimat, T. Risch, M. C. Shan and W. K. Wilkinson,
“Overview of the IRIS DBMS,” in Object-Oriented Concepts, Databases, and Applications, ed. W.
Kim and F. H. Lochovsky, Frontier Series, Addison-Wesley/ACM Press, 1989, pp. 219–250.

[20] Erich Gamma, “Objektorientierte Software-Entwicklung am Beispiel von ET++: Klassenbibliothek,

Werkzeuge, Design,” Dissertation, Universität Zürich, August 1991.

[21] Adele Goldberg and Daniel Robson, Smalltalk-80: The Language and its Implementation, Addison-

Wesley, Reading, Mass., 1983.

[22] Ralph E. Johnson and Brian Foote, “Designing Reusable Classes,” Journal of Object-Oriented Pro-

gramming, June-July 1988, pp. 22–35.

[23] Ralph E. Johnson and William F. Opdyke, “Refactoring and Aggregation,” in Object Technologies for
Advanced Software (First JSSST International Symposium), Lecture Notes in Computer Science, vol.
742, Springer-Verlag, Nov. 1993, pp. 264–278.

[24] Randy H. Katz, “Towards a Uniﬁed Framework for Version Modelling in Engineering Databases,”

ACM Computing Surveys, vol. 22, no. 4, Dec. 1990, pp. 375–408.

[25] Sonya E. Keene, Object-Oriented Programming in Common LISP: A Programmer’s Guide to CLOS,

Addison-Wesley, Reading, Mass., 1989.

[26] Hyoung-Joo Kim, “Algorithmic and Computational Aspects of OODB Schema Design,” in Object-
Oriented  Dabatases  with  Applications  to  CASE,  Networks  and VLSI  CAD,  ed.  R.  Gupta  and  E.
Horowitz, Prentice Hall, 1991, pp. 26–61.

[27] Barbara Staudt Lerner and A. Nico Habermann, “Beyond Schema Evolution to Database Reorganiza-
tion,” ACM SIGPLAN Notices (special issue on OOPSLA ’90), vol. 25, no. 10, Oct. 1990, pp. 67–76.
[28] Karl J. Lieberherr, Paul Bergstein and Ignacio Silva-Lepe, “From Objects to Classes: Algorithms for
Optimal Object-Oriented Design,” BCS/IEE Software Engineering Journal, July 1991, pp. 205–228.
[29] Karl Lieberherr, Ian Holland and Arthur Riel, “Object-Oriented Programming: an Objective Sense of
Style,” ACM SIGPLAN Notices (special issue on OOPSLA ’88), vol. 23, no. 11, Nov. 1988, pp. 323–
334.

[30] Bertrand Meyer, Eiffel: The Language, Object-Oriented Series, Prentice Hall, 1992.
[31] Bertrand Meyer, “Tools for the New Culture: Lessons from the Design of the Eiffel Libraries,” Com-

munications of the ACM, vol. 33, no. 9, Sept. 1990, pp. 68–88.

[32] Shamkant B. Navathe, Seong Geum, Dinesh K. Desai and Herman Lam, “Conceptual Design for
Non-Database Experts with an Interactive Schema Tailoring Tool,” in Proceedings of the 9th Entity–
Relationship Conference, ed. H. Kangassalo, Lausanne, 8–10 Oct. 1990, pp. 3–20.

[33] Objective-C  Compiler Version  4—User  Reference  Manual,  StepStone  Corporation,  Sandy  Hook,

1988.

[34] William F. Opdyke, “Refactoring Object-Oriented Frameworks,” Ph.D. thesis, Department of Com-

puter Science, University of Illinois at Urbana-Champaign, 1992.

[35] D. Jason Penney and Jacob Stein, “Class Modiﬁcation in the GemStone Object-Oriented DBMS,”

ACM SIGPLAN Notices (special issue on OOPSLA ’87), vol. 22, no. 12, Dec. 1987, pp. 111–117.

[36] Markku Sakkinen, “Comments on the ‘Law of Demeter’ and C++,” ACM SIGPLAN Notices, vol. 23,

no. 12, pp. 34–44.

[37] Andrea H. Skarra and Stanley B. Zdonik, “The Management of Changing Types in an Object-Orient-
ed Database,” in Research Directions in Object-Oriented Programming, ed. B. Shriver and P. Wegner,
MIT Press, Cambridge, Mass., 1987, pp. 393–415.

[38] Dave Thomas and Kent Johnson, “Orwell: a Conﬁguration Management System for Team Program-
ming,” ACM SIGPLAN Notices (special issue on OOPSLA ’88), vol. 23, no. 11, Nov. 1988, pp. 135–
141.

244

Managing Class Evolution in Object-Oriented Systems

[39] Emmanuel Waller, “Schema Updates and Consistency,” in DOOD’91 Proceedings, ed. C. Delobel,
M. Kifer and Y. Yasunaga, Lecture Notes in Computer Science, vol. 566, Springer-Verlag, Dec. 1991,
pp. 167–188.

[40] Franz Weber, “Getting Class Correctness and System Correctness Equivalent — How to Get Covari-
ance Right,” in Proceedings 8th TOOLS Conference, Santa Barbara, ed. R. Ege, M. Singh and B.
Meyer, Prentice Hall, 1992, pp. 199–213.

[41] Roberto Zicari, “A Framework for Schema Updates in an Object-Oriented Database System,” in
Building an Object-Oriented Database System — The Story of O2, ed. F. Bancilhon, C. Delobel and P.
Kanellakis, Morgan Kaufmann, 1992, pp. 146–182.

Chapter 9
The Afﬁnity Browser

Xavier Pintado

Abstract        Large  numbers  of  classes,  complex  inheritance  and  containment
graphs, and diverse patterns of dynamic interaction all contribute to difﬁculties in
understanding,  reusing,  debugging,  and  tuning  large  object-oriented  systems.
These difﬁculties may have a signiﬁcant impact on the usefulness of such systems.
Tools that help in understanding the contents and behaviour of an object-oriented
environment should play a major role in reducing such difﬁculties. Such tools allow
for  the  exploration  of  different  aspects  of  a  software  environment  such  as
inheritance structures, part-of relationships, etc. However, object-oriented systems
differ  in  many  respects  from  traditional  database  systems,  and  in  particular,
conventional querying mechanisms used in databases show poor performance
when  used  for  the  exploration  of  object-oriented  environments.  This  chapter
deﬁnes  the  requirements  for  effective  exploration  mechanisms  in  the  realm  of
object-oriented environments. We propose an approach to browsing based on
the notion of afﬁnity that satisﬁes such requirements. Our tool, the afﬁnity browser,
provides  a  visual  representation  of  object  relationships  presented  in  terms  of
afﬁnity. Objects that appear closer in the visual representation are more strongly
related  than  objects  lying  farther  apart.  So,  the  intensity  of  a  relationship  is
translated into distance in the visual representation that provides the support for
user navigation. We provide many examples of metrics deﬁned over the objects of
an environment to illustrate how object relationships can be translated in terms of
afﬁnity so that they can be used for the exploration of an environment.

9.1

Introduction

Large  numbers  of  classes,  complex  inheritance  and  containment  graphs,  and  diverse
patterns of dynamic interaction all contribute to difﬁculties in understanding, reusing, de-
bugging, and tuning large object-oriented systems. From the inception of object-oriented
environments, developers and software designers have felt the need for tools that support
the process of understanding the objects, the classes and the relationships provided by
their environments. For example, reuse of existing software components requires naviga-
tion and inspection of classes and how they are related. Inspection and navigation capabil-
ities are also instrumental for the combination of instantiated objects since they allow the

Xavier Pintado, “The Affinity Browser,” Object-Oriented Software Composition, O. Nierstrasz and D. Tsichritzis (Eds.), pp. 245-272, 
Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

246

The Afﬁnity Browser

user  to  go  back  and  forth,  inspecting  objects  and  combining  them.  In  a  similar  vein,
discerning global and local patterns of interaction among classes and among objects is
critical for tuning and debugging.

This chapter proposes an approach to browsing for object-oriented environments based
on the notion of afﬁnity. Our tool, the afﬁnity browser, allows for the exploration of col-
lections of objects based on a visual representation of object relationships presented in
terms of afﬁnity. Objects that appear closer in the visual representation are more strongly
related than objects lying farther apart. So, the intensity of a relationship is translated into
distance in the visual representation.

Our approach displays many advantages. First, afﬁnity browsing is not based on point-
to-point navigation. The user is provided with the set of objects that lie within a given
neighbourhood relative to the object currently being inspecting. The afﬁnity browser pro-
motes, therefore, proximity-based navigation whereby exploration proceeds by exploring
ﬁrst the objects that are close to the current object of interest. Second, the browser allows
for the exploration of dynamically evolving relationships. The evolution of such relation-
ships is visualized as an animation where the change in the relative position of objects con-
veys the change of the underlying relationships expressed in terms of afﬁnity. Third, many
different kinds of object relationships can be translated into afﬁnity representations allow-
ing the same exploration paradigm and the same user interface to be used to explore a large
spectrum of object relationships.

This chapter is organized as follows. Section 9.1.1 addresses the problem of ﬁnding and
selecting objects inside an object-oriented environment. It discusses the characteristics of
object-oriented systems that may have an impact on the effectiveness of various browsing
mechanisms. Section 9.1.2 surveys work related to browsing ranging from traditional
graph-based browsing to graphical and spatial browsing. Section 9.2 deﬁnes the require-
ments for effective exploration mechanisms in the realm of object-oriented environments.
Section 9.3 presents the afﬁnity browser as a tool that satisﬁes such requirements. In sec-
tion 9.4 we provide many examples of metrics deﬁned over the objects of an environment
to illustrate how object relationships can be translated in terms of afﬁnity so that they can
be used for the exploration of an environment

9.1.1 Object Selection

We address here the issue of selection in the object-oriented realm. Users may want, for
instance, to select classes, objects, or functionality. Selection in an object-oriented envi-
ronment has many problems, however. First, an application designer has only approxi-
mate selection criteria to select an appropriate reusable object class for developing his or
her application. Second, the object classes and the objects in a running system have rela-
tionships that change dynamically. Third, objects are encapsulated and content selection
has only very limited use.

Furthermore, object-oriented principles applied to software design seem to promote
systems with object relationships that are more complex than in more traditional software

Introduction

247

environments. Many authors think that these principles will allow designers and develop-
ers to create software environments that are an order of magnitude more complex than ex-
isting software systems [19] [4].

A noteworthy supporting reason for such belief is that object-oriented design tech-
niques seem to allow signiﬁcantly better decomposition of complex problems into units of
manageable complexity. First, by the virtue of encapsulation an object conceals its inter-
nal complexity and it acquires some level of autonomy. Second, incremental deﬁnition
through inheritance allows for the endless reﬁnement of object behaviour and functional-
ity without the need to rework the whole hierarchy at each reﬁnement step. These mecha-
nisms, with such desirable features, allow for the implementation of models that integrate
much detail both at the object level and at the level of object relationships. This intuition
is further supported by experience that shows that it is quite easy to introduce complexity
in the design and in the implementation of an object-oriented environment. For instance,
object-oriented programming is more an activity of wiring together sets of objects. For the
programmer or for the designer whose task is to build a system through the composition
of objects it might be quite easy to combine them in many different ways — this is the
producer’s view. On the other hand, for a developer who wants to understand existing
functionality for reuse or maintenance, it may be difﬁcult to comprehend the large number
of functional relationships that have been created — this might be the consumer’s view.
Early experiences with object-oriented environments highlighted the need for tools that
allow for the exploration of object relationships. The Smalltalk environment, for instance,
already provided a sophisticated integrated browsing tool [12]. Interestingly enough, it
has been argued that the Smalltalk browsing tool is one of the most appealing features of
that environment and it is often cited as a reference. For sure, almost every programming
activity on the environment relies on the browser to support navigation needed for the kind
of non-linear programming promoted by object-orientation. The browser is used to code
new objects, to ﬁnd reusable classes and to explore object relationships.

9.1.1.1 Querying and Browsing
The two methods commonly applied for selection are querying and browsing. The meth-
ods are usually applied in a complementary manner; we query and browse in alternation,
applying which method seems more appropriate at different stages of the selection proc-
ess.

Querying provides ﬁne selectivity when the structure of the information space is known
and when content selection can be used. For instance, querying is the primary selection
method in database systems. When querying provides good selectivity, browsing dimin-
ishes in importance. Most selected items are appropriate and we only need a crude brows-
ing tool to inspect them.

Querying, however, can have poor results for many reasons. If the selection criteria are
ill-deﬁned and fuzzy querying does not work well, e.g. in information retrieval. If the
structure of the information space changes dynamically, queries are not easy to formulate,
e.g. in ﬁnancial information systems. Finally, if content selectivity is difﬁcult to exploit,

248

The Afﬁnity Browser

querying loses a lot of selectivity power, e.g. in multimedia databases. In all these cases
powerful browsing capabilities become indispensable.

9.1.1.2 Dynamically Evolving Relationships
As we already mentioned, the analysis of dynamically evolving relationships plays an im-
portant role in debugging but can also be of invaluable assistance for reuse since it helps
understanding how objects are related in existing applications. However, providing sup-
port for the understanding of dynamically evolving relationships is a challenging task. In
fact, traditional querying techniques usually assume a user with knowledge of the search
structure that supports selection. Such an assumption usually implies structure stability
since it seems unrealistic to assume user knowledge of a quickly evolving structure.

With traditional databases it is usually assumed that their information contents changes
but  not  their  structure —  or  at  least  not  frequently.  For  example,  widely  used  query
languages such as SQL provide almost no support for selection in an environment with a
changing structure. The stability of database schemes represents an advantage in terms of
access to information but it makes traditional databases ill-suited for information with
dynamically evolving structures.

The  need  to  cope  with  dynamically  evolving  relationships  appears  in  many  object
selection problems. For example, we may be interested in ﬁnding which are the objects
that interact most frequently with a given object in order to determine its patterns of inter-
action. The change in the interaction patterns depending on what activities the system is
performing may provide useful information about the intended role of an object. This in-
formation can be used, for instance, to assess the potential of reuse for an object in an en-
vironment that may or may not provide the same activity context.

The need for more ﬂexibility than that provided by query mechanisms appeared also in
databases. For example, Motro [20] [21] [22] describes browsing tools that allow for nav-
igation in a semantic network extracted from the internal structure of a relational database,
and provide capabilities for fuzzy queries. The approach has been later extended to inte-
grate similar capabilities in an object-oriented environment [23].

9.1.2 Related Work

Because there is an observable trend towards more complex and quickly evolving infor-
mation systems we need to investigate how to enhance browsing capabilities for the explo-
ration  of  information  systems.  In  this  section  we  describe  previous  work  related  to
browsing.

The Smalltalk Browser

9.1.2.1
To the best of our knowledge, the Smalltalk system was the ﬁrst programming environ-
ment where exploration tools played a major role. Furthermore, the browsing concepts
and mechanisms have been clearly deﬁned [13] [12] and they are quite often cited as the
historical reference to which more recent browsing tools are compared.

Introduction

249

The Smalltalk environment provides capabilities to inspect the message interface of ob-
jects through a system view called a browser. Similarly, the internal state of an object can
be inspected through another system view called an inspector. Furthermore, it is possible
to obtain interface information about sets of objects through another kind of system view
called a message-set browser. These views are generated as responses to queries such as:
which classes implement a given message? Which objects send a particular message?

The main way to ﬁnd out about classes in the environment is to use a system class
browser. The browser presents a hierarchical view of class-related information. It presents
categories that organize the classes within the environment, and categories that arrange
messages within each class. Categories provide essentially a way of grouping classes and
messages into meaningful groups.

It should be noted that in the Smalltalk environment the role of the exploration tools is
not restricted to inspection. For example, an inspector allows users to change interactively
the values of instance variables and to send messages to objects. In general, inspection
tools are used for both inspection and programming purposes. For instance, the creation
of a new class derived from an existing one, and the deﬁnition of new methods is also per-
formed through the browser.

Other browsing tools have been described and implemented in various systems. The
browsing mechanisms implemented in the Smalltalk environment have been a continuous
source of inspiration for new browsing tools. For example, the Trellis programming envi-
ronment [24] provides browsing capabilities that are quite similar to those of the Smalltalk
environment [12].

The great majority of existing browsing tools allow for a point-to-point  navigation, i.e.
the navigation paths are deﬁned by a tree or a network structure. For instance, the tree
structure of the Smalltalk browser is based on classiﬁcation. This approach has proven to
be useful for small collections of objects. But when the number of classes becomes large
users may feel lost because there is no global view and the structure cannot be rearranged
to ﬁt their intuitive perception of the object’s space.

Discerning global and local patterns of interaction among classes is critical for tuning
and debugging. A few authors have already identiﬁed this as an important issue and pro-
posed adequate tools. For example, Böcker and Herczeg [1] introduce a software oscillo-
scope for visually tracking the interactions between objects in a system. The system’s
dynamic behaviour is inspected by placing obstacles between objects and animating the
ﬂow of messages across them. The tool focuses only on microscopic behaviour, however.
Brüegge, Gottschalk and Luo [3] describe BEE++, an object-oriented application frame-
work  for  the  analysis  of  distributed  applications.  BEE++  is  fundamentally  an  event
processing  system  since  it  views  the  execution  of  distributed  activities  as  streams  of
events. Event processing is encapsulated in a set of core base classes that are intended to
be derived for customization.

Other authors such as Kleyn and Gingrich [17] focus on object behaviour issues. Their
tool offers concurrently animated views of the behaviour of an object-oriented system.
These views include graphs of invocations between objects. Podgursky and Pierce address
the problem [30] of retrieving reusable software components based on sampled behaviour.

250

The Afﬁnity Browser

Finally, Rubin and Goldberg [31] sketch an object-oriented design approach based on ob-
ject behaviour analysis and stress the importance of exploration tools to support the design
process.

9.1.2.2 Graphical and Spatial Browsing
In the late 1970s Fields and Negroponte, in a visionary paper [10], expressed the need for
new clues to ﬁnd data. Among the many approaches they envisioned for locating informa-
tion are spatial referencing and proximity. Shortly after, Donelson [7], Bolt [2], and Herot
[14] published papers about spatial management of information which apply many tech-
niques for information exploration and inspection that will serve as a basis for future sys-
tems. They introduced the spatial data management system (SDMS) concept, whereby
information is expressed in graphical form and presented in a spatial framework so that the
information has a structure that is more obvious than in a conventional database. Herot ar-
gues that: “in this way the user can ﬁnd the information he seeks without having to specify
it precisely or know exactly where in the DBMS it is stored.”

More recently, Caplinger [5] has described a sophisticated browsing tool with a graph-
ical spatial interface that is, in fact, an evolution of the original SDMS idea. A further elab-
oration of SDMS is BEAD [6], a system for the visualization of bibliographical data. In
BEAD, articles in a bibliography are represented by particles in 3-space. The system uses
physically based modelling techniques to take advantage of methods for the approxima-
tion of potential ﬁelds. Interparticle forces tend to make similar articles move closer to one
another and dissimilar ones move apart, so that the relationships between articles are rep-
resented by their relative spatial positions. We may also mention the N-Land system [18],
which addresses the problem of visualizing higher dimension information spaces.

The growing interest on hypertext systems generalized the use of browsing as a mech-
anism for information access. Many things have been written recently about hypertext
browsing and hypertext navigation, and we will just mention a few works that seem to
deserve particular interest in the context of this work. SemNet [8] is a system for the three-
dimensional visualization and exploration of large knowledge bases that promotes a hy-
pertext-like navigation paradigm. Feiner’s work addresses the problem of how to con-
veniently display hypertext structures [9] so as to facilitate hypertext navigation.

Another interesting approach is described by Stotts and Furuta [34]. The basic idea is to
replace the usual directed graph of an hypertext system by a Petri net. Unlike a directed
graph, a Petri net also allows the speciﬁcation of browsing semantics, i.e. the dynamic
properties of a reader’s experience when browsing a document. So, Petri nets add to the
hypertext system access control capabilities based on a formally sound mechanism. The
authors describe the 
-Trellis system that has been implemented to experiment with the
Petri-net-based model. This approach is also discussed in [28] where it is used to explore
hypertext systems with an afﬁnity browser.

α

A sophisticated browsing tool with advanced capabilities for databases has been devel-
oped by Stonebraker [33], which combines query reﬁnement techniques and browsing.
Jones has described a personal ﬁler with interesting retrieving capabilities [15]. His sys-
tem, ME, is a database of ﬁles connected through links which represent weighted terms. A

Browsing Requirements

251

retrieval request is a set of terms, and a spreading activation process is used to match the
ﬁles that are most relevant. Finally we cite a browsing tool for speciﬁc databases; Gedye
[11] has discussed the problems associated with accessing information related to chip de-
sign, and described a browsing tool to inspect the contents of a chip design database.

9.2

Browsing Requirements

To illustrate our browsing requirements we will use a simple paradigm. Suppose we have
an information base relative to a city. We need a city browser which can guide visitors to
plan their stay. For example, suppose we arrive at a hotel and want to go to eat. We would
like the city browser to help us choose a restaurant which is geographically close, within
an interesting and safe walk (or a place easy to reach and park), with good food, nice
surroundings, good service and within our budget.* It is obvious that we have multiple
criteria for our choice and it will be very difﬁcult to ﬁnd a restaurant that is best in all. We
need, therefore, to be guided to reach a compromise. We should also be aware that restau-
rants do not always advertise all their points (especially their shortcomings). They have,
therefore — like encapsulated objects — hidden information which we can only get from
persons that have been there.

To begin, we should point out that if the number of restaurants is small then we don’t
need sophisticated browsing tools. We can explore each one of them according to the mul-
tiple criteria, while keeping the rest in the back of our mind. This approach, however,
breaks down when the number of objects and criteria becomes large.

The ﬁrst requirement for effective browsing is a notion of locality. The browser should
present us ﬁrst with the choices that are close. Close implies a measure of distance which
does not necessarily have a single interpretation. For instance it can be geographically
close, public-transportation close, etc. Each deﬁnition of closeness is within a certain
context. The browser should, therefore, be capable of dealing with many contexts. Each
context deﬁnes a measure of afﬁnity between the objects we are looking for, in this ex-
ample city locations. We should also be in a position to change contexts in our browsing
or combine contexts relating independent selection criteria.

The  second  requirement  is  that  the  measure  of  distance  should  be  able  to  change
dynamically. For example, time distances between locations can vary with trafﬁc. The
browser should be able, therefore, to deal with quickly changing deﬁnitions of closeness.
The third requirement is that we need a notion of set-at-a-time navigation. The browser
should present us with many choices which could be pursued in the information space.
There are two reasons for this requirement. First, the immediately next objects should all
be presented to allow other more subjective criteria to be considered. Second, if we insist
on point-to-point navigation we may reach many dead-ends and be forced to backtrack.
Backtracking is very confusing especially when trying to ﬁnd an object according to mul-
tiple criteria.

* Such a system was implemented at Bell Labs for New York city restaurants.

252

The Afﬁnity Browser

Finally, users should be able to visualize the information space they are searching. We
need, therefore, to project a multidimensional information space into a two dimensional
screen. This projection should somehow preserve the deﬁnition of closeness and give a
good user interface for identiﬁcation of choices.

To summarize, we need a browsing capability which can incorporate:
• a multidimensional space;
• a measure of distance among objects deﬁned according to a certain context;
• a facility for dealing with many contexts independently or in combination;
• a dynamic environment where measures can change;
• a set-of-objects-at-a-time navigation;
• visualization of contexts in two dimensions.

9.3

The Afﬁnity Browser

We describe in this section an approach to browsing based on the concept of afﬁnity. Our
approach, the afﬁnity browser, is a tool for the exploration of object relationships ex-
pressed as afﬁnity between objects that fulﬁls the requirements discussed in section 9.2.
The afﬁnity browser is a generic browsing tool for the exploration of information systems.
As a generic tool it is meant to be tailored to speciﬁc browsing activities. The tailoring is
accomplished in essentially two ways. First, by deﬁning the appropriate afﬁnity metrics to
describe object relationships of interest among the objects of the system. Second, by add-
ing concepts and visual features that enhance the navigation guidance of the associated
search space.

Most of the browsing tools that have been discussed in the previous sections support
either  point-to-point  navigation  based  on  hierarchical  structures  (e.g.  the  Smalltalk
browser), or they rely on spatial relations for navigation. Our approach is based on the con-
cept of afﬁnity that can be appropriately expressed in visual terms as a spatial relationship:
proximity. Objects that appear close in the representation space are more strongly related
than objects that lie farther apart. A signiﬁcant advantage of this approach is that a large
spectrum of object relationships can be expressed in terms of afﬁnity provided that we can
devise metrics deﬁned on the objects of the system that appropriately portray the relation-
ships in terms of afﬁnity.

The ﬁrst step for the realization of a visual representation of a relationship among ob-
jects portrayed in terms of afﬁnity is the choice of a metric that satisfactorily represents the
relationship. The second step is the construction of a multidimensional placement of the
objects based on the afﬁnity information. The dimension of the space, the coordinates and
the measure of distance are chosen in such a way that the position of each object conveys
its relationship to the others. Objects that appear close together should have an afﬁnity to
each other. Finally, the object placement needs to be visualized in order to provide naviga-
tion support for the user. A detailed discussion of the afﬁnity browser can be found in [28].

The Afﬁnity Browser

253

Afﬁnity is a powerful conceptual relationship that humans utilize in everyday life to
construct a cognitive structure over a generally loosely structured world. One of its impor-
tant characteristics is that it is highly context sensitive. A set of objects that are close in one
context can appear quite unrelated in another context. Furthermore, different views of the
same set of objects relating to different contexts can be displayed simultaneously and thus
complement one another. Adding new views increases, therefore, the user’s understand-
ing about these object relationships.

Once afﬁnity is visually represented, users perform proximity-based navigation. Be-
cause users can explore different contexts, the browser should allow them to explore the
system by choosing, at each step, the context that seems the most appropriate for the next
move and update the other views accordingly. The set of coordinated views are called
synchronized views. This capability seems convenient since objects that appear close to-
gether in one view may lie far apart in another view. Conversely, the user may wish to pur-
sue many explorations concurrently, so the browser should also allow for independent
views. These aspects will be discussed in more detail in the next section.

9.3.1 The Afﬁnity Browser Exploration Paradigm

The intended usage of the afﬁnity browser is the exploration of an information space
assisted  by  visual  representations  of  object  relationships.  Each  such  afﬁnity  can  be
explored through an afﬁnity browser.

Figure 9.1 represents the typical layout of an afﬁnity browser. Each of the round icons
represents an object. The black icon in the centre of the browser is the marked object. The
marked object is the object around which exploration recurs; users usually select, or mark
an object, and then explore the objects in its neighbourhood. Eventually, during the explo-
ration they will ﬁnd an object that appears to be more appropriate, in which case they may
select it as the new marked object.

The  selection  of  a  new  marked  object  has  two  main  consequences.  First,  the  new
marked object is displayed in the centre of the browser. Second, the set of objects that ap-
pear in the browser are those that correspond to the new marked object’s neighbourhood.
As a consequence of marking a new object, some objects may disappear from the repre-
sentation while others may become visible.

In terms of exploration concepts, marking a new object corresponds to a shift in per-
spective. The user chooses a new navigation focal point and then explores the neighbour-
hood of the new marked object.

In a typical browsing session users select either an object they are acquainted with if
they already have some knowledge of the information space or they selected one of the en-
try points that may be provided by the system.

An exploration path can be characterized by the sequence of marked objects. These
may act as exploration landmarks and it may be interesting to provide a set of exploration
paths that represent relevant guided tours.

254

The Afﬁnity Browser

Figure 9.1 Typical layout of an afﬁnity browser representing an afﬁnity context. 

The black icon represents the marked object.

9.3.1.1 Afﬁnity Neighbourhood
An afﬁnity browser does not usually show all the objects of an afﬁnity context at a time.
The  displayed  objects  are  those  that  lie  within  a  user-deﬁned  neighbourhood  of  the
marked object. More precisely, the neighbourhood of an object is controlled by a parame-
ter 
 which represents a discriminant threshold: only the objects that have an af-
ﬁnity higher than 

 relative to the marked object are displayed. 

∈

ε

ε

0 1,[

]

Alternatively, the user may specify the maximum number of objects to appear in the dis-
play. In practice this is the most commonly used way of specifying the visual neighbour-
hood range. The reason is that by keeping the same number of objects during exploration
the user avoids situations where the system does not provide enough choices (e.g. few ob-
jects displayed), or situations where the browser presents too many choices in a cluttered
display.

The notion of set-of-objects-at-a-time navigation results from limiting the displayed
objects to those that lie in the speciﬁed neighbourhood of an object. This set represents the
inspection  alternatives  that  the  browser  offers  concurrently  to  the  user. Although  the
“radius” of the neighbourhood can be changed at any time, it is an essential assumption of
our approach that proximity-based navigation is a convenient exploration paradigm for
most exploration or inspection tasks. Further, we see the neighbourhood restriction rather

The Afﬁnity Browser

255

as a feature than as a limitation. Once users locate a region of interest they should be pre-
sented only with the choices that are close in its exploration context.

Synchronised Afﬁnity Browsers

9.3.1.2
The proximity-based navigation provided by an afﬁnity browser is mainly intended for
“ﬁne-grained” exploration. That is, once users have identiﬁed an interesting region, they
explore the alternatives that are close in order to select the most appropriate. However,
when users are exploring the information space “at large”, local navigation alone is usual-
ly not enough. 

A powerful mechanism used in human mental processes is association. For example,
users proceed by association to recall entities that are close to a given entity. This mental
process  corresponds,  in  terms  of  browsing,  to  proximity-based  navigation. A  slightly
more elaborate mental process consists of focusing on an object, exploring its neighbours,
and investigating how the neighbouring objects in the present context are related in anoth-
er context, and then exploring the objects that are close in the new context. This is a pow-
erful process since it allows us to reach objects that are not closely related in the ﬁrst
context. Loosely speaking, we may say that exploration is based on transitive association;
navigation is proximity-based but by alternating the navigation context the user can reach
many other interesting objects. The mechanism that we provide to support this kind of
transitive associations is the synchronization of afﬁnity browsers. The synchronization of
the afﬁnity browsers implies that the object under inspection in one browser is also high-
lighted in the others. Users may pursue exploration in any of the browsers and the same
path is followed in the others provided the inspected object also belongs to the latter con-
text. We may recall here that two objects that are close in one context might not be close,
or may even be unrelated, in another context. Figure 9.2 shows a set of four synchronized
browsers. Synchronized views allow users to inspect objects that would otherwise be un-
reachable if navigation is based on just one exploration context. This stems from the fact
that, in one browser objects that are not related to the marked object are normally not dis-
played. So, to reach non-related objects the user needs to switch to another browser for
which the objects are related in the displayed context. This emphasizes the notion of
navigation based on the strict neighbourhood of the marked object. However, the browsers
allow users to display objects that are not directly related but are related by transitivity.

When objects are transitively related, their afﬁnity is calculated either by a max-min
transitivity rule or by a max-product rule. Refer to [28] for a detailed discussion about
these operations.

Finally, the user may also explore the information space based on multiple independent
browsers or a combination of synchronized and non-synchronized browsers. The syn-
chronization of the browsers is not a symmetric mechanism: saying that browser (a) is
synchronized  with  browser  (b)  does  not  imply  that  browser  (b)  is  synchronized  with
browser (a). To obtain two-way synchronization the user needs to specify it explicitly.

256

The Afﬁnity Browser

Figure 9.2 Synchronous afﬁnity browsers. The black icon represents the marked object. 
The user is performing exploration in the lower left browser where the marked 
object appears in the centre. Since the browsers are synchronized, the marked 
object is the same in all the browsers.

9.3.1.3

Exploration Based on Dynamically Evolving
Afﬁnity Contexts

As we stated in our browsing requirements, afﬁnity browsers are intended to provide nav-
igation guidance based on dynamically evolving object relationships. The browser pro-
vides such support essentially in two ways. First, it is able to track in a visual way and in
interactive  time-evolving  relationships.  Second,  the  browser  provides  for  a  degree  of
visual feedback where the movement of the visual objects gives the illusion of dynamic
motion and dynamic interaction. Both aspects are addressed in more depth in [28] and
[25].

One difﬁculty that users may ﬁnd with dynamically evolving afﬁnity contexts is that the
changes in object relationships may make some objects disappear from the representation
and  others  may  show  up  due  to  the  neighbourhood-restricted  display.  From  our  ex-
perience, this is quite cumbersome for unstable relationships that evolve at a fast pace.

The Afﬁnity Browser

257

9.3.2 Architectural Elements of an Afﬁnity Browser

The architectural foundation of the afﬁnity browser relies on an approach to software
construction based on the composition of software components. Such an approach em-
phasizes modularity and careful study of component interfaces in order to achieve reusa-
bility and ﬂexibility in software conﬁguration. This ﬂexibility is needed for the afﬁnity
browser since the idea is to provide a generic architecture that can be conﬁgured to meet
the exploration requirements that a speciﬁc browser is intended to support.

9.3.2.1 Afﬁnity Engine and View Engine
An afﬁnity browser is comprised of two main units: the afﬁnity engine and the view engine.
The afﬁnity engine is responsible for the management of tasks that are related to the trans-
lation of object relationships into a standard form of afﬁnity representation.

The view engine is responsible for display and user interaction management. The afﬁn-
ity engine and the view engine communicate through well-deﬁned protocols. The afﬁnity
engine  often  incorporates  application-domain-dependent  functionality  in  order  to  en-
hance navigation guidance with domain dependent-features. Similarly, the view engine
can also incorporate visual features speciﬁc to the application domain and we frequently
use this capability, in particular for ﬁnancial tools.

Translucency: One Browser, Multiple Contexts

9.3.2.2
In our architecture, a browser can display multiple contexts simultaneously. This capabil-
ity is made available by the view engine that supports a stack of translucent views so that
the user can see through the views those that lie behind. The user can specify the desired
degree of translucency from completely transparent to completely opaque. In a transpar-
ent view, no objects are visible. In an opaque view, objects hidden behind a front view do
not show up. The superimposition of views is displayed with a visual effect of depth
cueing: views progressively fade away from front to back.

The use of translucency is quite effective because it allows for the simultaneous explo-
ration of many contexts on the same visual space. As a rule of thumb, in order to be useful
the number of displayed views should not usually exceed four since the visual fading ef-
fect makes some views unreadable. Translucent visual layers are also effective to display
domain-dependent  information  such  as  names,  visual  cues,  transient  information  and
alarms.

The interaction protocols between the view engine and the visual layers is well-deﬁned,
which allows the dynamic insertion of new layers into the view stack. The main advantage
of having multiple views displayed in two dimensions is that lengths and distances can be
compared visually, which is not usually the case when display relies on three-dimensional
techniques since projection distorts distances.

258

The Afﬁnity Browser

9.3.3 User Interaction and Event Management

In order to conveniently support interaction with multiple superimposed visual layers, the
view engine provides an event distribution mechanism through which events from many
sources are distributed to the various layers that are responsible for reacting to them. When
a new event is queued, it is sent ﬁrst to the topmost layer, which is asked if it is interested
in the event. If the layer is not interested or if the layer does not consume the event, then it
is sent to the next layer in the view stack. The operation is applied recursively down the
view stack until either the event is consumed or the bottom of the view stack is reached.

The order of the visual layers can be changed interactively by the user. Typically, users
bring the layer with which they want to interact to the top of the stack. Furthermore, visual
layers can be added to and deleted from the stack. A new visual layer is inserted, by de-
fault, at the top of the stack. Object relationships displayed in different visual layers of the
same browser can be either synchronized or not, much in the same way as object relation-
ships are displayed in different browsers.

The event distribution mechanism plays an important role in implementing coupled co-
operative strategies between the visual layers. In fact, one of our design goals was to deﬁne
an architecture for the view engine independent of the application domain. To achieve this
goal, the interaction between the view engine and the visual layers only supports applica-
tion-independent operations and not intended to be extended. We decided to provide ﬂex-
ibility in the way cooperation between views can be speciﬁed through an extended event
distribution mechanism that acts as a messaging backbone.

The event distribution mechanism allows visual layers to communicate spontaneously
or in reaction to user-initiated events. Additionally, the browser can be dynamically con-
trolled by other applications that send events through the event distribution mechanism.

We applied the idea of external browser control to a ﬁnancial application that displays
real-time evolving relationships [29]. The application, which runs most of the time with-
out user interaction, implements various display strategies aimed at highlighting impor-
tant ﬁnancial instruments relationships. The display and the relative position of the visual
layers changes under the control of another application that monitors interesting invest-
ment opportunities. This approach to browsing control can be used to provide automatic
navigation for dynamically evolving system.

To summarize, the afﬁnity browser architecture has the following desirable character-

istics for an exploration tool:

• Versatility. Allows users to inspect the underlying system through object relation-
ships expressed in terms of afﬁnity. The exploration can be based both on static or
dynamic relationships, and the exploration perspective can be either local or global.
• Composability. Users can navigate based on multiple object relationships used inde-

pendently or in combination. Multiple views can be active concurrently.

• Extensibility. New object relationships can be easily added to the exploration tool

and combined with previously deﬁned ones.

The Afﬁnity Browser by Example

259

9.4

The Afﬁnity Browser by Example

An intuitive way to describe the afﬁnity browser approach is to say that we “measure” ob-
ject relationships in such a way that the measurements translate the relationships into ob-
ject afﬁnities. Alternatively, we can say that we quantify a relationship in order to express
it in terms of object afﬁnity or proximity. For the afﬁnity browser, these measurements are
always performed between pairs of objects and are called metrics (refer to [28] for a for-
mal presentation of these concepts).

As we may easily anticipate, one of the critical issues related to afﬁnity browsing is the
deﬁnition of metrics that portray interesting object relationships. We provide here a few
examples of such metrics describing both static and dynamic relationships. Our main goal
is to illustrate how the afﬁnity browser can help one to understand particular aspects of an
object-oriented environment, and provide typical examples of the kind of information an
afﬁnity browser is intended to provide for a system.

We ﬁrst discuss metrics based on static analysis of class relationships. This kind of anal-
ysis is usually important to assess design and to understand architectural articulations; it
provides insight into the relationships among classes without actually executing the code.
Therefore, the information is primarily extracted by source code analysis.

Next we address the issue of extracting relationships corresponding to the dynamic
behaviour of the system. We can identify interesting relationships among both classes and
objects. Metrics to portray such relationships are based on dynamic analysis that consists
of collecting statistical information, or simply frequency data during a system’s execu-
tion.

The analysis can be performed either dynamically, in which case the display of the
relationship is synchronized with the execution, or it can be off-line based on the informa-
tion collected. In the latter case, the exploration phase resembles static analysis since the
relationships  do  not  evolve  dynamically.  It  is  also  possible  to  collect  data  about  the
dynamic behaviour of the system and perform the analysis off-line. The advantage is that
the analysis can be performed at the user’s pace while still allowing for dynamic display.

9.4.1 Class Relationships

We discuss in this section three examples of metrics aimed at revealing class relationships.
The ﬁrst example deals with portraying functional commonality among classes. As a
result of inheritance, derived classes inherit functionality from their base classes, and this
raises the issue of the extent to which classes differ. The example discusses metrics related
to this issue.

The second example deals with class acquaintances. In order to perform their tasks, the
methods of a class send messages to other classes to invoke services. Patterns of interac-
tion  between  a  class  and  its  environment  may  provide  useful  information  about  the
required working environment for the class. We discuss metrics intended to reveal class
acquaintances.

260

The Afﬁnity Browser

The third example addresses the problem of class relationships related to object birth
and death. More speciﬁcally, we are interested in knowing which classes are instantiating
and freeing objects. Because we are focusing here on relationships among classes, we
consider that two classes are related if one class instantiates or frees objects of the other
class.

It should be noted that the extraction of information for building such metrics depends
considerably on the environment and on the language used to deﬁne the classes. In partic-
ular, with strongly typed object-oriented languages such as C++ and Eiffel, relationships
like those of the ﬁrst two examples are usually more accurately portrayed than when met-
rics  are  derived  from  classes  implemented  with  weakly  typed  languages  since,  with
strongly typed languages, relationships among classes are mostly statically deﬁned.

,

,

}

{

=

C

C0

… C8

Functional Commonality

9.4.1.1
In this example we construct a metric aimed at portraying the functional commonality
among classes. For the sake of concreteness, the metric construction is illustrated with the
set  of  classes
  depicted  in  ﬁgure  9.3.  Following  inheritance  rules,
classes recursively inherit methods from their superclasses. We further assume that a class
can redeﬁne the methods inherited from its superclasses. Let 
 be a function that re-
=
turns the set of methods in the interface to class
. With
this metric we want to convey the extent to which classes provide common functionality.
The measure of afﬁnity between two classes can, therefore, be expressed as the proportion
of methods that are common to the two classes relative to the total number of the methods
deﬁned in both classes. As a candidate measure we deﬁne the afﬁnity
 between
class

)
M X(
C3

. For instance,

A1 X Y,

,
a b g h

 and class

X

}

{

(

)

,

,

X

Y

 by the function:
A1 X Y,

(

)

=

card M X(
)
)
--------------------------------------------------
card M X(
)
)

) M Y(
∩
) M Y(
∪

(
(

where 

card()

 is a function that returns the cardinality of a set.

Suppose now that we want to emphasize the fact that redeﬁned functionality might dif-
fer from inherited functionality. We can modify slightly the afﬁnity measure for the case
m′
of redeﬁned functionality. Let 
 be its redeﬁnition. In the
 then for the afﬁnity calcu-
case where both 
m
lation we consider 
we take 
redeﬁnes a method from a superclass (such as class 
derive the table 9.1 of pairwise afﬁnities.

. This produces a slight reduction of the afﬁnity between classes where one
). From the afﬁnity function we can

 be the inherited method and 
)

∪
(
) M Y(
) M Y(
)
)
∩

 appear in 
(
 in 

card M X(

card M X(

card M X(

) M Y(
∪

 and 
=
m

m m′≠

 while in 

m′
m′

C1

m

)

(

)

)

Figure 9.4 shows a view of the afﬁnity browser depicting metric
C4

A1 X Y,
 applied to
,  is  the marked  item
the  classes  of  ﬁgure  9.3.  In  ﬁgure  9.4,  the  highlighted  class, 
selected by the user. Therefore, the exploration is centred on it and the browser displays
the items that lie inside the neighbourhood of the marked item, where the neighbourhood
is deﬁned as the set of objects for which the afﬁnity relative to the current object is higher

)

(

The Afﬁnity Browser by Example

261

C
0

ab

C
1

cda

C
2

ef

C
3

gh

C
4

ij

C
5

kl

C
6

mn

C
7

op

C
8

qr

Figure 9.3   Inheritance structure of a set of classes.

C1
2/5

C2
1/2

2/7

C3
1/2

2/7

1/3

C4
1/2

2/7

1/3

1/3

C5
2/7

2/3

2/9

2/9

2/9

C6
2/9

4/9

4/9

2/11

2/11

4/11

C7
2/8

2/11

1/2

2/10

1/2

2/13

4/13

C8
2/11

4/11

4/11

2/13

2/13

4/13

8/11

4/15

C0
C1
C2
C3
C4
C5
C6
C7

Table 9.1   Functional commonality: pairwise afﬁnity.

than a chosen value. In this case, however, due to the small number of items, they are all
displayed.

9.4.1.2 Metrics Based on Binary Vectors
Many other metrics can be deﬁned to reveal functional commonality. A particularly inter-
esting approach relies on metrics based on binary data. The interest in using binary vectors

262

The Afﬁnity Browser

C3

C7

C4

C0

C2

C5

C6

C1

C8

Figure 9.4   Afﬁnity browser display showing a set of classes.

to build metrics is that many relationships can be expressed in terms of binary vectors to
which we can apply a set of “standard” operations to measure their similarity.

In order to apply these metrics to portray functional commonality we assign to each
class a binary vector of length  , where   represents the number of distinct method signa-
tures in the system. Each entry of the vector is associated with a method signature. Refer-
ring to the set of classes depicted in ﬁgure 9.3, the binary vector takes the form:

l

l

a b c

d e f g h i

j k l m

n

o p

q

r

Each entry contains a Boolean value that tells if the associated method signature is
C0

present or absent in the class. For example, the binary vector associated with class
looks like:

1 1 0

0 0 0 0 0 0 0 0 0 0

0

0 0

0

0

and the vector associated with class 

C6

:

1 1 1

1 1 1 0 0 0 0 0 0 1

1

0 0

0

0

The Afﬁnity Browser by Example

263

The construction of an afﬁnity metric from binary vectors consists essentially in meas-
uring to what extent vectors match. These can be deﬁned based on the following auxiliary
parameters:

ψ

11

l∑=

k

1=

min xk yk

(

,

)

ψ

10

l∑=

k

1=

xk

–

ψ

11

ψ

01

l∑=

k

1=

yk

–

ψ

11

ψ

00

–=

l

(

ψ

ψ

+

ψ

+

)

11

10

01

Ψ

11

where x and y represent two binary vectors. 
simultaneously in the corresponding entries of x and y; 
appears in x and 0 in y for corresponding entries; 
in x and 1 in y for corresponding entries; and
simultaneously in the corresponding entries of x and y. So 
of entries in which x and y agree, while 

counts the number of times 1 appears
 counts the number of times 1
counts the number of times 0 appears
 counts the number of times 0 appears
count the number
 count the number of disagreements.
We propose three metrics to portray functional commonality based on the binary vector

Ψ
01Ψ
00

 and 

 and 

Ψ

Ψ

Ψ

Ψ

Ψ

11

01

00

10

10

representation. The ﬁrst metric is

(

A2 X Y,

)

=

Ψ
11
---------
l

(

Y

 and 
)

where 
X
A2 X Y,
of the binary vectors.

 represent the classes from which the binary vectors 

 are derived.
 assesses binary vector similarity in terms of 1-consensus relative to the length

 and 

y

x

The second metric is

(

A3 X Y,

)

=

Ψ
Ψ

11

-----------------------------------------
Ψ
01

Ψ

11

10

+

+

With this metric the proportion of the 1-consensus is evaluated relative to the number of
entries of the vectors excluding those that correspond to a 0-consensus; that is, the metric
assesses  afﬁnity  in  terms  of  1-consensus  relative  to  disagreement.  This  means  that
A3 X Y,
The third metric

 is equivalent to 

A1 X Y,

)

(

)

(

.

(

A4 X Y,

)

=

------------------------------------------------------------------------------------------------------------------------------
)
01

) Ψ
(

) Ψ
(

Ψ

Ψ

Ψ

Ψ

11

01

10

00

11

10

00

+

+

+

+

(

Ψ
Ψ

11

Ψ
00
) Ψ
(

measures binary vector correlation but is not a metric similarity index as are 
and, consequently, 

)

.

(

A1 X Y,

(

A3 X Y,

)

264

The Afﬁnity Browser

aa
ab
ac
ad
ae

ca
cb
cc
cd
ce

class A

class C

ba
bb
bc
bd
be

class B

Figure 9.5 A set of cooperating classes. The three classes cooperate by service 
exchange. Each slot represents the body of a method and the arrows 
represent the activation of a method from the body of another method.

9.4.1.3 Class Acquaintances
The functionality of a class is not usually self-contained. Methods belonging to a class can
invoke services from other classes. This perspective corresponds to a commonly accepted
view of object-oriented systems as sets of collaborating objects.

We are interested in understanding patterns of collaboration between objects. However,
collaboration has many aspects. We can focus, for instance, on the relationships between
classes that can be observed by static analysis of the source code. Alternately, we may
focus  on  dynamic  acquaintances  of  classes  measured  by  observing  message  sending
patterns between objects of the classes.

Both perspectives are interesting and are, to a large extent, complementary. The former
perspective usually reﬂects design decisions since “hard coded” relationships usually
materialize links deﬁned at the architectural level. Such links represent the required work-
ing environment for a class. But this perspective may fall short of providing an accurate
picture if we are looking for working acquaintances between classes. In this case the latter
perspective may be more helpful. 

In practice, the collaboration patterns revealed by the two perspectives usually differ
signiﬁcantly. However, the analysis of the differences might offer useful insight about
mismatch between the collaborations that have been foreseen by the designer and those
that show up in speciﬁc execution contexts. We start with a metric intended to portray
static class acquaintances. That is, acquaintances that can be determined without actually
executing the methods of the class.

The Afﬁnity Browser by Example

265

Figure 9.5 represents the analysis context for such a metric. Each class contains a set of
methods and the methods activate methods belonging to other classes that, in turn, trigger
other methods as well. So the execution of a class’s method usually involves the execution
of methods from many classes.

Let 

J
IK

 invokes methods from class 

IK
 to any other class. The following is a

, and let 

J

K

 denote the number of times class 

K

denote the total number of invocations from class 
candidate metric to portray class acquaintances:

(

A5 K J,

)

=

max





J
IK
-----
IK

,


K
IJ

-----

IJ

which means that the acquaintance afﬁnity between two classes is deﬁned as the maxi-
mum of relative invocation frequency of both classes. We may notice, however, that many
different functions can be used instead of 
 to combine the two “one-sided” ac-
quaintances. We can deﬁne a more general metric as follows:

max()

(

A5 K J,

)

=

1

–

log











1

1

λ

K
IJ
----–
IJ

J
IK
----–
IK





1–




---------------------------------------------------------





1–




λ 1–

λ






1+





x( )

λ

λ

∈

0 1,(

)

∪

1 ∞,(

)

log

 and 

where 
 has base . This metric is inspired from a func-
tion proposed by Frank [1] to deﬁne the union operation on fuzzy sets. The reader might
want to refer to [28] for a detailed discussion about other functions that can be used in this
context. This way of doing things may suggest an interpretation where 
 represents
the afﬁnity degree of an element 
 which depicts the unilateral afﬁnity ac-
J
quaintance between class 

K
 and the other classes.

 to afﬁnity set 

J
IK

IK

K

⁄

sC m,

 denote a service; that is, 

9.4.1.4 Class Acquaintance Similarities
We may also be interested in class acquaintance similarity. In other words, we want to dis-
cover to what extent classes match in terms of the services they ask for from other classes.
Let 
 and one of its
 denote the frequency of invoca-
methods represented by its method’s signature 
tion of service 
 a
vector 
 is equal to the number
of different services invoked by the classes of the system.
So, the collection of classes can be represented in the 
d

. Let 
. We can associate to each class 
K
. The dimension 
d

-dimensional space of the serv-
ices, where each class will appear as a point. The idea is that classes lying close together
in this space ask for similar services. We may want to modify slightly the service weight-

m
 from inside the methods of class

 is an association of a class name 

 with entries containing 

 of vector

s
fK

s
fK

vK

vK

C

K

s

s

266

The Afﬁnity Browser

ing scheme to improve selectivity. Let 
is
s

 is invoked, and let 

n

 denote the number of classes. We can deﬁne

 denote the number of classes from which service

Ls

=

log2n

–

log2is

1.+

⋅
s Ls
fK

A service weighting proportional to 
 will assign larger weights to services which
are invoked with high frequency in individual classes, but that are only invoked by a few
classes. This type of weighting scheme improves substantially both recall and precision
when applied to document retrieval [32]. Finally, we can deﬁne a distance metric between
two classes 
.
vJ

 as the Euclidean distance between the associated vectors 

 and 

 and

vK

K

J

9.4.2 Creation and Destruction Relationships

In an object-oriented environment, objects are usually created and destroyed by other ob-
jects. Understanding creation and destruction relationships is important for many reasons.
First, it provides essential information about which classes are managing the object pop-
ulation in the system and, in particular, which are the typical procreators of objects that
provide speciﬁc kinds of services. Second, this understanding is crucial for debugging
and, in particular, memory allocation related errors. As a matter of fact, the very nature of
object-oriented systems as sets of cooperating agents raises the problem of object clean-
up. Designers need to decide who is responsible for freeing the objects. It is often difﬁcult
to assign this responsibility to its creator, especially if the creator is not the consumer of
the services. The non-destruction of stale objects may become a particularly important is-
sue in the absence of automatic garbage collection.

Creation and destruction relationships can be analyzed either statically or dynamically.
Similar to acquaintance relationships, dynamic and static analysis provide different per-
spectives on the creation and destruction relationship. Static analysis based on source
code scanning essentially provides information about the structure of the creation and
destruction process. We can learn, for instance, which classes can create and destroy in-
stances of given classes.

Dynamic analysis provides another perspective on the relationship by showing which
class instances are actually creating and destroying objects, and also how many objects are
created and destroyed. However, the static perspective falls short of portraying an impor-
tant aspect of software execution: execution phases. A typical software system or subsys-
tem goes through a number of execution phases. It may start with an initialization phase,
then alternate through several phases. Different phases become evident by analysis of both
interclass acquaintances and creation and destruction relationships. Entering a new phase
usually corresponds to a signiﬁcant modiﬁcation of interaction patterns and an intense ac-
tivity of object destruction — for phase cleanup — and creation of new objects for the
new execution phase.

The Afﬁnity Browser by Example

267

The information about the creation relationship can be represented by a matrix like

C

=

CA A, CA B, CA C,
CB A, CB B, CB C,
CC A, CC B, CC C,

X

CX Y,

CX Y,

 create instances of class 

 represents the number of times creation of an instance of class 
Y

 can be iden-
where 
, if we are in the context of static analysis.
tiﬁed inside the source code specifying class 
In the context of dynamic analysis, 
 represents the number of times instances of class
 during a given time interval. In order to explore execution
X
phases we can collect data for several time intervals that should reveal the changes in cre-
 that has a
ation patterns. The destruction relationship can be represented by a matrix 
similar form to 
X
destroy instances of class 
We can derive a matrix

 represents the number of times instances of class 

 during a given time interval.

 where entry 

DX Y,

D

C

Y

Y

R

=

CA A,
CB A,
CC A,

–
–
–

DA A,
DB A,
DC A,

CA B,
CB B,
CC B,

–
–
–

DA B,
DB B,
DC B,

CA C,
CB C,
CC C,

–
–
–

DA C,
DB C,
DC C,

which might represent an acceptable view of the balance between creation and destruction
responsibilities. For instance, 
 destroyed more instances of
class 
 than it created during the time interval under analysis. Many insightful metrics can
Y
be derived from the information contained in these matrices. 

 means that class 

RX Y,

0<

X

We convey creation relationships in such a way that classes that are frequently involved
in creation (either by creating or by being created) have more afﬁnity and thus cluster to-
gether in the representation. A candidate metric is:

(

A6 X Y,

)

=

)
max CX Y, CY X,
------------------------------------------

(
,
max C(

)

max C(

)

 denotes the maximum value in matrix . 

where 
 fails to show which
one of two classes displaying high afﬁnity is responsible for creation. To obtain such in-
formation we may either deﬁne a pair of metrics to be used in exploration with synchro-
nized views or create a metric that highlights asymmetry. Both approaches have already
been discussed in the context of the formulation of previous metrics.

C A6 X Y,

(

)

We provide another metric to convey the balance between creation and destruction. The
idea is that instances of a class 
 than they
destroy, display more afﬁnity while a negative balance in the creation/destruction process
reduces the afﬁnity between 

 that create more instances of another class 

 and .
Y

X

X

Y

268

The Afﬁnity Browser

(

A7 X Y,

)

=

(

)
)
max RX Y,
-----------------------------------------------------------------------------------------

)
min R(
,
RY X,
) min R(
–

–
max R(

min R(

–
)

9.4.3 Object Relationships

We discussed in the previous section metrics to portray class relationships. The informa-
tion needed to apply those metrics relies either on static analysis of the class deﬁnitions,
on dynamic analysis of execution activity, or on both. We may notice, in passing, that
many of the metrics discussed could be used to portray object relationships as well. In this
section we focus speciﬁcally on object relationships that are related to dynamic aspects of
the system’s execution and, therefore, require dynamic behaviour analysis. Understand-
ing the dynamic behaviour of a set of objects that collaborate to perform a task can provide
useful information for reuse and for class management. Dynamic behaviour analysis can
be helpful:

• in giving useful hints about the usage a developer intended for a particular class;
• by showing the typical utilization of classes inside an application;
• to tune the performance of classes;
• in providing information for the assessment of class designs;
• in application debugging.

We now discuss candidate metrics intended to portray different aspects of the dynamic be-
haviour of objects deﬁned in terms of object afﬁnity. In order to perform tasks collectively,
objects exchange messages. As a ﬁrst goal we want to know which objects collaborate
closely. Because we are interested in dynamic patterns of collaboration, the information
needed to build the metrics is collected by monitoring message passing activity.

Let 

O

=

{

,

O1 O2

,

,

… On

}

interval. We may deﬁne an afﬁnity metric 
Y O∈

 by:

 denote the set of interacting objects during a given time
 and object

 between object 

X O∈

)

(

A8 X Y,

(

A8 X Y,

)

=

(

card send X Y,
)
)
-----------------------------------------------------------------------------------------

card send Y X,(

+

)

(
card send Oi

)
(

(

(
∑

)

)

i

(

send X Y,
card x( )

)
 returns the cardinality of a set. So 

 is a function that returns the set of messages sent by object 

where 
 to object
 represents the to-
, and 
Y
tal number of messages exchanged during the monitored time interval. With such a metric
of afﬁnity, objects that exchange messages frequently will have more afﬁnity and will
therefore cluster together in the afﬁnity browser’s visual representation.

icard send Oi

Σ

X

)

(

)

(

9.4.3.1 Detecting Object Interaction Asymmetry
(
However, metric 
example, that object 

 does not show asymmetric interaction patterns. Suppose, for
 seldom

 sends messages frequently to object 

 while object 

A8 X Y,

)

X

Y

Y

The Afﬁnity Browser by Example

269

sends messages to object 
pose asymmetry we deﬁne two metrics, 
be used in two synchronized views:

. Measure 

X

(
A8 X Y,
)
(
A9a X Y,

 will not reveal this fact. In order to ex-
)
, that are intended to

A9b X Y,

 and 

(

)

A9a X Y,

(

)

=

A9b X Y,

(

)

=

(

)
)
card send src X Y,
---------------------------------------------------------------------------------

) dest X Y,
,
(

(
)

)

)

(

card send dest X Y,
)
)
---------------------------------------------------------------------------------

) src X Y,
,
(

(
)

)

)

(

(

(
∑
card send Oi
(
∑
card send Oi

(
(

i

i

We introduce the notion of source and destination to cope with the asymmetry between
the two metrics; the functions src() and dest() return respectively the source object and the
destination object. The role of these functions is to enforce a rule so that an object that
plays the source role for a given pair (X,Y) in the ﬁrst metric plays the destination role for
the same pair in the other metric. Additionally, the rule copes with pair symmetry so that
)
A9a X Y,
A9a Y X,(
. The rule works as follows: for
 and 
)
an afﬁnity context with 
 objects we generate the 
 pairs that correspond to
n
4=
the upper right half of a matrix which is illustrated for 

A9b X Y,

A9b Y X,(

n n 1–(

) 2⁄
:

=

=

n

(

)

(

)

)

(

(

,

O1 O2

(
) O1 O3
(
O2 O3

,
,

(
) O1 O4
(
) O2 O4
(
O3 O4

,
,
,

)
)
)

The rule speciﬁes that for each pair, the object that appears on the left-hand side plays
the role of the source and the object on the right plays the role of the destination. Further-
more, for any such pair (X,Y) the roles for the symmetric pair (Y,X) are assigned to the same
objects. For example, 
the role of the destination in
(
both 

 plays the role of the source and 

 and

O3

)

)

(

,

O1 O3

When metrics 

 are represented in synchronized views, the
user can spot asymmetry by looking for pairs of objects that appear close in one view and
farther apart in the other. These two metrics provide both global information about collab-
oration as well as information about collaboration asymmetry.

A9b X Y,

(

)

O1
,
O3 O1
A9a X Y,
(
)

.
 and 

However, if we are mostly interested in detecting asymmetry, it might be more appro-
priate to emphasize pairwise interaction instead of global interaction afﬁnity. To this end
)
A10a X Y,
we may consider the replacement of metrics 
and

A9b X Y,

A9a X Y,

 and 

 by 

)

(

)

(

(

)

(

A10b X Y,
)
(
∆ X Y,

. Let
card send src X Y,

(

(

(

=

) dest X Y,
,

(

)

)

∪

send dest X Y,

(

(

) src X Y,
,

(

)

)

)

270

and

A10a X Y,

(

)

A10b X Y,

(

)

=

=

The Afﬁnity Browser

(

(

(

(

card send src X Y,
) dest X Y,
,
(
)
)
---------------------------------------------------------------------------------
(
)
∆ X Y,
card send dest X Y,
) src X Y,
(
,
)
)
---------------------------------------------------------------------------------
)
(
∆ X Y,

(

(

)

)

It is also possible to synthesize information about symmetry of message passing in one
metric, although the resulting display might be more difﬁcult to interpret. 
is a
candidate measure for such a view. This measure focuses on symmetry of message ex-
changes and, therefore, suppresses information about frequency of communication.

A11 X Y,

(

)

A11 X Y,

(

)

=

1

–

(
(

) A9b X Y,
abs A9a X Y,
)
)
–
-------------------------------------------------------------------
)
)
) A9b X Y,
abs A9a X Y,
+

(
(

(
(

Interaction asymmetry is an important issue at the design level. For instance, Booch [4]

identiﬁes three roles for objects in terms of message passing activity: 

• Actor: an object that operates upon other objects but that is never operated upon by

other objects.

• Server: an object that never operates upon other objects; it is only operated upon by

other objects.

• Agent: an object that can both operate upon other objects and be operated upon by
other objects; an agent is usually created to do some work on behalf of an actor or an-
other agent.

Such  roles  can  be  identiﬁed  with  metric 

.  The  comparison  of  the  roles
assigned to objects during the design phase, with the effective role they play in given exe-
cution contexts, might be instrumental to assess to what extent reusable software compo-
nents are used as intended by their designers.

A11 X Y,

(

)

9.5 Conclusion

This chapter dealt with the exploration of object relationships in the context of object-
oriented environments. We addressed the important issue of understanding how objects
are related because such understanding plays an important role in many key issues related
to software engineering such as reuse, debugging and software maintenance. Early object-
oriented environment designers have identiﬁed these issues and provided browsing tools
to help users explore the environment.

We have proposed a new approach to the exploration of an object-oriented environment
where object relationships are translated into afﬁnity relations so that the object relation-
ships can be graphically represented in terms of distance: objects that are strongly related
appear closer in the representation. The approach has the advantage that many different re-
lationships can be represented and explored with the same tool and with the same explo-

References

271

ration paradigm. From the user’s perspective, afﬁnity is a very intuitive concept that has
the advantage of being easily translated into a visual distance.

References

[1] Hans-Dieter  Böcker,  Jürgen  Herczeg,  “What  Tracers  are  Made  Of,”  Proceedings  of  OOPSLA/

ECOOP ’90, ACM SIGPLAN Notices, 1990, pp. 89–99.

[2] R. Bolt, “Spatial Data Management,” DARPA Report, MIT, Architecture Machine Group, 1979.
[3] Bernd Brüegge, Tim Gottschalk, Bin Luo, “A Framework for Dynamic Program Analysers,” Proceed-

ings of OOPSLA ’93, ACM SIGPLAN Notices, 1993, pp. 65–82.

[4] Grady Booch, Object Oriented Design With Applications, Benjamin/Cummings, 1991.
[5] Michael Caplinger, “Graphical Database Browsing,” Proceedings of ACM-SIGOIS, SIGOIS bulletin,

vol. 7, no. 2–3, Oct. 1986.

[6] Matthew Chalmers and Paul Chitson, “Bead: Explorations in Information Visualization,” Proceed-

ings of SIGIR ’92, June 1992, pp. 330–337.

[7] William Donelson, “Spatial Management of Information,” Computer Graphics (Proceedings of SIG-

[8]

[9]

GRAPH ’78), Aug. 1978, pp. 203–209.
Furnas Fairchild, Poltrock, “Semnet:Three-dimensional Graphic Representation of Large Knowl-
edge Bases,” in Cognitive Science and its Applications for Human–Computer Interaction, ed. R.
Guindon, Lawrence Erlbaum, Hillsdale, NJ, 1988.
Steven Feiner, “Seeing the Forest for the Trees: Hierarchical Display of Hypertext Structures,” Pro-
ceedings of COIS ’88, Palo Alto, March 1988, pp. 205–212.

[10] C. Fields and N. Negroponte, “Using New Clues to Find Data,” Third International Conference on

Very Large Data Bases, Tokyo, Oct. 1977, pp. 156–158.

[11] David Gedye and Randy Katz, “Browsing the Chip Design Database,” University of California at Ber-

keley, Computer Science Division, Oct. 1987.

[12] Adele Goldberg, Smalltalk-80: The Interactive Programming Environment, Addison-Wesley, Read-

[13]

ing, Mass., 1984.
I. Goldstein and D. Bobrow, “Browsing in a Programming Environment,” Proceedings of the 14th Ha-
waii International Conference on System Science, January 1981.

[14] Charles Herot, “Spatial Management of Data,” ACM Transactions on Database Systems, vol. 5, no. 4,

Dec. 1980, pp. 493–513.

[15] William P. Jones, “On the Applied Use of Human Memory Models: The Memory Extender Personal

Filing System,” International Journal Man–Machine Studies, vol. 25, no. 2, 1986, pp. 191–228.

[16] George Klir, Tina Folger, Fuzzy Sets, Uncertainty and Information, Prentice Hall, Englewood Cliffs,

NJ, 1988.

[17] M. Kleyn, P. Gingrich, “GraphTrace — Understanding Object-oriented Behaviour Systems Using
Concurrently Animated Views,” Proceedings of OOPSLA ’88, ACM SIGPLAN Notices, 1988, pp.
191–205.

[18] Jeffrey T. LeBlanc, “N-Land: A Visualization Tool for N-Dimensional Data,” Technical Report Com-

puter Science Department, University of Worcester, May 1991.

[19] Bertrand Meyer, Object-Oriented Software Construction, Prentice Hall, 1988.
[20] Amihai Motro, “Browsing in a Loosely Structured Database,” Proceedings of ACM–SIGMOD 1984,

International Conference on Management of Data, 1984, pp. 197–207.

[21] Amihai Motro, “BAROQUE: A Browser for Relational Databases,” vol. 4, no. 2, April 1986, pp. 164–

181.

272

The Afﬁnity Browser

[22] Amihai Motro, “VAGUE: A User Interface to Relational Databases that Permits Vague Queries,”

ACM Transactions on Ofﬁce Information Systems, vol. 6, no. 2, July 1988, pp. 187–214.

[23] Amihai Motro, Alessandro D’Atri, Laura Tarantino, “The Design of KIVIEW: An Object-Oriented
Browser,” Proceedings of the Second International Conference on Expert Database Systems, Virgin-
ia, 1988, pp. 17–31.

[24] P. O’Brien and D. Halbert and M. Kilian, “The Trellis Programming Environment,” Proceedings of

OOPSLA ’87, ACM SIGPLAN Notices, Oct. 1987.

[25] Xavier Pintado, Eugene Fiume, “Graﬁelds: Field-directed Dynamic Splines for Interactive Motion

Control,” Computers & Graphics, vol. 13, no. 1, Jan. 1989, pp. 77–82.

[26] Xavier Pintado, Dennis Tsichritzis, “An Afﬁnity Browser,” Technical Report, Centre Universitaire

d’Informatique, University of Geneva, June 1988.

[27] Xavier Pintado, “Selection and Exploration in an Object-oriented Environment: The Afﬁnity Brows-
er,” in Object Management, ed. D. Tsichritzis, Centre Universitaire d’Informatique, July 1990, pp.
79–88.

[28] Xavier Pintado, “Objects’ Relationships,” Ph.D. Thesis, Centre Universitaire d’Informatique, Uni-

versity of Geneva, Switzerland, 1994.

[29] Xavier Pintado, “Visualization in the Financial Markets,” VR ’94, Proceedings of the Fourth Annual

Conference on Virtual Reality, Mecklermedia, London, 1994, pp. 80–84.

[30] Andy Podgursky, Lynn Pierce, “Retrieving Reusable Software by Sampling Behaviour,” ACM Trans-

actions on Software Engineering and Methodology, vol. 2, no. 3, July 1993, pp. 286–303.

[31] Kenneth Rubin, Adele Goldberg, “Object Behaviour Aanlysis,” Communications of the ACM, vol. 35,

no. 9, Sept. 1992.

[32] Gerard Salton, Automatic Text Processing: The Transformation, Analysis, and Retrieval of Informa-

tion by Computer, Addison-Wesley, Reading, Mass. 1988.

[33] Michael Stonebraker and J. Kalash, “Timber: a Sophisticated Database Browser,” Proceedings of the

8th International Conference on Very Large Data Bases, Sept. 1982, pp. 1–10.

[34] David Stotts and Richard Furuta, “Petri-Net-Based Hypertext: Document Structure with Browsing

Semantics,” ACM Transactions on Information Systems, vol. 7, no. 1, Jan. 1989.

PART V

Frameworks and 
Applications

274

Chapter 10
Visual Composition of 
Software Applications

Vicki de Mey

Abstract    Open applications can be viewed as compositions of reusable and
conﬁgurable  components.  We  introduce  visual  composition  as  a  way  of
constructing applications from plug-compatible software components. After
presenting related work, we describe an object-oriented framework for visual
composition that supports open system development through the notion of
domain-speciﬁc composition models. We illustrate the use of the framework
through the application of a prototype implementation to a number of very
different  domains.  In  each  case,  a  specialized  visual  composition  tool  was
realized by developing a domain-speciﬁc composition model. We conclude
with some remarks and observations concerning component engineering and
application composition in a context where visual composition is an essential
part of the development process.

10.1 Introduction

We deﬁne visual composition as the interactive construction of running applications by
the direct manipulation and interconnection of visually presented software components.
The connections between components are governed by a set of plug-compatibility rules
speciﬁed within a composition model.

Visual composition is a response to the trends in software development towards more
component-oriented lifecycles described in chapter 1. With a large number of components
supplied by component engineers, application development becomes an activity of com-
posing components into running applications. Visual composition can be used to commu-
nicate  reusable  assets  from  component  engineers  to  application  developers,  reusable
designs to application developers, and open applications to end-users. A visual composi-
tion framework enables the construction of environments and tools to facilitate compo-
nent-oriented software development.

Vicki de Mey, “Visual Composition of Software Applications,” Object-Oriented Software Composition, O. Nierstrasz and D. Tsichritzis 
(Eds.), pp. 275-303, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

276

Visual Composition of Software Applications

In this chapter we present a framework for visual composition. The framework address-
es four issues: (1) components, (2) composition models, (3) user interaction, and (4) com-
ponent management. Components are made up of a behaviour and a presentation. The
behaviour is responsible for the component’s composition interface and the work the com-
ponent was designed to do. The presentation is the visual display of the component. A
component can have more than one presentation, and the presentations reﬂect the state of
the component. A set of components can be grouped together to function as a single com-
ponent through the composite component mechanism. Component composition is deﬁned
as communication between components through their composition interfaces. The frame-
work deﬁnes the notions of port and link to handle the communication. A composition
model is the set of rules for component composition in a particular application domain.
Decoupling the rules for composition from components allows a variety of different soft-
ware composition paradigms and increases the potential for reuse of a component.

Vista is a prototype implementation of the visual composition framework. A concrete
implementation of a visual composition tool is obtained by a component engineer (chapter
1) by completing the framework with components, their presentations and the composi-
tion model governing their interconnection. Finally, the resulting tool can be used by an
application developer to visually compose running applications, as shown in section 10.5.
In reference to software development environments, Ivar Jacobson made the following

statement: 

In the long run, we shall see new development environments that place more empha-
sis on applications and less on technique. Developers will be application experts, not
Unix or C++ experts. They will work with graphical objects presented in several
dimensions, not simply text. The language of today may be handled as a machine lan-
guage that is invisible to developers. [23].

These new development environments will have the potential to transform software devel-
opment. End-users will play a larger role in putting applications together and new ways of
creating applications will be necessary. Visual composition is one of these new ways.

10.2 Related Work

Visual composition is based on work done in many different ﬁelds from software lifecy-
cles to graphical user interfaces and graphical object editors, visual programming, com-
ponents and connectivity, and component integration. Since the latter two areas are the
most relevant for this chapter, they will be discussed here.

Visual composition supports components and connecting components together to form
running systems. Some exemplary systems based on these ideas are ConMan, Fabrik, Sil-
icon Graphic’s IRIS Explorer, Apple’s ATG Component Construction Kit and IBM’s
VisualAge. ConMan [14] is a high-level visual language that allows users to build and
modify graphics applications. To create an application the user interactively connects sim-
ple components using a directed dataﬂow metaphor. No concept of composite compo-

Related Work

277

nents exists. Fabrik [22] is a contemporary of ConMan. Fabrik is a visual programming
environment that supplies a kit of computational and user interface components that can
be wired together using a bidirectional dataﬂow metaphor. The environment can be used
to build new components and applications. Composite components are supported through
the gateway construct. IRIS Explorer is an application creation system and user environ-
ment that provides visualization and analysis functionality. It is based on a distributed, de-
centralized  dataﬂow  model.  Its  graphical  user  interface  allows  users  to  build  custom
applications by connecting modules together. Apple’s ATG Component Construction Kit
(CCK) [43] is a prototype component architecture and set of test components that allows
end-users to plug components into a framework at run-time. The kit has four elements: (1)
a component framework (the structure within which components are connected); (2) a
component palette (source of components); (3) an inference engine for automatically con-
necting components; (4) a component inspector for display and modiﬁcation of compo-
nent information. Objects are the medium of communication between components in the
CCK. VisualAge [20] is a product from IBM designed to build the client side of client–
server applications, focusing on business applications and decision support systems. The
tool is based on the “construction by parts” paradigm that is supported by a visual pro-
gramming tool for creating applications non-procedurally. These systems are interesting
but limited since some cater only to speciﬁc application domains or are based on one way
of expressing the relationships between components. 

A component can be seen as a separate tool, application or process. This brings up com-
ponent integration issues that run very close to the issues of component interfaces and
component  interconnection. Visual  composition  needs  component  integration  mecha-
nisms  to  implement  the  connections  between  components.  Integration  issues  can  be
viewed on two levels: coarse-grained and ﬁne-grained. Coarse-grained integration con-
cerns components that may be large objects that cooperate by exchanging messages, or
tools that cooperate through shared ﬁles. Fine-grained integration concerns components
that are smaller and usually need to communicate with each other more frequently. Harri-
son, Ossher and Kavianpour [17] have discussed this issue and proposed an approach
called Object-Oriented Tool Integration Services (OOTIS). They believe that applications
are moving more towards ﬁne-grained integration, but that current systems, which are
coarse-grained, must still be supported while this move takes place.

Many proposals have been made for speciﬁc solutions to coarse-grained integration.
Some examples are: Unix facilities that provide a variety of different tools and tool inte-
gration mechanisms (character ﬁles, I/O redirection, pipes, shell programming); Hewlett
Packard’s Softbench environment [19]; and Sun’s ToolTalk [26] for interapplication com-
munication. Fine-grained integration solutions include efforts by the OMG (Object Re-
quest Broker), NeXT (Distributed Objects [36]), Microsoft (OLE [34]) and Apple (Apple
events and the Apple event object model [1], and OpenDoc [2]). See also chapter 12 for a
more thorough discussion of these commercial efforts, and chapter 3 for an example of an
object-oriented framework to support interoperability.

278

Visual Composition of Software Applications

10.3 A Framework for Visual Composition

The framework we present provides a simple and ﬂexible core for visual composition.
There are three pieces of information that are needed in order to use the framework: com-
ponent behaviours, component presentations and rules for composition. This information
is plugged into the framework to produce a visual composition tool for a speciﬁc purpose.

10.3.1 Component Deﬁnition

The framework deﬁnes a component as a behaviour together with one or more presenta-
tions. Such a “division of labour” has been seen in other frameworks including Smalltalk’s
MVC framework [13], Unidraw [48] and Andrew [38]. Table 10.1 shows the correspond-
ing terms in the different frameworks. This division promotes reuse, because different
presentations can be reused with the same or different behaviours.

Behaviour

The behaviour is responsible for the following:
• Communication with the presentation(s).
• The component’s composition interface. The composition interface advertises the
component’s services and requests for services. The composition interface allows the
component to be reused in different contexts. A component’s context includes the
components it is immediately connected to as well as the entire ensemble of compo-
nents in which it ﬁnds itself embedded. The composition interface of a component
consists of a set of ports, each of which has a name, a type and a polarity. Ports may
be visually presented in a variety of ways, such as knobs, buttons, text ﬁelds, menus,
etc., depending on the intended semantics.

• Executing whatever the component was designed to do. The behaviour reﬂects the
inner part of the component. From the outside, two components can look like they
have the same behaviour, but their internal implementations could be very different
(e.g. implemented in different programming languages). A component can also be-
have differently depending on the other components it is connected to. 

Visual composition

Behaviour

Presentation

MVC

Unidraw

Andrew

Model

subject

data object

View, Controller

view

view

Table 10.1   Comparison of the behaviour/presentation division of labour.

A Framework for Visual Composition

279

User input

Location of presentation
Dimension of presentation

Presentation

Behaviour

Values

Figure 10.1 Communication between the behaviour and presentation 

entities in the framework.

Presentation

The presentation is responsible for the following:

• Communication with the behaviour.
• Visual display of the component. All components, whether inherently visual or not,
have a visual presentation. A presentation can also process user input if it contains an
interaction component such as a button or a text ﬁeld. 

Communication between the behaviour and presentation is pictured in ﬁgure 10.1. The
presentation informs the behaviour of its location and dimensions so that this information
can be passed on to other components that need it to display themselves. Also, input can
be done through the presentation, and this information is communicated to the behaviour.
The behaviour only informs the presentation of information that it might need to display
on the screen.

Composite Components

Components can be created by programming or by composition. When a component is
created by programming, only the behaviour and presentation need to be speciﬁed (or re-
used if an appropriate behaviour or presentation already exists) and hooked into the frame-
work. A composite component is a set of components linked together that is considered
useful as a component in its own right. To deﬁne a composite component, one must add to
the set of components (1) a composition interface (by specifying which ports of the set of
components are to become ports of the composite component), and (2) a visual presenta-
tion (which can be composed of existing presentations). The behaviour of a composite
component is simply the behaviour of the components it encapsulates. Figure 10.2 illus-
trates the idea of composite component. The framework supports composite components
by deﬁning external_port and external_view entities. A set of external_port entities repre-

280

Visual Composition of Software Applications

External ports

Becomes

External view

Figure 10.2   Composite component.

Active port

Link

Active port

Component

Component

Figure 10.3   Framework entities.

sents the composite component’s composition interface, and an external_view entity is the
presentation used for the composite component. Both external_port and external_view
entities are created interactively when a composite component is being deﬁned.

10.3.2 Component Composition

The way component composition is supported in the framework is through the creation of
networks. The  framework  uses  components  for  the  nodes  in  the  network  and  deﬁnes
active_port and link entities for edges in the network. Not all ports in the composition in-
terface of a component need to be used. An active_port is created only when a port in a
component’s composition interface is connected to a port in another component’s compo-
sition interface. A link represents the connection from one active_port to another. Figure
10.3 illustrates the relationship between the elements of the framework. Communication
between components can be either one-way (the dark arrows in ﬁgure 10.3) or bidirection-

A Framework for Visual Composition

281

Component

Location of presentation

Dimension of presentation

Values

Values

Values

Active port

Link

Port location

values

Figure 10.4   Communication between a component, active_port and link.

al (both the dark and the grey arrows in ﬁgure 10.3). The format of the information that
passes from component to component is deﬁned in the behaviour of the component. The
format is not restricted by the framework. The display information is internal to the frame-
work and should at least include the location and dimensions of the presentation so that the
active_ports and links can be displayed correctly. Figure 10.4 summarizes the information
that is communicated between the active_port and link entities of the framework. 

As components are composed, networks, such as the one pictured in ﬁgure 10.5, are
generated. The grey ovals in the ﬁgure are components, the black circles are ports, the
clear circles are active_ports and the rectangles are links. These networks have certain
characteristics: 

• Automatic network update: Information must be automatically propagated through
the network. Propagation occurs when a node indicates some change to the informa-
tion on its outputs. This indicates the need for some type of constraint mechanism to
specify the relations in the network that must always be satisﬁed. Information prop-
agation could imply some change to the display that must be done automatically and
immediately to support the requirement of direct manipulation. There must be the
option for immediate propagation or batching for the display, since the update of a
densely populated screen can be expensive and possibly postponed

• Hierarchical decomposition: The network must support nodes that are made up of

other network structures.

• Cyclic networks: In visual composition, the relationships between components can

create cycles in the network.

282

Visual Composition of Software Applications

Component

Port

Active port

Link

Figure 10.5   Network of components.

The division of labour among components, active_ports and links is ﬂexible, but in gen-
eral, a link is used to transport information between two active_ports, an input active_port
controls  whether  information  should  be  passed  into  a  component,  and  an  output
active_port packages up information for leaving a component. Both active_ports and links
can have an associated visual display.

Composition Model

The active_port and link framework entities do not impose rules on connections; they just
enable connections. Whether or not a connection is valid is determined by a composition
model. The composition model is the set of rules for component composition in a particu-
lar  application  domain.  The  rules  determine  compatibility  between  components,  i.e.
which component can be linked to which other component. The type of rules is open-
ended and based on the component, the component’s composition interface, and other ap-
plication domain-speciﬁc information. Different from many other frameworks, the com-
patibility  between  components  is  not  determined  by  the  components.  Decoupling
composition models from components supports a variety of different software composi-
tion paradigms and increases the potential for reuse of a component, because a component
can be reused without modiﬁcation in different application domains by associating it with
different composition models. A composition model is active when it is dynamically ap-
plied to a set of components to get them to cooperate in a speciﬁc application. The compo-
sition model can have some knowledge of what components it can be used with, but
usually components do not have to be designed with particular composition models in
mind.

A Framework for Visual Composition

283

Dataflow

Component

Port

Link

Supplier

Transformer

User

Data

Dataﬂow

Figure 10.6   Dataﬂow composition model and some connected components.

Composition Model Examples

Three examples of composition models will be given: dataﬂow, two-dimensional graphic
objects and class hierarchy diagrams. Dataﬂow composition is used for specifying ﬂows
of data in a network of components. Components have input and output ports through
which dataﬂow. Each data value is associated with some component responsible for com-
puting the value as a function of its inputs. The component makes the data value available
at one or more of its output ports. Input and output ports can be joined by links. All ports
have an associated type reﬂecting the type of the data that passes through the port. If a
component has only output ports, then it is a supplier of data; if it has only input ports, then
it is a user of data; and if it has both input and output ports, then it is a transformer of data.
Links represent data ﬂowing between components. Links are primarily responsible for en-
forcing valid dataﬂow networks. They allow ports to be connected only if they have com-
patible types and compatible directions (input to output and output to input). The dataﬂow
components and composition model are pictured in ﬁgure 10.6 

Another example is a composition model for two-dimensional graphic objects. This
model is used to attach and keep two-dimensional graphics objects connected. A compo-
nent (a graphic object) has ports that represent points on the object, i.e. ports are of type
point. These ports are either input or output depending on the operation being carried out
on the graphic object to which they belong. The points are the location of the object in two-

284

Visual Composition of Software Applications

Two-dimensional
graphic objects

Component

Graphic objects

Port

Point

Link

Position

Implicit in 
position of 
objects

Figure 10.7   Two-dimensional graphic composition model and some connected components.

dimensional space. Links are created between components by placing one point on top of
the other. Any point can be linked to any other point. When some point changes, as when
a graphic object is moved, all other points linked to this point will be updated. This update
guarantees the connectivity between graphic objects. The composition model for two-di-
mensional graphic objects is pictured in ﬁgure 10.7. 

A third example is that of a class hierarchy diagram. Class hierarchy diagrams are used
to show the class structure of an object-oriented application. There is one kind of compo-
nent for this type of diagram, namely the class component. The class component can have
ports of type subclass and superclass. Some class components will not have ports of type
superclass; these are leaf classes in the class hierarchy. Some class components will not
have subclass ports; these components are top-level classes in the class hierarchy. Links,
which represent class relationships, are unidirectional and connect ports of type subclass
to ports of type superclass. Links do not pass data from one class component to another;
their role is to make relationships between classes so that when a class is asked about its
superclasses and subclasses, it will be able to respond. The class hierarchy components
and composition model are pictured in ﬁgure 10.8.

10.3.3 Interactive Environment

The interactive environment is responsible for ensuring that the framework entities are
used  correctly. The  interactive  environment  supplies  ways  for  the  user  to  manipulate

A Framework for Visual Composition

285

Class hierarchy

Component

Port

Link

Class

Subclass

Class

relationship

Superclass

Figure 10.8   Class hierarchy composition model and some connected components.

components, ports and links. This is accomplished using various user interface metaphors
depending on the implementation. The operations listed in table 10.2 make up a minimal
set. The interactive environment is customizable so that operations can be added and/or re-
moved. 

The interactive environment supports direct manipulation [42]. Direct manipulation
makes objects more concrete and thus helps people to grasp better the ideas and concepts
being described. Users get immediate feedback to their actions and are informed when any
of their actions cause a change in the system. Ideally, users always know what to expect
from the system. Development becomes more of an exploratory activity where a “try it
and see what happens” attitude is encouraged. Being able to see immediately what is go-
ing on in an application is important in the early stages of application development. At the
same time, the interactive environment is as transparent as possible so that users do not
have to do things that make no sense in their speciﬁc application domain. 

The environment is visual — a mixture of text, graphics (two-dimensional and/or three-
dimensional), and other media like video, sound and images — and therefore visibility
control is very important. Visibility control is used to modify the presentations of compo-
nents, ports and links. There are operations (see table 10.2) that allow a user to make ele-
ments invisible according to different criteria like, for instance, what group they are in,
what component they are attached to, etc. An application developer using visual composi-
tion usually needs more objects visible than an end-user. The developer is working in more
general terms, while the end-user is working in a speciﬁc domain. To accommodate this
situation, visibility control can hide information that is not appropriate. The composite

286

Visual Composition of Software Applications

Components

Ports

Links

instantiation

identification

create

Manual creation relies on 
the user manually selecting 
the start port and target port 
for the link
Automatic connection 
would attempt to automati-
cally connect compatible 
ports when a component is 
placed in a composition
composition model veriﬁes 
link

delete

make a functional copy of 
the chosen component

name, type and 
polarity of port

determine location in space
ﬁxed into a particular loca-
tion in space, ﬁxed in rela-
tion to other components’ 
locations, or left free to be 
moved

copy

state is also copied

delete

links referencing the del-
eted component are also 
deleted

replace

The links that referenced 
the original component are 
reconnected to the new 
component

display different presenta-
tions

Table 10.2   Manipulations on components, ports and links.

component capability can also be used to shield an end-user from unwanted or unneces-
sary detail.

Some of the more common characteristics of interactive environment must also be con-
sidered. It is necessary that some type of grouping mechanism be available, such as win-

Vista — A Prototype Visual Composition Tool

287

dows in the desktop metaphor. The environment supports the undo/redo functionality,
because all users make mistakes. Skill levels, such as novice or expert, are ways of helping
users learn to use a system. These levels usually assume that a novice is not familiar with
the system and therefore needs a bit of “hand-holding.” Expert users, on the other hand,
could consider such hand-holding distracting. Skill levels can be implemented by allow-
ing or disallowing certain actions on the objects being manipulated. Different presenta-
tions of a component can be used to reﬂect different skill levels. To further facilitate the
usage of the environment, mode switches, such as those between building and running an
application, are minimized. The literature [39] suggests that avoiding such mode switches
is important for new users because it gives them the ﬂexibility simultaneously to use and
modify an application, and that typically there is almost no confusion about when input is
directed to the tool and when it is directed to the application. 

10.3.4 Component Management

The activities of storing, organizing and retrieving components are external to the
framework, but the framework supplies a simple mechanism that records enough informa-
tion about the network to a text ﬁle so that when the ﬁle is read, the network can be re-
created.  Composition  models  also  need  to  be  stored,  organized  and  retrieved.  The
information stored in the composition model must be activated when a network is used
and constantly accessible since it is consulted whenever a link is created and possibly
whenever information ﬂows through a link. Some notation, possibly textual, for the com-
position model is necessary. The framework supports “hooks” for more sophisticated
tools, such as the software information base described in chapter 7, for these activities.

10.4 Vista — A Prototype Visual Composition Tool

Vista is a prototype visual composition tool based on the framework described above. The
prototype is meant as a test-bed for the visual composition framework. Vista [29][37] was
developed as part of ITHACA’s application development environment. (See the preface
and chapter 7 for more information about the ITHACA project.) Vista is a second gen-
eration prototype; some of the ideas of visual composition were demonstrated in VST, an
earlier prototype based on a Unix composition model [45]. Vista is meant to be a simple
and evolutionary prototype.

The layers of software supporting Vista are pictured in ﬁgure 10.10. The major parts of
Vista are in the shaded region of the ﬁgure. The implementation of Vista conforms to the
ITHACA software platform which includes C++, X Windows and OSF/Motif. Graph
management for Vista is supplied by a set of class deﬁnitions and functions extracted from
the Labyrinth System [27], a generic framework for developing graphical applications. In
Vista, components and links are displayed on the screen using Motif widgets and the dis-
play capabilities of Labyrinth.

288

Visual Composition of Software Applications

Figure 10.9   RECAST example.

Composition Model Manager

There are at least two ways to go about implementing the functionality of the composition
model. One possibility is to implement a composition model manager as an oracle that
oversees the correct functioning of the framework based on the active composition model.
The other possibility is to delegate responsibility for checking and maintaining compat-
ibility rules to framework entities. If composition models are used to deﬁne global com-
patibility between components or global rules encompassing large groups of components,
an oracle would probably be the best choice. The oracle can have an overview of sets of

Vista — A Prototype Visual Composition Tool

289

Application-specific components and

composition models

Components

Active ports

Links

Graph management 

(Labyrinth)

OSF/Motif

Composition model 

manager

X Windows 

C++ 

Unix

Figure 10.10   Layers of software supporting Vista.

networks on which to base global decisions. Some powerful graph management systems
can also work on a global level in the network; thus the decision for a certain type of graph
manager could inﬂuence the implementation of the composition model manager. In Vista,
the composition model manager is an oracle implemented as a C++ class. A composition
model is expressed in a textual notation that expresses port compatibility and is parsed by
the composition model manager.

Components, Active_ports and Links

In Vista, components (behaviours and presentations), active_ports and links are imple-
mented as C++ classes. Vista supplies default active_port and link classes. To implement
the component behaviour and presentation, four classes are deﬁned. The behaviour of a
component is implemented in the cmp_Node class and subclasses of the abstract class
V_Base. The presentation of a component is implemented in the view_Node class and sub-
classes of the abstract class Framer. The cmp_Node and view_Node classes are internal to
Vista and maintain network connectivity. The V_Base and Framer classes are subclassed
by the user of Vista. This division is advantageous because Vista is implemented in C++
and modiﬁcations to superclasses necessitate recompilation of subclasses. The division
avoids much of this recompilation since the information added from outside the system
does not directly impact the internal framework classes and vice versa.

Dividing up the responsibilities of components, active_ports and links is not always
straightforward. For example, if two ports of different types are deﬁned to be compatible
by a particular composition model, and they are linked, where should the coercion be-
tween port types take place? The input active_port participating in the connection has a
type and can coerce things that it receives into that type. The link participating in the con-
nection knows it is connecting ports of compatible types and can coerce the type of the
information from the output active_port to the type that the input active_port expects. 

290

Visual Composition of Software Applications

(a) Direct interaction between 

components

(b) A component 
moderating the 

interaction

(c) Interaction seen as 

containment

Figure 10.11   Four-way component interaction.

Responsibilities can be divided up in certain ways to ameliorate the user’s experience.
For example, a four-way interaction where all four components interact. The interaction
can be a new component with the original four components linked to it by “interaction”
links or all of the components can be linked together. These two options are pictured in ﬁg-
ure 10.11. Figure 10.11(a) might not look hard to understand as it is pictured here, but the
picture would become indecipherable if twenty components were interacting. Ports could
accept more than one connection, but this does not reduce the number of links. Adding
components to a system does not necessarily imply that the system becomes more com-
plex. The number of components is not that important; it is how the components are pre-
sented that is important, as seen in ﬁgure 10.11(b) and 10.11(c). In ﬁgure 10.11(c) links
are represented by the location of components (e.g. all components contained in another
component interact) and not by lines connecting the components. 

In Vista, active_ports and links can be used to implement any of the scenarios described
above. But as classes are developed, the goal should be to keep active_ports and links sim-
ple, since too much hidden behaviour will make the system unpredictable and harder to
understand.

Application-Specific Components and Composition Models

Components and composition models for speciﬁc domains are deﬁned using the classes
and functionality of the lower layers of software. For components, only the behaviour and
presentation need to be deﬁned as subclasses of abstract classes supplied by Vista. Com-
position models are expressed in the textual notation supported by Vista.

10.5 Sample Applications

Johnson and Russo [25] have stated that:

Sample Applications

291

a use of a framework validates it when the use does not require any changes to the
framework, and helps improve the framework when it points out weaknesses in it.

Iteration is a major part of the validation cycle of a framework. The framework should get
better (more reusable) as results are gathered from its usage. To this end, the visual com-
position framework was used in three sample applications. The sample applications came
from actual ongoing projects and were not artiﬁcially devised as test cases for visual com-
position.

The ﬁrst application was part of a project that addresses the creation of a framework and
rapid prototyping environment for distributed multimedia applications [32] (see chapter
11). The visual composition framework was then used to implement a visual composition
tool for multimedia applications.

The second application was part of a project that addresses the requirements collection
and speciﬁcation phase of software development. The project deﬁnes a methodology that
functions as a formal basis for requirements speciﬁcation and support tools. The visual
composition framework was used to implement one of the support tools called RECAST. 
The third application was part of a project that addresses workﬂow applications. The
project deﬁnes a complete environment for designing and running coordination proce-
dures. The need for some type of visual representation of coordination procedures was
recognized by the participants in the project. The visual composition framework satisﬁed
this need and was used to draw pictures of coordination procedures and generate the code
that the procedures represented.

The scope of these sample applications varies considerably. The ﬁrst deals with running
applications and components represent actual executing modules.The other two are rela-
ted to software speciﬁcation, where components represent elements of the software spec-
iﬁcation model. We will describe the ﬁrst and second sample applications here. More
information about all three applications can be found in the author’s thesis [30].
Sample Application 1: Multimedia Component Kit

Chapter 11 introduces the basic concepts of a multimedia framework and multimedia
components. Based on this work, multimedia components and composition models were
created for visual composition. The visual composition tool for multimedia applications
is a rapid prototyping tool for experimenting with different combinations of multimedia
components.

A multimedia application is implemented by large number of interconnected hardware
and software components. Visual composition can be used to interactively plug compo-
nents together — rather than permanently “hard-wiring” them — thus making applica-
tions more ﬂexible and reconﬁgurable.

Various composition paradigms are appropriate to multimedia applications. Three ex-

ample composition models follow:

1. Dataﬂow composition describes an application as a conﬁguration of media compo-

nents and the data (media streams) that ﬂow between them. 

292

Visual Composition of Software Applications

2. Activity composition describes the behaviour of an application with respect to activ-

ities and events. 

3. Temporal composition describes relationships between temporal sequences and is

a special case of activity composition [31]. 

These three ways of viewing multimedia applications can be reﬂected in composition
models that determine the types of components useful in the applications and how the
components interact. The dataﬂow composition model has been implemented and will be
discussed in detail here.

Viewed from a dataﬂow perspective, a typical multimedia application accepts user in-
put and displays multimedia information related to the input. This type of application can
be built from components that represent input devices and multimedia renderers. Some
example multimedia components for dataﬂow composition are listed in table 10.3. The
GeoBall and Navigator components are responsible for getting user input into the appli-
cation. The GeoBall component represents an actual hardware device, pictured in the
presentation of the component, that generates 4 × 4 geometric transformation matrices.
This  component  can  be  considered  a  producer  of  information  of  type  GeoTransSeq
(sequences of 4 × 4 geometric transformation matrices). The Navigator component, a
transformer component, is responsible for taking the information produced by the input
device and transforming it into a type understandable by other components in the applica-
tion. Here, the Navigator component produces information of type MoveSeq (sequences
of Render requests dealing with movement of objects in the three-dimensional world). 

GeoBall

Renderer

Modeler

Navigator

ActiveCube

out: GeoTransSeq

in: RenderSeq

in: MoveSeq
in: RenderSeq
out: RenderSeq

in: GeoTransSeq
out: MoveSeq

out: RenderSeq

Table 10.3   Components for dataﬂow composition.

The Modeler component represents the content that will be displayed by the applica-
tion. The Modeler gathers together all the information in the application that will contrib-
ute  to  the  content  and  prepares  the  information  for  display. The  Modeler  can  accept
information from the Navigator component to incorporate user input into the display, as
well as information from other components that generate content such as the ActiveCube
component. The ActiveCube component represents a graphical cube object that can be
displayed. The Modeler produces information of type RenderSeq (sequences of Render

Sample Applications

293

Figure 10.12   Multimedia dataﬂow composition.

requests) that represent the content in a format suitable for rendering. The Renderer com-
ponent accepts information of type RenderSeq and is responsible for its display. 

A simple composition model for dataﬂow can check to make sure that only ports of the
same type are connected as a user interactively creates an application. This model ensures
that the components making up the application are correctly connected but cannot ensure
that the application is producing the desired result. More semantic information can be put
into the composition model to produce a particular desired result. For example, a rule like
“if a GeoBall component is in the application, then it must be connected to a Navigator
component” would eliminate the need to explicitly connect them, and would guarantee the
correct use of these two components.

Figure 10.12 shows a screen image of the tool displaying a simple dataﬂow of a multi-
media application using the components described in the preceding paragraphs. The Geo-
Ball component is implemented as a composite component. The internal view of the
composite component is pictured in the upper right side of the ﬁgure. The composite com-
ponent contains a geometry ball component and two sets of horizontal sliders. The sliders

294

Visual Composition of Software Applications

adjust the parameters of the device (x, y, z translation and x, y, z rotation sensitivity). These
parameters can be changed interactively and thereby modify the behaviour of the input de-
vice as a user navigates through the museum. The input device is connected to a Navigator
component, which connects to a Modeler component, which, in turn, is connected to a
Renderer component. ActiveCube components, which move cube-shaped graphic objects
given a velocity, are also connected into the Modeler component. 
Sample Application 2: RECAST

The RECAST tool [3][4] in the ITHACA software development environment uses a com-
position-based approach to requirements speciﬁcation and provides assisted inspection of
available  components  by  accessing  the  software  information  base  (SIB).  RECAST
assumes  that  requirements  are  specified  according  to  an  object-oriented  specification
model, called the Functionality in the Objects with Roles Model (F-ORM), which is used
for requirements representation. The model is based on the object-oriented paradigm ex-
tended with the concept of roles [8] to represent the different behaviours that an object can
have during its lifetime. F-ORM is a textual deﬁnition language and RECAST is a tool that
graphically manipulates F-ORM requirements. RECAST was built using the visual com-
position framework. F-ORM classes and class elements are represented by components
and class relationships are represented by links. The class relationships are recorded in a
composition model so that a user of RECAST is assured of using F-ORM correctly.

The composition concept of RECAST is reﬂected in a set of diagrams deﬁned by the
ITHACA object-oriented methodology [9]. The methodology deﬁnes ﬁve types of dia-
grams at the application design level: class diagram, cluster tree diagram, cluster cooper-
ation diagram, state/transition diagram and IsA/PartOf diagrams. These ﬁve diagrams are
used by the application designer when specifying requirements. The class diagram imple-
mented in RECAST is described here.

The class diagram represents F-ORM classes and roles along with the dependencies be-
tween classes and roles. Classes have corresponding Class components in the framework.
The presentation of the Class component contains at least the name of the class. Roles
have corresponding Role components and are graphically displayed embedded in the
Class component to which they belong. Class components can be in their base represen-
tation, where all the roles are visible, or in a compact representation, where only the class
name is visible. Role components are connected by message links that represent either
unidirectional or bidirectional message ﬂows. 

Colours are used extensively to distinguish different types of components and different
types of links. Shading is used to signal if certain classes or roles are selected. For exam-
ple, if a class or role is not selected, it is not shaded. If a class or role is darkly shaded, then
it was selected by the user. If a class or role is lightly shaded, then it was selected by a pos-
sible design action. If a class or role is moderately shaded, then it was selected as a conse-
quence of a design action.

The components for class diagrams are summarized in table 10.4. The behaviour of the
Class component is responsible for changes in the F-ORM requirements speciﬁcation.
These changes are made by direct manipulation of the graphical representation of the

Sample Applications

295

class. Such changes include the addition of classes to the diagram, adding and deleting
roles, and the transformation of a class into a set of classes. The behaviour is also respon-
sible for the display of the class (base or compact) and the display of information about the
class. The behaviour of the Role component is responsible for managing design actions of
the role, the presentation of the role, access to the properties of the role, and access to the
state/transition diagram for the role. The behaviour of the Cluster-reference component is
responsible for mediating the connection between the active class diagram and the cluster
the reference is representing. 

Process class

Resource class

Role

Cluster-reference

name
level

in: message
in: role
out: message
out: class
in/out: class
in/out: class
in/out: message

all from process class 
plus:
in/out: resclass
in/out: resclass

in: message
in: class
in: stdiagram
out: message
out: role
in/out: message

in: message
out: message
in/out: message
in/out: class
in/out: class
in/out: resclass
in/out: resclass

Table 10.4   Class diagram components.

Figure 10.13 shows the class diagram for the OrderManagementSystem cluster. This
diagram is generated by using RECAST to transform a request-processing application
into an order-processing application. Interacting with RECAST in the following way pro-
duces the OrderManagementSystem cluster:

1. The user starts a new application called OrderManagementSystem.

2. The user consults the SIB for the application domain and a generic application
frame. In this case the application domain is sales and the generic application frame
is request processing. The RequestProcessing class is chosen.

3. The RequestProcessing class is copied into the diagram generating a Class compo-
nent called MyReqProc. The MyReqProc component has a set of associated roles,
represented as Role components in the diagram, which are embedded inside the
presentation of MyReqProc. 

296

Visual Composition of Software Applications

Figure 10.13   RECAST example.

4. The Receive Role component is selected. Because of the selection, RECAST con-
sults its design suggestions and suggests adding a request manager agent and a cli-
ent agent to the diagram. The client agent represents the source of the information
for MyReqProc. The request manager agent represents the requested information of
MyReqProc. 

5. The  suggestions  are  executed  and  the  corresponding  Class  components  are  re-
trieved. For the client agent, MyClient class is retrieved. For the request manager
agent, MyRequest and MyReqAdmin are retrieved. The message links, represented
by thin black arrows, between all the Class components are displayed. 

Discussion

297

6. MyReqProc is specialized to MyOrderProc and MyRequest is specialized to My-

Order. Specialization is represented by thick grey arrows. 

The sample applications demonstrate that the visual composition framework makes the
process of building graphical, component-based applications easier by supplying much of
the infrastructure such applications require.

10.6 Discussion

As a result of the work done on the visual composition framework, the prototype imple-
mentation of a visual composition tool and the sample applications, certain suggestions
concerning component deﬁnition, composition and visualization can be made.

10.6.1 Component Deﬁnition

The choice of components for a particular application is still somewhat ad hoc, and results
from other ﬁelds, such as the reverse engineering of applications, could supply useful in-
formation for component design. Work by, among others, Johnson [24] [11] on framework
design has highlighted some key strategies such as ﬁnding common abstractions, decom-
posing problems into standard components, parameterizing and ﬁnding common patterns
of interaction. With this work in mind and the experience from the sample applications de-
scribed in the previous section, we present the following list of guidelines for designing
reusable components:

• If a concept is used, or looks like it could be used, in a number of different places or

application domains, this concept should probably be a component. 
If the same concept were included explicitly in every component, there would be the
same functionality spread throughout the component set, proliferating redundant in-
formation and negating efforts of encapsulation and reuse.
Parameterization can be used to generalize concepts that might look different at ﬁrst
glance but, with further investigation, they could really be the same concept with dif-
ferent values for a few different parameters.
User interface components are a good example since they represent concepts that are
reused in many applications. The Modeler component in the multimedia component
kit is also a good example. If the Modeler component had not been separate from the
3DRenderer component, the same model information would not be able to drive two
different renderers, say a three-dimensional and a two-dimensional renderer, at the
same time.

• If a component requires an undetermined or variable number of resources, these re-

sources should probably be components. 
Since this type of information can be quite variable, it seems natural to deﬁne a set of
lower-level primitive components and compose them into different conﬁgurations. 

298

Visual Composition of Software Applications

An example of this is found in RECAST for the implementation of the class and role
components. Since a class can have a variable number of roles, and roles can be dy-
namically added or removed, it is much easier to make classes and roles different
components that share the relationships roleOf and class than to include the role as
part of the class.

• Composite components should contain a small number of components and take ad-

vantage of hierarchical decomposition. 
This allows concepts to be organized more effectively and reduces the amount of
screen clutter. 

• The number of components should be small but extensible. 

A small set of components helps people remember what components they have to
work with, but the set must be extensible so that when valuable new primitives are
discovered they do not have to be simulated with the existing components.

• Components should strike a balance between concreteness and abstraction. 

From their experience with the world around them, people are more used to thinking
concretely  rather  than  abstractly. Visual  composition  uses  a  set  of  components,
which are abstractions, for application construction. A balance between the two must
be made. Components cannot require the user to ﬁll in every detail — if they had to
do that, then visual composition would be worthless. But components cannot conceal
all the details since the user would never ﬁgure out what to do with them.

• Big components can be reusable.

It is claimed that the bigger a component gets, the harder it is to reuse [5]. Here, “big-
ger” means more complex and more speciﬁc. A component being more speciﬁc does
make it harder to reuse, but being complex does not have to cause problems. As long
as the composition interface of a component correctly reﬂects its behaviour, more
complex components can be reused just as well as less complex components.

10.6.2 Composition

Choosing an effective set of rules for composition is not easy. Visual composition dele-
gates this decision to the users, on the basis that they know best how components should
communicate in their particular application. More effort is needed to determine common
sets of rules that are often observed in applications as well as domain-speciﬁc rules. Ef-
forts such as the Law of Demeter [28], contracts [18], law-governed systems [35] and de-
sign by contract [33] all contribute to this area.

Alternative  ways  for  expressing  composition  models  are  needed. The  composition
model was implemented as a small textual language (essentially just listing the port types
and their compatibilities) in Vista. It could be useful to use visual composition to describe
composition models. Certain rules, like no cycles allowed between components, could be
illustrated by diagrams like the ones pictured in ﬁgure 10.14. If a component set contains
a huge number of components, and a composition model has a huge number of rules, both

Discussion

299

Cycles allowed between 
neighbouring components

Cycles allowed between 

any two components

Figure 10.14   Example visualizations of some composition model rules.

the textual and graphical representation of the model could get awkward, and another
strategy might become necessary. 

10.6.3 Visualization

The visual aspect of visual composition is one of its most important features. Being able
to see the pieces that make up applications and manipulate these pieces directly contrib-
utes greatly to the understanding of an application. Seeing the impact of certain design
choices is very advantageous. But, as with all visual communication, a suitable presenta-
tion must be chosen otherwise the effectiveness and quality of the visual expression will
be brought into question. What is suitable can vary from person to person, so ﬂexibility is
important, but people still have to understand each other. Any enhancements to the visual
presentation must give a user a more comfortable, informative and familiar environment
in which to work.

Visualization is the visual representation of information using, for example, two-di-
mensional/three-dimensional computer graphics. Solutions and problems can often be
easier and faster to recognize visually than having to sort through program text. Brooks
does not favour visualizing software, saying: “In spite of progress in restricting and sim-
plifying the structures of software, they remain inherently unvisualizable, and thus do not
permit the mind to use some of its most powerful conceptual tools” [6] (emphasis added).
Despite Brooks’s pessimistic view, a person’s visual capacity is such a powerful concep-
tual tool that it must be explored as a possible aid in dealing with complex systems. It is
possible that not every level of software is visualizable, but this should not limit attempts
to try to proﬁt from visualization where appropriate. Scientiﬁc visualization has “demon-
strated  previously  unknown  ﬂaws  in  numerical  simulations  and  made  possible  new
knowledge and insight” [41]. Harel [15] takes a more optimistic view about the possibili-
ties of visualization. Like Brooks, he agrees that the “traditional” diagrams, such as ﬂow-

300

Visual Composition of Software Applications

charts, are not what is needed for modeling systems. But a lot of the conceptual constructs
underlying software systems can be captured naturally by notions from set-theory and to-
pology that have natural spatial/graphical representations. Harel calls these representa-
tions visual formalisms [16] and they all have rigorous mathematical semantics. Concepts
such as containment, connectedness, overlap and adjacency as well as shape, size and col-
our are used to depict a system. Combining these techniques can trigger many useful men-
tal images of what is going on in a system. 

In Vista, only two-dimensional presentations have been used, and it would be interest-
ing to see if a third dimension could enhance the effectiveness of the tool. Situations that
currently use up too much screen space could be more effectively treated in three dimen-
sions. Examples of this type of work exist [7][40][46]. Different conclusions can be drawn
if the application domain is inherently non-graphic or inherently graphic. Animation has
also been used to help understand systems [10][12][44] and would enhance visual compo-
sition. For example, a “data map” that shows where data is, how it is used and how it moves
around the application could give a global picture of data usage. Data could be tagged and
followed through the executing application.

10.7 Conclusion

The landscape of software is changing from monolithic closed applications to open appli-
cations composed of reusable components. As the landscape changes, end-users become
application developers and application developers become component engineers. To sup-
port this new landscape, the software industry needs to promote the idea of investment in
components. Among other things, this means developing repositories of components and
tools for developing applications from components. Visual composition can lead to new
tools and environments which would contribute to the fulﬁlment of our duty, as Harel puts
it, “to forge ahead to turn system modeling into a predominately visual and graphical
process.”

Acknowledgements

The work described in this chapter has beneﬁted from the efforts of many past and present
members of the Object Systems Group. The prototype visual composition tool described
here includes efforts by Betty Junod, Oscar Nierstrasz, Serge Renfer, Marc Stadelmann
and Ino Simitsek. The precursor to Vista — VST — was implemented by Jan Vitek and
Marc Stadelmann, with contributions from Gerti Kappel. The work on the multimedia
framework  includes  efforts  by  Christian  Breiteneder,  Laurent  Dami,  Simon  Gibbs,
Michael Papathomas and Dennis Tsichritzis.

References

301

Much of this work was done in the context of the ITHACA project. Roberto Bellinzona
of Politecnico di Milano worked on the RECAST sample application and Hayat Issad of
IFATEC worked on the component set of the workﬂow sample application.

References

[1] Apple Computer, Inc., Inside Macintosh: Interapplication Communication, Addison-Wesley, Read-

ing, Mass.
Jeff Alger, “OpenDoc vs. OLE,” MacTech Magazine, vol. 10, no. 8, Aug. 1994, pp. 58–70.

[2]

[3] Roberto Bellinzona and Mariagrazia Fugini, “RECAST Prototype Description,” ITHACA.POLI-

MI.91.E.2.8.#1, Politecnico di Milano, Nov. 28, 1991.

[4] Roberto Bellinzona, Mariagrazia Fugini and Giampo Bracchi, “Scripting Reusable Requirements

Through RECAST,” ITHACA.POLIMI.92.E.2.9.#1, Politecnico di Milano, July, 1992.

[5]

[6]

[7]

Ted J. Biggerstaff and C. Richter, “Reusability Framework, Assessment and Directions,” IEEE Soft-
ware, March 1987, pp. 41–49.

Fred P. Brooks, “No Silver Bullet,” IEEE Computer, April 1987, pp. 10–19.

Stuart Card, G. Robertson and J. Mackinlay, “The Information Visualizer: An Information Work-
space,” CHI ’91 Conference Proceedings, New Orleans.

[8] Valeria De Antonellis, Barbara Pernici and P. Samarati, “F-ORM METHOD: A F-ORM Methodol-
ogy for Reusing Specifications,” IFIP WG 8.4 Working Conference on Object-Oriented Aspects in
Information Systems, Quebec, Oct. 1991.

[9] Valeria De Antonellis and Barbara Pernici, “ITHACA Object-Oriented Methodology Manual — In-
troduction  and  Application  Developer  Manual  (IOOM/AD),”  ITHACA.POLIMI.UDUN-
IV.91.E.8.1, Oct., 1991.

[10] Wim De Pauw, Richard Helm, Doug Kimelman and John Vlissides, “Visualizing the Behavior of
Object-Oriented Systems,” in Proceedings OOPSLA ’93, ACM SIGPLAN Notices, vol. 28, no. 10,
Oct. 1993, pp. 326–337.

[11] Erich Gamma, Richard Helm, JohnVlissides and Ralph E. Johnson, “Design Patterns: Abstraction
and  Reuse  of  Object-Oriented  Design,”  in  Proceedings  ECOOP  ’93,  ed.  O.  Nierstrasz,  Lecture
Notes  in  Computer  Science,  vol.  707,  Springer-Verlag,  Kaiserslautern,  Germany,  July  1993,  pp.
406–431.

[12] Steven C. Glassman, “A Turbo Environment for Producing Algorithm Animations,” in Proceedings

IEEE Symposium on Visual Languages, Aug. 1993, pp. 32–36.

[13] Adele Goldberg, “Information Models, Views and Controllers,” Dr. Dobb’s Journal, July, 1990.

[14] Paul  E.  Haeberli,  ”ConMan:  A  Visual  Programming  Language  for  Interactive  Graphics,”  ACM

Computer Graphics, vol. 22, no. 4, Aug. 1988, pp. 103–111.

[15] David Harel, “Biting the Silver Bullet,” IEEE Computer, vol. 25 no. 1, Jan., 1992, pp.8–20.

[16] David Harel, “On Visual Formalisms,” Communications of the ACM, vol. 31, no. 5, May 1988, pp.

514–530.

[17] William Harrison, Harold Ossher and Mansour Kavianpour, “Integrating Coarse-Grained and Fine-

Grained Tool Integration,” Proceedings CASE ’92, July 1992.

302

Visual Composition of Software Applications

[18] Richard Helm, Ian Holland and Dipayan Gangopadhyay, “Contracts: Specifying Behavioural Com-
positions in Object-Oriented Systems,” Proceedings OOPSLA/ECOOP ’90, ACM SIGPLAN Notic-
es, vol. 25, no. 10, Oct. 1990, pp. 169–180.

[19] HP Journal, vol. 41, no. 3, June 1990 (HP SoftBench).

[20]

IBM, VisualAge documentation and demo diskette.

[21]

ITHACA Tecnical Annex, Sept. 1988.

[22] Dan Ingalls, “Fabrik: A Visual Programming Environment,” ACM SIGPLAN Notices, vol. 23, no.

11, Nov. 1988, pp. 176–190.

[23]

Ivar Jacobson, “Is Object Technology Software’s Industrial Platform?” IEEE Software, vol. 10, no.
1, Jan. 1993, pp. 24–30.

[24] Ralph E. Johnson, “How to Design Frameworks,” OOPSLA ’93 tutorial notes.

[25] Ralph E. Johnson and Vincent F. Russo, “Reusing Object-Oriented Designs,” University of Illinois,

TR UIUCDCS 91-1696.

[26] A. Julienne and L. Russell, “Why You Need ToolTalk,” SunExpert Magazine, vol. 4, no. 3, March

1993, pp. 51–58.

[27] Manolis  Katevenis,  T.  Sorilos  and  P.  Kalogerakis,  “Laby  Programmer’s  Manual  (version  3.0),”
ITHACA report FORTH.92.E3.3.#1, Foundation of Research and Technology — Hellas, Iraklion,
Crete, Jan. 1992. 

[28] Karl Lieberherr and Ian Holland, “Assuring Good Style for Object-Oriented Programs,” IEEE Soft-

ware, Sept. 89, pp. 38–48.

[29] Vicki de Mey, Betty Junod, Serge Renfer, Marc Stadelmann and Ino Simitsek, “The Implementation
of Vista — A Visual Scripting Tool,” in Object Composition, ed. D. Tsichritzis, Centre Universitaire
d’Informatique, University of Geneva, June 1991, pp. 31–56.

[30] Vicki de Mey, “Visual Composition of Software Applications,” Ph.D. thesis no. 2660, University of

Geneva, 1994.

[31] Vicki de Mey, Christian Breiteneder, Laurent Dami, Simon Gibbs and Dennis Tsichritzis, “Visual

Composition and Multimedia,” Proceedings Eurographics ’92.

[32] Vicki de Mey and Simon Gibbs, “A Multimedia Component Kit,” Proceedings ACM Multimedia

’93.

[33] Bertrand Meyer, “Applying ‘Design by Contract’,” IEEE Computer, Oct. 1992, pp. 40–51.

[34] Microsoft, Object Linking and Embedding Programmer’s Reference (pre-release), version 2, 1992.

[35] Naftaly H. Minsky and David Rozenshtein, “ A Law-Based Approach to Object-Oriented Program-

ming,” Proceedings OOPSLA ’87 , Oct. 1987, pp. 482–493.

[36] NeXT, Distributed Objects, release 3.1, 1993.

[37] Oscar Nierstrasz, Dennis Tsichritzis, Vicki de Mey and Marc Stadelmann, “Objects + Scripts = Ap-

plications,” Proceedings, Esprit 1991 Conference, Kluwer, Dordrecht, 1991, pp. 534–552. 

[38] Andrew J. Palay, “Towards an ‘Operating System’ for User Interface Components,” in Multimedia
Interface Design, ed. M. M. Blattner and R. B. Dannenberg, Frontier Series, ACM Press, 1992, pp.
339–355.

[39] Randy  Pausch,  Nathaniel  R.  Young  and  Robert  DeLine,  “SUIT:  The  Pascal  of  User  Interface
Toolkits,” Proceedings of the Fourth Annual Symposium on User Interface Software and Technol-
ogy, Nov. 1991, pp. 117–125.

References

303

[40] Steven P. Reiss, “A Framework for Abstract 3D Visualization,” in Proceedings IEEE Symposium

on Visual Languages, Aug. 1993, pp. 108–115.

[41] Lawrence  J.  Rosenblum  and  Gregory  M.  Nielson,  “Guest  Editors’  Introduction:  Visualization
Comes of Age,” IEEE Computer Graphics and Applications, vol. 11, no. 3, May 1991, pp. 15–17.
[42] Ben Shneiderman, “Direct Manipulation: A Step Beyond Programming Languages,” IEEE Compu-

ter, vol. 16, no. 8, Aug. 1983, pp. 57–69.

[43] David C. Smith and Joshua Susser, “A Component Architecture for Personal Computer Software,”

in  Languages for Developing User Interfaces, ed. B. Myers, Jones & Bartlett, 1992, pp. 31–56.

[44] Randall B. Smith, “Experiences with the Alternate Reality Kit: An Example of the Tension Between

Literalism and Magic,” IEEE Computer Graphics and Applications, Sept. 1987, pp. 42–50.

[45] Marc Stadelmann, Gerti Kappel and Jan Vitek, “VST: A Scripting Tool Based on the UNIX Shell,”
in Object Management, ed. D. Tsichritzis, Centre Universitaire d’Informatique, University of Gene-
va, July 1990, pp. 333–344.

[46] John T. Stasko and Joseph F. Wehrli, “Three-Dimensional Computation Visualization,” in Proceed-

ings IEEE Symposium on Visual Languages, Aug. 1993, pp. 100–107.

[47] Dennis Tsichritzis and Simon Gibbs, “Virtual Museums and Virtual Realities” Proceedings Inter-
national Conference on Hypermedia & Interactivity in Museums, Archives and Museum Informat-
ics, Technical Report no. 14, Pittsburgh, Oct. 14–16, 1991, pp. 17–25.

[48] John Vlissides, “Generalized Graphical Object Editing,” Technical Report CSL-TR-90-427, Stan-

ford University June 1990. 

304

Chapter 11
Multimedia Component 
Frameworks

Simon Gibbs

Abstract        This  chapter  looks  at  the  use  of  object-oriented  technology,  in
particular class frameworks, in the domain of multimedia programming. After
introducing digital media and multimedia programming, the central notion of
multimedia frameworks is examined; an example of a multimedia framework
and  an  application  that  uses  the  framework  are  presented.  The  example
application demonstrates how object-oriented multimedia programming helps
to  insulate  application  developers  from “volatility”  in  multimedia  processing
capabilities — this volatility and related uncertainty is currently one of the key
factors hindering multimedia application development.

11.1 Digital Media and Multimedia

In  discussing  object-oriented  multimedia,  a  convenient  starting  point  is  the  notion  of
media artefacts. Here the term “media” is used in the sense of materials and forms of ex-
pression. This includes both natural media, such as inks and paints, and digital media
made possible by computer technology. The latter either mimic natural media, as is the
case with drawing and paint programs, or have no natural counterparts. Those things pro-
duced by working in or with a particular medium are what we call media artefacts.

The distinction between natural and digital media also applies to artefacts. Natural ar-
tefacts are those produced using natural media. Among natural artefacts are paintings,
prints, sculptures, photographs, musical recordings, and video and ﬁlm clips. Digital arte-
facts include both the artefacts of digital media, such as an image produced by a paint pro-
gram, and the digitized artefacts of natural media, for instance an image produced by
scanning a photograph.

Until fairly recently, artists and designers primarily worked with natural media and so
produced what we have just described as natural artefacts (it should be noted, though, that

Simon Gibbs, “Multimedia Component Frameworks,” Object-Oriented Software Composition, O. Nierstrasz and D. Tsichritzis (Eds.), pp. 
305-319, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

306

Multimedia Component Frameworks

we are including such technologies as ﬁlm and video as “natural” media). But the tools of
the trade are changing, and now, as a result of the increasing capabilities of the computer,
high-quality digital artefacts are becoming easier, and less expensive, to produce. There
are many advantages to digital, as opposed to natural, artefacts — digital artefacts can be
easily modiﬁed, copied, stored or retrieved. They can be sent over communications net-
works and can be made interactive. Equally intriguing is the ease with which digital arte-
facts are combined. Because, ultimately, digital artefacts simply reduce to bits and bytes,
there are no physical restrictions on combining artefacts of different digital media. Digital
video can be placed in text, or, vice versa, text can be placed in video; similarly audio and
graphics can be combined, speech and text can be combined, and so on.

The notion of media artefacts leads to a natural deﬁnition for multimedia. We consider
multimedia to be broadly concerned with the creation, composition, presentation, record-
ing, editing and, in general, manipulation, of artefacts from diverse media. Since multime-
dia is so free in style, an immense variety of techniques, and combinations of techniques,
are available to the artist. This is reﬂected in the wealth of media manipulation, composi-
tion and transformational capabilities packaged in multimedia authoring tools.

11.2 Multimedia Systems and Multimedia Programming

A complex multimedia production, whether a video game, a multimedia encyclopaedia or
a “location-based entertainment environment,” often requires the concerted effort of large
teams of people. Like ﬁlm and video production, multimedia production calls upon the
talents of artists, actors, musicians, script writers, editors and directors. These people, re-
sponsible for “content design” to use current terminology, create raw material and prepare
it for presentation and interaction. In doing so they rely on multimedia authoring environ-
ments to edit and compose digital media. 

The authoring environments used for multimedia production are examples of multi-

media systems [9]. Some other examples are:

• multimedia database systems — used to store and retrieve, or better, to “play” and

“record” digital media;

• hypermedia systems — used to navigate through interconnected multimedia materi-

al;

• video-on-demand systems — used to deliver interactive video services over wide-

area networks.

The design and implementation of the above systems, and other systems dealing with dig-
ital media, forms the domain of multimedia programming.

Multimedia programming is based on the manipulation of media artefacts through soft-
ware. One of the most important consequences arising from the digitization of media is
that artefacts are released from the conﬁnes of studios and museums and can be brought
into the realm of software. For instance, the ordinary spreadsheet or wordprocessor no
longer need content itself with simple text and graphics, but can embellish its appearance

Multimedia Systems and Multimedia Programming

307

with high-resolution colour images and video sequences. (Although the example is in-
tended somewhat facetiously, we should keep in mind that digital media offer many op-
portunities  for  abuse.  Just  as  the  inclusion  of  multiple  fonts  in  document  processing
systems led to many “formatting excesses,” so the ready availability of digital media can
lead to their gratuitous use.)

With  the  appearance  of  media  artefacts  in  software  applications,  programmers  are
faced with new issues and new problems. Although recent work in data encoding stand-
ards, operating system design and network design has identiﬁed a number of possible
services for supporting multimedia applications, the application programmer must still be
aware of the capabilities and limitations of these services. Issues inﬂuencing application
design include: 

• Media composition — digital media can be easily combined and merged. Among the
composition mechanisms found in practice are: spatial composition (the document
metaphor) which deals with the spatial layout of media elements; temporal composi-
tion (the movie metaphor) considers the relative positioning of media elements along
a temporal dimension; procedural composition (the script metaphor) describes ac-
tions to be performed on media elements and how media elements react to events;
and  semantic  composition  (the  web  metaphor)  establishes  links  between  related
media elements.

• Media synchronisation — media processing and presentation activities often have
synchronisation  constraints  [10][13].  A  familiar  example  is  the  simultaneous
playback of audio and video material where the audio must be “lip synched” with the
video. In general, synchronisation cannot be solved solely by the network or operat-
ing system and, at the very least, application developers must be aware of the syn-
chronisation requirements of their applications and be capable of specifying these re-
quirements to the operating system and network.

• User-interfaces — multimedia enriches the user-interface but complicates imple-
mentation since a greater number of design choices are available. For example, ques-
tions of “look-and-feel” and interface aesthetics must now take into account audio,
video and other digital media, instead of just text and graphics. Multimodal inter-
action [2], where several “channels” can be used for information presentation, is an-
other challenge in the design of multimedia user-interfaces.

• Compression schemes — many techniques are currently used, some standard and
some proprietary, for the compression of digital audio and video data streams. Appli-
cation developers need to be aware of the various performance and quality trade-offs
among the numerous compression schemes.

• Database services — application programming interfaces (APIs) for multimedia da-
tabases are likely to differ considerably from the APIs of both traditional databases
and the more recent object-oriented databases. For example, it has been argued that
multimedia databases require asynchronous, multithreaded APIs [6] as opposed to
the more common synchronous and single-threaded APIs (where the application

308

Multimedia Component Frameworks

sends the database a request and then waits for the reply). The introduction of con-
currency and asynchrony has a major impact on application architecture.

• Operating system and network services — recent work on operating system support
for multimedia — see Tokuda [14] for an overview — proposes a number of new
services such as real-time scheduling and stream operations for time-based media.
Similarly, research on “multimedia networks” (e.g. [4], [12]) introduces new servic-
es such as multicasting and “quality of service” (QoS) guarantees. Developers must
consider these new services and their impact on application architecture.

• Platform heterogeneity — cross-platform development, and the ability to easily port
an application from one platform to another, are important for the commercial suc-
cess of multimedia applications. It is also desirable that multimedia applications
adapt to performance differences on a given platform (such as different processor
speeds, device access times and display capabilities).

In summary, a rich set of data representation, user interface, application architecture,
performance and portability issues face the developers of multimedia systems. What we
seek from environments for multimedia programming are high-level software abstrac-
tions that help developers explore this wide design space.

11.3 Multimedia Frameworks

In identifying abstractions for multimedia programming one should consider the prevail-
ing programming paradigms such as functional programming, rule-based programming
and object-oriented programming. While discussion of this topic is beyond the scope of
this chapter, our position is that each of these paradigms has something to offer to multi-
media, but that object-oriented programming, because of its support for encapsulation and
software extension, is perhaps the most natural.

The apparent afﬁnity between multimedia and object-oriented programming is clearly
evident if one looks at the short history of programming environments for multimedia ap-
plications. From the earliest multimedia toolkits, such as Muse [8] and Andrew [3], to re-
cent commercial multimedia development environments (e.g. Apple [1], Microsoft [11])
one can see the inﬂuence of the object-oriented paradigm. Often these environments and
toolkits, in addition to structuring interfaces into classes and class hierarchies, have the
more ambitious goal of building class frameworks for multimedia programming.

Perhaps the main beneﬁts of object-oriented technology to multimedia programming
are its mechanisms for extending software environments. Many of the issues listed in the
previous section (media composition techniques, compression schemes, etc.) are, at their
core,  questions  of  how  best  to  cope  with  the  uncertainties  of  evolving  environments.
Frameworks, or hierarchies of extensible and interworking classes, offer developers a way
of coping with evolution (see chapter 1). In the case of multimedia programming, several
“evolutionary processes” are of concern, in particular:

A Multimedia Framework Example — Components

309

• Platform evolution — the hardware platforms for multimedia applications are rapid-
ly evolving. Capabilities that were once considered exotic, such as video compres-
sion and digital signal processing, are now found on the desktop (and soon the “set
top”).

• Performance evolution — many of the operations of interest to multimedia program-
ming have real-time constraints, consider audio or video playback as examples. Such
temporal dependencies make multimedia applications particularly sensitive to plat-
form performance. It may be necessary, for instance, to adapt to less than optimal
processing capacity by reducing presentation “quality” (e.g. lowering frame rates or
sample sizes).

• Format evolution — new data representations for image, audio, video and other me-
dia types are likely to appear as a result of on-going standardization activities and re-
search in data compression and media composition.

Developers want to create applications that can adapt to and take advantage of changes
in platform functionality, increases in platform performance and new data representa-
tions. Of course it is impossible to write applications that can fully anticipate future devel-
opments  in  multimedia  technology,  but  frameworks  at  least  offer  a  mechanism  for
incorporating these changes into the programming environment.

11.4 A Multimedia Framework Example — Components

We now look at a particular multimedia framework — one that provides explicit support
for component-oriented software development. This framework is described more fully
elsewhere [5]. In essence it consists of four main class hierarchies: media classes, trans-
form classes, format classes and component* classes (see ﬁgure 11.1):

• Media classes correspond to audio, video and the other media types. Instances of
these classes are particular media values — what were called media artefacts earlier
in the chapter.

• Transform classes represent media operations in a ﬂexible and extensible manner.
For example, many image editing programs provide a large number of ﬁlter opera-
tions with which to transform images. These operations could be represented by
methods of an image class; however, this makes the image class overly complicated
and adding new ﬁlter operations would require modifying this class. These problems
are avoided by using separate transform classes to represent ﬁlter operations.

• Format classes encapsulate information about external representations of media val-
ues. Format classes can be deﬁned for both ﬁle formats (such as GIF and TIFF, two

* The term “component” appears throughout this book, here the term is used in the specific sense of a soft-
ware interface encapsulating software and/or hardware processes that produce, consume or transform media 
streams. Some examples are video codecs and audio players.

310

Multimedia Component Frameworks

Media

Text
Image

BinaryImage
GrayScaleImage
ColourImage

Graphic

2dGraphic
3dGraphic
TemporalMedia

Audio

RawAudio
CompressedAudio

Video

RawVideo
CompressedVideo

Animation

EventBasedAnimation
SceneBasedAnimation

Music

EventBasedMusic
ScoreBasedMusic

Transform

ImageTransform
AudioTransform
VideoTransform

Format

TextFormat
ImageFormat
GraphicFormat
TemporalMediaFormat

AudioFormat
VideoFormat
AnimationFormat
MusicFormat

Component

Producer
Consumer
Transformer

Figure 11.1 Four class hierarchies of a multimedia framework: the Media, Format, 
Transform and Component classes and examples of their immediate 
subclasses. The classes shown are abstract (with the exception of those in 
italics) — concrete classes appear deeper in the hierarchies.

image ﬁle formats) and for “stream” formats (for instance, CCIR 601 4:2:2, a stream
format for uncompressed digital video). 

• Component classes represent hardware and software resources that produce, con-
sume and transform media streams. For instance, a CD-DA player is a component
that produces a digital audio stream (speciﬁcally, stereo 16 bit PCM samples at 44.1
kHz).

Components  are  central  to  the  framework  for  two  reasons.  First,  the  framework  is
adapted to a particular platform by implementing component classes that encapsulate the
media processing services found on the platform. Second, applications are constructed by
instantiating and connecting components. The remainder of this section looks at compo-
nents in more detail.

11.4.1 Producers, Consumers and Transformers

The structure of a component is depicted graphically in ﬁgure 11.2. Of central importance
are the ports through which media streams enter and leave. Components can be divided

A Multimedia Framework Example — Components

311

Messages

Event emission

Event

Connector

Port

Component

Figure 11.2 Structure of a component. Three interfaces are available to the programmer: a 
synchronous interface based on message passing, an asynchronous interface 
based on events, and an isochronous interface based on streams. Streams 
enter and leave components through their ports and ﬂow over the connectors 
joining components.

into three broad categories based on the directionality of their ports: producers have only
output ports, consumers have only input ports, and transformers have both input and out-
put ports.

11.4.2 Component Interfaces

Components communicate with other components, and with other objects, via three inter-
faces:

• Synchronous interface — components, since they are objects, have a method inter-
face  describing  messages  that  can  be  sent  to  the  component  and  the  associated
replies. This interface is intended to allow external control over the component. For
example, methods might include starting and stopping the component and querying
or modifying operational parameters.

• Asynchronous  interface  —  components  emit  events  that  can  be  caught  by  other
objects (including other components, although building in dependencies between
components is not recommended). As an example of event generation, a video player
component might emit a “frame completed” event each time it produces a new frame
on its output port. Generally the asynchronous interface is intended for monitoring
and coordinating component behaviour.

312

Multimedia Component Frameworks

• Isochronous interface — ﬁnally the input and output ports provide a third form of in-
terface. Streams of media data (such as audio samples, video frames or animation
events) enter and leave through ports. If congestion (or starvation) is to be avoided,
connected components must operate at the same rate — in other words, connected
components are isochronous.

11.4.3 Plug Compatibility

Several conditions must be satisﬁed before a pair of ports can be connected. In particular:

• One port must be an output port, the other an input port.
• The ports must be plug compatible.
• Creating the connection cannot exceed either port’s fan-limit (the number of simul-

taneous incoming or outgoing connections a port may accept).

• The ports must accept the same form of connector. Generally connectors come in a
variety of “forms” such as shared memory connectors, network connectors and con-
nectors using a hardware bus.

Plug compatibility is related to type compatibility. Each port is associated with a set of
stream format classes; these are the supported types of the port. When a port is to be con-
nected, a speciﬁc member of this set is speciﬁed and is called the activated type of the port.
An input and output port are then said to be plug compatible when the activated type of the
output port is either identical to or a subtype of the activated type of the input port.

Plug compatibility rules out such errors as connecting a video output to an audio input.
Of more interest though, are the situations involving subtyping. It is best to think of a port
type as specifying the form of elements in the stream that ﬂows through the port. Note that
streams need not be homogeneous, one could have a stream containing both “circular”
elements and “square” elements. Plug compatibility then says that an output port produc-
ing, for instance, only “circular” elements, can be connected to an input port that accepts
streams containing both “circular” and “square” elements. In practice this means that we
can connect a source to a sink provided the “vocabulary” of the source is included in that
of the sink.

11.4.4 Component Networks

Groups of connected components are called component networks. A component network
resembles a dataﬂow machine — streams of media data ﬂow from producers, through
transformers, and ﬁnally to consumer components. Applications are responsible for build-
ing component networks — in other words, applications build the virtual machine on
which they run. This involves:

Video Widgets — A Programming Example

313

• Instantiation — the instantiation of a component results in resources being allocated
for its operation. Resources include such things as memory, bus and network band-
width, processor cycles, and hardware devices.

• Initialization — after creating a component object it must be initialized, i.e. opera-
tional parameters such as “speed” or “volume” must be set. The component’s method
interface is used for this purpose.

• Connection — after instantiating and initializing components, they can then be con-
nected. Depending on the application, all connections may be made statically when
the application begins (e.g. a two-party desktop conferencing application) or dynam-
ically as the application runs (e.g. a multi-party desktop conferencing application
where users have the ability to enter and leave conferences as they are running). An
example of a tool that can be adapted to allow the visual conﬁguration of media
processing components is described in chapter 10.

• Synchronisation — components are subject to real-time constraints. In particular,
media values enter and leave their ports at speciﬁc rates. If for some reason compo-
nents are no longer able to process streams at the proper rates, then synchronisation
errors start to appear (such as video lagging behind audio). When a component net-
work falls “out-of-sync” it may be necessary for the application to specify corrective
action (such as shutting down components, reducing quality, or acquiring more re-
sources).

• Event-handling — during operation, components generate a variety of events. Appli-
cations can register interest in events and must then provide appropriate event han-
dlers.

11.4.5 Media Processing Platforms and Component Kits

Finally, two important notions related to components are media processing platforms and
component kits. A media processing platform is simply a set of hardware and software re-
sources. Some examples would be a CD-i player, a MIDI network, a PC with a sound
board, a video editing suite, a digital signal processor, and a network of “multimedia
workstations” (workstations with audio and video capabilities).

Given a media processing platform, a component kit is the set of components offered by
the platform. Clearly applications can only use available components. However, it should
be possible for applications to adapt themselves, at least to some extent, to different plat-
forms and different component kits. For instance, consider an application that plays mul-
tiple audio, video and MIDI tracks. If the application ﬁnds itself on a platform with no
MIDI components, it might select simply to ignore any MIDI tracks during playback.

11.5 Video Widgets — A Programming Example

The preceding section contained a short overview of a proposal for an object-oriented
framework for multimedia programming. To give a better idea of how such frameworks

314

Multimedia Component Frameworks

Figure 11.3   A video widget and application windows.

can be used, and how they can help shield applications from changes in platform architec-
ture, we will look at a programming example based on an existing prototype.

The programming example we have chosen is the implementation of “video widgets”
[7]. Video widgets, like graphics widgets (menus, buttons, icons and so on) are user-inter-
face elements encapsulating both visual and behavioural information. Video widgets are
rendered (i.e. displayed) by compositing video sequences (stored either in analog or dig-
ital form) over application graphics.

An example of a video widget is shown in ﬁgure 11.3. This widget is the basis of a sim-
ple “video assistant” for explaining and demonstrating the use of buttons belonging to
some application. Such a video widget could be of use in multimedia kiosks or other situ-
ations where users may not be familiar with the operation of the application.

The implementation of video widgets involves components for playing, mixing and
displaying video — these are producers, transformers and consumers respectively. The in-
stantiation and connection of these components is performed by a class called Video-
Widget, this class also provides application programmers methods for controlling widget
behaviour. A partial class deﬁnition for VideoWidget is as follows:

class VideoWidget {
private:

VideoPlayer*
VideoMixer*
WindowServer*
Display*
ActionTable*

player;
mixer;
wserver;
display;
atab;

// a Component object (a Producer)
// a Component object (a Transformer)
// a Component object (a Producer)
// a Component object (a Consumer)
// identiﬁes widget actions

Video Widgets — A Programming Example

315

player

wserver

mixer

display

Figure 11.4   A component network for a video widget. 

public:

void

}; 

// create a video widget
VideoWidget(WindowServer* w, Display* d,

Video* v, ActionTable* a, ChromaKey k);

// have widget perform some action
// this may generate events that can be
// caught by the application
Perform(ActionId  aid, ﬂoat  speed, bool  blockFlag);

The VideoWidget class includes instance variables that refer to the component objects
used to build the “virtual machine” (i.e. component network) on which a video widget
runs. The classes of these components are:

• VideoPlayer — an abstract class for components that playback video values (either
analog or digital). Some specializations could include: VideoTapePlayer, VideoDisc-
Player, MpegPlayer and JpegPlayer. Methods declared by VideoPlayer (and implement-
ed by the subclasses) include Load, Cue, Play and Pause.

• VideoMixer — a class for components that mix video using techniques such as chro-

ma-keying. Methods include SetChromaKey, EnableKeying, BypassKeying.

• WindowServer — a class used to encapsulate window server functionality. A window

server is represented by a producer component with a video-valued output port.

• Display — a class used for display devices. A particular display is represented by a

consumer component with a video-valued input port.

Using the framework’s notion of components and connections, a typical graphics appli-
cation would consist of a WindowServer component connected to a Display component.
Video widgets can then be implemented by “splicing” a video mixer and a video player
into this connection. The resulting component network is shown in ﬁgure 11.4. 

Conﬁguration of the component network takes place in the constructor for VideoWidget.

An outline of this method is:

316

Multimedia Component Frameworks

VideoWidget::VideoWidget(WindowServer* w, Display* d,

Video* v, ActionTable* a, ChromaKey k)

{

}

player = new VideoPlayer(v->Format( ));
mixer = new VideoMixer;
wserver = w;
display = d;
atab = a;

// connect player and wserver outputs to mixer inputs
// connect mixer output to display input

// initialize components
player->Load(v);
mixer->SetChromaKey(k);
mixer->EnableKeying( );

In addition to making component connections, the constructor loads a video value onto
the video player and conﬁgures the mixer for chroma-keying. The constructor also takes
an ActionTable argument; this is a data structure identifying offsets within the video value
for particular “actions” that can be performed by the widget. A particular action is played
back by using the Perform method:

VideoWidget::Perform(ActionId  aid, ﬂoat  speed, bool  blockFlag)
{

player->Cue(atab[aid]);
player->Play(speed, blockFlag);

// cue at start frame of action aid
// start playing, this method blocks
// if blockFlag is TRUE

}

The VideoWidget class can be expanded in many ways to include such things as audio ca-
pabilities, multi-layer mixing and video effects (e.g. fading in or out a video widget).
However, our purpose here is not really to discuss the use of video widgets or their design
requirements, but rather to provide a non-trivial example of how component networks are
mapped to media processing platforms.

Two possible, but radically different, platforms for video widgets are shown in ﬁgures
11.5 and 11.6. The ﬁrst is based on analog video and external devices for mixing and
switching. The second assumes a fast internal bus and hardware components for process-
ing high data rate uncompressed digital video.

The important point of this example is that the differences between the platforms need
not be visible to the user of video widgets. More speciﬁcally, it is possible to have a single
implementation of the VideoWidget class for both platforms. The code for methods such as
Perform remains the same; what changes between platforms are the implementations of the
components used by VideoWidget. However, as long as implementations of VideoMixer,
VideoPlayer, etc., provide the same interfaces, there is no reason to change the VideoWidget
class.

Summary

317

Ethernet

Scan converter

RGB

Workstation

SCSI

B

 Videodisc

Serial port
expander

Sync generator

“House Sync”

RS-232
control lines

F

TBC

F

TBC

B

Analog video routing switch

F+B

F

B

F+B

Video
monitor

Video mixer

Control

NTSC

RGB

Figure 11.5 An analog video platform for “video widgets”. The two video signals F (front) 
and B (back) come from the video widget and the application respectively.The 
central part of this layout is an analog video routing switch allowing video 
equipment to be connected under computer control. The TBCs (time-base 
correctors) synchronize video signals against some reference signal (coming 
here from a sync generator) and are needed when video signals are mixed.

11.6 Summary

Multimedia raises a host of new design issues for application developers. Questions of
media composition, media synchronisation, data formats, user interfaces and database in-
terfaces must be re-examined in the light of the capabilities of multimedia platforms. To
take one example, advances in video compression techniques now make it possible to con-
struct “video servers.” These digital video storage and delivery systems are the basis of the
new family of video-on-demand services and lead us to question the nature of the interface
between applications and database systems.

One of the more severe practical difﬁculties facing developers of multimedia applica-
tions is the lack of stable target platforms. What can be called “platform volatility” results
from the rapid pace of additions to the functionality of multimedia hardware, improve-

318

Multimedia Component Frameworks

CPU

RAM

Disk

CD

Network
interface

System bus

Frame
buffer

Compress

Decompress

Grab

Crossbar switch or high speed bus

“video studio”
subsystem

Mixer

ADC

DAC

Transform

From analog source

To analog sink

Figure 11.6 A digital video platform for “video widgets”. Heavy lines indicate high data 
rate streams. The analog-to-digital converter (ADC) and digital-to-analog 
converter (DAC) connect the “video studio subsystem” to external analog 
sources (e.g. video cameras) and sinks (e.g. monitors).

ments  in  performance  and  quality  characteristics,  and  the  introduction  of  new  media
formats. In order to simplify cross-platform development, multimedia programming en-
vironments must address the issue of platform volatility. This chapter has argued, through
a concrete example, that object-oriented programming, class frameworks and component-
based software allow us to cope with platform evolution — that constructing applications
from connectable and “swappable” components helps protect developers from even radi-
cal changes in target platforms.

References

[1] Apple Computer Inc., QuickTime 1.5 Developer’s Kit, 1992.

[2] Meera Blattner and Roger Dannenberg (eds.), Multimedia Interface Design, ACM Press, Reading,

Mass., 1992.

[3] Nathaniel Borenstein, Multimedia Applications Development with the Andrew Toolkit, Prentice Hall,

Englewood Cliffs, NJ, 1990.

[4] Dominico Ferrari, Anindo Banerjea and Hui Zhang, “Network Support for Multimedia: A Discussion
of the Tenet Approach,” Technical Report TR-92-072, International Computer Science Institute, Uni-
versity of California at Berkeley, 1992.

[5]

Simon Gibbs and Dennis Tsichritzis, Multimedia Programming: Objects, Environments and Frame-
works, Addison-Wesley / ACM Press, Wokingham, England, 1994.

References

319

[6]

[7]

Simon Gibbs, Christian Breiteneder and Dennis Tsichritzis, “Audio/Video Databases: An Object-Ori-
ented Approach,” in Proceedings IEEE Data Engineering Conference, Vienna, 1993, pp. 381–390.
Simon Gibbs, Christian Breiteneder, Vicki de Mey and Michael Papathomas, “Video Widgets and
Video Actors,” in Symposium on User Interface Software and Technology (UIST ’93), 1993, pp. 179–
185.

[8] Matthew Hodges, Russel Sasnett and Mark Ackerman, “A Construction Set for Multimedia Applica-

tions,” IEEE Software, vol. 6, no. 1, 1989, pp. 37–43.
John Koegel Buford (ed.), Multimedia Systems, Addison-Wesley, Reading, Mass., 1994.

[9]
[10] Thomas D.C. Little et al., “Multimedia Synchronization, IEEE Data Engineering Bulletin, vol. 14,

no. 3, 1991, pp. 26–35.

[11] Microsoft Corporation, Microsoft Windows Multimedia Programmer’s Reference, Microsoft Press,

1991.

[12] Doug Shepherd and Michale Salmony, “Extending OSI to Support Synchronization Required by Mul-

timedia Applications,” Computer Communications, vol. 13, no. 7, 1990, pp. 399–406.

[13] Ralf Steinmetz, “Synchronization Properties in Multimedia Systems,” IEEE Journal on Selected Ar-

eas in Communications, vol. 8, no. 3, 1990, pp. 401–412.

[14] Hideyuki Tokuda, “Operating System Support for Continuous Media Applications,” in Multimedia

Systems, ed. John Koegel Buford, Addison-Wesley, Reading, Mass., 1994, pp. 201–220.

320

Chapter 12
Gluons and the
Cooperation between 
Software Components

Xavier Pintado

Abstract    A major problem in software engineering is how to specify the patterns
of interaction among software components so that they can be assembled to
perform tasks in a cooperative way. Such cooperative assembly requires that
components obey rules ensuring their interaction compatibility. The choice of a
speciﬁc approach to specifying rules depends on various criteria such as the
kind of target environment, the nature of the software components or the kind of
programming  language.  This  chapter  reviews  major  efforts  to  develop  and
promote standards that address this issue. We present our own approach to the
construction of a development framework for software applications that make
use of real-time ﬁnancial information. For this domain, the two main requirements
are (1) to facilitate the integration of new components into an existing system,
and (2) to allow for the run-time composition of software components.The goal
of  the  development  framework  is  to  provide  dynamic  interconnection
capabilities. The basic idea is to standardize and reuse interaction protocols that
are encapsulated inside special objects called gluons. These objects mediate
the cooperation of software components. We discuss the advantages of the
approach,  and  provide  examples  of  how  gluons  are  used  in  the  ﬁnancial
framework.

12.1 Introduction

The advent of object-oriented techniques has brought many beneﬁts to the ﬁeld of soft-
ware engineering. One notable beneﬁt is that objects provide a higher degree of autonomy
than obtained with the traditional separation of software into functions and data structures.
This autonomy promotes component-oriented software construction, since autonomous

Xavier Pintado, “Gluons and the Cooperation between Software Components,” Object-Oriented Software Composition, O. Nierstrasz 
and D. Tsichritzis (Eds.), pp. 321-349, Prentice Hall, 1995. 
Reproduced with the permission of the Publisher, Prentice Hall (a Pearson Education company).  This work is protected by copyright and 
may not be reproduced other than when downloaded and viewed on a single Central Processor Unit (CPU) for private use only.  It is not 
otherwise to be reproduced or transmitted or made available on a network without prior written permission of Prentice Hall.  All other 
rights reserved.

322

Gluons and the Cooperation between Software Components

objects can be reused in many different context with reasonable integration efforts. Com-
ponent reuse can reduce development time and costs, and can lead to improved reliability,
since reusable components will become thoroughly tested as a consequence of reuse.

Although component-oriented software is fairly promising in terms of its reuse poten-
tial some major problems remain to be solved. Among these, a salient problem is the
definition of the patterns of cooperation between software components, to which consid-
erable effort has already been devoted. We may notice, for instance, that a class interface
condenses assumptions about the objects that can be instantiated from it, but not assump-
tions about the interactions that those objects may have with other objects.

We may better capture the essence of the problem by observing that virtually any kind
of cooperation requires agreement between the cooperating entities [29]. Cooperation
agreements can take many forms, however. They can be speciﬁed, for instance, by a “law”
to which all the cooperating entities obey. But cooperation can also rely on bilateral agree-
ments each deﬁning the cooperation between pairs of entities.

In the context of component-oriented software design, the goal is to make software
components cooperate through reliable and ﬂexible mechanisms that appropriately sup-
port and enforce convenient interaction patterns. In this context, the interaction “law” or
cooperation agreement is usually captured by the notion of an object-oriented develop-
ment framework [9] [10]. An object-oriented framework is a collection of classes that are
designed to work together. A framework is intended to provide a development environ-
ment that promotes reuse and reduces development effort by providing a comprehensive
set of classes and development rules. Frameworks come in many different ﬂavours: they
can, for example, target a narrow application domain such as the development of device
drivers (e.g. NeXTStep Driver Kit [19]), or they can address the requirements of a generic
development environment (e.g. Visual C++ framework [4]) comprising multiple sets of
classes and development rules.

The distinguishing characteristic of a framework is the design philosophy that pervades
all aspects of the framework such as the deﬁnition of foundation classes, the rules for the
design of new classes and the tools that support the development process. By applying a
consistent design philosophy to all the aspects of the framework, designers attempt to
provide the user with a uniform development model that reduces the learning effort and
deﬁnes a generic architecture for applications developed with the framework.

In this chapter we develop a framework for the development of ﬁnancial applications.
The framework is intended for the development of applications that involve the retrieval
of real-time ﬁnancial data sources. The typical target environment for the framework is
rapidly evolving, in the sense that the behaviour of the objects and the way they are related
evolves at a fast pace to reﬂect the real world of ﬁnance. The framework focuses on run-
time connection of software components and on capabilities that support the incremental
development of applications. Figure 12.1 shows a typical display of an application devel-
oped with the ﬁnancial framework.

The distinguishing feature of the framework is the introduction of a special family of
objects, called gluons, which are responsible for the cooperation among software compo-

Introduction

323

3

4

5

1

2

6

7

8

Figure 12.1 Display presenting some of the visualization tools available for the display of 

real-time information. Windows 1 and 2 display real-time information about 
DEC and IBM stocks in the Zurich stock exchange. Windows 3 and 4 provide 
transaction information about foreign exchange rates. Window 5 and 6 display 
index values (French Cac 40 and Dow Jones Industrial). Finally, window 7 
displays information in page format, and window 8 offers news highlights.

nents. Although  gluons  essentially  encapsulate  communication  protocols,  they  play  a
prominent role at the design level by promoting a protocol-centered design.

This chapter is organized as follows: the next section provides an overview of how dif-
ferent frameworks address the issue of object cooperation and the patterns of cooperation
that they promote. We focus on standardization proposals promoted by major software
houses since they will most likely have a signiﬁcant impact on the future architecture of
software applications. Section 12.3 discusses the requirements for the ﬁnancial frame-
work. Such requirements cannot be easily satisﬁed with the previously described ap-
proaches and we therefore introduce a new protocol-centered approach. Section 12.4
discusses gluons as special components that enable a protocol-centered approach. Section
12.5 presents the ﬁnancial framework, focusing on the illustration of commonly used
gluons. We conclude with a summary of the advantages of protocol-centered frameworks.

324

Gluons and the Cooperation between Software Components

12.2 An Overview of Cooperation Patterns

The development of mechanisms that support communication between software compo-
nents is hardly a new problem. A signiﬁcant effort has been devoted in the past, for in-
stance, to interapplication communication. A typical mechanism is the remote procedure
call (RPC), which allows an application to invoke routines belonging to another applica-
tion. RPC is the kind of cooperation mechanism one expects in software environments
where the principal entities are functions and data structures. In a word of objects, how-
ever, we might expect to have remote message capabilities since the message is the inter-
object communication mechanism.

To the best of our knowledge the ﬁrst commercially available implementation of remote
messages came bundled with NeXTStep AppKit framework[19]. However, remote mes-
saging only provides a communication layer. For software components to cooperate in a
dependable and ﬂexible way we need to deﬁne the laws of cooperation. In what follows
we provide an overview of various standardization efforts that address, in a broad sense,
the  problem  of  deﬁning  laws  of  cooperation  in  the  context  of  software  development
frameworks.

12.2.1 Object Management Group

The Object Management Group (OMG) promotes a standard to support the interaction of
software components within a framework called the Object Management Architecture
(OMA). One of the main goals of OMA is to achieve object distribution transparency,
which means that the interaction between a client component and a server component
through the server’s interface should be independent of its physical location, access path,
and should be relocation invariant. This standard relies on a common object model, the
OMG Object Model which is used by all OMG-compliant technologies.

12.2.1.1 The OMG Object Model
The OMG Object Model deﬁnes a way to specify externally visible characteristics of ob-
jects in an implementation-independent way. The visible characteristics of an object are
described as a collection of operation signatures called the object’s interface. The OMG
Object Model deﬁnition of an operation signature extends in interesting ways the typical
deﬁnition of a method’s signature in order to make it more convenient for distributed com-
puting environments. The optional oneway keyword speciﬁes an exactly-once operation
semantics if the operation successfully returns results or a at-most-once semantics if an
exception is returned. Each parameter is ﬂagged with one of the three qualiﬁers — in, out
or inout — to specify the write access to the parameter of the client, the server or both. An
exception is an indication that the request was not performed successfully. The raises key-
word introduces the list of possible exceptions that can be raised by the operation. Finally,

An Overview of Cooperation Patterns

325

[oneway] <return_type> <operation>(in|out|inout param1, ..., in|out|inout paramK)

[raises (except1, ..., exceptL)]
[context (name1, ..., nameM)]

Figure 12.2   The OMG Object Model operation signature.

the context keyword allows for the speciﬁcation of additional information that may affect
the performance of the operation. These extensions address issues related to distributed
environments such as unreliable communications, and the need for appropriate mecha-
nisms for exception handling.

12.2.1.2 Object Request Broker
The communication between objects is mediated by an Object Request Broker (ORB).
The ORB is responsible for ﬁnding the object implementation for the requested operation,
to perform any preprocessing needed to perform an operation, and to communicate any
data associated with the operation. The functionality of object request brokers is deﬁned
in the Common Object Request Broker Architecture (CORBA)[21]. In order to ensure
language  independence,  CORBA  deﬁnes  a  Interface  Deﬁnition  Language  (IDL)  that
obeys the same lexical rules as C++, although additional keywords are introduced essen-
tially to support distributed environments. However, IDL differs from C++ in that it is only
a declarative language. In order for object implementations to communicate with the ORB
they need to implement a Basic Object Adaptor (BOA) which deals with such aspects as
interface registration, implementation activation, and authentication and access control.
An important component of the ORB is the interface repository which provides access to
a collection of object interfaces speciﬁed in IDL.

To summarize, the OMG provides a standard for the communication of objects in dis-
tributed environments. The standard focuses on interoperability of heterogeneous sys-
tems, where interoperability is achieved through a request broker that deﬁnes standard
interface rules which the interacting agents need to obey.

12.2.2 Microsoft DDE and OLE
Microsoft provides  two main standards for interapplication cooperation: DDE (Dynamic
Data Exchange) and OLE (Object Linking and Embedding). DDE is much simpler than
OLE since it addresses essentially the exchange of data between applications that run on
the same computer. On the other hand, OLE is an ambitious standard that encompasses
many aspects related to the structures of software components.

12.2.2.1 Dynamic Data Exchange
DDE focuses on data exchange between applications based on a client–server model. In
DDE parlance, a client is any application that initiates a DDE connection. Usually a client
requests data after establishing a connection with a server. The connection establishes a

326

Gluons and the Cooperation between Software Components

Client

Server

Client requests data

(1) Server notifies client about data update

(2) Client eventually requests new data

Server updates data on the client side

Cold link

Warm link

Hot link

Figure 12.3 DDE involves three types of links between clients and servers. The variety 

of links reﬂects the different requirements of applications on how to 
maintain client’s data consistent with the corresponding server’s data.

link that according to the way the link deals with data updates on the server side can be one
of three types: cold, warm and hot. These three links are illustrated in ﬁgure 12.3. With
cold links the server plays a passive role: it takes no action whenever data is updated. The
client  is,  therefore,  responsible  for  implementing  the  update  policy  by  issuing  data
requests when appropriate. With warm links the responsibility for data update is shared
between the client and the server: the server notiﬁes the client upon a data update but the
data request to perform the update on the client’s side is initiated by the client. Finally,
with hot links the server is responsible for the whole update process on the client’s side.

The  three  types  of  links  allow  for  the  implementation  of  data  consistency  policies
between the client and the server that appropriately reﬂect the requirements of the client
application. The actions on both the client and the server side are carried out through call-
back functions.

The data organization at the server end follows a three-level hierarchy that recognizes
three entity types: services, topics and items, as illustrated in ﬁgure 12.4. Typically, a topic
corresponds to a document (e.g. an open document in a wordprocessor server) but it can
also represent a relation in a relational database since the DDE standard does not specify
what a topic should be. Items are the smallest entities that can be addressed through DDE.
Items can be of any type and format recognized by the Windows clipboard. In order for a
client to request data from a server it needs to know the name of the service provided by
the server, the name of the topic and the name of the item it is looking for. A client can con-
nect to multiple servers and a server can be linked to multiple clients. Although DDE is es-
sentially  a  mechanism  for  data  exchange  among  applications  it  also  provides  limited
capabilities that allow a client to execute commands on the server side. These capabilities
can be used to implement cooperation mechanisms that are, to some extent, similar to re-
mote messaging in other environments.

An Overview of Cooperation Patterns

327

Topic A

Service

Topic B

Topic C

Item 1

Item 2

Item 3

Item 4

Item 5

Item 6

Figure 12.4 DDE hierarchy showing the service provided by a server and how it is 

hierarchically organized in topics and items.

12.2.2.2 OLE 2.0
OLE is another standard deﬁned by Microsoft that enables the cooperation of applica-
tions. In its current 2.0 version [17][18] it shares many similarities with OpenDoc that we
will describe in section 12.2.4.2. For instance, both standards comprise a set of coopera-
tion protocols and a deﬁnition for compliant structured documents. OLE 2.0 is relatively
hard to summarize brieﬂy. In fact OLE 2.0 is much more than a application cooperation
standard; it is the foundation for a Microsoft strategy to make MS-Windows migrate to ob-
ject-oriented technology. As such, OLE 2.0 comprises a set of apparently loosely related
standard deﬁnitions, models and implementations which provide, as a whole, a coordinat-
ed platform for future object-technology. OLE 2.0 provides standard deﬁnitions and im-
plementation  support  for  compound  documents,  drag-and-drop  operations,  name
services, linking and embedding of documents, and application interaction automation.

The unifying concept underlying the OLE 2.0 platform is the Component Object Model
(COM). All the other pieces of OLE 2.0 either rely on the COM deﬁnitions or use COM
objects, usually called Windows objects [17]. Windows objects differ slightly from the ob-
jects proposed by commonly used programming languages such as C++ or Eiffel. A Win-
dows object is fully deﬁned by its set of interfaces. An interface is a collection of function
pointers and there is no such notion as references to Windows objects. When we obtain a
reference to an object it is in fact a reference to one of its interfaces. Another interesting
aspect of Windows objects is that there is no inheritance mechanism, but because Win-
dows objects provide multiple interfaces, it is easy to encapsulate Windows objects with
programming  languages  that  offer  either  single  or  multiple  inheritance.  The  COM
presents Windows objects essentially as collections of functions [7][17] (i.e. interfaces),
which can be fairly confusing for readers acquainted with object-oriented concepts. The
main reason, we believe, is that the OLE 2.0 is to be implemented with many different pro-
gramming languages, such as BASIC, C, C++, which may or may not endorse object-ori-
ented techniques. With different programming languages the binding between the object’s
data and the object’s methods may be implemented in different ways that are not speciﬁed
in OLE. Microsoft offers an OLE 2.0 software development kit for C++ environments.

328

Gluons and the Cooperation between Software Components

A key feature of OLE 2.0 is the deﬁnition of structured documents. Structured docu-
ments contain storages and streams that are organized in a similar way to traditional ﬁle
systems: streams are analogous to ﬁles while storages act as directories. So, storages con-
tain either streams or storages. Storages and streams provide support for structured or
composite documents that are organized in a hierarchical structure. OLE 2.0 provides a
standard deﬁnition for the document’s structure and also a set of functions that support the
standard operations on structured documents. 

The best-known features of OLE 2.0 are probably embedding and linking. A typical
compound document (e.g. a text with graphics, sound, data in spreadsheet format, etc.)
contains data objects that have been created by different applications. The owner of the
compound document, say a wordprocessor, may know how to display most of these items
but cannot deal with the full complexity of retrieving and modifying them. An OLE con-
tainer is any application that can incorporate OLE objects. Containers usually display the
OLE objects and accept commands for them. However, containers are not intended to
process the objects. Objects retain an association with server applications that are respon-
sible for servicing the requests addressed to the objects. The idea here is that clients do not
need to be aware of the internals of the objects they contain. The object (data) together
with its associate server corresponds to the usual notion of object in object-oriented termi-
nology which encapsulates both data and operations on the data. Servers accept com-
mands, called verbs, that correspond to actions that can be applied to the objects. An
interface is the set of operations that can be applied to an object via its server.

OLE 2.0 offers two ways to integrate an object into a compound document: linking and
embedding. Embedding is most frequently used. The container application owns and
stores each embedded object, but the server retrieves the object. The server plays an anon-
ymous role by processing the object on behalf of the container application. Conversely, an
object can be linked into a document. A linked document belongs to a given document
(and is stored in the document’s ﬁle) but it is referenced in another document. In this way
several containers can share a single linked object.

Additionally, OLE 2.0 provides a standard for data transfer called Uniform Data Trans-
fer (UDT) and a standard for scripting called Automation. Automation allows objects
associated with one application to be directed from another application, or to perform op-
erations on a set of objects under the control of a macro language [18].

To summarize the OLE 2.0 standard suite we may say that the Component Object Mod-
el standardizes how an object and an object’s client communicate; compound documents
standardize document structure and storage; Uniform Data Transfer standardizes data
exchange capabilities and Automation provides a support for remote control of applica-
tions.

It should be noted that with OLE version 2.0 the interapplication cooperation primitives
are restricted to the scope of the same machine. However, these mechanisms could easily
be extended to provide the same capabilities across networks and serve, therefore, as a
foundation for distributed computing.

An Overview of Cooperation Patterns

329

Application

Driver

Manager

Driver A

Driver B

Driver C

Driver D

Data source A

Data source B

Data source C

Data source D

ODBC interface

Figure 12.5   ODBC 2.0 application architecture.

12.2.3 ODBC 2.0

Although the Open Database Connectivity standard from Microsoft is more a standard for
the interconnection of applications and databases, it is worth mentioning here for two rea-
sons. First, it represents a much-needed standardization effort to isolate applications from
the access to speciﬁc databases. Second, databases will be, at least in the near future, one
of the most prominent reusable software components since they are responsible for object
persistence.

The architecture of an ODBC 2.0 application is represented in ﬁgure 12.5. From the
view point of the application, the access to the various data sources is transparent through
the ODBC interface. The ODBC 2.0 standard interface provides the following:

• a standard way to connect to databases;
• a set of function calls that allows an application to connect to one or many databases,

execute SQL statements, and retrieve the results;

• a standard representation for data types.
The Driver Manager loads drivers on behalf of the application, while the Drivers imple-
ment ODBC function calls and submit, when appropriate, requests to the associated data
source. The Drivers are responsible for adapting to the speciﬁc syntax of the associated
DBMS. ODBC 2.0 does not rely on object-oriented principles and is fairly low level in the
sense that it provides a vendor-independent mechanism to execute SQL statements on
host databases.

12.2.4 Apple’s Interapplication Communication Architecture

and OpenDoc

Like Microsoft, Apple devoted signiﬁcant efforts to the deﬁnition and implementation of
standard mechanism for the cooperation of applications. Also like Microsoft, Apple has a

330

Gluons and the Cooperation between Software Components

Edition Manager

Open Scripting Architecture

Event Manager

Program-to-Program Communication toolbox

Figure 12.6   The layers of the Interapplication Communication Architecture.

large developer base and a large software base that did not already fully adopt object-
oriented tools. The consequence is that the migration towards an object-oriented platform
started by the introduction of object-oriented concepts such as message passing into de-
velopment environments that are not object-oriented.

12.2.4.1 Interapplication Communication Architecture
This migration was the driving force for the development of the Interapplication Commu-
nication architecture (ICA), which provides a standard mechanism for communication
among Macintosh applications[1]. More speciﬁcally the goal is to allow applications to:

• exchange data through copy-and-paste operations;
• read and write data blocks from and to other applications;
• send and respond to Apple events;
• be controlled through scripts.

A signiﬁcant effort has been devoted by Apple to deﬁne a common vocabulary of high-lev-
el messages, called Apple events, that are published in the Apple Event Registry: Standard
Suites. To the best of our knowledge, this has been the only effort to date to standardize the
messages that applications may respond to.

• Applications typically use Apple events to request services from other applications
or to provide services in response to other applications requests. A client application
is an application that sends an Apple event to request a service, while the application
that provides the service is the server application. The client and server applications
can reside on the same machine, or on different machines connected to the same net-
work.

The ICA comprises the following:

An Overview of Cooperation Patterns

331

• The Edition Manager, which provides support for copy-and-paste operations among
applications and updating information automatically when data in the source docu-
ment changes.

• The Open Scripting Architecture, which deﬁnes the standard mechanisms that allow
for the external control of single or multiple applications. OSA is comparable, to
some extent, to Automation in OLE 2.0. OSA is not tied to any speciﬁc scripting
language. Each scripting language has a corresponding scripting component that
translates the scripts into events.

• The Event Manager, which provides the support that allows applications to send and
receive events. The Event Manager standard deﬁnes the architecture and the pieces
of Apple messaging backplane.

• The  Program-to-Program  Communication  toolbox,  which  provides  low-level
support that allows applications to exchange blocks of data in an efﬁcient way. The
Edition Manager and the Open Scripting Architecture provide the user level support.
They both rely on the Event Manager to exchange data and messages across applica-
tions. The Event Manager, in turn, relies on the Program-to-Program Communica-
tion toolbox to transport data. Figure 12.6 illustrates how the different parts of the
ICA are related. 

12.2.4.2 OpenDoc
As opposed to OLE, the ICA only deals with the problem of application interaction and
does not deﬁne a standard for documents. Apple, together with other companies such as
Novell and IBM, is proposing another standard, OpenDoc, that is quite similar in scope to
OLE 2.0. It deﬁnes both standards for application interaction mechanisms and for struc-
tured documents. In reality, OpenDoc integrates three other standards: (1) System Object
Model (SOM), which originated as a CORBA compliant IBM standard for interapplica-
tion message exchange; (2) BENTO, which standardizes the format of structured docu-
ments  and  (3)  the  Open  Scripting Architecture  that  we  already  mentioned  as  part  of
Apple’s ICA.

BENTO deﬁnes the standard elements for structuring documents in OpenDoc. BENTO
documents are stored in containers which are collections of objects. BENTO objects are
organized as schematized in ﬁgure 12.7. An object has a persistent ID which is unique
within its container. Objects contain a set of properties, which in turn contain values of
some type. The values are where data is actually stored and their types describe the corre-
sponding formats.

The ideas underlying OpenDoc are quite similar to those on which OLE 2.0 is based:
composite documents may contain heterogeneous objects that are managed and manipu-
lated using a variety of specialized software components. With OLE 2.0 the specialized
components are heavyweight applications such as wordprocessors and spreadsheets. On
the other hand, OpenDoc targets components that are more ﬁne-grained. The goal is to
make the concept of application vanish, giving place to a document-centered approach
that promotes the document as the main user concept. Each part of a document retains an
association with a specialized component that knows how to retrieve it. Naturally, the in-

332

Gluons and the Cooperation between Software Components

Object “Budget”

Property X
Object

Value of type A
Value of type B
Value of type C
Value of type D
Value of type A
Value of type C

Property Y
Object

Value of type A
Value of type B
Value of type C
Value of type D

Property Z
Object

Value of type C
Value of type A
Value of type C
Value of type S

Property U
Object

Value of type F
Value of type G
Value of type A
Value of type B
Value of type A
Value of type H

Figure 12.7 A Bento object contains a collection of properties and properties contain 

values which are the placeholders where data is actually stored.

vocation of the retrieving component is transparent to the user, who can easily increase the
variety of the parts that can be incorporated into composite documents by purchasing new
specialized software components.

12.2.5 Discussion

The considerable effort that has been devoted to designing, implementing and promoting
the adoption of these cooperation standards suggests the critical role that such standards
may play in future software technology. We may notice, however, that the various stand-
ards differ considerably in scope.

For example, OMG standards focus on interoperability among heterogeneous subsys-
tems and they essentially provide mechanisms that allow software components to request
services from other software components. Software components need to provide a stand-
ard layer that adapts them to the request broker in much the same way that ODBC 2.0 ap-
plications need drivers to adapt data sources to the ODBC 2.0 interface. Conversely, OLE
2.0 and OpenDoc each provide a complete integration platform-centered on a standard
deﬁnition of composite document. The document-centered approach that underlies both
standards seems appropriate for ofﬁce information systems where the composite docu-
ment seems to be indeed the fundamental user abstraction.

However, there exist many software application domains that do not revolve around the
notion of document. For example, in real-time software and communications software,
the notion of document does not play an important role. We may also notice that these
standards do not promote interaction at the software component level, but rather at the ap-

Requirements for a Financial Framework

333

plication level, even though OpenDoc encourages document retrieval through a set of
small and specialized retrieval units while OLE 2.0 promotes communication among full-
ﬂedged applications such as wordprocessors, spreadsheets, etc.

The ICA from Apple (in particular, the Apple events suite) takes a rather different ap-
proach, focusing on the standardization of operations. The goal is to promote a standard
vocabulary for services so that applications that provide similar services (e.g. spread-
sheets) can be replaced by one another.

Another observation is that any of the standards discussed requires mechanisms that are
speciﬁc to object-oriented languages such as inheritance and encapsulation. In fact, they
are being used as a vehicle for the migration towards object-oriented environments by in-
troducing object-oriented concepts expressed in non-object-oriented languages. This is
probably the reason why these standards focus mainly on interaction between applica-
tions; the same interaction rules do not usually apply to interaction of software compo-
nents occupying the same address space.

12.3 Requirements for a Financial Framework

The application cooperation standards we have discussed address the needs of a generic
software  environment  and  reﬂect  many  other  constraints  not  all  related  to  software
engineering, such as market constraints and applicability of standards to old development
environments. Our ﬁnancial framework targets applications that retrieve real-time and
historical data from ﬁnancial information sources. Typically, these applications display
data such as the price of securities, interest rates and currency exchange rates, and allow
users to explore real-time and ﬁnancial historical information. These applications present
to the professional user a window into ﬁnancial activities which provides access to the dis-
tributed world-wide ﬁnancial market.

Financial markets are characterized by rapidly evolving, complex relationships among
the wide variety of ﬁnancial instruments. Market relationships that hold among ﬁnancial
instruments are continuously evolving, and professional investors are constantly tracking
that evolution in order to detect new investment opportunities. Decision support systems
(DSSs) play an important role in supporting the user while ﬁnding such investment oppor-
tunities. The user needs to combine ﬁnancial instruments, test the combination with vari-
ous economic scenarios, look at the present cost of the combination, reﬁne the choice of
instruments, re-evaluate them, and eventually make an investment decision. In order to
provide the appropriate support the DSS should allow the dynamic combination of ﬁnan-
cial instruments so that any instrument can be combined with any other instrument. This
asks for a DSS architecture that facilitates the run-time interaction of software compo-
nents. Furthermore, new ﬁnancial instruments are frequently added so the DSS should be
easily extendable with operational models for new instruments. To summarize, the archi-
tecture needs to provide capabilities for the dynamic connection of software components
and facilitate the integration of new software components.

334

Gluons and the Cooperation between Software Components

12.3.1 Towards a Protocol-Centered Framework

As we already mentioned, the goal of a framework is to provide a set of classes that are de-
signed to work together. This operational compatibility can be achieved in many ways.
The Object Management Group focuses on compatibility mediated by an object request
broker. They impose no restriction on the software components themselves. Their main
concern is to provide interoperability in heterogeneous environments. OLE 2.0 and Open-
Doc emphasize the compound document as the main shared entity. Their main concern is
to provide the most ﬂexible environment for document retrieval. Apple’s ICA approach,
on the other hand, attempts to standardize common operations by deﬁning a standard op-
erations vocabulary and its associated semantics. ICA pursues two main goals. The ﬁrst
goal is to make the access to core standards functionality, such as common spreadsheet op-
erations, database access and wordprocessor tasks, application independent. The second
goal is to offer powerful scripting capabilities to automate tasks and to compose applica-
tions together.

The goal of the ﬁnancial framework is to provide support for dynamic control of the in-
teraction between software components. To achieve such a goal we need to provide a
mechanism that allows for dynamic interconnection of software components.

12.3.2 Standardizing a Service’s Vocabulary

During the early stages of the framework’s design we considered a number of alternative
intercomponent  interaction  principles.  The  goal  was  to  ﬁnd  a  mechanism  that  could
provide the highest degree of dynamic interconnection for the kind of applications we are
targeting with the ﬁnancial framework. We tried, for instance, to standardize a set of core
services so that each service is associated to a unique name called a verb, much in the same
way as the Apple events suite standardizes the operations vocabulary of common services
provided by wordprocessors, spreadsheets, databases, etc.

12.3.2.1 The Advantages
The intuition behind this approach is that we can identify among the services provided by
the various software components of a framework many services that, although not identi-
cal, have comparable semantics. For example, most components in our environment pro-
vide services such as evaluate, print, and notify. We attempted to identify within the scope
of the ﬁnancial framework the principal groups of services and we ended up with the list
shown in table 12.1. Software components may provide other services as well. These serv-
ices belong either to more specialized groups, such as a group that is related to real-time
services, or they do not belong to any group since they are too speciﬁc to a particular class
of components.

A major advantage of this approach is simplicity. A service request can be performed by
sending a message, a mechanism that every object-oriented environment offers. The ad-
vantage of standardizing a vocabulary for services is perhaps more compelling for many

Requirements for a Financial Framework

335

Service group name

Description

Common services

Messaging and notiﬁcation

Computational

Display

Object management

Services that are usually provided by most components 
such as: print, show-services, identify-error, and store

Services related to messaging and event notiﬁcation such 
as: call-back, notify, add-to-broadcast-list, message, 
forward-message

Services related to computational servers: evaluate, 
iterate, perform-aggregation, set-value, get-value

Services related to visual operations such as: display, 
undisplay, front, drag-and-drop

Services related to software component management 
such as: create, replicate, destroy, add-object, instance-
of-class, component-id

Table 12.1   

reasons. First, reusing components is made easier since services with similar or close se-
mantics bear the same name on all the software components, thus simplifying the name
space. Second, dynamic interconnection of software components is improved because if
a component provides a service conforming to a standard protocol, such as a print service,
then that service can be invoked by any client understanding the same protocol. Third, in-
terchangeability of software components is increased since two software components that
provide similar functionality will most probably show a fair degree of commonality in
their interfaces.

12.3.2.2 The Shortcomings
We noticed, however, that this approach is not the best in terms of dynamic interconnec-
tion. The main reason is that, in general, the interaction between two or more components
involves more operations than simply sending a message. Although we can compose soft-
ware components by specifying the appropriate sequences of messages to be exchanged
between the components, a collection of sequences of messages is not the appropriate way
to specify components’ interactions. All but the simplest interactions involve a state, and
the set of permissible messages that can be exchanged between interacting components,
at a given point in time, usually depends on the present state of the interaction. Real-time
ﬁnancial  environments  provide  many  illustrations.  Consider,  for  example,  a  software
component, called the server, that offers real-time data updating services to other compo-
nents. A component may register to be notiﬁed for data updates. Registering starts an in-
teraction  that  ends,  hopefully,  when  the  client  component  requests  the  server  to  stop
notiﬁcation. Such interaction may comprise many data updates, error messages, notiﬁca-
tion of temporary interruption of real-time services, with subsequent service resumption,
etc. Another example is a database transaction. A server may execute a database trans-
action on a client component’s behalf. The transaction may involve many different opera-

336

Gluons and the Cooperation between Software Components

A

C

D

B

Y

F

G

Z

H

E

X

Figure 12.8 Protocols deﬁne compatibility classes inside which members are able to 
interact. Protocol X allows interaction between objects A, B, C and D, while 
protocol Y deﬁnes an interaction pattern between D, C, B and F. Object H 
cannot interact with other objects since it does not adhere to any speciﬁed 
protocol.

tions  that  individually  succeed  or  fail.  The  transaction  succeeds  if  all  its  operations
succeed, otherwise the transaction fails. The interaction between the client and the server
depends on the state of the transaction, which can be deﬁned as the logical “and” of the in-
dividual operation results. Whenever, the state condition switches to fail, the already exe-
cuted operations need to be unrolled before terminating the transaction. 

The two examples illustrate the need for a higher-level mechanism to specify compo-
nents’ interactions that allows for interaction states and state-dependent actions. We call
such a mechanism a component’s interaction protocol. These observations lay the founda-
tions  that  lead  us  from  message-based  frameworks  to  protocol-centered  frameworks
which focus on protocols as the main components interaction mechanisms.

12.3.3 Component Interaction Protocols

Software component protocols share many similarities with computer communication
protocols. Both specify object interaction patterns. As such they fulﬁl two important func-
tions. First, they provide a mechanism or a formalism to specify the rules of interaction be-
tween objects. Second, protocols deﬁne compatibility classes in the sense that entities that
obey the same protocol display an interaction compatibility as illustrated in ﬁgure 12.8 

12.3.3.1 Requirements for Interaction Protocols 
Software component interaction protocols should support a number of important features.
First, they should be appropriate to specify various aspects of component interactions
such as synchronization, negotiation and data exchange. Second, they should play the role

Requirements for a Financial Framework

337

of “contracts” or “interaction agreements” that represent the necessary and sufﬁcient con-
ditions for a software component to interact with other software components that comply
with the same “agreement”. Helm et al. [12] focus on this important aspect of interactions.
Third, the interaction speciﬁcations should be multilateral agreements rather than bilater-
al interaction agreements between two software components.

Another desirable property of component interaction protocols is that their implemen-
tations reside as much as possible outside the components since as an agreement, a proto-
col does not belong to any component. We may observe, looking at programs written in an
object-oriented language, that a signiﬁcant fraction of a component’s code is devoted to
the communication of the component with other software components. Most of the com-
munication functionality is inside the component. This has two main objectionable conse-
quences. First, components tend to become “hard-wired” to their environments, which has
the undesirable side effect of reducing their reuse potential within other environments.
Second, the intermix of code responsible for interaction with the code that is proper to the
component reduces readability and maintainability. Naturally, it might be impossible and
perhaps undesirable to strip all the interaction code out of a component. The goal is to
leave inside the component only the sufﬁcient interaction functionality that can be used by
many different protocols. For example, we will keep inside the component methods to ex-
port values, methods to notify events, and methods to send generic messages since they do
not implement any interaction among speciﬁc components and represent the hooks neces-
sary to build protocols.

12.3.3.2 Roles and Interplay Relations
We will be more precise now about what we mean by a protocol. A protocol speciﬁes the
interaction between software components. A protocol P = (R, I, F) consists of a set of
roles, R, an interplay relation, I, and a ﬁnite state automaton, F. 

P

 deﬁnes a set of roles:

R

=

{

,

R1 R2

,

,

… Rr

}

P

Each component that is 

-compliant plays one or more roles. A typical example of
roles are the client and server roles in a client–server protocol, where components can play
either the client’s role, the server’s role, or both depending on the speciﬁc responsibility
assigned to the components. In general, the number of roles deﬁned by a protocol is small.
A protocol also deﬁnes an interplay relation that speciﬁes the interaction compatibili-

ties allowed by protocol 
{

I

i

P

,
I1 I2

. The interplay relation is deﬁned by a set:
,
≤ ≤

,⊆

,≠
∅ 1

k

} where Ik R Ik
,
… Ii
,
r r,{
{ }
}
}
=
I1
I

=

{

=
r{ }

=

R

, then 

Moreover, if 

. In words, it is always assumed
 are compatible in the
for a one-role protocol that all the software components obeying 
sense  that  they  are  able  to  interact  under 
.  Referring  to  the  previous  example,
 speciﬁes that the protocol allows for the interaction between ob-
I
jects that play a server’s role and objects that play a client’s role. To specify that the proto-

server,client

P

P

=

}

}

{

{

338

Gluons and the Cooperation between Software Components

col  also  allows  for  the  interaction  between  objects  that  play  the  role  of  servers,  the
interplay relation should be speciﬁed as:

{

{

I

=

server client

,

}

,

{

server server′

,

}

}

(

)

Oi

=
 of its interplay relation deﬁnes a domain of interaction compatibility 

 together with an element (i.e. a set of roles) 

Ik

P

roles Oi

Each object of the environment 

 denote a function that returns the set of all roles component 
,
xs
=

 eventually conforms to roles of one or many proto-
 con-
cols. Let 
Oi
,
… xt
}
forms to. A protocol 
,
x R∈
)
(
,
.
P Ik
Domains of interaction compatibility play an important role in our framework since they
deﬁne which are the components that can potentially interact. The compatibility deﬁned
by a domain of interaction extends not only to the components that exist at the time the
protocol is deﬁned and implemented, but also to all future components that obey the same
protocol and are compatible through an interplay relation.

{
D

Finally, each protocol is associated with a ﬁnite state automaton that speciﬁes valid se-
quences of interactions between participants in the protocol. (See chapter 4 for a formal
treatment of two-party protocols based on ﬁnite state processes.) In the following section
we will see examples of how the state of a protocol can be speciﬁed, and how it controls
the interactions between components.

12.4 Gluons

Gluons encapsulate and implement interaction protocols by instantiating an interplay re-
lation for a given protocol. The principle idea underlying gluons is to standardize and en-
capsulate  protocols,  rather  than  just  standardizing  service  names,  since  interaction
protocols should represent one of the primary resources to be reused. Gluons support a
protocol-centered reuse strategy. By embedding interaction protocols inside gluons we
can use them as agents to implement many different interaction strategies. 

Applications that we developed with the ﬁnancial framework show that with this ap-

proach we can achieve the following:

• A high degree of dynamic interconnection — The reuse of interaction protocols pro-
vides signiﬁcantly more ﬂexibility to express interaction patterns than the reuse of a
naming convention. In particular, we typically need a small set of interaction proto-
cols to express interactions that would require a large quantity of standard service
names to achieve the same result. For example, all interactions between two software
components that involve a service request followed by an agreement on the data
types to be exchanged, and ending with a notiﬁcation of both components about the
result of the operation, can be expressed with just one protocol. Service name stand-
ardization  would  require  standard  names  for  each  possible  service  request,  and
would probably ask for additional code to build the sequence of messages needed to
perform the interaction. This point will be better illustrated later with examples of
gluons from the ﬁnancial framework.

Gluons

339

• Easy integration of new software components into an environment — This stems
from the fact that the unique interoperability constraint is that the new component re-
uses existing interaction protocols that can be instantiated through gluons.

12.4.1 Gluons and Software Design

We already mentioned that in a protocol-centered framework the primary reuse resource
is the protocol. The adoption of a protocol-centered approach has a signiﬁcant impact in
software design. While methods such as CRC [5] promote an iterative design procedure
that emphasizes identiﬁcation of the responsibilities and collaboration for each compo-
nent, in a protocol-centered framework the design team attempts to identify the typical in-
teraction protocols for the speciﬁc environment prior to any other design decisions. Once
the choice of the basic interaction protocols has been made, we then proceed with the iden-
tiﬁcation of the components’ responsibilities and the collaborations needed to fulﬁl such
responsibilities.

At ﬁrst, we seem to be adding just another layer (i.e. the deﬁnition of the reusable inter-
action protocols) to the design process. However, experience shows that, at least in the
case of the ﬁnancial framework, the addition of such a layer simpliﬁes signiﬁcantly the
whole design process provided the reusable protocols are properly deﬁned. Our ﬁrst de-
sign deﬁned only eight protocols that allowed us to express most of the interactions in a
simple system. The reusable interaction protocols represent the “glue” that allow for the
connection of software components.

12.4.2 Anatomy of a Gluon

In terms of its internal structure, a gluon is a software component that handles a ﬁnite state
automaton with output to control the execution of a protocol’s interplay relation. It con-
tains a start state and any number of intermediate states. A gluon can provide many end
states (i.e. accepting states in ﬁnite automation parlance) but for simplicity it is better to
have a unique end state. Figure 12.9 shows the symbols that can appear in a gluon’s ﬁnite
state automaton. States and state transitions are the common constituents that can be
found in any ﬁnite state automaton [8]. A participant’s role stores a reference to a software
component that is compatible with the role deﬁned by the interplay relation, while a mes-
sage selector container stores an arbitrary message selector.

A state transition triggers the execution of an action which is composed of operations.

A state transition is ﬁred whenever the gluon receives a message.

There are three types of operations that compose an action: messages sends, object as-
signments and message selector assignments. A message send is what its name implies:
the gluon sends a message to a software component requesting a service. Object assign-
ments allows a gluon to keep a reference to software components. Message selector as-
signments are similar to object assignment operations, the difference lies in the fact that

340

Gluons and the Cooperation between Software Components

State

Start

State transition

Participant role

0

Server

Message selector

container
MessSel

Figure 12.9   Symbols for the gluon’s ﬁnite state automaton.

2

0

Start

End

Server
MessSel

1

Figure 12.10  The SimpleGluon ﬁnite state automaton. SimpleGluons forward 
messages to an attached software component called the Server.

the gluon keeps a reference to a message selector instead of a reference to a software com-
ponent. These are the only allowable operations in a gluon’s action. Furthermore, the only
assignments allowed are those that involve either a participant’s role or a message selector
container in the left side of the assignment.

Figure 12.10 shows the ﬁnite automaton embedded inside the simplest gluon provided
by the ﬁnancial framework. The SimpleGluon contains two states, Start and End, and three
transitions. The diagram also shows a participant, the Server and a message selector Mess-
Sel that can store an arbitrary message selector. State transition triggers and the actions as-
sociated with state transitions are shown in table 12.2.

The SimpleGluon handles an asymmetric interaction protocol between a server and a
client. The protocol handles message forwarding. The asymmetry stems from the fact that
a gluon is associated with a unique server component while the client can be any compo-
nent that can send a message to the gluon. The association between the server and the
gluon is requested by the server component by sending message registerServer to the gluon
(refer to table 12.2). This message triggers state transition 0 which initiates the gluon’s
protocol. Any component can now send messages to the gluon and these messages are for-
warded to the server with transition 1. Finally, the gluon can be disconnected from the
server by sending it the message exit. SimpleGluons are used in the ﬁnancial framework

Gluons and the Financial Framework

341

Protocol transitions

State

Transition

State

Event / action

Start

Start

0

1

2

Start

Start

End

Source: registerServer{server}

Server := server

<any_obj>: <message>

MessSel := <message>
<message> →Server
<any_obj>: exit
gluonDisconnecting{self} → Server
Server := none

Table 12.2   Protocol transition table for the SimpleGluon.

for two main purposes. The ﬁrst purpose is to isolate services from service providers. By
assigning different components to the server’s role, the clients can be granted services
from different components. The SimpleGluon plays here the role of a proxy. The second
typical usage of SimpleGluons requires a slightly modiﬁed gluon with multicasting capa-
bilities. The modiﬁed version accepts the registration of multiple servers so that the mes-
sages sent by the clients are forwarded to all the servers.

12.5 Gluons and the Financial Framework

Gluons are the architectural elements of the ﬁnancial framework that are responsible for
the way in which other components are composed. The ﬁnancial framework offers other
components as well. One such component, the RealTimeRecord acts as a container for
real-time information. This component plays a central role in the distribution of real-time
information. The RealTimeRecord plays usually the role of a server to clients request up-
date notiﬁcations. The structure of RealTimeRecords is illustrated in ﬁgure 12.11. Each
entry of the record is a pair (key, obj_ref), where the key allows for the lookup of an object
by name.

Most of the components in an application act as data sinks, data sources or both. They
are connected through notiﬁcations chains so that updates are readily broadcast down the
chain. Pure data sources are those components that are either connected to external data
source such as those provided by Reuters, or are associated to ﬁles providing streams of
data. Components that act both as data sinks and data sources are data transformers. They
usually get information from data sources, transform it and redistribute it to client compo-
nents. Pure sink components usually correspond either to display components or to com-

342

Gluons and the Cooperation between Software Components

DataFeed

1

(IBM)
(DEC)
(HP)
(NeXT)
(SUN)
(SG)
(Options)
(Futures)
(Forex)

2

(price) 234.34
(price) 234.34
(volat) 24.34
(price) 234.34
(volat) 24.34
(high) 235.20
(price) 234.34
(volat) 24.34
(high) 235.20
(low) 230,30
(price) 234.34
(volat) 24.34
(high) 235.20
(low) 230,30
(date) 12 jul
(price) 234.34
(volat) 24.34
(high) 235.20
(low) 230,30
(date) 12 jul
(moves) 123
(volat) 24.34
(high) 235.20
(low) 230,30
(date) 12 jul
(moves) 123
(news) LRTS
(high) 235.20
(low) 230,30
(date) 12 jul
(moves) 123
(news) LRTS
(yearhg) 235.7
(low) 230,30
(date) 12 jul
(moves) 123
(news) LRTS
(yearhg) 235.7
(yearlo) 200.1
(date) 12 jul
(moves) 123
(news) LRTS
(yearhg) 235.7
(yearlo) 200.1
(moves) 123
(news) LRTS
(yearhg) 235.7
(yearlo) 200.1
(news) LRTS
(yearhg) 235.7
(yearlo) 200.1
(yearhg) 235.7
(yearlo) 200.1
(yearlo) 200.1

(SBC)
(SBC)
(UBS)
(SBC)
(UBS)
(CS1800)
(UBS)
(CS1800)
(CS1900)
(CS1800)
(CS1900)
(CS2000)
(CS1900)
(CS2000)
(NESTL)
(CS2000)
(NESTL)
(NESTL)

3

(ATL)
(SWI)
(FRF)
(CHF)
(DEM)
(LSTR)

(ATL)
(SWI)
(FRF)
(CHF)
(DEM)
(LSTR)

(ATL)
(SWI)
(FRF)
(CHF)
(DEM)
(LSTR)

Figure 12.11  Structure of the RealTimeRecord component. The data is contained in 

dictionaries. Dictionary 1, for instance, contains references to all the 
information updated in real time by a data source. The other dictionaries 
contain either values (2) or references to other objects (3).

ponents that write to ﬁles. So an application can be seen as a set of components connected
by a notiﬁcation web. 

The rest of this section illustrates the ﬁnancial framework by providing two examples
of gluons that play an essential role in the framework: the dragging gluon and the real-time
data notiﬁcation gluon.

12.5.1 The Dragging Gluon

The dragging gluon implements the common dragging mechanism we are acquainted
with from most windowing systems (see ﬁgure 12.12). A drag operation is an operation in-
itiated by a component, the dragging source, that attempts to ﬁnd a partner component to
cooperate with. The choice of the partner, the destination component, is performed by the
user with the visual assistance of the windowing system. Both the dragging source and the
dragging destination need to be associated with a visual representation since dragging is a
visual operation. Figure 12.13 illustrates the ﬁnite state automaton associated with the
dragging gluon, while table 12.3 shows the events that ﬁre each state transition and the as-
sociated actions.

To simplify the understanding of how the dragging gluon works it is useful to consult
simultaneously ﬁgure 12.13, which shows the state transitions, and table 12.3, which ex-
hibits the events that trigger a state transition together with the actions executed during the
transition. The three boxes in the lower left corner of ﬁgure 12.13 represent the roles of the
components that participate in the dragging process.

Gluons and the Financial Framework

343

Gluons

Figure 12.12  User interfaces of some software components available. The gluons that 

allow for the connection of the components are indicated by arrows. To 
connect the components the user drags the circle from one gluon to another.

The server is the component that initiates the interaction by sending the message start-
Dragging to the gluon with its object identiﬁer as parameter (see table 12.3, transition 0).
Upon receipt of this message the gluon enters state Start followed by the execution of an
action that makes the gluon send the message startDragging to the component that plays the
WindowManager role, and assigns object identiﬁers to the destination and the source
roles. The destination is assigned the void object identiﬁer since at this stage the object that
will play the destination role is not yet determined. The WindowManager responds to the
ﬁrst the message by sending back to the gluon the dragCandidateEntered message. The re-
ception of this message triggers state transition 1 on the gluon. The candidate object iden-
tiﬁer that is sent as parameter corresponds to the source component since at the beginning
of the drag operation the mouse is over the visual representation of that component. Con-
sequently, the ﬁrst component that is assigned the destination role is always the same com-
ponent as the one that plays the source role. Later, the assignment will change as the user
drags the mouse out of the source visual representation to enter another visual representa-
tion (i.e. icon) that is associated to a software component that accepts dragging. In the
process of ﬁnding the appropriate destination component, the user may move the mouse
in and out of visual representations that accept dragging. This process corresponds to al-
ternations between state IN and state OUT.

If the user releases the mouse button when the gluon is in state OUT, then the dragging
operation stops with no side effects since the mouse has been released outside a visual rep-
resentation that accepts dragging. Conversely, if the mouse is released when the gluon is

344

Gluons and the Cooperation between Software Components

2

End

IN

8

9

OUT

10

5

6

7

PRE

3

OPER

4

POST

1

Start

0

Source
Destination
WindowManager

Figure 12.13 Finite automata for the dragging protocol. The ellipses represent the states while 

the the arrows represent state transitions. The three boxes at the lower left 
corner represent the roles of the components that participate in the interaction.

in the IN state, the gluon undergoes state transition 2 which puts the gluon in state PRE.
This state corresponds to a pre-operation that is usually a negotiation between the source
and destination components to agree on an operation to be performed. If both agree, the
gluon transits to state OPER, which corresponds to execution of the agreed operation be-
tween the source and the destination. If no agreement is reached, then the dragging oper-
ation will end through transition 5. State POST allows for post-operation cleanup before
the interaction ends.

We may notice that state IN and state OUT correspond to the visual process of establish-
ing a relationship between two software components: the source and the destination. Like-
wise, states PRE, OPER and POST manage the negotiation and execution of an operation
between two components.

The dragging gluon illustrates the generality and usefulness of an interaction protocol
speciﬁed as a ﬁnite state automaton. Such generic protocols are intended to be reﬁned.
Typically, when the source component negotiates an operation with the destination com-
ponent, they agree on another gluon to which both are compatible. This gluon manages the
execution of an operation, or in other terms it mediates the delivery of a service. In the im-
plementation of a visual workbench for the retrieval of real-time ﬁnancial information,
called ReutersLab [25], which has been implemented with the ﬁnancial framework we ex-
tensively use the dragging protocol together with another protocol that negotiates the type

Gluons and the Financial Framework

345

Protocol transitions

State Transition State

Event / action

0

1

2

3

4

5

6

7

8

9

Start

In

Pre

Oper

Post

End

End

End

Out

In

Start

In

Pre

Oper

Pre

Oper

Post

In

Out

Out

10

End

Source: startDragging{Source}
startDragging{source} → WindowManager
Source := source
Destination := none

WindowManager: dragCandidateEntered{candidate}

Destination := candidate
dragEnter{Source} → Destination
WindowManager: endDragging
preOperation{Source} → Destination
Destination: ACK{destination} | Source: ACK{source}
operation{source} → Destination
Destination: ACK{destination} | Source: ACK{source}
postOperation{Source} → Destination
Destination: NACK{destination}
slideDragViewBack → WindowManager
Destination: NACK{destination}
slideDragViewBack → WindowManager
Destination: ACK{destination}
operationComplete{Destination} → Source
WindowManager:dragCandidateExit{candidate}
dragExited → Destination
Destination := none

WindowManager: dragCandidateEntered{candidate}

Destination := candidate
dragEnter{Source} → Destination
WindowManager: endDragging
dragAborted → Source
slideDragViewBack → WindowManager
Source := none

Table 12.3   Dragging gluon protocol transition table.

346

Gluons and the Cooperation between Software Components

of data to be exchanged between the source and destination components. Once the com-
ponents agree on a data type, they interact under the control of another type of gluon that
establishes a real-time update notiﬁcation between the components. The real-time notiﬁ-
cation gluon is discussed next.

12.5.2 Real-time Data Notiﬁcation Gluon

Since the ﬁnancial framework is intended to support the access to information sources that
are updated in real time, the framework provides a gluon that supports notiﬁcation be-
tween data sources and client components so that after data updates on the source side the
client can be updated to reﬂect the information change. In a typical situation the client
component registers with the source to request update notiﬁcation. The request creates a
link between the source and the client.

In order to provide for ﬂexible notiﬁcation, the framework allows for three types of no-
tiﬁcation links — cold, warm and hot — which correspond to the three type of links pro-
vided by Microsoft DDE depicted in ﬁgure 12.3. The reason for providing three types of
notiﬁcation links stems from the fact that different components have different data update
requirements. For example, a client software component that handles a visual display of
real-time data usually needs to be updated as soon as the information changes on the
source side since the user is expecting the fastest update possible. These requirements cor-
respond to a hot link between the client and the source. Other components expect change
notiﬁcations but they only need actually to update the values in a few cases. These corre-
spond to the typical requirements for a warm link where the source is in charge of notify-
ing the client while the client is responsible for eventually issuing an update request to the
source. The least demanding kind of link is the cold link in which the client is responsible
for requesting updates to the source at its own pace with no notiﬁcation from the source.
A typical usage of cold links is portfolio evaluations that require access to market data
only when the portfolio is evaluated with no need for further updates.

Figure 12.14 represents the ﬁnite automaton embedded in a real-time data notiﬁcation
gluon. The protocol deﬁnes three roles: the source, the client and the data. The role of the
source and client components has been discussed above, while the component that as-
sumes the data role acts as an information container that is exchanged between the source
and the client. The states COLD, HOT and WARM, correspond to three types of links avail-
able. When the link is established between the source and the client, the gluon enters the
COLD state and waits for a message from the client requesting an update. Upon reception
of the client’s request the gluon enters state CUP in which it waits until an update message
issued by the source puts the gluon back in state COLD through transition 3. A gluon can
be requested to switch from one type of link to another provided it is in any one of the three
states, COLD, HOT or WARM, so that the update mechanism can be changed at any point in
time to adapt to evolving requirements on the client’s side. We may notice that state WARM
has a self-looping state transition (i.e. number 11), which is ﬁred when the source notiﬁes
the client for an update, and two transitions (i.e. transitions 9 and 10) with an intermediary

Conclusion

347

0

Start

1

6

9

10

Source

Client

Data

WUP

CUP

3

2

COLD

4

5

HOT

7

8

WARM

11

14

15

16

13

End

12

Figure 12.14   Finite automata for a real-time data notiﬁcation protocol.

state WUP which handles the update request from the client component. As expected, the
actions associated with transitions 9 and 10 are similar to actions associated with transi-
tions 2 and 3 since they perform the same task.

12.6 Conclusion

We have addressed in this chapter the problem of deﬁning patterns of interaction among
software components. We adopt the point of view of component-oriented software design
and development which promotes an approach to software construction based on the con-
nection of software components. 

We provide a survey of previous efforts that address similar problems. The focus is on
work from large software houses since they represent signiﬁcant efforts to standardize and
promote approaches that may have a considerable impact, in the near future, on software
design and development. The survey suggest that the sizeable differences that can be ob-
served between such approaches reﬂect differences in design goals and differences in the
requirements of the target environments.

Our development framework targets ﬁnancial applications that retrieve real-time data
and  require  support  that  allows  for  fast  reconﬁguration  of  the  patterns  of  interaction

348

Gluons and the Cooperation between Software Components

among the software components as well as mechanisms that facilitate the introduction of
new software components. These requirements can be equated to support for dynamic in-
terconnection of software components. Unfortunately none of the approaches surveyed
achieves the desired level of dynamic interconnection capabilities.

We propose a new approach which focuses on the reuse of component interaction pro-
tocols. We call a framework based on such principle a protocol-centered framework. Our
experience with a ﬁnancial framework shows that we can achieve a fairly high degree of
dynamic interconnection with a small number of reusable protocols (typically less than
twenty). However, the applications that we developed have a scope that is too narrow to
allow us to infer that the approach is of wide applicability.

References

[1] Apple Computer Inc., Inside Macintosh: Interapplication Communication, 1993.
[2] Constantin Arapis, “Specifying Object Interactions,” in Object Composition, ed. D. Tsichritzis, Cen-

tre Universitaire d'Informatique, June 1991.

[3] Constantin Arapis, “Dynamic Evolution of Object Behavior and Object Cooperation,” Ph.D. thesis

no. 2529, Centre Universitaire d'Informatique, University of Geneva, Switzerland,1992.

[4] Nabajyoti Barkakati, Peter D. Hipson, Visual C++ Developer's Guide, Sams, Carmel, 1993.
[5] Kent Beck and Ward Cunningham, “A Laboratory for Teaching Object-Oriented Thinking,” Proceed-

ings of OOPSLA ’89, ACM SIGPLAN Notices, vol. 24, no. 10, Oct. 1989, pp. 1–6.
Ted J. Biggerstaff and Alan J. Perlis, Software Reusability, Volume I, Concepts and Models, Frontier
Series, ACM Press, 1989.

[6]

[7] Kraig Brockschmidt, Inside OLE 2 : The Fast Track to Buiding Powerful Object-Oriented Applica-

tions, Microsoft Press, Redmond, Wash., 1993.

[8] Daniel I. A. Cohen, Introduction to Computer Theory, John Wiley, 1986.
[9]

L. Peter Deutsch, “Design Reuse and Frameworks in the Smalltalk-80 System,” in Software Reusabil-
ity, ed. T.J. Biggerstaff and A.J. Perlis, ACM Press, 1989, pp. 57–71.

[10] Erich Gamma, Andre Weinand and Rudolf Marty, “Integration of a Programming Environment into
ET++,” Proceedings of ECOOP ’89, British Computer Society Workshop Series, Cambridge Univer-
sity Press, Cambridge, 1989.

[11] Simon Gibbs, Dennis Tsichritzis, Eduardo Casais, Oscar Nierstrasz and Xavier Pintado, “Class Man-
agement for Software Communities,” Communications of the ACM, vol. 33, no. 9, Sept. 1990, pp. 90–
103.

[12] Richard Helm, Ian Holland and Dipayan Gangopadhyay, “Contracts: Specifying Behavioral Compo-
sitions in Object-Oriented Systems,” ACM SIGPLAN Notices, vol. 25, no. 10, Oct. 1990, pp.169–180.
[13] Dan Ingalls, “Fabrik: A Visual Programming Environment,” Proceedings of OOPSLA '88, ACM SIG-

PLAN Notices, vol. 23, no. 11, Nov. 1988, pp. 176–190.

[14] Ralph E. Johnson and Brian Foote, “Designing Reusable Classes,” Journal of Object-Oriented Pro-

gramming, vol. 1, no. 2, 1988, pp. 22–35.

[15] Chris Laffra, “Procol, a Concurrent Object Language with Protocols, Delegation, Persistence, and

Constraints,” Ph.D. Thesis, Amsterdam, 1992.

[16] Michael Mahoney, “Interface Builder and Object-Oriented Design in the NeXTstep Environment,”

Tutorial Notes of CHI ’91, available through anonymous ftp at nova.cc.purdue.edu.

References

349

[17] Microsoft Press, OLE 2 Programmer’s Reference: Working with Windows Objects, Vol. 1, Redmond,

Wash., 1994.

[18] Microsoft Press, OLE 2 Programmer’s Reference: Creating Programmable Applications with Ole Au-

tomation, Vol. 2, Redmond, Wash., 1994.

[19] NeXT Computer Inc., NextStep Concepts Manual, 1990.
[20] Oscar Nierstrasz, Dennis Tsichritzis, Vicki de Mey and Marc Stadelmann, “Objects + Scripts = Ap-
plications,”  in  Object  Composition,  ed.  D.  Tsichritzis,  Centre  Universitaire  d'Informatique,  June
1991, pp. 11–30.

[21] Object Management Group, Common Object Request Broker: Architecture and Speciﬁcation, 1991.
[22] Object Management Group, Object Management Architecture Guide, 1992.
[23] Object Management Group (OMG), The Common Object Request Broker: Architecture and Speciﬁ-

cation, Object Management Group and X Open, OMG document 91.12.1, revision 1.1, 1992.

[24] Xavier Pintado, Dennis Tsichritzis, “Gluons: Connecting Software Components,” in Object Compo-

sition, ed. D. Tsichritzis, Centre Universitaire d'Informatique, 1991, pp. 73–84.

[25] Xavier Pintado, Betty Junod, “Gluons: A Support for Software Component Cooperation,” in Object

Frameworks, ed. D. Tsichritzis, Centre Universitaire d'Informatique, 1992, pp. 311–330.

[26] Xavier  Pintado,  “Gluons:  a  Support  for  Software  Component  Cooperation,”  in  Proceedings  of
ISOTAS ’93, International Symposium on Object Technologies for Advanced Software, ed. S. Nishio
and A. Yonezawa, Kanazawa, Japan, November 1993, Springer-Verlag, pp. 43–54.

[27] Xavier Pintado, “Fuzzy Relationships and Afﬁnity Links,” in Object Composition, ed. D. Tsichritzis,

Centre Universitaire d'Informatique, 1991.

[28] Rajendra Raj, Henry Levy, “A Compositional Model for Software Reuse,” Proceedings of ECOOP
’89, British Computer Society Workshop Series, Cambridge University Press, Cambridge, 1989, pp.
3–24.

[29] Jeffrey S. Rosenschein and Gilad Zlotkin, Rules of encounter : Designing Conventions for Automated

Negotiation Among Computers, MIT Press, Cambridge, Mass., 1994.

[30] Al Williams, OLE 2.0 and DDE Distilled : A Programmer’s Crash Course, Addison-Wesley, Reading,

Mass., 1994. 

350

Index

ABCL/1 35, 38–42, 52
ABCL/AP100 59
ABCL/R 40, 41, 43
Abramsky, Samson 170
abstract class 48

abstract superclass 224

abstract state 60, 110, 111, 120
abstraction 13, 191
ACT++ 34, 36, 41, 42, 57, 120
ACTALK 41, 43
activated type 316
activation condition 42
active object 18, 43, 102, 191
ActiveCube component 296
activity composition 296
actor-based languages 43
ActorSpace 37, 38
Ada 34, 35, 41, 42
adaption function 88
administrator 45, 49, 51–54, 61
affinity 186

browser xiv, 249, 256

example 263

engine 261
neighbourhood 258

agents 9, 11
aggregation 185
Aït-Kaci, Hassan 158, 175
α substitution 158
α-Trellis 254
Andrew 282, 312
Apple 281, 334–335, 338, 339

ATG Component Construction Kit 

280, 281

application development 21, 184
application engineer 184
application frame 184

see also GAF, SAF

application programming interface 311
approximation ordering 171
Arcadia 74
Argus 34, 78
association 187
asynchronous

communication 135
interface 315

asynchronous interface 315
atomicity 32
attribute redefinition 207
attribution 184
AVANCE 219, 221

backtracking 256
backward scope restriction 243
Basic 332
Basic Object Adaptor 329
BEAD 254
become primitive 36
BEE++ 253
behaviour 19, 280, 282
BENTO 336
Bergmans, Lodewijk 59
Beta 57, 59
bind reduction 160
blackboard 10, 11
Bloom, Bard 172
BOA 329
Böcker, Hans-Dieter 253

352

Index

Booch, Grady 125
bottom element 170
Boudol, Gérard 170, 172, 174
bounded buffer 110, 111
Brinksma, Ed 101, 102, 109
broadcast primitive 37
browser

message-set 253
see also affinity browser
see also Smalltalk browser

browsing 182, 186, 187, 251

semantics 254
spatial 254
tool 251

Brüegge, Bernd 253
built-in proxy 52, 63
Bull, S.A. xiii

C 15, 76
C++ xiv, 15, 47, 72, 76, 81, 94, 169, 183, 
191, 192, 201, 220, 223, 229, 280, 
292, 329, 331

CAD/CAM 221
CAML-Light 15
category 253
CBox 38, 52
CCS 19, 102
Ceiffel 56
Cell 77, 84

framework 73, 76, 93
change avoidance 207, 234
channels 102
CHOCS 19
Church encoding of Booleans 156
Church, Alonzo ix
class

evolution 206, 220
refactoring 225
relationship 263
renaming 207, 214, 235
reorganization 222–234
surgery 206
tailoring 206, 207, 234

evaluation 209

versioning 206

classification 185
CLOS 13, 229, 238, 239
close reduction 160
CLU 34
cobegin 35
Colibri 198, 200, 201
COM 331
combination and alternation 173
Common Object Request Broker 
Architecture, see CORBA

communicating processes 127
comp.object newsgroup 7
compatibility 11, 18, 155, 169, 209

class 341
ordering 171

component 18, 20, 313

class 314
classification 181–204
constraints universalization 151
definition 301
engineer xii, 23, 279, 280
engineering 20–23
framework 4, 22, 281
initialization 317
inspector 281
instantiation 317
interface 315
management 291
network 316–317
palette 281
synchronisation 317
visual composition 284

Component Object Model 331
component-oriented
development 4
lifecycle 14

composition

activity 296
dataflow 287, 296
framework 279
functional 10

Index

353

higher-order 10
media 311
model 279, 280, 286

manager 293
procedural 311
run-time 325
semantic 311
spatial 311
temporal 296, 311
Unix composition model 291
visual, see visual composition

compression scheme 311
concurrency 5, 8, 9, 14, 18, 25, 31–69, 

102, 117, 121

see also internal concurrency

Concurrent C 42
concurrent object 35
concurrent rewriting 56
ConcurrentSmalltalk 38, 52
condition variable 60
conformance 101, 102, 109, 110, 222
congestion 316
ConMan 280, 281
connection 279, 284, 286, 290, 294, 299, 

316–320

dynamic 340, 343

connector 315, 316
consumer 315
container 110, 332
contracts 16, 17, 102, 303, 341
conversion 207
CooL 81, 84, 87–89, 191, 198, 200
CORBA 74–78, 94, 329, 336
correspondence 185

property 146

CSP 38, 40, 109
Curry type scheme 17
Curry-Howard isomorphism 174
currying 156, 165
Cusack, Elspeth 109

database service 311
dataflow 280, 287, 316

analysis 215
composition 287, 296

Datamont, S.p.A. xiii
DDE 329, 350
de Bruijn

calculus 160
indices 155, 157, 158
de Bruijn, N. 158, 161, 164
deadlock 104, 118
decision support systems 338
delegated call 54
delegation 11, 38, 39
denotational semantics 17
dependency 191
dependent type 120
derivation graph 219
derived classification 196
design by contract 303
see also contracts
design description 183
destination pattern 37
detach primitive 35
Dezani-Ciancaglini, Mariangiola 19
direct manipulation 289
distinct name invariant 211
distinct origin invariant 211
Distributed Objects 281
divergence 170
domain knowledge 23
dragging gluon 346
see also gluons
DRAGOON 56–60
dynamic analysis 270
Dynamic Data Exchange 329
dynamic interconnection 340, 343
dynamic linking 13

Eiffel 16, 47, 182, 205, 207, 331

Ceiffel 56
library 231, 233

Eiffel // 34, 38, 41, 42, 56
Emerald 34, 41, 54
enabled set 34

354

Index

encapsulation 8, 182, 205, 229, 251, 301, 

first class representation of requests and 

312, 337

and concurrency 9
blackboard 11
violation of 8, 47

ENCORE 242
Engberg, Uffe 19
equivalent type 80
erroneous term 171
ESPRIT ix, xiii, 81, 181, 182
event distribution mechanism 262
event-handling 317
evolution

class 206, 220
format 313
framework 24
platform 313
schema evolution taxonomy 213

expert services team 24
explicit acceptance 42
extensibility 11, 48, 156, 167, 262
extension 101, 102, 109

Fabrik 280, 281
faceted classification 190
factorization 222

algorithm 231
class refactoring 225
incremental 234

failures 108

equivalence 109

F-bounded quantification 120
features 175
filtering 240

mechanisms 241

financial framework 325
finite state

automata 110, 113, 125, 126, 342, 

344, 350

process 121, 342
protocol 110, 111
transition system 113

replies 39

Fisher, Kathleen 16
fixed-point

induction 174
operation 165

F-ORM 297
format class 313
format evolution 313
Forsythe 174
FORTH xiii
forward scope restriction 243
Foundation of Research and Technology, 

Hellas xiii

framework xi, 4, 71, 101, 205, 295, 326

Cell, see Cell framework
component, see component 

framework

design 24
evolution 24
financial 325
multimedia, see multimedia 

framework

NeXTStep AppKit 328
protocol-centered, see protocol-

centered framework

visual composition 279

Freeman, Peter 182, 190
Frølund, Svend 56, 59–61
full inheritance invariant 211
functional commonality 264
functional composition 10
functionality phase 79
future variable 38, 39, 52
fuzzy querying 251

GAF 21, 23, 184
Garrigue, Jacques 158, 175
GemStone 211, 239
generalization 185
Generic Application Frame, see GAF
genericity 46, 57, 186
GeoBall component 296

Index

355

Gingrich, P. 275
global reorganization 230
global time 138
gluons xiv, 102, 325–354
Goguen, Joseph A. 17
Gottschalk, Tim 253
Guide 36, 41, 42, 47, 56–61

Haskell 16
Hennessy, Matthew 121
Hennessy–Milner logic 121
Herczeg, Jürgen 253
heterogeneous object model 34, 49
Hewlett Packard 281
higher-order

composition xii, 10
process calculus 19

homogeneous object model 34, 49, 62
Hybrid xii, 34, 35, 40, 41, 54, 79, 81, 84, 

87–89

hypermedia systems 310
hypertext 188, 254

IAL 76, 83, 87–89
IBM 280, 281, 336

repository 182, 184

ICA 337, 338
IDL 74, 78, 329
imitation 222
implementation description 183
incremental reorganization algorithm 224
inheritance 7, 8, 13, 205, 249, 264

and synchronisation 47
anomaly 56
in Beta 57
code sharing 209
concurrency 5, 33, 46
consistency 220
dependencies 206
in DRAGOON 57
graph invariant 211
hierarchy 182, 211
interface 8, 9, 13

invariant 211
mixins 13
multiple, strict 183, 185, 193
request/reply scheduling 61
restructuring 229
reuse potential 48
strict 185
and subtyping 8, 47, 174
and synchronisation 43, 46, 47, 56, 

63

versioning 220
Windows 331

initials 108
inner mechanism 57
inspector 253
interaction

compatibility 325
pattern 252, 326
protocol 261, 325, 340, 341
Interapplication Communication 

Architecture, see ICA

interconnection, see connection
interface

adaption 78, 90
adaption language, see IAL
bridging 76
definition language, see IDL
phase 80
re-declaration 209

interference of features 32
internal concurrency 44, 46
Internet 7
inter-object 83, 85, 89–93
interoperability 71–98, 337
object-oriented 73, 75
procedure-oriented 73
specification level 74, 81
intersection type 105, 120, 174
intra-object concurrency 60
IRIS 219, 221

Explorer 280, 281

islands 11
isochronous interface 315, 316

356

Index

ITHACA ix, xiii–xv, 20, 81, 181, 182, 

184, 198, 291, 297, 305

object-oriented methodology 298
software development environment 

marked object 257
Matsuoka, Satoshi 56, 59, 60, 61
ME database system 255
media

297

software platform 292

Kafura, Dennis G. 56
KAROS 78
Kleyn, M. 253
Knos xii
Krueger, Charles W. 182

Labyrinth System 292
λ calculus 19, 156

label-selective 158

λN calculus 155–177
Lamping, John 158
Lassie 182
lattice structure 172
Law of Demeter 225, 226, 229, 303
law-governed systems 303
lazy data structure 165
Lee, Kueng Hae 56
Leroy, Xavier 16
Lieberherr, Karl 225
lifecycle 136, 202

component-oriented 14
ITHACA 184
object 136, 138, 147, 148
software 6, 202
software development 181

lifting operation 160
link 280
Liskov, Barbara 118
LISP 168
local time 138
locality 255
LOTOS 102
Luo, Bin 253

Macintosh 334
Manna, Zohar 152, 153

artefacts 309
class 313
composition 311
synchronization 311

Meseguer, José 56
message-set browser 253
meta-class 192
meta-object 43
method set 60
metrics 249

binary vector 265
reuse 24

Meyer, Bertrand 16
Microsoft 281, 329, 331, 333, 350
MIDI 317
migration 75, 80, 88
Milner, Robin 19, 102, 121
Mitchell, John C. 16
mixin 4, 8, 13, 60, 61
ML 16

ML-like type system 16
SML 16

modal process logic 121
mode switch 291
modeler component 296
module 14, 16, 71

interconnection language 17

monitor 34, 35, 41, 54
Mosses, Peter D. 17
Motro, Amihai 252
MS-Windows 331
multimedia xiv, 189
application 295
component kit 295
database 252
database system 310
framework xiv, 295, 309, 313
programming 309

multimodal interaction 311

Index

357

multi-threaded object 53
Muse 312
mutual exclusion 44, 46, 49
MVC 282
MVS 184

navigation 249
navigator component 296
nested monitor call 54
NeXT 281
NeXTStep 13

AppKit framework 328
Driver Kit 326

nib file 13
Nielsen, M. 19
NIMBLE 73, 77
Nixdorf Informationssysteme xiii
N-Land 254
non-determinism 109, 111
non-uniform service availability 101
normal-order reduction 162
Novell 336
NP-complete 231
ν calculus 19

O2 210, 211, 239
object calculus 19, 120
object invocation graph 254
Object Linking and Embedding, see OLE
Object Management Architecture 328
Object Management Group, see OMG
object mapping 78, 83, 90
object model 18
COM 331
heterogeneous 34
homogeneous, see homogeneous 

object model

OMG 328
SOM 336
temporal specification 126

Object Request Broker, see ORB
Object Systems Group xi, xii
Objective-C 169, 182, 209

object-oriented interoperability, see 

interoperability

Object-Oriented Tool Integration Services 

281

Obliq 13
observational equivalence 174
ODBC 333, 337
offers 116
ogre 170
OLE 281, 329, 331, 337–338
OMA 328
OMG 74, 76, 281, 328
Object Model 328

one-way message passing 38, 50, 53, 62
Open Database Connectivity, see ODBC
Open Scripting Architecture 335
open systems 3
OpenDoc 281, 331, 336–338
OpenStep 15
operation term 191
ORB 74, 281, 329
ORION 211, 212, 221, 243
Orwell 221
OSA 335
OSF/Motif 292
OTGen 210, 211, 238

PAL 52
parallel functions 172, 174
parallelism 32, 54
parameter phase 80
part-of relation 125, 224, 249
Pascal 16
path expressions 41, 42
PCTE+ OMS 184
performance evolution 313
Perl 15
persistence 12, 32
Petri net 127, 254
π-calculus 11, 19, 174

polyadic 102

platform evolution 313
Plotkin, Gordon 172

358

Index

plug compatibility xii, xiv, 18, 156, 279, 

316

plugs 6
PO 56–61
point-to-point navigation 253, 255
Polylith 73, 75
polymorphism 48, 102, 165, 209

bounded 120

POOL-I 47
POOL-T 34, 35, 40–42
port 280, 282, 314
posing 209
powerdomains 172
pre- and post-conditions 207
presentation

of component 280, 283
Prieto-Diaz, Ruben 182, 190
principle of substitutability 101, 102, 103
procedural composition 311
procedure-oriented interoperability, see 

interoperability

PROCOL 37, 38, 40–42, 57, 59
producer 315
propositional logic 128
propositional temporal logic, see PTL
protected method 220
protocol

client/server 19
conformance 101, 107, 340
dragging 350
errors 104
generic 350
implementation 343
initialization 102
interaction 7, 261, 325, 340, 341
non-determinism 108
protocol-centered framework 327, 

338

request/reply 38, 62
RPC 62
service provider 116
specification 110, 342

prototypes 11

proximity 254
proximity-based navigation 250, 257, 259
proxy 38, 50, 61, 63, 83
PTL 128

semantics 131
syntax 129

public component constraints

universalization 150

quasi-concurrent object 34, 54
querying 187, 251

Ranghanathan, Sarada 190
reader/writer

property 47
scheduling policy 58

real-time

data notification gluon 350
financial data 325, 337
multimedia constraint 317
multimedia scheduling 312

REBOOT 182, 190
RECAST 21, 295, 297, 302
records

encoding of 167

re-engineering 23, 186
reference consistency invariant 211
reflective computation 43
regular

expression 112
language 112
process 110
type 101, 110, 153

relationship

dynamically evolving 252
evolving 250
relative failure 109
remote delay 54
renderer component 296
reorganization

class library 205, 206
global 230
incremental algorithm 224

Index

359

reply scheduling 36, 45, 46, 51
repository

IBM 182, 184

representation invariant 211
request channel 105
request satisfiability 116
request scheduling 37, 44, 46
request substitutability 102, 108, 109

multiple state 113

requirements description 183
reuse 72, 249

metrics 24

Reuters 346
ReutersLab 350
roles 342
Rosette 34, 36
RPC 38, 39, 50–52, 55, 62, 73, 328
run-time composition 325

SAF 21, 184
Sangiorgi, Davide 19
satisfiability

algorithm 147
graph 132
of PTL 132

scalability 13
Scheduling Predicates 56
schema evolution taxonomy 213
schema invariant 210, 212
scientific visualization 304
SDMS 254
Selection Tool 187
Self 15
self 48, 61
semantic composition 311
semantic domain 103
semantics 17, 155
browsing 254
concurrency 120, 174
intersection types 106
lazy operational 170
of functions 157
PTL 131

semaphore 34, 58
SemNet 254
send primitive 37
send/receive/reply 40
separate method argument 42
sequential objects 62
service type 102
set-at-a-time navigation 255
SIB xiii, 182, 183, 291, 297
Siemens-Nixdorf xiii, 198
similarity link 186
Sina 35, 41, 55, 56, 60–61
Singh, Vineet 56
SINIX 191
SLI 74, 75, 77
Smalltalk 15, 34, 35, 40, 41, 43, 47, 48, 

57, 72, 79, 168, 169, 182, 205, 
216, 229, 252

browser 251, 252, 256
class hierarchy 233
environment 251
Smith, Scott 170, 174
SML 16
Softbench 281
software

community 182
component 5
cookbook 23
junkyard 22
lifecycle, see lifecycle
oscilloscope 253
reuse 7, 31, 32, 206

Software Information Base, see SIB
SOM 336
spatial

browsing 254
composition 311
data management system 254
referencing 254

specialization 185
Specific Application Frame, see SAF
specification level interoperability, see 

interoperability

360

Index

SPN 56
SQL 252
SR 35, 41, 42, 55
starvation 316
state predicate 42, 60, 61
static analysis 181, 270
storage 332
stream 315, 332
strongly distributed environment 79
strongly distributed object-based system 

Owl 34, 40, 41, 54

TSOM 126
type

compatibility 316

invariant 211

inference 120
matching 82
translation 81
variable invariant 211

type translation 81

76

structured programming xi
substitutability 102, 107

see also request substitutability

substitution operation 160
subtyping 8, 103, 112, 155
super 48, 57
synchronisation constraint 47
Synchronising Actions 56, 60, 61
synchronized view 257
synchronizers 42, 56
synchronous interface 315
System Object Model 336

TAO xiii
Tècnics en Automatitzaciò d’Oficines xiii
Telescript 13
Telos 184
temporal

composition 296, 311
logic 121, 125
scripting language xiii

Temporal Specification Object Model 126
Tomlinson, Chris 56
ToolTalk 281
traces 108
transaction 78
transform class 313
transformer 315
translucency 261
transposed file 235
Trellis 253

α-Trellis 254

unconditional acceptance 41
Unidraw 282
unified system of parameterization 158
Unifying Type Model 74
Universal Decimal Classification 190
universalization 138
Unix 183, 192, 193, 199, 201
composition model 291

UTM 74

verification

composite objects 147
correspondence property 151
elementary objects 146

version

compatibility 240
identification 219

video

assistant 318
on demand 310
widgets 317

Vista 291–301
visual

composition xiv, 279

framework 279
tool 279

configuration 317
formalism 304
representation 250
scripting tool xiii

Visual C++ 326
VisualAge 280, 281

361

Index

VisualBasic 7
visualisation xiv
VLSI Design 221
VST xiv, xv, 291

wait filter 60, 61
Wegner, Peter 8, 34, 47, 101–103
Wing, Jeannette 118
Wolper, Pierre 152, 153
worker 45, 49, 51, 52, 54, 61
workflow application 295
World Wide Web xv

X Windows 292

Zdonik, Stanley 47, 101–103

362

Index

